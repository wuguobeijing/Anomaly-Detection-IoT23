{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# try auto-gloun"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "from autogluon.tabular import TabularDataset\n",
    "import autogluon"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loaded data from: ./Data/split/test_data_big.csv | Columns = 31 / 31 | Rows = 857260 -> 857260\n"
     ]
    }
   ],
   "source": [
    "train_data = TabularDataset(\"./Data/split/test_data_big.csv\")\n",
    "# train_data = train_data.sample(random_state=0)\n",
    "# subsample_size = 500  # subsample subset of data for faster demo, try setting this to much larger values\n",
    "# train_data = train_data.sample(n=subsample_size,random_state=0)\n",
    "# test_data = test_data.sample(random_state=0)\n",
    "# train_data.head()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Summary of class variable: \n",
      " count        857260\n",
      "unique            2\n",
      "top       Malicious\n",
      "freq         781382\n",
      "Name: label, dtype: object\n"
     ]
    },
    {
     "data": {
      "text/plain": "Malicious    781382\nBenign        75878\nName: label, dtype: int64"
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label = 'label'\n",
    "print(\"Summary of class variable: \\n\", train_data[label].describe())\n",
    "train_data['label'].value_counts()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning: path already exists! This predictor may overwrite an existing predictor! path=\"./auto_gl/Models-predictClass\"\n",
      "Presets specified: ['best_quality']\n",
      "Beginning AutoGluon training ...\n",
      "AutoGluon will save models to \"./auto_gl/Models-predictClass/\"\n",
      "AutoGluon Version:  0.4.0\n",
      "Python Version:     3.8.13\n",
      "Operating System:   Linux\n",
      "Train Data Rows:    20000\n",
      "Train Data Columns: 30\n",
      "Label Column: category\n",
      "Preprocessing data ...\n",
      "AutoGluon infers your prediction problem is: 'binary' (because only two unique label-values observed).\n",
      "\t2 unique label values:  ['Malware', 'Benign']\n",
      "\tIf 'binary' is not the correct problem_type, please manually specify the problem_type parameter during predictor init (You may specify problem_type as one of: ['binary', 'multiclass', 'regression'])\n",
      "Selected class <--> label mapping:  class 1 = Malware, class 0 = Benign\n",
      "\tNote: For your binary classification, AutoGluon arbitrarily selected which label-value represents positive (Malware) vs negative (Benign) class.\n",
      "\tTo explicitly set the positive_class, either rename classes to 1 and 0, or specify positive_class in Predictor init.\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    4294.52 MB\n",
      "\tTrain Data (Original)  Memory Usage: 4.8 MB (0.1% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\t\t\tNote: Converting 8 features to boolean dtype as they only contain 2 unique values.\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\tUseless Original Features (Count: 4): ['missed_bytes', 'service_dhcp', 'conn_state_SH', 'conn_state_SHR']\n",
      "\t\tThese features carry no predictive signal and should be manually investigated.\n",
      "\t\tThis is typically a feature which has the same value for all rows.\n",
      "\t\tThese features do not need to be present at inference time.\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('float', []) : 26 | ['duration', 'orig_bytes', 'resp_bytes', 'orig_pkts', 'orig_ip_bytes', ...]\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('float', [])     : 18 | ['duration', 'orig_bytes', 'resp_bytes', 'orig_pkts', 'orig_ip_bytes', ...]\n",
      "\t\t('int', ['bool']) :  8 | ['service_dns', 'service_ssh', 'service_ssl', 'service_irc', 'conn_state_RSTOS0', ...]\n",
      "\t0.1s = Fit runtime\n",
      "\t26 features in original data used to generate 26 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 3.04 MB (0.1% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 0.12s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'accuracy'\n",
      "\tTo change this, specify the eval_metric parameter of Predictor()\n",
      "AutoGluon will fit 2 stack levels (L1 to L2) ...\n",
      "Fitting 13 L1 models ...\n",
      "Fitting model: KNeighborsUnif_BAG_L1 ...\n",
      "\t0.8776\t = Validation score   (accuracy)\n",
      "\t0.15s\t = Training   runtime\n",
      "\t6.48s\t = Validation runtime\n",
      "Fitting model: KNeighborsDist_BAG_L1 ...\n",
      "\t0.8775\t = Validation score   (accuracy)\n",
      "\t0.01s\t = Training   runtime\n",
      "\t5.78s\t = Validation runtime\n",
      "Fitting model: LightGBMXT_BAG_L1 ...\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "2022-05-13 23:19:46,509\tERROR import_thread.py:88 -- ImportThread: Connection closed by server.\n",
      "2022-05-13 23:19:46,636\tERROR worker.py:1230 -- listen_error_messages_raylet: Connection closed by server.\n"
     ]
    }
   ],
   "source": [
    "save_path = './auto_gl/Models-predictClass'  # specifies folder to store trained models\n",
    "from autogluon.tabular import TabularPredictor\n",
    "predictor = TabularPredictor(label=label, path=save_path).fit(train_data,ag_args_fit={'num_gpus':1},presets='best_quality')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "data": {
      "text/plain": "autogluon.core.dataset.TabularDataset"
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(train_data)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** Summary of fit() ***\n",
      "Estimated performance of each model:\n",
      "                          model  score_val  pred_time_val    fit_time  pred_time_val_marginal  fit_time_marginal  stack_level  can_infer  fit_order\n",
      "0           WeightedEnsemble_L2   0.880473     125.540038  663.134592                3.865987         338.842138            2       True          6\n",
      "1       RandomForestGini_BAG_L1   0.880381      59.867095  184.887903               59.867095         184.887903            1       True          3\n",
      "2       RandomForestEntr_BAG_L1   0.880335      61.810953  183.408793               61.810953         183.408793            1       True          4\n",
      "3               LightGBM_BAG_L1   0.880018       2.198431   70.528784                2.198431          70.528784            1      False          2\n",
      "4         ExtraTreesGini_BAG_L1   0.866051      61.806957  139.404551               61.806957         139.404551            1       True          5\n",
      "5             LightGBMXT_BAG_L1   0.850435       1.336821   55.193047                1.336821          55.193047            1      False          1\n",
      "6  RandomForestGini_BAG_L1_FULL        NaN      59.867095  184.887903               59.867095         184.887903            1       True          7\n",
      "7    ExtraTreesGini_BAG_L1_FULL        NaN      61.806957  139.404551               61.806957         139.404551            1       True          9\n",
      "8  RandomForestEntr_BAG_L1_FULL        NaN      61.810953  183.408793               61.810953         183.408793            1       True          8\n",
      "9      WeightedEnsemble_L2_FULL        NaN            NaN  663.134592                     NaN         338.842138            2       True         10\n",
      "Number of models trained: 10\n",
      "Types of models trained:\n",
      "{'StackerEnsembleModel_XT', 'StackerEnsembleModel_RF', 'WeightedEnsembleModel', 'StackerEnsembleModel_LGB'}\n",
      "Bagging used: True  (with 8 folds)\n",
      "Multi-layer stack-ensembling used: False \n",
      "Feature Metadata (Processed):\n",
      "(raw dtype, special dtypes):\n",
      "('float', [])     : 29 | ['duration', 'orig_bytes', 'resp_bytes', 'missed_bytes', 'orig_pkts', ...]\n",
      "('int', ['bool']) :  1 | ['service_irc']\n",
      "*** End of fit() summary ***\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/media/wuguo-buaa/LENOVO_USB_HDD/PycharmProjects/Machine_learning_venv/lib/python3.8/site-packages/autogluon/core/utils/plots.py:138: UserWarning: AutoGluon summary plots cannot be created because bokeh is not installed. To see plots, please do: \"pip install bokeh==2.0.1\"\n",
      "  warnings.warn('AutoGluon summary plots cannot be created because bokeh is not installed. To see plots, please do: \"pip install bokeh==2.0.1\"')\n"
     ]
    }
   ],
   "source": [
    "import bokeh\n",
    "results = predictor.fit_summary(show_plot=True)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AutoGluon infers problem type is:  binary\n",
      "AutoGluon identified the following types of features:\n",
      "('float', [])     :  7 | ['duration', 'missed_bytes', 'orig_pkts', 'orig_ip_bytes', 'resp_pkts', ...]\n",
      "('int', [])       :  2 | ['orig_bytes', 'resp_bytes']\n",
      "('int', ['bool']) : 21 | ['proto_tcp', 'proto_udp', 'service_-', 'service_dhcp', 'service_dns', ...]\n"
     ]
    }
   ],
   "source": [
    "print(\"AutoGluon infers problem type is: \", predictor.problem_type)\n",
    "print(\"AutoGluon identified the following types of features:\")\n",
    "print(predictor.feature_metadata)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loaded data from: ./Data/split/test_data.csv | Columns = 31 / 31 | Rows = 30287 -> 30287\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                  model  score_test  score_val  pred_time_test  pred_time_val   fit_time  pred_time_test_marginal  pred_time_val_marginal  fit_time_marginal  stack_level  can_infer  fit_order\n",
      "0         LightGBMLarge    1.000000     1.0000        0.004927       0.006740   0.188401                 0.004927                0.006740           0.188401            1       True         13\n",
      "1            LightGBMXT    1.000000     1.0000        0.012682       0.045708   5.978460                 0.012682                0.045708           5.978460            1       True          3\n",
      "2   WeightedEnsemble_L2    1.000000     1.0000        0.014530       0.048954   6.714831                 0.001848                0.003246           0.736371            2       True         14\n",
      "3              CatBoost    1.000000     1.0000        0.034284       0.034029   5.231436                 0.034284                0.034029           5.231436            1       True          7\n",
      "4              LightGBM    1.000000     1.0000        0.045332       0.060652   0.184128                 0.045332                0.060652           0.184128            1       True          4\n",
      "5               XGBoost    0.867435     0.8792        0.037753       0.021373   3.275636                 0.037753                0.021373           3.275636            1       True         11\n",
      "6        NeuralNetTorch    0.867402     0.8792        0.127484       0.017372  41.659184                 0.127484                0.017372          41.659184            1       True         12\n",
      "7        ExtraTreesGini    0.857860     0.8672        0.291325       0.058187   2.867509                 0.291325                0.058187           2.867509            1       True          8\n",
      "8        ExtraTreesEntr    0.857728     0.8680        0.347332       0.056820   2.914552                 0.347332                0.056820           2.914552            1       True          9\n",
      "9      RandomForestGini    0.857299     0.8648        0.181877       0.055672   4.158240                 0.181877                0.055672           4.158240            1       True          5\n",
      "10     RandomForestEntr    0.857265     0.8648        0.186229       0.060088   3.895449                 0.186229                0.060088           3.895449            1       True          6\n",
      "11       KNeighborsUnif    0.727177     0.7484        6.212823       0.536441   0.187428                 6.212823                0.536441           0.187428            1       True          1\n",
      "12       KNeighborsDist    0.716908     0.7316        6.075372       0.548948   0.137230                 6.075372                0.548948           0.137230            1       True          2\n",
      "13      NeuralNetFastAI    0.592036     0.5988        0.400959       0.193358  87.798907                 0.400959                0.193358          87.798907            1       True         10\n"
     ]
    },
    {
     "data": {
      "text/plain": "                  model  score_test  score_val  pred_time_test  pred_time_val  \\\n0         LightGBMLarge    1.000000     1.0000        0.004927       0.006740   \n1            LightGBMXT    1.000000     1.0000        0.012682       0.045708   \n2   WeightedEnsemble_L2    1.000000     1.0000        0.014530       0.048954   \n3              CatBoost    1.000000     1.0000        0.034284       0.034029   \n4              LightGBM    1.000000     1.0000        0.045332       0.060652   \n5               XGBoost    0.867435     0.8792        0.037753       0.021373   \n6        NeuralNetTorch    0.867402     0.8792        0.127484       0.017372   \n7        ExtraTreesGini    0.857860     0.8672        0.291325       0.058187   \n8        ExtraTreesEntr    0.857728     0.8680        0.347332       0.056820   \n9      RandomForestGini    0.857299     0.8648        0.181877       0.055672   \n10     RandomForestEntr    0.857265     0.8648        0.186229       0.060088   \n11       KNeighborsUnif    0.727177     0.7484        6.212823       0.536441   \n12       KNeighborsDist    0.716908     0.7316        6.075372       0.548948   \n13      NeuralNetFastAI    0.592036     0.5988        0.400959       0.193358   \n\n     fit_time  pred_time_test_marginal  pred_time_val_marginal  \\\n0    0.188401                 0.004927                0.006740   \n1    5.978460                 0.012682                0.045708   \n2    6.714831                 0.001848                0.003246   \n3    5.231436                 0.034284                0.034029   \n4    0.184128                 0.045332                0.060652   \n5    3.275636                 0.037753                0.021373   \n6   41.659184                 0.127484                0.017372   \n7    2.867509                 0.291325                0.058187   \n8    2.914552                 0.347332                0.056820   \n9    4.158240                 0.181877                0.055672   \n10   3.895449                 0.186229                0.060088   \n11   0.187428                 6.212823                0.536441   \n12   0.137230                 6.075372                0.548948   \n13  87.798907                 0.400959                0.193358   \n\n    fit_time_marginal  stack_level  can_infer  fit_order  \n0            0.188401            1       True         13  \n1            5.978460            1       True          3  \n2            0.736371            2       True         14  \n3            5.231436            1       True          7  \n4            0.184128            1       True          4  \n5            3.275636            1       True         11  \n6           41.659184            1       True         12  \n7            2.867509            1       True          8  \n8            2.914552            1       True          9  \n9            4.158240            1       True          5  \n10           3.895449            1       True          6  \n11           0.187428            1       True          1  \n12           0.137230            1       True          2  \n13          87.798907            1       True         10  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>model</th>\n      <th>score_test</th>\n      <th>score_val</th>\n      <th>pred_time_test</th>\n      <th>pred_time_val</th>\n      <th>fit_time</th>\n      <th>pred_time_test_marginal</th>\n      <th>pred_time_val_marginal</th>\n      <th>fit_time_marginal</th>\n      <th>stack_level</th>\n      <th>can_infer</th>\n      <th>fit_order</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>LightGBMLarge</td>\n      <td>1.000000</td>\n      <td>1.0000</td>\n      <td>0.004927</td>\n      <td>0.006740</td>\n      <td>0.188401</td>\n      <td>0.004927</td>\n      <td>0.006740</td>\n      <td>0.188401</td>\n      <td>1</td>\n      <td>True</td>\n      <td>13</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>LightGBMXT</td>\n      <td>1.000000</td>\n      <td>1.0000</td>\n      <td>0.012682</td>\n      <td>0.045708</td>\n      <td>5.978460</td>\n      <td>0.012682</td>\n      <td>0.045708</td>\n      <td>5.978460</td>\n      <td>1</td>\n      <td>True</td>\n      <td>3</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>WeightedEnsemble_L2</td>\n      <td>1.000000</td>\n      <td>1.0000</td>\n      <td>0.014530</td>\n      <td>0.048954</td>\n      <td>6.714831</td>\n      <td>0.001848</td>\n      <td>0.003246</td>\n      <td>0.736371</td>\n      <td>2</td>\n      <td>True</td>\n      <td>14</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>CatBoost</td>\n      <td>1.000000</td>\n      <td>1.0000</td>\n      <td>0.034284</td>\n      <td>0.034029</td>\n      <td>5.231436</td>\n      <td>0.034284</td>\n      <td>0.034029</td>\n      <td>5.231436</td>\n      <td>1</td>\n      <td>True</td>\n      <td>7</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>LightGBM</td>\n      <td>1.000000</td>\n      <td>1.0000</td>\n      <td>0.045332</td>\n      <td>0.060652</td>\n      <td>0.184128</td>\n      <td>0.045332</td>\n      <td>0.060652</td>\n      <td>0.184128</td>\n      <td>1</td>\n      <td>True</td>\n      <td>4</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>XGBoost</td>\n      <td>0.867435</td>\n      <td>0.8792</td>\n      <td>0.037753</td>\n      <td>0.021373</td>\n      <td>3.275636</td>\n      <td>0.037753</td>\n      <td>0.021373</td>\n      <td>3.275636</td>\n      <td>1</td>\n      <td>True</td>\n      <td>11</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>NeuralNetTorch</td>\n      <td>0.867402</td>\n      <td>0.8792</td>\n      <td>0.127484</td>\n      <td>0.017372</td>\n      <td>41.659184</td>\n      <td>0.127484</td>\n      <td>0.017372</td>\n      <td>41.659184</td>\n      <td>1</td>\n      <td>True</td>\n      <td>12</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>ExtraTreesGini</td>\n      <td>0.857860</td>\n      <td>0.8672</td>\n      <td>0.291325</td>\n      <td>0.058187</td>\n      <td>2.867509</td>\n      <td>0.291325</td>\n      <td>0.058187</td>\n      <td>2.867509</td>\n      <td>1</td>\n      <td>True</td>\n      <td>8</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>ExtraTreesEntr</td>\n      <td>0.857728</td>\n      <td>0.8680</td>\n      <td>0.347332</td>\n      <td>0.056820</td>\n      <td>2.914552</td>\n      <td>0.347332</td>\n      <td>0.056820</td>\n      <td>2.914552</td>\n      <td>1</td>\n      <td>True</td>\n      <td>9</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>RandomForestGini</td>\n      <td>0.857299</td>\n      <td>0.8648</td>\n      <td>0.181877</td>\n      <td>0.055672</td>\n      <td>4.158240</td>\n      <td>0.181877</td>\n      <td>0.055672</td>\n      <td>4.158240</td>\n      <td>1</td>\n      <td>True</td>\n      <td>5</td>\n    </tr>\n    <tr>\n      <th>10</th>\n      <td>RandomForestEntr</td>\n      <td>0.857265</td>\n      <td>0.8648</td>\n      <td>0.186229</td>\n      <td>0.060088</td>\n      <td>3.895449</td>\n      <td>0.186229</td>\n      <td>0.060088</td>\n      <td>3.895449</td>\n      <td>1</td>\n      <td>True</td>\n      <td>6</td>\n    </tr>\n    <tr>\n      <th>11</th>\n      <td>KNeighborsUnif</td>\n      <td>0.727177</td>\n      <td>0.7484</td>\n      <td>6.212823</td>\n      <td>0.536441</td>\n      <td>0.187428</td>\n      <td>6.212823</td>\n      <td>0.536441</td>\n      <td>0.187428</td>\n      <td>1</td>\n      <td>True</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>12</th>\n      <td>KNeighborsDist</td>\n      <td>0.716908</td>\n      <td>0.7316</td>\n      <td>6.075372</td>\n      <td>0.548948</td>\n      <td>0.137230</td>\n      <td>6.075372</td>\n      <td>0.548948</td>\n      <td>0.137230</td>\n      <td>1</td>\n      <td>True</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>13</th>\n      <td>NeuralNetFastAI</td>\n      <td>0.592036</td>\n      <td>0.5988</td>\n      <td>0.400959</td>\n      <td>0.193358</td>\n      <td>87.798907</td>\n      <td>0.400959</td>\n      <td>0.193358</td>\n      <td>87.798907</td>\n      <td>1</td>\n      <td>True</td>\n      <td>10</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data = TabularDataset(\"./Data/split/test_data.csv\")\n",
    "predictor.leaderboard(test_data)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** Summary of fit() ***\n",
      "Estimated performance of each model:\n",
      "                  model  score_val  pred_time_val   fit_time  pred_time_val_marginal  fit_time_marginal  stack_level  can_infer  fit_order\n",
      "0         LightGBMLarge     1.0000       0.006740   0.188401                0.006740           0.188401            1       True         13\n",
      "1              CatBoost     1.0000       0.034029   5.231436                0.034029           5.231436            1       True          7\n",
      "2            LightGBMXT     1.0000       0.045708   5.978460                0.045708           5.978460            1       True          3\n",
      "3   WeightedEnsemble_L2     1.0000       0.048954   6.714831                0.003246           0.736371            2       True         14\n",
      "4              LightGBM     1.0000       0.060652   0.184128                0.060652           0.184128            1       True          4\n",
      "5        NeuralNetTorch     0.8792       0.017372  41.659184                0.017372          41.659184            1       True         12\n",
      "6               XGBoost     0.8792       0.021373   3.275636                0.021373           3.275636            1       True         11\n",
      "7        ExtraTreesEntr     0.8680       0.056820   2.914552                0.056820           2.914552            1       True          9\n",
      "8        ExtraTreesGini     0.8672       0.058187   2.867509                0.058187           2.867509            1       True          8\n",
      "9      RandomForestGini     0.8648       0.055672   4.158240                0.055672           4.158240            1       True          5\n",
      "10     RandomForestEntr     0.8648       0.060088   3.895449                0.060088           3.895449            1       True          6\n",
      "11       KNeighborsUnif     0.7484       0.536441   0.187428                0.536441           0.187428            1       True          1\n",
      "12       KNeighborsDist     0.7316       0.548948   0.137230                0.548948           0.137230            1       True          2\n",
      "13      NeuralNetFastAI     0.5988       0.193358  87.798907                0.193358          87.798907            1       True         10\n",
      "Number of models trained: 14\n",
      "Types of models trained:\n",
      "{'TabularNeuralNetTorchModel', 'NNFastAiTabularModel', 'XTModel', 'WeightedEnsembleModel', 'LGBModel', 'XGBoostModel', 'KNNModel', 'RFModel', 'CatBoostModel'}\n",
      "Bagging used: False \n",
      "Multi-layer stack-ensembling used: False \n",
      "Feature Metadata (Processed):\n",
      "(raw dtype, special dtypes):\n",
      "('float', [])     :  7 | ['duration', 'missed_bytes', 'orig_pkts', 'orig_ip_bytes', 'resp_pkts', ...]\n",
      "('int', [])       :  2 | ['orig_bytes', 'resp_bytes']\n",
      "('int', ['bool']) : 21 | ['proto_tcp', 'proto_udp', 'service_-', 'service_dhcp', 'service_dns', ...]\n",
      "*** End of fit() summary ***\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/media/wuguo-buaa/LENOVO_USB_HDD/PycharmProjects/Machine_learning_venv/lib/python3.8/site-packages/autogluon/core/utils/plots.py:138: UserWarning: AutoGluon summary plots cannot be created because bokeh is not installed. To see plots, please do: \"pip install bokeh==2.0.1\"\n",
      "  warnings.warn('AutoGluon summary plots cannot be created because bokeh is not installed. To see plots, please do: \"pip install bokeh==2.0.1\"')\n"
     ]
    }
   ],
   "source": [
    "predict_results = predictor.fit_summary(show_plot=True)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# try different preset"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## best quality"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "from autogluon.tabular import TabularDataset\n",
    "import autogluon\n",
    "label = 'label'\n",
    "train_data = TabularDataset(\"./Data/split/train_data.csv\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning: path already exists! This predictor may overwrite an existing predictor! path=\"./auto_gl/exp-iot23/best_q\"\n",
      "Presets specified: ['best_quality']\n",
      "Warning: Training may take a very long time because `time_limit` was not specified and `train_data` is large (121148 samples, 36.89 MB).\n",
      "\tConsider setting `time_limit` to ensure training finishes within an expected duration or experiment with a small portion of `train_data` to identify an ideal `presets` and `hyperparameters` configuration.\n",
      "Beginning AutoGluon training ...\n",
      "AutoGluon will save models to \"./auto_gl/exp-iot23/best_q/\"\n",
      "AutoGluon Version:  0.4.0\n",
      "Python Version:     3.8.13\n",
      "Operating System:   Linux\n",
      "Train Data Rows:    121148\n",
      "Train Data Columns: 30\n",
      "Label Column: label\n",
      "Preprocessing data ...\n",
      "AutoGluon infers your prediction problem is: 'binary' (because only two unique label-values observed).\n",
      "\t2 unique label values:  ['Benign', 'Malicious']\n",
      "\tIf 'binary' is not the correct problem_type, please manually specify the problem_type parameter during predictor init (You may specify problem_type as one of: ['binary', 'multiclass', 'regression'])\n",
      "Selected class <--> label mapping:  class 1 = Malicious, class 0 = Benign\n",
      "\tNote: For your binary classification, AutoGluon arbitrarily selected which label-value represents positive (Malicious) vs negative (Benign) class.\n",
      "\tTo explicitly set the positive_class, either rename classes to 1 and 0, or specify positive_class in Predictor init.\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    10633.77 MB\n",
      "\tTrain Data (Original)  Memory Usage: 29.08 MB (0.3% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\t\t\tNote: Converting 21 features to boolean dtype as they only contain 2 unique values.\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('float', []) :  7 | ['duration', 'missed_bytes', 'orig_pkts', 'orig_ip_bytes', 'resp_pkts', ...]\n",
      "\t\t('int', [])   : 23 | ['orig_bytes', 'resp_bytes', 'proto_tcp', 'proto_udp', 'service_-', ...]\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('float', [])     :  7 | ['duration', 'missed_bytes', 'orig_pkts', 'orig_ip_bytes', 'resp_pkts', ...]\n",
      "\t\t('int', [])       :  2 | ['orig_bytes', 'resp_bytes']\n",
      "\t\t('int', ['bool']) : 21 | ['proto_tcp', 'proto_udp', 'service_-', 'service_dhcp', 'service_dns', ...]\n",
      "\t0.2s = Fit runtime\n",
      "\t30 features in original data used to generate 30 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 11.27 MB (0.1% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 0.29s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'accuracy'\n",
      "\tTo change this, specify the eval_metric parameter of Predictor()\n",
      "AutoGluon will fit 2 stack levels (L1 to L2) ...\n",
      "Fitting 13 L1 models ...\n",
      "Fitting model: KNeighborsUnif_BAG_L1 ...\n",
      "\t0.7336\t = Validation score   (accuracy)\n",
      "\t0.2s\t = Training   runtime\n",
      "\t23.59s\t = Validation runtime\n",
      "Fitting model: KNeighborsDist_BAG_L1 ...\n",
      "\t0.7237\t = Validation score   (accuracy)\n",
      "\t0.14s\t = Training   runtime\n",
      "\t25.31s\t = Validation runtime\n",
      "Fitting model: LightGBMXT_BAG_L1 ...\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t1.0\t = Validation score   (accuracy)\n",
      "\t9.48s\t = Training   runtime\n",
      "\t0.04s\t = Validation runtime\n",
      "Fitting model: LightGBM_BAG_L1 ...\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t1.0\t = Validation score   (accuracy)\n",
      "\t1.78s\t = Training   runtime\n",
      "\t0.04s\t = Validation runtime\n",
      "Fitting model: RandomForestGini_BAG_L1 ...\n",
      "\t0.8604\t = Validation score   (accuracy)\n",
      "\t3.9s\t = Training   runtime\n",
      "\t2.11s\t = Validation runtime\n",
      "Fitting model: RandomForestEntr_BAG_L1 ...\n",
      "\t0.8604\t = Validation score   (accuracy)\n",
      "\t3.64s\t = Training   runtime\n",
      "\t2.11s\t = Validation runtime\n",
      "Fitting model: CatBoost_BAG_L1 ...\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "2022-05-12 12:11:15,806\tWARNING worker.py:1228 -- A worker died or was killed while executing a task by an unexpected system error. To troubleshoot the problem, check the logs for the dead worker. RayTask ID: 475ca1036458f091ab5339f7ff4b958869396e7de1cc9d2f Worker ID: 83c21ed7199e4faa729b425b5d05857aa87b137a382c0c688e27fd19 Node ID: e5f3b6dee7e41b73b1c07f60b0527e87a402e607be0e511a6b4d89a7 Worker IP address: 192.168.0.133 Worker port: 46033 Worker PID: 16211\n",
      "2022-05-12 12:11:15,806\tWARNING worker.py:1228 -- 3 retries left for task 34c9c2094e42fdbfffffffffffffffffffffffff01000000, attempting to resubmit.\n",
      "2022-05-12 12:11:15,817\tWARNING worker.py:1228 -- A worker died or was killed while executing a task by an unexpected system error. To troubleshoot the problem, check the logs for the dead worker. RayTask ID: 0853ee1f821ec7938fa7ee33567d9a4c53b0c775cbd67e38 Worker ID: 99fe4e9ab6532b369503f53fe0df04bbe09c9da0c04742028ddafe83 Node ID: e5f3b6dee7e41b73b1c07f60b0527e87a402e607be0e511a6b4d89a7 Worker IP address: 192.168.0.133 Worker port: 46783 Worker PID: 16209\n",
      "2022-05-12 12:11:15,817\tWARNING worker.py:1228 -- 3 retries left for task 42867781e3b6e074ffffffffffffffffffffffff01000000, attempting to resubmit.\n",
      "2022-05-12 12:11:15,828\tWARNING worker.py:1228 -- A worker died or was killed while executing a task by an unexpected system error. To troubleshoot the problem, check the logs for the dead worker. RayTask ID: b791b44889067523945a206c12f4d7fe78bcf897429a725f Worker ID: e1cca8d811c8e8769a541d4155ec1c1bb2284806a3866e5afc8ae8f6 Node ID: e5f3b6dee7e41b73b1c07f60b0527e87a402e607be0e511a6b4d89a7 Worker IP address: 192.168.0.133 Worker port: 43993 Worker PID: 16213\n",
      "2022-05-12 12:11:15,828\tWARNING worker.py:1228 -- 3 retries left for task e11fe2800445c79affffffffffffffffffffffff01000000, attempting to resubmit.\n",
      "2022-05-12 12:11:15,849\tWARNING worker.py:1228 -- A worker died or was killed while executing a task by an unexpected system error. To troubleshoot the problem, check the logs for the dead worker. RayTask ID: 2fe1d183d24b0e25c3ea14d5b8f27af06801bf77d5d7a71f Worker ID: f5c60c0e1c9c0af15870cab00630485e9b8c67e6a7a9b5adb20b74eb Node ID: e5f3b6dee7e41b73b1c07f60b0527e87a402e607be0e511a6b4d89a7 Worker IP address: 192.168.0.133 Worker port: 44175 Worker PID: 16210\n",
      "2022-05-12 12:11:15,850\tWARNING worker.py:1228 -- 3 retries left for task 27c0dca5954f99afffffffffffffffffffffffff01000000, attempting to resubmit.\n",
      "2022-05-12 12:11:15,850\tWARNING worker.py:1228 -- A worker died or was killed while executing a task by an unexpected system error. To troubleshoot the problem, check the logs for the dead worker. RayTask ID: 6c0f38d21c08fc1246716b3cb95032afe250798d3270167c Worker ID: 92127bb2ccf265e968544926511980191e8293a3162ddcf2559b240e Node ID: e5f3b6dee7e41b73b1c07f60b0527e87a402e607be0e511a6b4d89a7 Worker IP address: 192.168.0.133 Worker port: 37513 Worker PID: 16212\n",
      "2022-05-12 12:11:15,850\tWARNING worker.py:1228 -- 3 retries left for task 747754f46b61f47dffffffffffffffffffffffff01000000, attempting to resubmit.\n",
      "2022-05-12 12:11:55,062\tWARNING worker.py:1228 -- A worker died or was killed while executing a task by an unexpected system error. To troubleshoot the problem, check the logs for the dead worker. RayTask ID: 5e156908347cec09bd985ee44897a0f496351b32331fa728 Worker ID: fe766a4a4ccdc9ba469dd6a06823ac1d011b5d5deb0cf9087c45d090 Node ID: e5f3b6dee7e41b73b1c07f60b0527e87a402e607be0e511a6b4d89a7 Worker IP address: 192.168.0.133 Worker port: 41827 Worker PID: 16655\n",
      "2022-05-12 12:11:55,063\tWARNING worker.py:1228 -- A worker died or was killed while executing a task by an unexpected system error. To troubleshoot the problem, check the logs for the dead worker. RayTask ID: 3790d5701eb692ad7852eb4e7c6ad271e26fe2dc3ee1875a Worker ID: a8c599bee2c78d04120fe02eaca3bb7733db5708612bf94979ceaafd Node ID: e5f3b6dee7e41b73b1c07f60b0527e87a402e607be0e511a6b4d89a7 Worker IP address: 192.168.0.133 Worker port: 33111 Worker PID: 16657\n",
      "2022-05-12 12:11:55,063\tWARNING worker.py:1228 -- 2 retries left for task 42867781e3b6e074ffffffffffffffffffffffff01000000, attempting to resubmit.\n",
      "2022-05-12 12:11:55,064\tWARNING worker.py:1228 -- 2 retries left for task 27c0dca5954f99afffffffffffffffffffffffff01000000, attempting to resubmit.\n",
      "2022-05-12 12:12:44,876\tWARNING worker.py:1228 -- A worker died or was killed while executing a task by an unexpected system error. To troubleshoot the problem, check the logs for the dead worker. RayTask ID: 0b1b2130a3a9f8a3fe29fef0f6e234a11eb7411a4e7e5f94 Worker ID: 95889b716fb89892beac0574376d515a84deaea48bd4b81faf925121 Node ID: e5f3b6dee7e41b73b1c07f60b0527e87a402e607be0e511a6b4d89a7 Worker IP address: 192.168.0.133 Worker port: 34471 Worker PID: 16206\n",
      "2022-05-12 12:12:44,876\tWARNING worker.py:1228 -- 3 retries left for task 24eed4584329c19affffffffffffffffffffffff01000000, attempting to resubmit.\n",
      "\t1.0\t = Validation score   (accuracy)\n",
      "\t131.02s\t = Training   runtime\n",
      "\t0.03s\t = Validation runtime\n",
      "Fitting model: ExtraTreesGini_BAG_L1 ...\n",
      "\t0.8609\t = Validation score   (accuracy)\n",
      "\t3.06s\t = Training   runtime\n",
      "\t2.45s\t = Validation runtime\n",
      "Fitting model: ExtraTreesEntr_BAG_L1 ...\n",
      "\t0.8609\t = Validation score   (accuracy)\n",
      "\t3.01s\t = Training   runtime\n",
      "\t2.42s\t = Validation runtime\n",
      "Fitting model: NeuralNetFastAI_BAG_L1 ...\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy\n"
     ]
    }
   ],
   "source": [
    "save_path = './auto_gl/exp-iot23/best_q'  # specifies folder to store trained models\n",
    "from autogluon.tabular import TabularPredictor\n",
    "predictor = TabularPredictor(label=label, path=save_path).fit(train_data,ag_args_fit={'num_gpus':1},presets='best_quality')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** Summary of fit() ***\n",
      "Estimated performance of each model:\n",
      "                      model  score_val  pred_time_val    fit_time  pred_time_val_marginal  fit_time_marginal  stack_level  can_infer  fit_order\n",
      "0           CatBoost_BAG_L1   1.000000       0.033231  131.023886                0.033231         131.023886            1       True          7\n",
      "1           LightGBM_BAG_L1   1.000000       0.036842    1.775970                0.036842           1.775970            1       True          4\n",
      "2      LightGBMLarge_BAG_L1   1.000000       0.040418   10.055639                0.040418          10.055639            1       True         12\n",
      "3         LightGBMXT_BAG_L1   1.000000       0.044001    9.479686                0.044001           9.479686            1       True          3\n",
      "4       WeightedEnsemble_L2   1.000000       0.177872   33.086067                0.133871          23.606381            2       True         13\n",
      "5      LightGBMLarge_BAG_L2   1.000000      61.733382  533.726953                0.037642          29.137388            2       True         22\n",
      "6           LightGBM_BAG_L2   1.000000      61.750229  506.477836                0.054489           1.888272            2       True         15\n",
      "7         LightGBMXT_BAG_L2   1.000000      61.754743  506.555802                0.059003           1.966237            2       True         14\n",
      "8            XGBoost_BAG_L2   1.000000      61.935982  510.389151                0.240242           5.799586            2       True         21\n",
      "9     ExtraTreesGini_BAG_L2   1.000000      63.358050  505.933799                1.662310           1.344234            2       True         19\n",
      "10    ExtraTreesEntr_BAG_L2   1.000000      63.364817  505.926847                1.669077           1.337283            2       True         20\n",
      "11  RandomForestGini_BAG_L2   1.000000      63.388964  507.920509                1.693224           3.330944            2       True         16\n",
      "12  RandomForestEntr_BAG_L2   1.000000      63.414093  506.496725                1.718353           1.907161            2       True         17\n",
      "13      WeightedEnsemble_L3   1.000000      63.481585  523.530595                0.123535          17.596796            3       True         23\n",
      "14          CatBoost_BAG_L2   0.999992      61.839226  533.029563                0.143486          28.439998            2       True         18\n",
      "15           XGBoost_BAG_L1   0.870852       0.095186   25.722861                0.095186          25.722861            1       True         11\n",
      "16    ExtraTreesEntr_BAG_L1   0.860930       2.421909    3.010697                2.421909           3.010697            1       True          9\n",
      "17    ExtraTreesGini_BAG_L1   0.860906       2.447874    3.057243                2.447874           3.057243            1       True          8\n",
      "18  RandomForestGini_BAG_L1   0.860419       2.108596    3.900055                2.108596           3.900055            1       True          5\n",
      "19  RandomForestEntr_BAG_L1   0.860410       2.110142    3.635849                2.110142           3.635849            1       True          6\n",
      "20    KNeighborsUnif_BAG_L1   0.733607      23.593365    0.195653               23.593365           0.195653            1       True          1\n",
      "21    KNeighborsDist_BAG_L1   0.723743      25.310233    0.135993               25.310233           0.135993            1       True          2\n",
      "22   NeuralNetFastAI_BAG_L1   0.643692       3.453942  312.596032                3.453942         312.596032            1       True         10\n",
      "Number of models trained: 23\n",
      "Types of models trained:\n",
      "{'StackerEnsembleModel_XGBoost', 'StackerEnsembleModel_NNFastAiTabular', 'WeightedEnsembleModel', 'StackerEnsembleModel_CatBoost', 'StackerEnsembleModel_RF', 'StackerEnsembleModel_LGB', 'StackerEnsembleModel_XT', 'StackerEnsembleModel_KNN'}\n",
      "Bagging used: True  (with 8 folds)\n",
      "Multi-layer stack-ensembling used: True  (with 3 levels)\n",
      "Feature Metadata (Processed):\n",
      "(raw dtype, special dtypes):\n",
      "('float', [])     :  7 | ['duration', 'missed_bytes', 'orig_pkts', 'orig_ip_bytes', 'resp_pkts', ...]\n",
      "('int', [])       :  2 | ['orig_bytes', 'resp_bytes']\n",
      "('int', ['bool']) : 21 | ['proto_tcp', 'proto_udp', 'service_-', 'service_dhcp', 'service_dns', ...]\n",
      "*** End of fit() summary ***\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/media/wuguo-buaa/LENOVO_USB_HDD/PycharmProjects/Machine_learning_venv/lib/python3.8/site-packages/autogluon/core/utils/plots.py:138: UserWarning: AutoGluon summary plots cannot be created because bokeh is not installed. To see plots, please do: \"pip install bokeh==2.0.1\"\n",
      "  warnings.warn('AutoGluon summary plots cannot be created because bokeh is not installed. To see plots, please do: \"pip install bokeh==2.0.1\"')\n"
     ]
    }
   ],
   "source": [
    "from autogluon.tabular import TabularPredictor\n",
    "RF_predictor = TabularPredictor.load('/media/wuguo-buaa/LENOVO_USB_HDD/PycharmProjects/Anomaly-Detection-IoT23/Models/auto_gl/exp-iot23/best_q/')\n",
    "RF_results = RF_predictor.fit_summary(show_plot=True)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                      model  score_test  score_val  pred_time_test  pred_time_val    fit_time  pred_time_test_marginal  pred_time_val_marginal  fit_time_marginal  stack_level  can_infer  fit_order\n",
      "0           LightGBM_BAG_L1    1.000000   1.000000        0.044971       0.036842    1.775970                 0.044971                0.036842           1.775970            1       True          4\n",
      "1         LightGBMXT_BAG_L1    1.000000   1.000000        0.047302       0.044001    9.479686                 0.047302                0.044001           9.479686            1       True          3\n",
      "2       WeightedEnsemble_L2    1.000000   1.000000        0.049023       0.177872   33.086067                 0.001721                0.133871          23.606381            2       True         13\n",
      "3      LightGBMLarge_BAG_L1    1.000000   1.000000        0.692796       0.040418   10.055639                 0.692796                0.040418          10.055639            1       True         12\n",
      "4           CatBoost_BAG_L1    1.000000   1.000000        1.488141       0.033231  131.023886                 1.488141                0.033231         131.023886            1       True          7\n",
      "5           CatBoost_BAG_L2    1.000000   0.999992       44.199703      61.839226  533.029563                 0.037058                0.143486          28.439998            2       True         18\n",
      "6           LightGBM_BAG_L2    1.000000   1.000000       44.226615      61.750229  506.477836                 0.063969                0.054489           1.888272            2       True         15\n",
      "7      LightGBMLarge_BAG_L2    1.000000   1.000000       44.228395      61.733382  533.726953                 0.065750                0.037642          29.137388            2       True         22\n",
      "8     ExtraTreesGini_BAG_L2    1.000000   1.000000       44.230879      63.358050  505.933799                 0.068233                1.662310           1.344234            2       True         19\n",
      "9         LightGBMXT_BAG_L2    1.000000   1.000000       44.231328      61.754743  506.555802                 0.068682                0.059003           1.966237            2       True         14\n",
      "10  RandomForestGini_BAG_L2    1.000000   1.000000       44.231898      63.388964  507.920509                 0.069252                1.693224           3.330944            2       True         16\n",
      "11      WeightedEnsemble_L3    1.000000   1.000000       44.232434      63.481585  523.530595                 0.001555                0.123535          17.596796            3       True         23\n",
      "12    ExtraTreesEntr_BAG_L2    1.000000   1.000000       44.234387      63.364817  505.926847                 0.071741                1.669077           1.337283            2       True         20\n",
      "13  RandomForestEntr_BAG_L2    1.000000   1.000000       44.235653      63.414093  506.496725                 0.073008                1.718353           1.907161            2       True         17\n",
      "14           XGBoost_BAG_L2    1.000000   1.000000       44.361975      61.935982  510.389151                 0.199329                0.240242           5.799586            2       True         21\n",
      "15           XGBoost_BAG_L1    0.867402   0.870852        0.227478       0.095186   25.722861                 0.227478                0.095186          25.722861            1       True         11\n",
      "16    ExtraTreesGini_BAG_L1    0.857992   0.860906        4.119613       2.447874    3.057243                 4.119613                2.447874           3.057243            1       True          8\n",
      "17    ExtraTreesEntr_BAG_L1    0.857992   0.860930        4.610659       2.421909    3.010697                 4.610659                2.421909           3.010697            1       True          9\n",
      "18  RandomForestEntr_BAG_L1    0.857662   0.860410        2.845744       2.110142    3.635849                 2.845744                2.110142           3.635849            1       True          6\n",
      "19  RandomForestGini_BAG_L1    0.857662   0.860419        3.014276       2.108596    3.900055                 3.014276                2.108596           3.900055            1       True          5\n",
      "20    KNeighborsUnif_BAG_L1    0.726946   0.733607        6.082420      23.593365    0.195653                 6.082420               23.593365           0.195653            1       True          1\n",
      "21    KNeighborsDist_BAG_L1    0.717073   0.723743        6.481201      25.310233    0.135993                 6.481201               25.310233           0.135993            1       True          2\n",
      "22   NeuralNetFastAI_BAG_L1    0.592961   0.643692       14.508045       3.453942  312.596032                14.508045                3.453942         312.596032            1       True         10\n"
     ]
    },
    {
     "data": {
      "text/plain": "                      model  score_test  score_val  pred_time_test  \\\n0           LightGBM_BAG_L1    1.000000   1.000000        0.044971   \n1         LightGBMXT_BAG_L1    1.000000   1.000000        0.047302   \n2       WeightedEnsemble_L2    1.000000   1.000000        0.049023   \n3      LightGBMLarge_BAG_L1    1.000000   1.000000        0.692796   \n4           CatBoost_BAG_L1    1.000000   1.000000        1.488141   \n5           CatBoost_BAG_L2    1.000000   0.999992       44.199703   \n6           LightGBM_BAG_L2    1.000000   1.000000       44.226615   \n7      LightGBMLarge_BAG_L2    1.000000   1.000000       44.228395   \n8     ExtraTreesGini_BAG_L2    1.000000   1.000000       44.230879   \n9         LightGBMXT_BAG_L2    1.000000   1.000000       44.231328   \n10  RandomForestGini_BAG_L2    1.000000   1.000000       44.231898   \n11      WeightedEnsemble_L3    1.000000   1.000000       44.232434   \n12    ExtraTreesEntr_BAG_L2    1.000000   1.000000       44.234387   \n13  RandomForestEntr_BAG_L2    1.000000   1.000000       44.235653   \n14           XGBoost_BAG_L2    1.000000   1.000000       44.361975   \n15           XGBoost_BAG_L1    0.867402   0.870852        0.227478   \n16    ExtraTreesGini_BAG_L1    0.857992   0.860906        4.119613   \n17    ExtraTreesEntr_BAG_L1    0.857992   0.860930        4.610659   \n18  RandomForestEntr_BAG_L1    0.857662   0.860410        2.845744   \n19  RandomForestGini_BAG_L1    0.857662   0.860419        3.014276   \n20    KNeighborsUnif_BAG_L1    0.726946   0.733607        6.082420   \n21    KNeighborsDist_BAG_L1    0.717073   0.723743        6.481201   \n22   NeuralNetFastAI_BAG_L1    0.592961   0.643692       14.508045   \n\n    pred_time_val    fit_time  pred_time_test_marginal  \\\n0        0.036842    1.775970                 0.044971   \n1        0.044001    9.479686                 0.047302   \n2        0.177872   33.086067                 0.001721   \n3        0.040418   10.055639                 0.692796   \n4        0.033231  131.023886                 1.488141   \n5       61.839226  533.029563                 0.037058   \n6       61.750229  506.477836                 0.063969   \n7       61.733382  533.726953                 0.065750   \n8       63.358050  505.933799                 0.068233   \n9       61.754743  506.555802                 0.068682   \n10      63.388964  507.920509                 0.069252   \n11      63.481585  523.530595                 0.001555   \n12      63.364817  505.926847                 0.071741   \n13      63.414093  506.496725                 0.073008   \n14      61.935982  510.389151                 0.199329   \n15       0.095186   25.722861                 0.227478   \n16       2.447874    3.057243                 4.119613   \n17       2.421909    3.010697                 4.610659   \n18       2.110142    3.635849                 2.845744   \n19       2.108596    3.900055                 3.014276   \n20      23.593365    0.195653                 6.082420   \n21      25.310233    0.135993                 6.481201   \n22       3.453942  312.596032                14.508045   \n\n    pred_time_val_marginal  fit_time_marginal  stack_level  can_infer  \\\n0                 0.036842           1.775970            1       True   \n1                 0.044001           9.479686            1       True   \n2                 0.133871          23.606381            2       True   \n3                 0.040418          10.055639            1       True   \n4                 0.033231         131.023886            1       True   \n5                 0.143486          28.439998            2       True   \n6                 0.054489           1.888272            2       True   \n7                 0.037642          29.137388            2       True   \n8                 1.662310           1.344234            2       True   \n9                 0.059003           1.966237            2       True   \n10                1.693224           3.330944            2       True   \n11                0.123535          17.596796            3       True   \n12                1.669077           1.337283            2       True   \n13                1.718353           1.907161            2       True   \n14                0.240242           5.799586            2       True   \n15                0.095186          25.722861            1       True   \n16                2.447874           3.057243            1       True   \n17                2.421909           3.010697            1       True   \n18                2.110142           3.635849            1       True   \n19                2.108596           3.900055            1       True   \n20               23.593365           0.195653            1       True   \n21               25.310233           0.135993            1       True   \n22                3.453942         312.596032            1       True   \n\n    fit_order  \n0           4  \n1           3  \n2          13  \n3          12  \n4           7  \n5          18  \n6          15  \n7          22  \n8          19  \n9          14  \n10         16  \n11         23  \n12         20  \n13         17  \n14         21  \n15         11  \n16          8  \n17          9  \n18          6  \n19          5  \n20          1  \n21          2  \n22         10  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>model</th>\n      <th>score_test</th>\n      <th>score_val</th>\n      <th>pred_time_test</th>\n      <th>pred_time_val</th>\n      <th>fit_time</th>\n      <th>pred_time_test_marginal</th>\n      <th>pred_time_val_marginal</th>\n      <th>fit_time_marginal</th>\n      <th>stack_level</th>\n      <th>can_infer</th>\n      <th>fit_order</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>LightGBM_BAG_L1</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>0.044971</td>\n      <td>0.036842</td>\n      <td>1.775970</td>\n      <td>0.044971</td>\n      <td>0.036842</td>\n      <td>1.775970</td>\n      <td>1</td>\n      <td>True</td>\n      <td>4</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>LightGBMXT_BAG_L1</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>0.047302</td>\n      <td>0.044001</td>\n      <td>9.479686</td>\n      <td>0.047302</td>\n      <td>0.044001</td>\n      <td>9.479686</td>\n      <td>1</td>\n      <td>True</td>\n      <td>3</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>WeightedEnsemble_L2</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>0.049023</td>\n      <td>0.177872</td>\n      <td>33.086067</td>\n      <td>0.001721</td>\n      <td>0.133871</td>\n      <td>23.606381</td>\n      <td>2</td>\n      <td>True</td>\n      <td>13</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>LightGBMLarge_BAG_L1</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>0.692796</td>\n      <td>0.040418</td>\n      <td>10.055639</td>\n      <td>0.692796</td>\n      <td>0.040418</td>\n      <td>10.055639</td>\n      <td>1</td>\n      <td>True</td>\n      <td>12</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>CatBoost_BAG_L1</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>1.488141</td>\n      <td>0.033231</td>\n      <td>131.023886</td>\n      <td>1.488141</td>\n      <td>0.033231</td>\n      <td>131.023886</td>\n      <td>1</td>\n      <td>True</td>\n      <td>7</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>CatBoost_BAG_L2</td>\n      <td>1.000000</td>\n      <td>0.999992</td>\n      <td>44.199703</td>\n      <td>61.839226</td>\n      <td>533.029563</td>\n      <td>0.037058</td>\n      <td>0.143486</td>\n      <td>28.439998</td>\n      <td>2</td>\n      <td>True</td>\n      <td>18</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>LightGBM_BAG_L2</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>44.226615</td>\n      <td>61.750229</td>\n      <td>506.477836</td>\n      <td>0.063969</td>\n      <td>0.054489</td>\n      <td>1.888272</td>\n      <td>2</td>\n      <td>True</td>\n      <td>15</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>LightGBMLarge_BAG_L2</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>44.228395</td>\n      <td>61.733382</td>\n      <td>533.726953</td>\n      <td>0.065750</td>\n      <td>0.037642</td>\n      <td>29.137388</td>\n      <td>2</td>\n      <td>True</td>\n      <td>22</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>ExtraTreesGini_BAG_L2</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>44.230879</td>\n      <td>63.358050</td>\n      <td>505.933799</td>\n      <td>0.068233</td>\n      <td>1.662310</td>\n      <td>1.344234</td>\n      <td>2</td>\n      <td>True</td>\n      <td>19</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>LightGBMXT_BAG_L2</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>44.231328</td>\n      <td>61.754743</td>\n      <td>506.555802</td>\n      <td>0.068682</td>\n      <td>0.059003</td>\n      <td>1.966237</td>\n      <td>2</td>\n      <td>True</td>\n      <td>14</td>\n    </tr>\n    <tr>\n      <th>10</th>\n      <td>RandomForestGini_BAG_L2</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>44.231898</td>\n      <td>63.388964</td>\n      <td>507.920509</td>\n      <td>0.069252</td>\n      <td>1.693224</td>\n      <td>3.330944</td>\n      <td>2</td>\n      <td>True</td>\n      <td>16</td>\n    </tr>\n    <tr>\n      <th>11</th>\n      <td>WeightedEnsemble_L3</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>44.232434</td>\n      <td>63.481585</td>\n      <td>523.530595</td>\n      <td>0.001555</td>\n      <td>0.123535</td>\n      <td>17.596796</td>\n      <td>3</td>\n      <td>True</td>\n      <td>23</td>\n    </tr>\n    <tr>\n      <th>12</th>\n      <td>ExtraTreesEntr_BAG_L2</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>44.234387</td>\n      <td>63.364817</td>\n      <td>505.926847</td>\n      <td>0.071741</td>\n      <td>1.669077</td>\n      <td>1.337283</td>\n      <td>2</td>\n      <td>True</td>\n      <td>20</td>\n    </tr>\n    <tr>\n      <th>13</th>\n      <td>RandomForestEntr_BAG_L2</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>44.235653</td>\n      <td>63.414093</td>\n      <td>506.496725</td>\n      <td>0.073008</td>\n      <td>1.718353</td>\n      <td>1.907161</td>\n      <td>2</td>\n      <td>True</td>\n      <td>17</td>\n    </tr>\n    <tr>\n      <th>14</th>\n      <td>XGBoost_BAG_L2</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>44.361975</td>\n      <td>61.935982</td>\n      <td>510.389151</td>\n      <td>0.199329</td>\n      <td>0.240242</td>\n      <td>5.799586</td>\n      <td>2</td>\n      <td>True</td>\n      <td>21</td>\n    </tr>\n    <tr>\n      <th>15</th>\n      <td>XGBoost_BAG_L1</td>\n      <td>0.867402</td>\n      <td>0.870852</td>\n      <td>0.227478</td>\n      <td>0.095186</td>\n      <td>25.722861</td>\n      <td>0.227478</td>\n      <td>0.095186</td>\n      <td>25.722861</td>\n      <td>1</td>\n      <td>True</td>\n      <td>11</td>\n    </tr>\n    <tr>\n      <th>16</th>\n      <td>ExtraTreesGini_BAG_L1</td>\n      <td>0.857992</td>\n      <td>0.860906</td>\n      <td>4.119613</td>\n      <td>2.447874</td>\n      <td>3.057243</td>\n      <td>4.119613</td>\n      <td>2.447874</td>\n      <td>3.057243</td>\n      <td>1</td>\n      <td>True</td>\n      <td>8</td>\n    </tr>\n    <tr>\n      <th>17</th>\n      <td>ExtraTreesEntr_BAG_L1</td>\n      <td>0.857992</td>\n      <td>0.860930</td>\n      <td>4.610659</td>\n      <td>2.421909</td>\n      <td>3.010697</td>\n      <td>4.610659</td>\n      <td>2.421909</td>\n      <td>3.010697</td>\n      <td>1</td>\n      <td>True</td>\n      <td>9</td>\n    </tr>\n    <tr>\n      <th>18</th>\n      <td>RandomForestEntr_BAG_L1</td>\n      <td>0.857662</td>\n      <td>0.860410</td>\n      <td>2.845744</td>\n      <td>2.110142</td>\n      <td>3.635849</td>\n      <td>2.845744</td>\n      <td>2.110142</td>\n      <td>3.635849</td>\n      <td>1</td>\n      <td>True</td>\n      <td>6</td>\n    </tr>\n    <tr>\n      <th>19</th>\n      <td>RandomForestGini_BAG_L1</td>\n      <td>0.857662</td>\n      <td>0.860419</td>\n      <td>3.014276</td>\n      <td>2.108596</td>\n      <td>3.900055</td>\n      <td>3.014276</td>\n      <td>2.108596</td>\n      <td>3.900055</td>\n      <td>1</td>\n      <td>True</td>\n      <td>5</td>\n    </tr>\n    <tr>\n      <th>20</th>\n      <td>KNeighborsUnif_BAG_L1</td>\n      <td>0.726946</td>\n      <td>0.733607</td>\n      <td>6.082420</td>\n      <td>23.593365</td>\n      <td>0.195653</td>\n      <td>6.082420</td>\n      <td>23.593365</td>\n      <td>0.195653</td>\n      <td>1</td>\n      <td>True</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>21</th>\n      <td>KNeighborsDist_BAG_L1</td>\n      <td>0.717073</td>\n      <td>0.723743</td>\n      <td>6.481201</td>\n      <td>25.310233</td>\n      <td>0.135993</td>\n      <td>6.481201</td>\n      <td>25.310233</td>\n      <td>0.135993</td>\n      <td>1</td>\n      <td>True</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>22</th>\n      <td>NeuralNetFastAI_BAG_L1</td>\n      <td>0.592961</td>\n      <td>0.643692</td>\n      <td>14.508045</td>\n      <td>3.453942</td>\n      <td>312.596032</td>\n      <td>14.508045</td>\n      <td>3.453942</td>\n      <td>312.596032</td>\n      <td>1</td>\n      <td>True</td>\n      <td>10</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data = TabularDataset(\"./Data/split/test_data.csv\")\n",
    "RF_predictor.leaderboard(test_data)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## high quality"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning: path already exists! This predictor may overwrite an existing predictor! path=\"./auto_gl/exp-iot23/high_q\"\n",
      "Presets specified: ['high_quality']\n",
      "Warning: Training may take a very long time because `time_limit` was not specified and `train_data` is large (121148 samples, 36.89 MB).\n",
      "\tConsider setting `time_limit` to ensure training finishes within an expected duration or experiment with a small portion of `train_data` to identify an ideal `presets` and `hyperparameters` configuration.\n",
      "Beginning AutoGluon training ...\n",
      "AutoGluon will save models to \"./auto_gl/exp-iot23/high_q/\"\n",
      "AutoGluon Version:  0.4.0\n",
      "Python Version:     3.8.13\n",
      "Operating System:   Linux\n",
      "Train Data Rows:    121148\n",
      "Train Data Columns: 30\n",
      "Label Column: label\n",
      "Preprocessing data ...\n",
      "AutoGluon infers your prediction problem is: 'binary' (because only two unique label-values observed).\n",
      "\t2 unique label values:  ['Benign', 'Malicious']\n",
      "\tIf 'binary' is not the correct problem_type, please manually specify the problem_type parameter during predictor init (You may specify problem_type as one of: ['binary', 'multiclass', 'regression'])\n",
      "Selected class <--> label mapping:  class 1 = Malicious, class 0 = Benign\n",
      "\tNote: For your binary classification, AutoGluon arbitrarily selected which label-value represents positive (Malicious) vs negative (Benign) class.\n",
      "\tTo explicitly set the positive_class, either rename classes to 1 and 0, or specify positive_class in Predictor init.\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    12263.2 MB\n",
      "\tTrain Data (Original)  Memory Usage: 29.08 MB (0.2% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\t\t\tNote: Converting 21 features to boolean dtype as they only contain 2 unique values.\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('float', []) :  7 | ['duration', 'missed_bytes', 'orig_pkts', 'orig_ip_bytes', 'resp_pkts', ...]\n",
      "\t\t('int', [])   : 23 | ['orig_bytes', 'resp_bytes', 'proto_tcp', 'proto_udp', 'service_-', ...]\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('float', [])     :  7 | ['duration', 'missed_bytes', 'orig_pkts', 'orig_ip_bytes', 'resp_pkts', ...]\n",
      "\t\t('int', [])       :  2 | ['orig_bytes', 'resp_bytes']\n",
      "\t\t('int', ['bool']) : 21 | ['proto_tcp', 'proto_udp', 'service_-', 'service_dhcp', 'service_dns', ...]\n",
      "\t0.2s = Fit runtime\n",
      "\t30 features in original data used to generate 30 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 11.27 MB (0.1% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 0.28s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'accuracy'\n",
      "\tTo change this, specify the eval_metric parameter of Predictor()\n",
      "AutoGluon will fit 2 stack levels (L1 to L2) ...\n",
      "Fitting 13 L1 models ...\n",
      "Fitting model: KNeighborsUnif_BAG_L1 ...\n",
      "\t0.7336\t = Validation score   (accuracy)\n",
      "\t0.13s\t = Training   runtime\n",
      "\t24.61s\t = Validation runtime\n",
      "Fitting model: KNeighborsDist_BAG_L1 ...\n",
      "\t0.7237\t = Validation score   (accuracy)\n",
      "\t0.12s\t = Training   runtime\n",
      "\t24.4s\t = Validation runtime\n",
      "Fitting model: LightGBMXT_BAG_L1 ...\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "2022-05-12 15:00:32,183\tWARNING services.py:1748 -- WARNING: The object store is using /tmp instead of /dev/shm because /dev/shm has only 3557904384 bytes available. This will harm performance! You may be able to free up space by deleting files in /dev/shm. If you are inside a Docker container, you can increase /dev/shm size by passing '--shm-size=3.88gb' to 'docker run' (or add it to the run_options list in a Ray cluster config). Make sure to set this to more than 30% of available RAM.\n",
      "\t1.0\t = Validation score   (accuracy)\n",
      "\t1.86s\t = Training   runtime\n",
      "\t0.04s\t = Validation runtime\n",
      "Fitting model: LightGBM_BAG_L1 ...\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t1.0\t = Validation score   (accuracy)\n",
      "\t1.96s\t = Training   runtime\n",
      "\t0.04s\t = Validation runtime\n",
      "Fitting model: RandomForestGini_BAG_L1 ...\n",
      "\t0.8604\t = Validation score   (accuracy)\n",
      "\t3.34s\t = Training   runtime\n",
      "\t2.07s\t = Validation runtime\n",
      "Fitting model: RandomForestEntr_BAG_L1 ...\n",
      "\t0.8604\t = Validation score   (accuracy)\n",
      "\t3.67s\t = Training   runtime\n",
      "\t2.08s\t = Validation runtime\n",
      "Fitting model: CatBoost_BAG_L1 ...\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "2022-05-12 15:01:12,497\tWARNING worker.py:1228 -- A worker died or was killed while executing a task by an unexpected system error. To troubleshoot the problem, check the logs for the dead worker. RayTask ID: 5576d9e8d786fd3831e2fb1642d06f17d2ca6a3d9f2c3b5b Worker ID: 06a0212727dcb43f2f8b0e4f070f9ae3e8d8ad8b60d1022a4fec9b9b Node ID: 9c4110c72cae824271f2eb8b3e304b3fb63d3335a6c0b4a7cf5926f2 Worker IP address: 192.168.0.133 Worker port: 41667 Worker PID: 24679\n",
      "2022-05-12 15:01:12,497\tWARNING worker.py:1228 -- 3 retries left for task 34c9c2094e42fdbfffffffffffffffffffffffff01000000, attempting to resubmit.\n",
      "2022-05-12 15:01:12,518\tWARNING worker.py:1228 -- A worker died or was killed while executing a task by an unexpected system error. To troubleshoot the problem, check the logs for the dead worker. RayTask ID: 0e4ea71cf54a3b31ac466e71d4d6e3ea4c635a1956910dce Worker ID: 8f0b3162507f380442faa9583010b3aaef7d5425d0fafcc485ec24c1 Node ID: 9c4110c72cae824271f2eb8b3e304b3fb63d3335a6c0b4a7cf5926f2 Worker IP address: 192.168.0.133 Worker port: 42463 Worker PID: 24678\n",
      "2022-05-12 15:01:12,519\tWARNING worker.py:1228 -- 3 retries left for task 27c0dca5954f99afffffffffffffffffffffffff01000000, attempting to resubmit.\n",
      "2022-05-12 15:01:12,529\tWARNING worker.py:1228 -- A worker died or was killed while executing a task by an unexpected system error. To troubleshoot the problem, check the logs for the dead worker. RayTask ID: ccfd6f7e50fd3fc433f4cb17bc0acb93413d5ef040310b1d Worker ID: b5c2bc396bdc5f915444ebe06e11fb968b88a9961b45b0fce9bc61bf Node ID: 9c4110c72cae824271f2eb8b3e304b3fb63d3335a6c0b4a7cf5926f2 Worker IP address: 192.168.0.133 Worker port: 43057 Worker PID: 24674\n",
      "2022-05-12 15:01:12,530\tWARNING worker.py:1228 -- 3 retries left for task 24eed4584329c19affffffffffffffffffffffff01000000, attempting to resubmit.\n",
      "2022-05-12 15:01:12,551\tWARNING worker.py:1228 -- A worker died or was killed while executing a task by an unexpected system error. To troubleshoot the problem, check the logs for the dead worker. RayTask ID: 3ea139a76dbf50b40333d4ee3af677ec7570df3a7664f15e Worker ID: 52cdadd459fa21ab91dc62b0aee45f5a64f58c07ad35931d753b3315 Node ID: 9c4110c72cae824271f2eb8b3e304b3fb63d3335a6c0b4a7cf5926f2 Worker IP address: 192.168.0.133 Worker port: 46603 Worker PID: 24677\n",
      "2022-05-12 15:01:12,551\tWARNING worker.py:1228 -- 3 retries left for task 42867781e3b6e074ffffffffffffffffffffffff01000000, attempting to resubmit.\n",
      "2022-05-12 15:01:12,562\tWARNING worker.py:1228 -- A worker died or was killed while executing a task by an unexpected system error. To troubleshoot the problem, check the logs for the dead worker. RayTask ID: e2133c6e67f27ced72baba12b691afe890e46b9afb1ccdb1 Worker ID: 7926188c758c5e1af97cf929f9abfe2bfd64afee6c9a26844362369f Node ID: 9c4110c72cae824271f2eb8b3e304b3fb63d3335a6c0b4a7cf5926f2 Worker IP address: 192.168.0.133 Worker port: 36313 Worker PID: 24681\n",
      "2022-05-12 15:01:12,562\tWARNING worker.py:1228 -- 3 retries left for task e11fe2800445c79affffffffffffffffffffffff01000000, attempting to resubmit.\n",
      "2022-05-12 15:01:12,583\tWARNING worker.py:1228 -- A worker died or was killed while executing a task by an unexpected system error. To troubleshoot the problem, check the logs for the dead worker. RayTask ID: dcf0d329d3636c64cc8d632aa63a05dac49345b6eeaabaa8 Worker ID: b8ee4981b176187f14dee692a2cd7983880b72b953cd99c612430df8 Node ID: 9c4110c72cae824271f2eb8b3e304b3fb63d3335a6c0b4a7cf5926f2 Worker IP address: 192.168.0.133 Worker port: 39187 Worker PID: 24676\n",
      "2022-05-12 15:01:12,583\tWARNING worker.py:1228 -- 3 retries left for task cc0320e00aa0584cffffffffffffffffffffffff01000000, attempting to resubmit.\n",
      "2022-05-12 15:01:21,837\tWARNING worker.py:1228 -- A worker died or was killed while executing a task by an unexpected system error. To troubleshoot the problem, check the logs for the dead worker. RayTask ID: c5182b791f0d6658cfc9ee527e3f168d6452037809d05d98 Worker ID: 5a198c7390d93f29cdea94a6929d314c707215f3f3c392c0dad6ac50 Node ID: 9c4110c72cae824271f2eb8b3e304b3fb63d3335a6c0b4a7cf5926f2 Worker IP address: 192.168.0.133 Worker port: 40715 Worker PID: 25091\n",
      "2022-05-12 15:01:21,837\tWARNING worker.py:1228 -- 2 retries left for task e11fe2800445c79affffffffffffffffffffffff01000000, attempting to resubmit.\n",
      "2022-05-12 15:01:21,858\tWARNING worker.py:1228 -- A worker died or was killed while executing a task by an unexpected system error. To troubleshoot the problem, check the logs for the dead worker. RayTask ID: d8d0190623c15095efa141a3d0012779d55d3207d82ce539 Worker ID: 4c2feaf6be0f1e5372b29a8d02c21a6d72f17fc3e97dbe1daa342570 Node ID: 9c4110c72cae824271f2eb8b3e304b3fb63d3335a6c0b4a7cf5926f2 Worker IP address: 192.168.0.133 Worker port: 36433 Worker PID: 25089\n",
      "2022-05-12 15:01:21,859\tWARNING worker.py:1228 -- 2 retries left for task 24eed4584329c19affffffffffffffffffffffff01000000, attempting to resubmit.\n",
      "2022-05-12 15:01:21,879\tWARNING worker.py:1228 -- A worker died or was killed while executing a task by an unexpected system error. To troubleshoot the problem, check the logs for the dead worker. RayTask ID: b71454560f743e17832da8d9d9fbe70c164902afe34266bb Worker ID: 91b9e0fa42d15f33bf04e0624071fe98a2c73cbd9b8be9d2d9cc54f7 Node ID: 9c4110c72cae824271f2eb8b3e304b3fb63d3335a6c0b4a7cf5926f2 Worker IP address: 192.168.0.133 Worker port: 43367 Worker PID: 25092\n",
      "2022-05-12 15:01:21,880\tWARNING worker.py:1228 -- 2 retries left for task cc0320e00aa0584cffffffffffffffffffffffff01000000, attempting to resubmit.\n",
      "\t1.0\t = Validation score   (accuracy)\n",
      "\t23.66s\t = Training   runtime\n",
      "\t0.02s\t = Validation runtime\n",
      "Fitting model: ExtraTreesGini_BAG_L1 ...\n",
      "\t0.8609\t = Validation score   (accuracy)\n",
      "\t2.67s\t = Training   runtime\n",
      "\t2.26s\t = Validation runtime\n",
      "Fitting model: ExtraTreesEntr_BAG_L1 ...\n",
      "\t0.8609\t = Validation score   (accuracy)\n",
      "\t2.65s\t = Training   runtime\n",
      "\t2.28s\t = Validation runtime\n",
      "Fitting model: NeuralNetFastAI_BAG_L1 ...\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "2022-05-12 15:02:10,823\tWARNING worker.py:1228 -- This worker was asked to execute a function that it does not have registered. You may have to restart Ray.\n",
      "2022-05-12 15:02:10,824\tWARNING worker.py:1228 -- This worker was asked to execute a function that it does not have registered. You may have to restart Ray.\n",
      "2022-05-12 15:02:11,457\tWARNING worker.py:1228 -- This worker was asked to execute a function that it does not have registered. You may have to restart Ray.\n",
      "2022-05-12 15:02:12,332\tWARNING worker.py:1228 -- This worker was asked to execute a function that it does not have registered. You may have to restart Ray.\n",
      "2022-05-12 15:02:12,333\tWARNING worker.py:1228 -- This worker was asked to execute a function that it does not have registered. You may have to restart Ray.\n",
      "2022-05-12 15:02:12,333\tWARNING worker.py:1228 -- This worker was asked to execute a function that it does not have registered. You may have to restart Ray.\n",
      "2022-05-12 15:02:12,354\tWARNING worker.py:1228 -- This worker was asked to execute a function that it does not have registered. You may have to restart Ray.\n",
      "2022-05-12 15:03:53,677\tWARNING worker.py:1228 -- A worker died or was killed while executing a task by an unexpected system error. To troubleshoot the problem, check the logs for the dead worker. RayTask ID: b221402f07a770292d89fcddf9a4a72b7f1178337f9bd047 Worker ID: 160ad94954078abf7cbd535a530201844c85b67bd07c019e1e438e33 Node ID: 9c4110c72cae824271f2eb8b3e304b3fb63d3335a6c0b4a7cf5926f2 Worker IP address: 192.168.0.133 Worker port: 36553 Worker PID: 25414\n",
      "2022-05-12 15:03:54,289\tWARNING worker.py:1228 -- 3 retries left for task 139e431dd460af76ffffffffffffffffffffffff01000000, attempting to resubmit.\n",
      "2022-05-12 15:04:16,791\tWARNING worker.py:1228 -- A worker died or was killed while executing a task by an unexpected system error. To troubleshoot the problem, check the logs for the dead worker. RayTask ID: c1c12d75fd973f979364a65ac45abaa509ab7568eb7d28c3 Worker ID: 7ec017bb5362d8a63d315e2e2422dfe758e5203f84fb710c0121e750 Node ID: 9c4110c72cae824271f2eb8b3e304b3fb63d3335a6c0b4a7cf5926f2 Worker IP address: 192.168.0.133 Worker port: 36647 Worker PID: 25720\n",
      "2022-05-12 15:04:17,047\tWARNING worker.py:1228 -- 3 retries left for task bbde8638d39a1245ffffffffffffffffffffffff01000000, attempting to resubmit.\n",
      "2022-05-12 15:05:45,610\tWARNING worker.py:1228 -- This worker was asked to execute a function that it does not have registered. You may have to restart Ray.\n",
      "\t0.6437\t = Validation score   (accuracy)\n",
      "\t269.01s\t = Training   runtime\n",
      "\t2.44s\t = Validation runtime\n",
      "Fitting model: XGBoost_BAG_L1 ...\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t0.8709\t = Validation score   (accuracy)\n",
      "\t12.32s\t = Training   runtime\n",
      "\t0.11s\t = Validation runtime\n",
      "Fitting model: NeuralNetTorch_BAG_L1 ...\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "2022-05-12 15:07:55,654\tWARNING worker.py:1228 -- A worker died or was killed while executing a task by an unexpected system error. To troubleshoot the problem, check the logs for the dead worker. RayTask ID: 41d43e3eb6bbf4dd02cc385717aa3f67d62d09b5c01f1ac6 Worker ID: c2fd5a62f11b9981aad9b3c003c8339b6e95d69dec6f90b5f093bb52 Node ID: 9c4110c72cae824271f2eb8b3e304b3fb63d3335a6c0b4a7cf5926f2 Worker IP address: 192.168.0.133 Worker port: 34333 Worker PID: 26283\n",
      "2022-05-12 15:07:56,329\tWARNING worker.py:1228 -- 3 retries left for task 6f4f08f301901921ffffffffffffffffffffffff01000000, attempting to resubmit.\n",
      "2022-05-12 15:08:56,482\tWARNING worker.py:1228 -- A worker died or was killed while executing a task by an unexpected system error. To troubleshoot the problem, check the logs for the dead worker. RayTask ID: 0b9a547fb7754b8ef26014bc642f1d64e8aab48a1e887ca9 Worker ID: 4a2d052d6d6c6f0fbe9faf3bfd99f1f5cbf39894c6475f24ad7179ac Node ID: 9c4110c72cae824271f2eb8b3e304b3fb63d3335a6c0b4a7cf5926f2 Worker IP address: 192.168.0.133 Worker port: 45029 Worker PID: 26533\n",
      "2022-05-12 15:08:56,736\tWARNING worker.py:1228 -- 3 retries left for task 7513710212de102affffffffffffffffffffffff01000000, attempting to resubmit.\n",
      "2022-05-12 15:09:20,019\tWARNING worker.py:1228 -- A worker died or was killed while executing a task by an unexpected system error. To troubleshoot the problem, check the logs for the dead worker. RayTask ID: 9bfc8a26f2a30feceb63f13cdde42dd39464a068dc1ecf18 Worker ID: db56e3e9d04c738049c95f4c463fc5c95780adcb0bdc4ebc9f2ed49c Node ID: 9c4110c72cae824271f2eb8b3e304b3fb63d3335a6c0b4a7cf5926f2 Worker IP address: 192.168.0.133 Worker port: 45011 Worker PID: 26527\n",
      "2022-05-12 15:09:20,020\tWARNING worker.py:1228 -- 2 retries left for task 6f4f08f301901921ffffffffffffffffffffffff01000000, attempting to resubmit.\n",
      "2022-05-12 15:09:56,894\tWARNING worker.py:1228 -- This worker was asked to execute a function that it does not have registered. You may have to restart Ray.\n",
      "2022-05-12 15:09:56,895\tWARNING worker.py:1228 -- This worker was asked to execute a function that it does not have registered. You may have to restart Ray.\n",
      "\t0.871\t = Validation score   (accuracy)\n",
      "\t260.84s\t = Training   runtime\n",
      "\t0.81s\t = Validation runtime\n",
      "Fitting model: LightGBMLarge_BAG_L1 ...\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t1.0\t = Validation score   (accuracy)\n",
      "\t10.75s\t = Training   runtime\n",
      "\t0.04s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L2 ...\n",
      "\t1.0\t = Validation score   (accuracy)\n",
      "\t25.34s\t = Training   runtime\n",
      "\t0.12s\t = Validation runtime\n",
      "Fitting 11 L2 models ...\n",
      "Fitting model: LightGBMXT_BAG_L2 ...\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t1.0\t = Validation score   (accuracy)\n",
      "\t4.77s\t = Training   runtime\n",
      "\t0.05s\t = Validation runtime\n",
      "Fitting model: LightGBM_BAG_L2 ...\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t1.0\t = Validation score   (accuracy)\n",
      "\t4.79s\t = Training   runtime\n",
      "\t0.05s\t = Validation runtime\n",
      "Fitting model: RandomForestGini_BAG_L2 ...\n",
      "\t1.0\t = Validation score   (accuracy)\n",
      "\t4.22s\t = Training   runtime\n",
      "\t2.01s\t = Validation runtime\n",
      "Fitting model: RandomForestEntr_BAG_L2 ...\n",
      "\t1.0\t = Validation score   (accuracy)\n",
      "\t1.95s\t = Training   runtime\n",
      "\t1.76s\t = Validation runtime\n",
      "Fitting model: CatBoost_BAG_L2 ...\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "2022-05-12 15:12:44,918\tWARNING worker.py:1228 -- A worker died or was killed while executing a task by an unexpected system error. To troubleshoot the problem, check the logs for the dead worker. RayTask ID: 001fdf57bd661db1e31020b683e22dc1ca5f77cba963f685 Worker ID: d8a05b9d834b3c2c480e4978de659cd71416b89a16e5f17037af7587 Node ID: 9c4110c72cae824271f2eb8b3e304b3fb63d3335a6c0b4a7cf5926f2 Worker IP address: 192.168.0.133 Worker port: 45425 Worker PID: 27939\n",
      "2022-05-12 15:12:44,919\tWARNING worker.py:1228 -- 3 retries left for task b9c64831282591f9ffffffffffffffffffffffff01000000, attempting to resubmit.\n",
      "2022-05-12 15:12:44,929\tWARNING worker.py:1228 -- A worker died or was killed while executing a task by an unexpected system error. To troubleshoot the problem, check the logs for the dead worker. RayTask ID: bf348d007f72fc6dff6819a61720a3caf75566f5e7ae123d Worker ID: 72de8948605698cb2e4c0b90895ddd68ccf54bd0e0c328124163130e Node ID: 9c4110c72cae824271f2eb8b3e304b3fb63d3335a6c0b4a7cf5926f2 Worker IP address: 192.168.0.133 Worker port: 43773 Worker PID: 27933\n",
      "2022-05-12 15:12:44,930\tWARNING worker.py:1228 -- 3 retries left for task aae99729138a74d2ffffffffffffffffffffffff01000000, attempting to resubmit.\n",
      "2022-05-12 15:12:44,951\tWARNING worker.py:1228 -- A worker died or was killed while executing a task by an unexpected system error. To troubleshoot the problem, check the logs for the dead worker. RayTask ID: 432c04c5b1dc2b97dd6846291bc4bcf484ceff1009984cb9 Worker ID: 53c53ae4a796d4525c2417be78264bfded41b4c25f1c437314eaf33e Node ID: 9c4110c72cae824271f2eb8b3e304b3fb63d3335a6c0b4a7cf5926f2 Worker IP address: 192.168.0.133 Worker port: 36785 Worker PID: 27936\n",
      "2022-05-12 15:12:44,952\tWARNING worker.py:1228 -- 3 retries left for task 2638cdc57fda8d43ffffffffffffffffffffffff01000000, attempting to resubmit.\n",
      "2022-05-12 15:12:44,972\tWARNING worker.py:1228 -- A worker died or was killed while executing a task by an unexpected system error. To troubleshoot the problem, check the logs for the dead worker. RayTask ID: d65c3ed59b7fd03688bf61ac02d5c7f35345a6d67f574823 Worker ID: 481433a3c77c17a102e5599bf3a04e9b0b536b823b95d49789f97613 Node ID: 9c4110c72cae824271f2eb8b3e304b3fb63d3335a6c0b4a7cf5926f2 Worker IP address: 192.168.0.133 Worker port: 41857 Worker PID: 27934\n",
      "2022-05-12 15:12:44,973\tWARNING worker.py:1228 -- 3 retries left for task c0e56a21dcb5fe64ffffffffffffffffffffffff01000000, attempting to resubmit.\n",
      "2022-05-12 15:12:44,994\tWARNING worker.py:1228 -- A worker died or was killed while executing a task by an unexpected system error. To troubleshoot the problem, check the logs for the dead worker. RayTask ID: a47b4af9149bb466ddb4ab613ac4fa43be7702788f16c21b Worker ID: 897a99b30bf89e266aa182f756df47facec35ac7ef56058f121aaba3 Node ID: 9c4110c72cae824271f2eb8b3e304b3fb63d3335a6c0b4a7cf5926f2 Worker IP address: 192.168.0.133 Worker port: 38915 Worker PID: 27935\n",
      "2022-05-12 15:12:44,994\tWARNING worker.py:1228 -- 3 retries left for task 764f8475f05bf001ffffffffffffffffffffffff01000000, attempting to resubmit.\n",
      "2022-05-12 15:12:53,857\tWARNING worker.py:1228 -- A worker died or was killed while executing a task by an unexpected system error. To troubleshoot the problem, check the logs for the dead worker. RayTask ID: a28387e09a5b062bd173dfd8b05576d492cb3999a42e36d2 Worker ID: 5e732a8cbf22aa8c4bc0ff97044cbdd4ca2d00becdb2cbbd1276c2d5 Node ID: 9c4110c72cae824271f2eb8b3e304b3fb63d3335a6c0b4a7cf5926f2 Worker IP address: 192.168.0.133 Worker port: 33841 Worker PID: 28350\n",
      "2022-05-12 15:12:53,857\tWARNING worker.py:1228 -- 2 retries left for task c0e56a21dcb5fe64ffffffffffffffffffffffff01000000, attempting to resubmit.\n",
      "2022-05-12 15:12:53,868\tWARNING worker.py:1228 -- A worker died or was killed while executing a task by an unexpected system error. To troubleshoot the problem, check the logs for the dead worker. RayTask ID: c55d0ba96bd6420fe46cfef1aa764ccc6831765637cb5db5 Worker ID: facb13396cec706d9d3b77bca4bda3221bb9fbb83f7d95a7749d38d2 Node ID: 9c4110c72cae824271f2eb8b3e304b3fb63d3335a6c0b4a7cf5926f2 Worker IP address: 192.168.0.133 Worker port: 39889 Worker PID: 28351\n",
      "2022-05-12 15:12:53,868\tWARNING worker.py:1228 -- 2 retries left for task 764f8475f05bf001ffffffffffffffffffffffff01000000, attempting to resubmit.\n",
      "\t1.0\t = Validation score   (accuracy)\n",
      "\t28.75s\t = Training   runtime\n",
      "\t0.03s\t = Validation runtime\n",
      "Fitting model: ExtraTreesGini_BAG_L2 ...\n",
      "\t1.0\t = Validation score   (accuracy)\n",
      "\t1.34s\t = Training   runtime\n",
      "\t1.76s\t = Validation runtime\n",
      "Fitting model: ExtraTreesEntr_BAG_L2 ...\n",
      "\t1.0\t = Validation score   (accuracy)\n",
      "\t1.34s\t = Training   runtime\n",
      "\t1.75s\t = Validation runtime\n",
      "Fitting model: NeuralNetFastAI_BAG_L2 ...\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "2022-05-12 15:14:03,682\tWARNING worker.py:1228 -- A worker died or was killed while executing a task by an unexpected system error. To troubleshoot the problem, check the logs for the dead worker. RayTask ID: 6f18dda447272904b6c8d578bb02a394dff8291a9af9f922 Worker ID: 39a334c81443dc671947c1e8ca3d959efb62cda658afa1b3d9151eee Node ID: 9c4110c72cae824271f2eb8b3e304b3fb63d3335a6c0b4a7cf5926f2 Worker IP address: 192.168.0.133 Worker port: 37455 Worker PID: 28644\n",
      "2022-05-12 15:14:04,425\tWARNING worker.py:1228 -- 3 retries left for task faf123d8b1b35293ffffffffffffffffffffffff01000000, attempting to resubmit.\n",
      "2022-05-12 15:14:28,730\tWARNING worker.py:1228 -- A worker died or was killed while executing a task by an unexpected system error. To troubleshoot the problem, check the logs for the dead worker. RayTask ID: 5359a2728ce5d590cd0c6382e16cf0a4ca49d064f63f3069 Worker ID: c2c135a01a70d1379d97bbe37aace5c4ebd44580d8a79ba4c9186114 Node ID: 9c4110c72cae824271f2eb8b3e304b3fb63d3335a6c0b4a7cf5926f2 Worker IP address: 192.168.0.133 Worker port: 46381 Worker PID: 28830\n",
      "2022-05-12 15:14:29,494\tWARNING worker.py:1228 -- 3 retries left for task 6346e12fbb9bd273ffffffffffffffffffffffff01000000, attempting to resubmit.\n",
      "2022-05-12 15:15:57,869\tWARNING worker.py:1228 -- This worker was asked to execute a function that it does not have registered. You may have to restart Ray.\n",
      "\t1.0\t = Validation score   (accuracy)\n",
      "\t220.44s\t = Training   runtime\n",
      "\t1.26s\t = Validation runtime\n",
      "Fitting model: XGBoost_BAG_L2 ...\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t1.0\t = Validation score   (accuracy)\n",
      "\t12.68s\t = Training   runtime\n",
      "\t0.14s\t = Validation runtime\n",
      "Fitting model: NeuralNetTorch_BAG_L2 ...\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "2022-05-12 15:17:48,768\tWARNING worker.py:1228 -- A worker died or was killed while executing a task by an unexpected system error. To troubleshoot the problem, check the logs for the dead worker. RayTask ID: b85b4f6c3aac5c826dd700db96d73b8d2be13385e69f4f6f Worker ID: d9ee71cd7bb892da220690645099d632f0c14ad2cfef2bbac0fccd7b Node ID: 9c4110c72cae824271f2eb8b3e304b3fb63d3335a6c0b4a7cf5926f2 Worker IP address: 192.168.0.133 Worker port: 36915 Worker PID: 29367\n",
      "2022-05-12 15:17:49,685\tWARNING worker.py:1228 -- 3 retries left for task 671f1fd57bc3e36effffffffffffffffffffffff01000000, attempting to resubmit.\n",
      "\tWarning: Exception caused NeuralNetTorch_BAG_L2 to fail during training... Skipping this model.\n",
      "\t\t\u001B[36mray::_ray_fit()\u001B[39m (pid=29629, ip=192.168.0.133)\n",
      "  File \"/media/wuguo-buaa/LENOVO_USB_HDD/PycharmProjects/Machine_learning_venv/lib/python3.8/site-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 288, in _ray_fit\n",
      "    fold_model.fit(X=X_fold, y=y_fold, X_val=X_val_fold, y_val=y_val_fold,\n",
      "  File \"/media/wuguo-buaa/LENOVO_USB_HDD/PycharmProjects/Machine_learning_venv/lib/python3.8/site-packages/autogluon/core/models/abstract/abstract_model.py\", line 577, in fit\n",
      "    out = self._fit(**kwargs)\n",
      "  File \"/media/wuguo-buaa/LENOVO_USB_HDD/PycharmProjects/Machine_learning_venv/lib/python3.8/site-packages/autogluon/tabular/models/tabular_nn/torch/tabular_nn_torch.py\", line 183, in _fit\n",
      "    self._get_net(train_dataset, params=params)\n",
      "  File \"/media/wuguo-buaa/LENOVO_USB_HDD/PycharmProjects/Machine_learning_venv/lib/python3.8/site-packages/autogluon/tabular/models/tabular_nn/torch/tabular_nn_torch.py\", line 212, in _get_net\n",
      "    self.model = self.model.to(self.device)\n",
      "  File \"/media/wuguo-buaa/LENOVO_USB_HDD/PycharmProjects/Machine_learning_venv/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 899, in to\n",
      "    return self._apply(convert)\n",
      "  File \"/media/wuguo-buaa/LENOVO_USB_HDD/PycharmProjects/Machine_learning_venv/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 570, in _apply\n",
      "    module._apply(fn)\n",
      "  File \"/media/wuguo-buaa/LENOVO_USB_HDD/PycharmProjects/Machine_learning_venv/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 570, in _apply\n",
      "    module._apply(fn)\n",
      "  File \"/media/wuguo-buaa/LENOVO_USB_HDD/PycharmProjects/Machine_learning_venv/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 593, in _apply\n",
      "    param_applied = fn(param)\n",
      "  File \"/media/wuguo-buaa/LENOVO_USB_HDD/PycharmProjects/Machine_learning_venv/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 897, in convert\n",
      "    return t.to(device, dtype if t.is_floating_point() or t.is_complex() else None, non_blocking)\n",
      "RuntimeError: CUDA error: unknown error\n",
      "CUDA kernel errors might be asynchronously reported at some other API call,so the stacktrace below might be incorrect.\n",
      "For debugging consider passing CUDA_LAUNCH_BLOCKING=1.\n",
      "Detailed Traceback:\n",
      "Traceback (most recent call last):\n",
      "  File \"/media/wuguo-buaa/LENOVO_USB_HDD/PycharmProjects/Machine_learning_venv/lib/python3.8/site-packages/autogluon/core/trainer/abstract_trainer.py\", line 1074, in _train_and_save\n",
      "    model = self._train_single(X, y, model, X_val, y_val, **model_fit_kwargs)\n",
      "  File \"/media/wuguo-buaa/LENOVO_USB_HDD/PycharmProjects/Machine_learning_venv/lib/python3.8/site-packages/autogluon/core/trainer/abstract_trainer.py\", line 1032, in _train_single\n",
      "    model = model.fit(X=X, y=y, X_val=X_val, y_val=y_val, **model_fit_kwargs)\n",
      "  File \"/media/wuguo-buaa/LENOVO_USB_HDD/PycharmProjects/Machine_learning_venv/lib/python3.8/site-packages/autogluon/core/models/abstract/abstract_model.py\", line 577, in fit\n",
      "    out = self._fit(**kwargs)\n",
      "  File \"/media/wuguo-buaa/LENOVO_USB_HDD/PycharmProjects/Machine_learning_venv/lib/python3.8/site-packages/autogluon/core/models/ensemble/stacker_ensemble_model.py\", line 153, in _fit\n",
      "    return super()._fit(X=X, y=y, time_limit=time_limit, **kwargs)\n",
      "  File \"/media/wuguo-buaa/LENOVO_USB_HDD/PycharmProjects/Machine_learning_venv/lib/python3.8/site-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 211, in _fit\n",
      "    self._fit_folds(X=X, y=y, model_base=model_base, X_pseudo=X_pseudo, y_pseudo=y_pseudo,\n",
      "  File \"/media/wuguo-buaa/LENOVO_USB_HDD/PycharmProjects/Machine_learning_venv/lib/python3.8/site-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 481, in _fit_folds\n",
      "    fold_fitting_strategy.after_all_folds_scheduled()\n",
      "  File \"/media/wuguo-buaa/LENOVO_USB_HDD/PycharmProjects/Machine_learning_venv/lib/python3.8/site-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 455, in after_all_folds_scheduled\n",
      "    raise processed_exception\n",
      "  File \"/media/wuguo-buaa/LENOVO_USB_HDD/PycharmProjects/Machine_learning_venv/lib/python3.8/site-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 423, in after_all_folds_scheduled\n",
      "    time_end_fit, predict_time, predict_1_time = self.ray.get(finished)\n",
      "  File \"/media/wuguo-buaa/LENOVO_USB_HDD/PycharmProjects/Machine_learning_venv/lib/python3.8/site-packages/ray/_private/client_mode_hook.py\", line 105, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/media/wuguo-buaa/LENOVO_USB_HDD/PycharmProjects/Machine_learning_venv/lib/python3.8/site-packages/ray/worker.py\", line 1625, in get\n",
      "    raise value.as_instanceof_cause()\n",
      "ray.exceptions.RayTaskError(RuntimeError): \u001B[36mray::_ray_fit()\u001B[39m (pid=29629, ip=192.168.0.133)\n",
      "  File \"/media/wuguo-buaa/LENOVO_USB_HDD/PycharmProjects/Machine_learning_venv/lib/python3.8/site-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 288, in _ray_fit\n",
      "    fold_model.fit(X=X_fold, y=y_fold, X_val=X_val_fold, y_val=y_val_fold,\n",
      "  File \"/media/wuguo-buaa/LENOVO_USB_HDD/PycharmProjects/Machine_learning_venv/lib/python3.8/site-packages/autogluon/core/models/abstract/abstract_model.py\", line 577, in fit\n",
      "    out = self._fit(**kwargs)\n",
      "  File \"/media/wuguo-buaa/LENOVO_USB_HDD/PycharmProjects/Machine_learning_venv/lib/python3.8/site-packages/autogluon/tabular/models/tabular_nn/torch/tabular_nn_torch.py\", line 183, in _fit\n",
      "    self._get_net(train_dataset, params=params)\n",
      "  File \"/media/wuguo-buaa/LENOVO_USB_HDD/PycharmProjects/Machine_learning_venv/lib/python3.8/site-packages/autogluon/tabular/models/tabular_nn/torch/tabular_nn_torch.py\", line 212, in _get_net\n",
      "    self.model = self.model.to(self.device)\n",
      "  File \"/media/wuguo-buaa/LENOVO_USB_HDD/PycharmProjects/Machine_learning_venv/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 899, in to\n",
      "    return self._apply(convert)\n",
      "  File \"/media/wuguo-buaa/LENOVO_USB_HDD/PycharmProjects/Machine_learning_venv/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 570, in _apply\n",
      "    module._apply(fn)\n",
      "  File \"/media/wuguo-buaa/LENOVO_USB_HDD/PycharmProjects/Machine_learning_venv/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 570, in _apply\n",
      "    module._apply(fn)\n",
      "  File \"/media/wuguo-buaa/LENOVO_USB_HDD/PycharmProjects/Machine_learning_venv/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 593, in _apply\n",
      "    param_applied = fn(param)\n",
      "  File \"/media/wuguo-buaa/LENOVO_USB_HDD/PycharmProjects/Machine_learning_venv/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 897, in convert\n",
      "    return t.to(device, dtype if t.is_floating_point() or t.is_complex() else None, non_blocking)\n",
      "RuntimeError: CUDA error: unknown error\n",
      "CUDA kernel errors might be asynchronously reported at some other API call,so the stacktrace below might be incorrect.\n",
      "For debugging consider passing CUDA_LAUNCH_BLOCKING=1.\n",
      "Fitting model: LightGBMLarge_BAG_L2 ...\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "2022-05-12 15:18:05,591\tWARNING services.py:1748 -- WARNING: The object store is using /tmp instead of /dev/shm because /dev/shm has only 3557904384 bytes available. This will harm performance! You may be able to free up space by deleting files in /dev/shm. If you are inside a Docker container, you can increase /dev/shm size by passing '--shm-size=4.14gb' to 'docker run' (or add it to the run_options list in a Ray cluster config). Make sure to set this to more than 30% of available RAM.\n",
      "\t1.0\t = Validation score   (accuracy)\n",
      "\t11.09s\t = Training   runtime\n",
      "\t0.06s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L3 ...\n",
      "\t1.0\t = Validation score   (accuracy)\n",
      "\t19.9s\t = Training   runtime\n",
      "\t0.13s\t = Validation runtime\n",
      "AutoGluon training complete, total runtime = 1184.16s ... Best model: \"WeightedEnsemble_L2\"\n",
      "Fitting model: KNeighborsUnif_BAG_L1_FULL | Skipping fit via cloning parent ...\n",
      "\t0.13s\t = Training   runtime\n",
      "\t24.61s\t = Validation runtime\n",
      "Fitting model: KNeighborsDist_BAG_L1_FULL | Skipping fit via cloning parent ...\n",
      "\t0.12s\t = Training   runtime\n",
      "\t24.4s\t = Validation runtime\n",
      "Fitting 1 L1 models ...\n",
      "Fitting model: LightGBMXT_BAG_L1_FULL ...\n",
      "\tTraining S1F1 with GPU, note that this may negatively impact model quality compared to CPU training.\n",
      "\t4.86s\t = Training   runtime\n",
      "Fitting 1 L1 models ...\n",
      "Fitting model: LightGBM_BAG_L1_FULL ...\n",
      "\tTraining S1F1 with GPU, note that this may negatively impact model quality compared to CPU training.\n",
      "\t0.24s\t = Training   runtime\n",
      "Fitting model: RandomForestGini_BAG_L1_FULL | Skipping fit via cloning parent ...\n",
      "\t3.34s\t = Training   runtime\n",
      "\t2.07s\t = Validation runtime\n",
      "Fitting model: RandomForestEntr_BAG_L1_FULL | Skipping fit via cloning parent ...\n",
      "\t3.67s\t = Training   runtime\n",
      "\t2.08s\t = Validation runtime\n",
      "Fitting 1 L1 models ...\n",
      "Fitting model: CatBoost_BAG_L1_FULL ...\n",
      "\tTraining S1F1 with GPU, note that this may negatively impact model quality compared to CPU training.\n",
      "\tWarning: CatBoost on GPU is experimental. If you encounter issues, use CPU for training CatBoost instead.\n",
      "\t4.62s\t = Training   runtime\n",
      "Fitting model: ExtraTreesGini_BAG_L1_FULL | Skipping fit via cloning parent ...\n",
      "\t2.67s\t = Training   runtime\n",
      "\t2.26s\t = Validation runtime\n",
      "Fitting model: ExtraTreesEntr_BAG_L1_FULL | Skipping fit via cloning parent ...\n",
      "\t2.65s\t = Training   runtime\n",
      "\t2.28s\t = Validation runtime\n",
      "Fitting 1 L1 models ...\n",
      "Fitting model: NeuralNetFastAI_BAG_L1_FULL ...\n",
      "\tStopping at the best epoch learned earlier - 3.\n",
      "\t28.94s\t = Training   runtime\n",
      "Fitting 1 L1 models ...\n",
      "Fitting model: XGBoost_BAG_L1_FULL ...\n",
      "\t3.07s\t = Training   runtime\n",
      "Fitting 1 L1 models ...\n",
      "Fitting model: NeuralNetTorch_BAG_L1_FULL ...\n",
      "\t54.43s\t = Training   runtime\n",
      "Fitting 1 L1 models ...\n",
      "Fitting model: LightGBMLarge_BAG_L1_FULL ...\n",
      "\tTraining S1F1 with GPU, note that this may negatively impact model quality compared to CPU training.\n",
      "\t0.24s\t = Training   runtime\n",
      "Fitting model: WeightedEnsemble_L2_FULL | Skipping fit via cloning parent ...\n",
      "\t25.34s\t = Training   runtime\n",
      "Fitting 1 L2 models ...\n",
      "Fitting model: LightGBMXT_BAG_L2_FULL ...\n",
      "\tTraining S1F1 with GPU, note that this may negatively impact model quality compared to CPU training.\n",
      "\t0.27s\t = Training   runtime\n",
      "Fitting 1 L2 models ...\n",
      "Fitting model: LightGBM_BAG_L2_FULL ...\n",
      "\tTraining S1F1 with GPU, note that this may negatively impact model quality compared to CPU training.\n",
      "\t0.28s\t = Training   runtime\n",
      "Fitting model: RandomForestGini_BAG_L2_FULL | Skipping fit via cloning parent ...\n",
      "\t4.22s\t = Training   runtime\n",
      "\t2.01s\t = Validation runtime\n",
      "Fitting model: RandomForestEntr_BAG_L2_FULL | Skipping fit via cloning parent ...\n",
      "\t1.95s\t = Training   runtime\n",
      "\t1.76s\t = Validation runtime\n",
      "Fitting 1 L2 models ...\n",
      "Fitting model: CatBoost_BAG_L2_FULL ...\n",
      "\tTraining S1F1 with GPU, note that this may negatively impact model quality compared to CPU training.\n",
      "\tWarning: CatBoost on GPU is experimental. If you encounter issues, use CPU for training CatBoost instead.\n",
      "\t0.12s\t = Training   runtime\n",
      "Fitting model: ExtraTreesGini_BAG_L2_FULL | Skipping fit via cloning parent ...\n",
      "\t1.34s\t = Training   runtime\n",
      "\t1.76s\t = Validation runtime\n",
      "Fitting model: ExtraTreesEntr_BAG_L2_FULL | Skipping fit via cloning parent ...\n",
      "\t1.34s\t = Training   runtime\n",
      "\t1.75s\t = Validation runtime\n",
      "Fitting 1 L2 models ...\n",
      "Fitting model: NeuralNetFastAI_BAG_L2_FULL ...\n",
      "\tStopping at the best epoch learned earlier - 8.\n",
      "\t21.0s\t = Training   runtime\n",
      "Fitting 1 L2 models ...\n",
      "Fitting model: XGBoost_BAG_L2_FULL ...\n",
      "\t0.26s\t = Training   runtime\n",
      "Fitting 1 L2 models ...\n",
      "Fitting model: LightGBMLarge_BAG_L2_FULL ...\n",
      "\tTraining S1F1 with GPU, note that this may negatively impact model quality compared to CPU training.\n",
      "\t0.29s\t = Training   runtime\n",
      "Fitting model: WeightedEnsemble_L3_FULL | Skipping fit via cloning parent ...\n",
      "\t19.9s\t = Training   runtime\n",
      "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"./auto_gl/exp-iot23/high_q/\")\n"
     ]
    }
   ],
   "source": [
    "from autogluon.tabular import TabularDataset\n",
    "import autogluon\n",
    "\n",
    "label = 'label'\n",
    "train_data = TabularDataset(\"./Data/split/train_data.csv\")\n",
    "save_path = './auto_gl/exp-iot23/high_q'  # specifies folder to store trained models\n",
    "from autogluon.tabular import TabularPredictor\n",
    "predictor_high = TabularPredictor(label=label, path=save_path).fit(train_data, ag_args_fit={'num_gpus': 1},                                                              presets='high_quality')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** Summary of fit() ***\n",
      "Estimated performance of each model:\n",
      "                           model  score_val  pred_time_val    fit_time  pred_time_val_marginal  fit_time_marginal  stack_level  can_infer  fit_order\n",
      "0                CatBoost_BAG_L1   1.000000       0.016600   23.659507                0.016600          23.659507            1      False          7\n",
      "1              LightGBMXT_BAG_L1   1.000000       0.035022    1.856974                0.035022           1.856974            1      False          3\n",
      "2           LightGBMLarge_BAG_L1   1.000000       0.038616   10.746465                0.038616          10.746465            1      False         13\n",
      "3                LightGBM_BAG_L1   1.000000       0.041969    1.958253                0.041969           1.958253            1      False          4\n",
      "4            WeightedEnsemble_L2   1.000000       0.157289   27.195524                0.122266          25.338550            2      False         14\n",
      "5                CatBoost_BAG_L2   1.000000      61.214887  621.729176                0.031606          28.754601            2      False         19\n",
      "6                LightGBM_BAG_L2   1.000000      61.232831  597.763436                0.049550           4.788861            2      False         16\n",
      "7              LightGBMXT_BAG_L2   1.000000      61.233541  597.745317                0.050260           4.770741            2      False         15\n",
      "8           LightGBMLarge_BAG_L2   1.000000      61.242990  604.060338                0.059709          11.085763            2      False         24\n",
      "9                 XGBoost_BAG_L2   1.000000      61.324853  605.652658                0.141572          12.678082            2      False         23\n",
      "10         ExtraTreesEntr_BAG_L2   1.000000      62.937403  594.314496                1.754122           1.339921            2      False         21\n",
      "11       RandomForestEntr_BAG_L2   1.000000      62.945439  594.928093                1.762158           1.953518            2      False         18\n",
      "12         ExtraTreesGini_BAG_L2   1.000000      62.946283  594.313286                1.763002           1.338711            2      False         20\n",
      "13           WeightedEnsemble_L3   1.000000      63.071484  614.212137                0.125201          19.898851            3      False         25\n",
      "14       RandomForestGini_BAG_L2   1.000000      63.195164  597.199162                2.011883           4.224587            2      False         17\n",
      "15        NeuralNetFastAI_BAG_L2   0.999992      62.445103  813.413985                1.261822         220.439410            2      False         22\n",
      "16         NeuralNetTorch_BAG_L1   0.870993       0.811856  260.839062                0.811856         260.839062            1      False         12\n",
      "17                XGBoost_BAG_L1   0.870852       0.112619   12.324926                0.112619          12.324926            1      False         11\n",
      "18         ExtraTreesEntr_BAG_L1   0.860930       2.275418    2.645035                2.275418           2.645035            1       True          9\n",
      "19         ExtraTreesGini_BAG_L1   0.860906       2.255471    2.672107                2.255471           2.672107            1       True          8\n",
      "20       RandomForestGini_BAG_L1   0.860419       2.068322    3.339995                2.068322           3.339995            1       True          5\n",
      "21       RandomForestEntr_BAG_L1   0.860410       2.081737    3.670271                2.081737           3.670271            1       True          6\n",
      "22         KNeighborsUnif_BAG_L1   0.733607      24.610187    0.127796               24.610187           0.127796            1       True          1\n",
      "23         KNeighborsDist_BAG_L1   0.723743      24.396994    0.121297               24.396994           0.121297            1       True          2\n",
      "24        NeuralNetFastAI_BAG_L1   0.643692       2.438470  269.012887                2.438470         269.012887            1      False         10\n",
      "25  RandomForestGini_BAG_L1_FULL        NaN       2.068322    3.339995                2.068322           3.339995            1       True         30\n",
      "26  RandomForestEntr_BAG_L1_FULL        NaN       2.081737    3.670271                2.081737           3.670271            1       True         31\n",
      "27    ExtraTreesGini_BAG_L1_FULL        NaN       2.255471    2.672107                2.255471           2.672107            1       True         33\n",
      "28    ExtraTreesEntr_BAG_L1_FULL        NaN       2.275418    2.645035                2.275418           2.645035            1       True         34\n",
      "29    KNeighborsDist_BAG_L1_FULL        NaN      24.396994    0.121297               24.396994           0.121297            1       True         27\n",
      "30    KNeighborsUnif_BAG_L1_FULL        NaN      24.610187    0.127796               24.610187           0.127796            1       True         26\n",
      "31           XGBoost_BAG_L2_FULL        NaN            NaN  109.227386                     NaN           0.256261            2       True         48\n",
      "32           XGBoost_BAG_L1_FULL        NaN            NaN    3.070240                     NaN           3.070240            1       True         36\n",
      "33      WeightedEnsemble_L3_FULL        NaN            NaN  130.208687                     NaN          19.898851            3       True         50\n",
      "34      WeightedEnsemble_L2_FULL        NaN            NaN   30.195099                     NaN          25.338550            2       True         39\n",
      "35  RandomForestGini_BAG_L2_FULL        NaN            NaN  113.195713                2.011883           4.224587            2       True         42\n",
      "36  RandomForestEntr_BAG_L2_FULL        NaN            NaN  110.924643                1.762158           1.953518            2       True         43\n",
      "37    NeuralNetTorch_BAG_L1_FULL        NaN            NaN   54.433322                     NaN          54.433322            1       True         37\n",
      "38   NeuralNetFastAI_BAG_L2_FULL        NaN            NaN  129.975572                     NaN          21.004447            2       True         47\n",
      "39   NeuralNetFastAI_BAG_L1_FULL        NaN            NaN   28.937116                     NaN          28.937116            1       True         35\n",
      "40          LightGBM_BAG_L2_FULL        NaN            NaN  109.252347                     NaN           0.281222            2       True         41\n",
      "41          LightGBM_BAG_L1_FULL        NaN            NaN    0.237376                     NaN           0.237376            1       True         29\n",
      "42        LightGBMXT_BAG_L2_FULL        NaN            NaN  109.245672                     NaN           0.274547            2       True         40\n",
      "43        LightGBMXT_BAG_L1_FULL        NaN            NaN    4.856549                     NaN           4.856549            1       True         28\n",
      "44     LightGBMLarge_BAG_L2_FULL        NaN            NaN  109.259349                     NaN           0.288223            2       True         49\n",
      "45     LightGBMLarge_BAG_L1_FULL        NaN            NaN    0.240868                     NaN           0.240868            1       True         38\n",
      "46    ExtraTreesGini_BAG_L2_FULL        NaN            NaN  110.309836                1.763002           1.338711            2       True         45\n",
      "47    ExtraTreesEntr_BAG_L2_FULL        NaN            NaN  110.311046                1.754122           1.339921            2       True         46\n",
      "48          CatBoost_BAG_L2_FULL        NaN            NaN  109.089105                     NaN           0.117979            2       True         44\n",
      "49          CatBoost_BAG_L1_FULL        NaN            NaN    4.619153                     NaN           4.619153            1       True         32\n",
      "Number of models trained: 50\n",
      "Types of models trained:\n",
      "{'StackerEnsembleModel_XGBoost', 'StackerEnsembleModel_NNFastAiTabular', 'WeightedEnsembleModel', 'StackerEnsembleModel_CatBoost', 'StackerEnsembleModel_RF', 'StackerEnsembleModel_LGB', 'StackerEnsembleModel_TabularNeuralNetTorch', 'StackerEnsembleModel_XT', 'StackerEnsembleModel_KNN'}\n",
      "Bagging used: True  (with 8 folds)\n",
      "Multi-layer stack-ensembling used: True  (with 3 levels)\n",
      "Feature Metadata (Processed):\n",
      "(raw dtype, special dtypes):\n",
      "('float', [])     :  7 | ['duration', 'missed_bytes', 'orig_pkts', 'orig_ip_bytes', 'resp_pkts', ...]\n",
      "('int', [])       :  2 | ['orig_bytes', 'resp_bytes']\n",
      "('int', ['bool']) : 21 | ['proto_tcp', 'proto_udp', 'service_-', 'service_dhcp', 'service_dns', ...]\n",
      "*** End of fit() summary ***\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/media/wuguo-buaa/LENOVO_USB_HDD/PycharmProjects/Machine_learning_venv/lib/python3.8/site-packages/autogluon/core/utils/plots.py:138: UserWarning: AutoGluon summary plots cannot be created because bokeh is not installed. To see plots, please do: \"pip install bokeh==2.0.1\"\n",
      "  warnings.warn('AutoGluon summary plots cannot be created because bokeh is not installed. To see plots, please do: \"pip install bokeh==2.0.1\"')\n"
     ]
    }
   ],
   "source": [
    "from autogluon.tabular import TabularPredictor\n",
    "# RF_predictor = TabularPredictor.load(\n",
    "#     '/media/wuguo-buaa/LENOVO_USB_HDD/PycharmProjects/Anomaly-Detection-IoT23/Models/auto_gl/exp-iot23/best_q/')\n",
    "results_high = predictor_high.fit_summary(show_plot=True)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                           model  score_test  score_val  pred_time_test  pred_time_val    fit_time  pred_time_test_marginal  pred_time_val_marginal  fit_time_marginal  stack_level  can_infer  fit_order\n",
      "0         LightGBMXT_BAG_L1_FULL    1.000000        NaN        0.004901            NaN    4.856549                 0.004901                     NaN           4.856549            1       True         28\n",
      "1           CatBoost_BAG_L1_FULL    1.000000        NaN        0.005472            NaN    4.619153                 0.005472                     NaN           4.619153            1       True         32\n",
      "2           LightGBM_BAG_L1_FULL    1.000000        NaN        0.005914            NaN    0.237376                 0.005914                     NaN           0.237376            1       True         29\n",
      "3       WeightedEnsemble_L2_FULL    1.000000        NaN        0.006500            NaN   30.195099                 0.001599                     NaN          25.338550            2       True         39\n",
      "4      LightGBMLarge_BAG_L1_FULL    1.000000        NaN        0.013608            NaN    0.240868                 0.013608                     NaN           0.240868            1       True         38\n",
      "5           LightGBM_BAG_L2_FULL    1.000000        NaN        5.459824            NaN  109.252347                 0.009350                     NaN           0.281222            2       True         41\n",
      "6         LightGBMXT_BAG_L2_FULL    1.000000        NaN        5.459951            NaN  109.245672                 0.009477                     NaN           0.274547            2       True         40\n",
      "7      LightGBMLarge_BAG_L2_FULL    1.000000        NaN        5.473377            NaN  109.259349                 0.022903                     NaN           0.288223            2       True         49\n",
      "8            XGBoost_BAG_L2_FULL    1.000000        NaN        5.476804            NaN  109.227386                 0.026330                     NaN           0.256261            2       True         48\n",
      "9           CatBoost_BAG_L2_FULL    1.000000        NaN        5.488034            NaN  109.089105                 0.037561                     NaN           0.117979            2       True         44\n",
      "10  RandomForestGini_BAG_L2_FULL    1.000000        NaN        5.520628            NaN  113.195713                 0.070155                2.011883           4.224587            2       True         42\n",
      "11    ExtraTreesGini_BAG_L2_FULL    1.000000        NaN        5.520733            NaN  110.309836                 0.070260                1.763002           1.338711            2       True         45\n",
      "12      WeightedEnsemble_L3_FULL    1.000000        NaN        5.522141            NaN  130.208687                 0.001408                     NaN          19.898851            3       True         50\n",
      "13  RandomForestEntr_BAG_L2_FULL    1.000000        NaN        5.522563            NaN  110.924643                 0.072089                1.762158           1.953518            2       True         43\n",
      "14    ExtraTreesEntr_BAG_L2_FULL    1.000000        NaN        5.569760            NaN  110.311046                 0.119286                1.754122           1.339921            2       True         46\n",
      "15   NeuralNetFastAI_BAG_L2_FULL    0.999439        NaN        5.705902            NaN  129.975572                 0.255428                     NaN          21.004447            2       True         47\n",
      "16    NeuralNetTorch_BAG_L1_FULL    0.867501        NaN        0.143589            NaN   54.433322                 0.143589                     NaN          54.433322            1       True         37\n",
      "17           XGBoost_BAG_L1_FULL    0.867402        NaN        0.077041            NaN    3.070240                 0.077041                     NaN           3.070240            1       True         36\n",
      "18    ExtraTreesEntr_BAG_L1_FULL    0.857992        NaN        0.320152       2.275418    2.645035                 0.320152                2.275418           2.645035            1       True         34\n",
      "19         ExtraTreesGini_BAG_L1    0.857992   0.860906        0.328750       2.255471    2.672107                 0.328750                2.255471           2.672107            1       True          8\n",
      "20    ExtraTreesGini_BAG_L1_FULL    0.857992        NaN        0.337282       2.255471    2.672107                 0.337282                2.255471           2.672107            1       True         33\n",
      "21         ExtraTreesEntr_BAG_L1    0.857992   0.860930        0.426562       2.275418    2.645035                 0.426562                2.275418           2.645035            1       True          9\n",
      "22       RandomForestEntr_BAG_L1    0.857662   0.860410        0.239840       2.081737    3.670271                 0.239840                2.081737           3.670271            1       True          6\n",
      "23  RandomForestEntr_BAG_L1_FULL    0.857662        NaN        0.244074       2.081737    3.670271                 0.244074                2.081737           3.670271            1       True         31\n",
      "24       RandomForestGini_BAG_L1    0.857662   0.860419        0.247300       2.068322    3.339995                 0.247300                2.068322           3.339995            1       True          5\n",
      "25  RandomForestGini_BAG_L1_FULL    0.857662        NaN        0.249193       2.068322    3.339995                 0.249193                2.068322           3.339995            1       True         30\n",
      "26         KNeighborsUnif_BAG_L1    0.726946   0.733607        1.696443      24.610187    0.127796                 1.696443               24.610187           0.127796            1       True          1\n",
      "27    KNeighborsUnif_BAG_L1_FULL    0.726946        NaN        1.733741      24.610187    0.127796                 1.733741               24.610187           0.127796            1       True         26\n",
      "28    KNeighborsDist_BAG_L1_FULL    0.717073        NaN        1.716454      24.396994    0.121297                 1.716454               24.396994           0.121297            1       True         27\n",
      "29         KNeighborsDist_BAG_L1    0.717073   0.723743        1.764806      24.396994    0.121297                 1.764806               24.396994           0.121297            1       True          2\n",
      "30   NeuralNetFastAI_BAG_L1_FULL    0.592201        NaN        0.599052            NaN   28.937116                 0.599052                     NaN          28.937116            1       True         35\n",
      "31               CatBoost_BAG_L1         NaN   1.000000             NaN       0.016600   23.659507                      NaN                0.016600          23.659507            1      False          7\n",
      "32             LightGBMXT_BAG_L1         NaN   1.000000             NaN       0.035022    1.856974                      NaN                0.035022           1.856974            1      False          3\n",
      "33          LightGBMLarge_BAG_L1         NaN   1.000000             NaN       0.038616   10.746465                      NaN                0.038616          10.746465            1      False         13\n",
      "34               LightGBM_BAG_L1         NaN   1.000000             NaN       0.041969    1.958253                      NaN                0.041969           1.958253            1      False          4\n",
      "35           WeightedEnsemble_L2         NaN   1.000000             NaN       0.157289   27.195524                      NaN                0.122266          25.338550            2      False         14\n",
      "36               CatBoost_BAG_L2         NaN   1.000000             NaN      61.214887  621.729176                      NaN                0.031606          28.754601            2      False         19\n",
      "37               LightGBM_BAG_L2         NaN   1.000000             NaN      61.232831  597.763436                      NaN                0.049550           4.788861            2      False         16\n",
      "38             LightGBMXT_BAG_L2         NaN   1.000000             NaN      61.233541  597.745317                      NaN                0.050260           4.770741            2      False         15\n",
      "39          LightGBMLarge_BAG_L2         NaN   1.000000             NaN      61.242990  604.060338                      NaN                0.059709          11.085763            2      False         24\n",
      "40                XGBoost_BAG_L2         NaN   1.000000             NaN      61.324853  605.652658                      NaN                0.141572          12.678082            2      False         23\n",
      "41         ExtraTreesEntr_BAG_L2         NaN   1.000000             NaN      62.937403  594.314496                      NaN                1.754122           1.339921            2      False         21\n",
      "42       RandomForestEntr_BAG_L2         NaN   1.000000             NaN      62.945439  594.928093                      NaN                1.762158           1.953518            2      False         18\n",
      "43         ExtraTreesGini_BAG_L2         NaN   1.000000             NaN      62.946283  594.313286                      NaN                1.763002           1.338711            2      False         20\n",
      "44           WeightedEnsemble_L3         NaN   1.000000             NaN      63.071484  614.212137                      NaN                0.125201          19.898851            3      False         25\n",
      "45       RandomForestGini_BAG_L2         NaN   1.000000             NaN      63.195164  597.199162                      NaN                2.011883           4.224587            2      False         17\n",
      "46        NeuralNetFastAI_BAG_L2         NaN   0.999992             NaN      62.445103  813.413985                      NaN                1.261822         220.439410            2      False         22\n",
      "47         NeuralNetTorch_BAG_L1         NaN   0.870993             NaN       0.811856  260.839062                      NaN                0.811856         260.839062            1      False         12\n",
      "48                XGBoost_BAG_L1         NaN   0.870852             NaN       0.112619   12.324926                      NaN                0.112619          12.324926            1      False         11\n",
      "49        NeuralNetFastAI_BAG_L1         NaN   0.643692             NaN       2.438470  269.012887                      NaN                2.438470         269.012887            1      False         10\n"
     ]
    },
    {
     "data": {
      "text/plain": "                           model  score_test  score_val  pred_time_test  \\\n0         LightGBMXT_BAG_L1_FULL    1.000000        NaN        0.004901   \n1           CatBoost_BAG_L1_FULL    1.000000        NaN        0.005472   \n2           LightGBM_BAG_L1_FULL    1.000000        NaN        0.005914   \n3       WeightedEnsemble_L2_FULL    1.000000        NaN        0.006500   \n4      LightGBMLarge_BAG_L1_FULL    1.000000        NaN        0.013608   \n5           LightGBM_BAG_L2_FULL    1.000000        NaN        5.459824   \n6         LightGBMXT_BAG_L2_FULL    1.000000        NaN        5.459951   \n7      LightGBMLarge_BAG_L2_FULL    1.000000        NaN        5.473377   \n8            XGBoost_BAG_L2_FULL    1.000000        NaN        5.476804   \n9           CatBoost_BAG_L2_FULL    1.000000        NaN        5.488034   \n10  RandomForestGini_BAG_L2_FULL    1.000000        NaN        5.520628   \n11    ExtraTreesGini_BAG_L2_FULL    1.000000        NaN        5.520733   \n12      WeightedEnsemble_L3_FULL    1.000000        NaN        5.522141   \n13  RandomForestEntr_BAG_L2_FULL    1.000000        NaN        5.522563   \n14    ExtraTreesEntr_BAG_L2_FULL    1.000000        NaN        5.569760   \n15   NeuralNetFastAI_BAG_L2_FULL    0.999439        NaN        5.705902   \n16    NeuralNetTorch_BAG_L1_FULL    0.867501        NaN        0.143589   \n17           XGBoost_BAG_L1_FULL    0.867402        NaN        0.077041   \n18    ExtraTreesEntr_BAG_L1_FULL    0.857992        NaN        0.320152   \n19         ExtraTreesGini_BAG_L1    0.857992   0.860906        0.328750   \n20    ExtraTreesGini_BAG_L1_FULL    0.857992        NaN        0.337282   \n21         ExtraTreesEntr_BAG_L1    0.857992   0.860930        0.426562   \n22       RandomForestEntr_BAG_L1    0.857662   0.860410        0.239840   \n23  RandomForestEntr_BAG_L1_FULL    0.857662        NaN        0.244074   \n24       RandomForestGini_BAG_L1    0.857662   0.860419        0.247300   \n25  RandomForestGini_BAG_L1_FULL    0.857662        NaN        0.249193   \n26         KNeighborsUnif_BAG_L1    0.726946   0.733607        1.696443   \n27    KNeighborsUnif_BAG_L1_FULL    0.726946        NaN        1.733741   \n28    KNeighborsDist_BAG_L1_FULL    0.717073        NaN        1.716454   \n29         KNeighborsDist_BAG_L1    0.717073   0.723743        1.764806   \n30   NeuralNetFastAI_BAG_L1_FULL    0.592201        NaN        0.599052   \n31               CatBoost_BAG_L1         NaN   1.000000             NaN   \n32             LightGBMXT_BAG_L1         NaN   1.000000             NaN   \n33          LightGBMLarge_BAG_L1         NaN   1.000000             NaN   \n34               LightGBM_BAG_L1         NaN   1.000000             NaN   \n35           WeightedEnsemble_L2         NaN   1.000000             NaN   \n36               CatBoost_BAG_L2         NaN   1.000000             NaN   \n37               LightGBM_BAG_L2         NaN   1.000000             NaN   \n38             LightGBMXT_BAG_L2         NaN   1.000000             NaN   \n39          LightGBMLarge_BAG_L2         NaN   1.000000             NaN   \n40                XGBoost_BAG_L2         NaN   1.000000             NaN   \n41         ExtraTreesEntr_BAG_L2         NaN   1.000000             NaN   \n42       RandomForestEntr_BAG_L2         NaN   1.000000             NaN   \n43         ExtraTreesGini_BAG_L2         NaN   1.000000             NaN   \n44           WeightedEnsemble_L3         NaN   1.000000             NaN   \n45       RandomForestGini_BAG_L2         NaN   1.000000             NaN   \n46        NeuralNetFastAI_BAG_L2         NaN   0.999992             NaN   \n47         NeuralNetTorch_BAG_L1         NaN   0.870993             NaN   \n48                XGBoost_BAG_L1         NaN   0.870852             NaN   \n49        NeuralNetFastAI_BAG_L1         NaN   0.643692             NaN   \n\n    pred_time_val    fit_time  pred_time_test_marginal  \\\n0             NaN    4.856549                 0.004901   \n1             NaN    4.619153                 0.005472   \n2             NaN    0.237376                 0.005914   \n3             NaN   30.195099                 0.001599   \n4             NaN    0.240868                 0.013608   \n5             NaN  109.252347                 0.009350   \n6             NaN  109.245672                 0.009477   \n7             NaN  109.259349                 0.022903   \n8             NaN  109.227386                 0.026330   \n9             NaN  109.089105                 0.037561   \n10            NaN  113.195713                 0.070155   \n11            NaN  110.309836                 0.070260   \n12            NaN  130.208687                 0.001408   \n13            NaN  110.924643                 0.072089   \n14            NaN  110.311046                 0.119286   \n15            NaN  129.975572                 0.255428   \n16            NaN   54.433322                 0.143589   \n17            NaN    3.070240                 0.077041   \n18       2.275418    2.645035                 0.320152   \n19       2.255471    2.672107                 0.328750   \n20       2.255471    2.672107                 0.337282   \n21       2.275418    2.645035                 0.426562   \n22       2.081737    3.670271                 0.239840   \n23       2.081737    3.670271                 0.244074   \n24       2.068322    3.339995                 0.247300   \n25       2.068322    3.339995                 0.249193   \n26      24.610187    0.127796                 1.696443   \n27      24.610187    0.127796                 1.733741   \n28      24.396994    0.121297                 1.716454   \n29      24.396994    0.121297                 1.764806   \n30            NaN   28.937116                 0.599052   \n31       0.016600   23.659507                      NaN   \n32       0.035022    1.856974                      NaN   \n33       0.038616   10.746465                      NaN   \n34       0.041969    1.958253                      NaN   \n35       0.157289   27.195524                      NaN   \n36      61.214887  621.729176                      NaN   \n37      61.232831  597.763436                      NaN   \n38      61.233541  597.745317                      NaN   \n39      61.242990  604.060338                      NaN   \n40      61.324853  605.652658                      NaN   \n41      62.937403  594.314496                      NaN   \n42      62.945439  594.928093                      NaN   \n43      62.946283  594.313286                      NaN   \n44      63.071484  614.212137                      NaN   \n45      63.195164  597.199162                      NaN   \n46      62.445103  813.413985                      NaN   \n47       0.811856  260.839062                      NaN   \n48       0.112619   12.324926                      NaN   \n49       2.438470  269.012887                      NaN   \n\n    pred_time_val_marginal  fit_time_marginal  stack_level  can_infer  \\\n0                      NaN           4.856549            1       True   \n1                      NaN           4.619153            1       True   \n2                      NaN           0.237376            1       True   \n3                      NaN          25.338550            2       True   \n4                      NaN           0.240868            1       True   \n5                      NaN           0.281222            2       True   \n6                      NaN           0.274547            2       True   \n7                      NaN           0.288223            2       True   \n8                      NaN           0.256261            2       True   \n9                      NaN           0.117979            2       True   \n10                2.011883           4.224587            2       True   \n11                1.763002           1.338711            2       True   \n12                     NaN          19.898851            3       True   \n13                1.762158           1.953518            2       True   \n14                1.754122           1.339921            2       True   \n15                     NaN          21.004447            2       True   \n16                     NaN          54.433322            1       True   \n17                     NaN           3.070240            1       True   \n18                2.275418           2.645035            1       True   \n19                2.255471           2.672107            1       True   \n20                2.255471           2.672107            1       True   \n21                2.275418           2.645035            1       True   \n22                2.081737           3.670271            1       True   \n23                2.081737           3.670271            1       True   \n24                2.068322           3.339995            1       True   \n25                2.068322           3.339995            1       True   \n26               24.610187           0.127796            1       True   \n27               24.610187           0.127796            1       True   \n28               24.396994           0.121297            1       True   \n29               24.396994           0.121297            1       True   \n30                     NaN          28.937116            1       True   \n31                0.016600          23.659507            1      False   \n32                0.035022           1.856974            1      False   \n33                0.038616          10.746465            1      False   \n34                0.041969           1.958253            1      False   \n35                0.122266          25.338550            2      False   \n36                0.031606          28.754601            2      False   \n37                0.049550           4.788861            2      False   \n38                0.050260           4.770741            2      False   \n39                0.059709          11.085763            2      False   \n40                0.141572          12.678082            2      False   \n41                1.754122           1.339921            2      False   \n42                1.762158           1.953518            2      False   \n43                1.763002           1.338711            2      False   \n44                0.125201          19.898851            3      False   \n45                2.011883           4.224587            2      False   \n46                1.261822         220.439410            2      False   \n47                0.811856         260.839062            1      False   \n48                0.112619          12.324926            1      False   \n49                2.438470         269.012887            1      False   \n\n    fit_order  \n0          28  \n1          32  \n2          29  \n3          39  \n4          38  \n5          41  \n6          40  \n7          49  \n8          48  \n9          44  \n10         42  \n11         45  \n12         50  \n13         43  \n14         46  \n15         47  \n16         37  \n17         36  \n18         34  \n19          8  \n20         33  \n21          9  \n22          6  \n23         31  \n24          5  \n25         30  \n26          1  \n27         26  \n28         27  \n29          2  \n30         35  \n31          7  \n32          3  \n33         13  \n34          4  \n35         14  \n36         19  \n37         16  \n38         15  \n39         24  \n40         23  \n41         21  \n42         18  \n43         20  \n44         25  \n45         17  \n46         22  \n47         12  \n48         11  \n49         10  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>model</th>\n      <th>score_test</th>\n      <th>score_val</th>\n      <th>pred_time_test</th>\n      <th>pred_time_val</th>\n      <th>fit_time</th>\n      <th>pred_time_test_marginal</th>\n      <th>pred_time_val_marginal</th>\n      <th>fit_time_marginal</th>\n      <th>stack_level</th>\n      <th>can_infer</th>\n      <th>fit_order</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>LightGBMXT_BAG_L1_FULL</td>\n      <td>1.000000</td>\n      <td>NaN</td>\n      <td>0.004901</td>\n      <td>NaN</td>\n      <td>4.856549</td>\n      <td>0.004901</td>\n      <td>NaN</td>\n      <td>4.856549</td>\n      <td>1</td>\n      <td>True</td>\n      <td>28</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>CatBoost_BAG_L1_FULL</td>\n      <td>1.000000</td>\n      <td>NaN</td>\n      <td>0.005472</td>\n      <td>NaN</td>\n      <td>4.619153</td>\n      <td>0.005472</td>\n      <td>NaN</td>\n      <td>4.619153</td>\n      <td>1</td>\n      <td>True</td>\n      <td>32</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>LightGBM_BAG_L1_FULL</td>\n      <td>1.000000</td>\n      <td>NaN</td>\n      <td>0.005914</td>\n      <td>NaN</td>\n      <td>0.237376</td>\n      <td>0.005914</td>\n      <td>NaN</td>\n      <td>0.237376</td>\n      <td>1</td>\n      <td>True</td>\n      <td>29</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>WeightedEnsemble_L2_FULL</td>\n      <td>1.000000</td>\n      <td>NaN</td>\n      <td>0.006500</td>\n      <td>NaN</td>\n      <td>30.195099</td>\n      <td>0.001599</td>\n      <td>NaN</td>\n      <td>25.338550</td>\n      <td>2</td>\n      <td>True</td>\n      <td>39</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>LightGBMLarge_BAG_L1_FULL</td>\n      <td>1.000000</td>\n      <td>NaN</td>\n      <td>0.013608</td>\n      <td>NaN</td>\n      <td>0.240868</td>\n      <td>0.013608</td>\n      <td>NaN</td>\n      <td>0.240868</td>\n      <td>1</td>\n      <td>True</td>\n      <td>38</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>LightGBM_BAG_L2_FULL</td>\n      <td>1.000000</td>\n      <td>NaN</td>\n      <td>5.459824</td>\n      <td>NaN</td>\n      <td>109.252347</td>\n      <td>0.009350</td>\n      <td>NaN</td>\n      <td>0.281222</td>\n      <td>2</td>\n      <td>True</td>\n      <td>41</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>LightGBMXT_BAG_L2_FULL</td>\n      <td>1.000000</td>\n      <td>NaN</td>\n      <td>5.459951</td>\n      <td>NaN</td>\n      <td>109.245672</td>\n      <td>0.009477</td>\n      <td>NaN</td>\n      <td>0.274547</td>\n      <td>2</td>\n      <td>True</td>\n      <td>40</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>LightGBMLarge_BAG_L2_FULL</td>\n      <td>1.000000</td>\n      <td>NaN</td>\n      <td>5.473377</td>\n      <td>NaN</td>\n      <td>109.259349</td>\n      <td>0.022903</td>\n      <td>NaN</td>\n      <td>0.288223</td>\n      <td>2</td>\n      <td>True</td>\n      <td>49</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>XGBoost_BAG_L2_FULL</td>\n      <td>1.000000</td>\n      <td>NaN</td>\n      <td>5.476804</td>\n      <td>NaN</td>\n      <td>109.227386</td>\n      <td>0.026330</td>\n      <td>NaN</td>\n      <td>0.256261</td>\n      <td>2</td>\n      <td>True</td>\n      <td>48</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>CatBoost_BAG_L2_FULL</td>\n      <td>1.000000</td>\n      <td>NaN</td>\n      <td>5.488034</td>\n      <td>NaN</td>\n      <td>109.089105</td>\n      <td>0.037561</td>\n      <td>NaN</td>\n      <td>0.117979</td>\n      <td>2</td>\n      <td>True</td>\n      <td>44</td>\n    </tr>\n    <tr>\n      <th>10</th>\n      <td>RandomForestGini_BAG_L2_FULL</td>\n      <td>1.000000</td>\n      <td>NaN</td>\n      <td>5.520628</td>\n      <td>NaN</td>\n      <td>113.195713</td>\n      <td>0.070155</td>\n      <td>2.011883</td>\n      <td>4.224587</td>\n      <td>2</td>\n      <td>True</td>\n      <td>42</td>\n    </tr>\n    <tr>\n      <th>11</th>\n      <td>ExtraTreesGini_BAG_L2_FULL</td>\n      <td>1.000000</td>\n      <td>NaN</td>\n      <td>5.520733</td>\n      <td>NaN</td>\n      <td>110.309836</td>\n      <td>0.070260</td>\n      <td>1.763002</td>\n      <td>1.338711</td>\n      <td>2</td>\n      <td>True</td>\n      <td>45</td>\n    </tr>\n    <tr>\n      <th>12</th>\n      <td>WeightedEnsemble_L3_FULL</td>\n      <td>1.000000</td>\n      <td>NaN</td>\n      <td>5.522141</td>\n      <td>NaN</td>\n      <td>130.208687</td>\n      <td>0.001408</td>\n      <td>NaN</td>\n      <td>19.898851</td>\n      <td>3</td>\n      <td>True</td>\n      <td>50</td>\n    </tr>\n    <tr>\n      <th>13</th>\n      <td>RandomForestEntr_BAG_L2_FULL</td>\n      <td>1.000000</td>\n      <td>NaN</td>\n      <td>5.522563</td>\n      <td>NaN</td>\n      <td>110.924643</td>\n      <td>0.072089</td>\n      <td>1.762158</td>\n      <td>1.953518</td>\n      <td>2</td>\n      <td>True</td>\n      <td>43</td>\n    </tr>\n    <tr>\n      <th>14</th>\n      <td>ExtraTreesEntr_BAG_L2_FULL</td>\n      <td>1.000000</td>\n      <td>NaN</td>\n      <td>5.569760</td>\n      <td>NaN</td>\n      <td>110.311046</td>\n      <td>0.119286</td>\n      <td>1.754122</td>\n      <td>1.339921</td>\n      <td>2</td>\n      <td>True</td>\n      <td>46</td>\n    </tr>\n    <tr>\n      <th>15</th>\n      <td>NeuralNetFastAI_BAG_L2_FULL</td>\n      <td>0.999439</td>\n      <td>NaN</td>\n      <td>5.705902</td>\n      <td>NaN</td>\n      <td>129.975572</td>\n      <td>0.255428</td>\n      <td>NaN</td>\n      <td>21.004447</td>\n      <td>2</td>\n      <td>True</td>\n      <td>47</td>\n    </tr>\n    <tr>\n      <th>16</th>\n      <td>NeuralNetTorch_BAG_L1_FULL</td>\n      <td>0.867501</td>\n      <td>NaN</td>\n      <td>0.143589</td>\n      <td>NaN</td>\n      <td>54.433322</td>\n      <td>0.143589</td>\n      <td>NaN</td>\n      <td>54.433322</td>\n      <td>1</td>\n      <td>True</td>\n      <td>37</td>\n    </tr>\n    <tr>\n      <th>17</th>\n      <td>XGBoost_BAG_L1_FULL</td>\n      <td>0.867402</td>\n      <td>NaN</td>\n      <td>0.077041</td>\n      <td>NaN</td>\n      <td>3.070240</td>\n      <td>0.077041</td>\n      <td>NaN</td>\n      <td>3.070240</td>\n      <td>1</td>\n      <td>True</td>\n      <td>36</td>\n    </tr>\n    <tr>\n      <th>18</th>\n      <td>ExtraTreesEntr_BAG_L1_FULL</td>\n      <td>0.857992</td>\n      <td>NaN</td>\n      <td>0.320152</td>\n      <td>2.275418</td>\n      <td>2.645035</td>\n      <td>0.320152</td>\n      <td>2.275418</td>\n      <td>2.645035</td>\n      <td>1</td>\n      <td>True</td>\n      <td>34</td>\n    </tr>\n    <tr>\n      <th>19</th>\n      <td>ExtraTreesGini_BAG_L1</td>\n      <td>0.857992</td>\n      <td>0.860906</td>\n      <td>0.328750</td>\n      <td>2.255471</td>\n      <td>2.672107</td>\n      <td>0.328750</td>\n      <td>2.255471</td>\n      <td>2.672107</td>\n      <td>1</td>\n      <td>True</td>\n      <td>8</td>\n    </tr>\n    <tr>\n      <th>20</th>\n      <td>ExtraTreesGini_BAG_L1_FULL</td>\n      <td>0.857992</td>\n      <td>NaN</td>\n      <td>0.337282</td>\n      <td>2.255471</td>\n      <td>2.672107</td>\n      <td>0.337282</td>\n      <td>2.255471</td>\n      <td>2.672107</td>\n      <td>1</td>\n      <td>True</td>\n      <td>33</td>\n    </tr>\n    <tr>\n      <th>21</th>\n      <td>ExtraTreesEntr_BAG_L1</td>\n      <td>0.857992</td>\n      <td>0.860930</td>\n      <td>0.426562</td>\n      <td>2.275418</td>\n      <td>2.645035</td>\n      <td>0.426562</td>\n      <td>2.275418</td>\n      <td>2.645035</td>\n      <td>1</td>\n      <td>True</td>\n      <td>9</td>\n    </tr>\n    <tr>\n      <th>22</th>\n      <td>RandomForestEntr_BAG_L1</td>\n      <td>0.857662</td>\n      <td>0.860410</td>\n      <td>0.239840</td>\n      <td>2.081737</td>\n      <td>3.670271</td>\n      <td>0.239840</td>\n      <td>2.081737</td>\n      <td>3.670271</td>\n      <td>1</td>\n      <td>True</td>\n      <td>6</td>\n    </tr>\n    <tr>\n      <th>23</th>\n      <td>RandomForestEntr_BAG_L1_FULL</td>\n      <td>0.857662</td>\n      <td>NaN</td>\n      <td>0.244074</td>\n      <td>2.081737</td>\n      <td>3.670271</td>\n      <td>0.244074</td>\n      <td>2.081737</td>\n      <td>3.670271</td>\n      <td>1</td>\n      <td>True</td>\n      <td>31</td>\n    </tr>\n    <tr>\n      <th>24</th>\n      <td>RandomForestGini_BAG_L1</td>\n      <td>0.857662</td>\n      <td>0.860419</td>\n      <td>0.247300</td>\n      <td>2.068322</td>\n      <td>3.339995</td>\n      <td>0.247300</td>\n      <td>2.068322</td>\n      <td>3.339995</td>\n      <td>1</td>\n      <td>True</td>\n      <td>5</td>\n    </tr>\n    <tr>\n      <th>25</th>\n      <td>RandomForestGini_BAG_L1_FULL</td>\n      <td>0.857662</td>\n      <td>NaN</td>\n      <td>0.249193</td>\n      <td>2.068322</td>\n      <td>3.339995</td>\n      <td>0.249193</td>\n      <td>2.068322</td>\n      <td>3.339995</td>\n      <td>1</td>\n      <td>True</td>\n      <td>30</td>\n    </tr>\n    <tr>\n      <th>26</th>\n      <td>KNeighborsUnif_BAG_L1</td>\n      <td>0.726946</td>\n      <td>0.733607</td>\n      <td>1.696443</td>\n      <td>24.610187</td>\n      <td>0.127796</td>\n      <td>1.696443</td>\n      <td>24.610187</td>\n      <td>0.127796</td>\n      <td>1</td>\n      <td>True</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>27</th>\n      <td>KNeighborsUnif_BAG_L1_FULL</td>\n      <td>0.726946</td>\n      <td>NaN</td>\n      <td>1.733741</td>\n      <td>24.610187</td>\n      <td>0.127796</td>\n      <td>1.733741</td>\n      <td>24.610187</td>\n      <td>0.127796</td>\n      <td>1</td>\n      <td>True</td>\n      <td>26</td>\n    </tr>\n    <tr>\n      <th>28</th>\n      <td>KNeighborsDist_BAG_L1_FULL</td>\n      <td>0.717073</td>\n      <td>NaN</td>\n      <td>1.716454</td>\n      <td>24.396994</td>\n      <td>0.121297</td>\n      <td>1.716454</td>\n      <td>24.396994</td>\n      <td>0.121297</td>\n      <td>1</td>\n      <td>True</td>\n      <td>27</td>\n    </tr>\n    <tr>\n      <th>29</th>\n      <td>KNeighborsDist_BAG_L1</td>\n      <td>0.717073</td>\n      <td>0.723743</td>\n      <td>1.764806</td>\n      <td>24.396994</td>\n      <td>0.121297</td>\n      <td>1.764806</td>\n      <td>24.396994</td>\n      <td>0.121297</td>\n      <td>1</td>\n      <td>True</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>30</th>\n      <td>NeuralNetFastAI_BAG_L1_FULL</td>\n      <td>0.592201</td>\n      <td>NaN</td>\n      <td>0.599052</td>\n      <td>NaN</td>\n      <td>28.937116</td>\n      <td>0.599052</td>\n      <td>NaN</td>\n      <td>28.937116</td>\n      <td>1</td>\n      <td>True</td>\n      <td>35</td>\n    </tr>\n    <tr>\n      <th>31</th>\n      <td>CatBoost_BAG_L1</td>\n      <td>NaN</td>\n      <td>1.000000</td>\n      <td>NaN</td>\n      <td>0.016600</td>\n      <td>23.659507</td>\n      <td>NaN</td>\n      <td>0.016600</td>\n      <td>23.659507</td>\n      <td>1</td>\n      <td>False</td>\n      <td>7</td>\n    </tr>\n    <tr>\n      <th>32</th>\n      <td>LightGBMXT_BAG_L1</td>\n      <td>NaN</td>\n      <td>1.000000</td>\n      <td>NaN</td>\n      <td>0.035022</td>\n      <td>1.856974</td>\n      <td>NaN</td>\n      <td>0.035022</td>\n      <td>1.856974</td>\n      <td>1</td>\n      <td>False</td>\n      <td>3</td>\n    </tr>\n    <tr>\n      <th>33</th>\n      <td>LightGBMLarge_BAG_L1</td>\n      <td>NaN</td>\n      <td>1.000000</td>\n      <td>NaN</td>\n      <td>0.038616</td>\n      <td>10.746465</td>\n      <td>NaN</td>\n      <td>0.038616</td>\n      <td>10.746465</td>\n      <td>1</td>\n      <td>False</td>\n      <td>13</td>\n    </tr>\n    <tr>\n      <th>34</th>\n      <td>LightGBM_BAG_L1</td>\n      <td>NaN</td>\n      <td>1.000000</td>\n      <td>NaN</td>\n      <td>0.041969</td>\n      <td>1.958253</td>\n      <td>NaN</td>\n      <td>0.041969</td>\n      <td>1.958253</td>\n      <td>1</td>\n      <td>False</td>\n      <td>4</td>\n    </tr>\n    <tr>\n      <th>35</th>\n      <td>WeightedEnsemble_L2</td>\n      <td>NaN</td>\n      <td>1.000000</td>\n      <td>NaN</td>\n      <td>0.157289</td>\n      <td>27.195524</td>\n      <td>NaN</td>\n      <td>0.122266</td>\n      <td>25.338550</td>\n      <td>2</td>\n      <td>False</td>\n      <td>14</td>\n    </tr>\n    <tr>\n      <th>36</th>\n      <td>CatBoost_BAG_L2</td>\n      <td>NaN</td>\n      <td>1.000000</td>\n      <td>NaN</td>\n      <td>61.214887</td>\n      <td>621.729176</td>\n      <td>NaN</td>\n      <td>0.031606</td>\n      <td>28.754601</td>\n      <td>2</td>\n      <td>False</td>\n      <td>19</td>\n    </tr>\n    <tr>\n      <th>37</th>\n      <td>LightGBM_BAG_L2</td>\n      <td>NaN</td>\n      <td>1.000000</td>\n      <td>NaN</td>\n      <td>61.232831</td>\n      <td>597.763436</td>\n      <td>NaN</td>\n      <td>0.049550</td>\n      <td>4.788861</td>\n      <td>2</td>\n      <td>False</td>\n      <td>16</td>\n    </tr>\n    <tr>\n      <th>38</th>\n      <td>LightGBMXT_BAG_L2</td>\n      <td>NaN</td>\n      <td>1.000000</td>\n      <td>NaN</td>\n      <td>61.233541</td>\n      <td>597.745317</td>\n      <td>NaN</td>\n      <td>0.050260</td>\n      <td>4.770741</td>\n      <td>2</td>\n      <td>False</td>\n      <td>15</td>\n    </tr>\n    <tr>\n      <th>39</th>\n      <td>LightGBMLarge_BAG_L2</td>\n      <td>NaN</td>\n      <td>1.000000</td>\n      <td>NaN</td>\n      <td>61.242990</td>\n      <td>604.060338</td>\n      <td>NaN</td>\n      <td>0.059709</td>\n      <td>11.085763</td>\n      <td>2</td>\n      <td>False</td>\n      <td>24</td>\n    </tr>\n    <tr>\n      <th>40</th>\n      <td>XGBoost_BAG_L2</td>\n      <td>NaN</td>\n      <td>1.000000</td>\n      <td>NaN</td>\n      <td>61.324853</td>\n      <td>605.652658</td>\n      <td>NaN</td>\n      <td>0.141572</td>\n      <td>12.678082</td>\n      <td>2</td>\n      <td>False</td>\n      <td>23</td>\n    </tr>\n    <tr>\n      <th>41</th>\n      <td>ExtraTreesEntr_BAG_L2</td>\n      <td>NaN</td>\n      <td>1.000000</td>\n      <td>NaN</td>\n      <td>62.937403</td>\n      <td>594.314496</td>\n      <td>NaN</td>\n      <td>1.754122</td>\n      <td>1.339921</td>\n      <td>2</td>\n      <td>False</td>\n      <td>21</td>\n    </tr>\n    <tr>\n      <th>42</th>\n      <td>RandomForestEntr_BAG_L2</td>\n      <td>NaN</td>\n      <td>1.000000</td>\n      <td>NaN</td>\n      <td>62.945439</td>\n      <td>594.928093</td>\n      <td>NaN</td>\n      <td>1.762158</td>\n      <td>1.953518</td>\n      <td>2</td>\n      <td>False</td>\n      <td>18</td>\n    </tr>\n    <tr>\n      <th>43</th>\n      <td>ExtraTreesGini_BAG_L2</td>\n      <td>NaN</td>\n      <td>1.000000</td>\n      <td>NaN</td>\n      <td>62.946283</td>\n      <td>594.313286</td>\n      <td>NaN</td>\n      <td>1.763002</td>\n      <td>1.338711</td>\n      <td>2</td>\n      <td>False</td>\n      <td>20</td>\n    </tr>\n    <tr>\n      <th>44</th>\n      <td>WeightedEnsemble_L3</td>\n      <td>NaN</td>\n      <td>1.000000</td>\n      <td>NaN</td>\n      <td>63.071484</td>\n      <td>614.212137</td>\n      <td>NaN</td>\n      <td>0.125201</td>\n      <td>19.898851</td>\n      <td>3</td>\n      <td>False</td>\n      <td>25</td>\n    </tr>\n    <tr>\n      <th>45</th>\n      <td>RandomForestGini_BAG_L2</td>\n      <td>NaN</td>\n      <td>1.000000</td>\n      <td>NaN</td>\n      <td>63.195164</td>\n      <td>597.199162</td>\n      <td>NaN</td>\n      <td>2.011883</td>\n      <td>4.224587</td>\n      <td>2</td>\n      <td>False</td>\n      <td>17</td>\n    </tr>\n    <tr>\n      <th>46</th>\n      <td>NeuralNetFastAI_BAG_L2</td>\n      <td>NaN</td>\n      <td>0.999992</td>\n      <td>NaN</td>\n      <td>62.445103</td>\n      <td>813.413985</td>\n      <td>NaN</td>\n      <td>1.261822</td>\n      <td>220.439410</td>\n      <td>2</td>\n      <td>False</td>\n      <td>22</td>\n    </tr>\n    <tr>\n      <th>47</th>\n      <td>NeuralNetTorch_BAG_L1</td>\n      <td>NaN</td>\n      <td>0.870993</td>\n      <td>NaN</td>\n      <td>0.811856</td>\n      <td>260.839062</td>\n      <td>NaN</td>\n      <td>0.811856</td>\n      <td>260.839062</td>\n      <td>1</td>\n      <td>False</td>\n      <td>12</td>\n    </tr>\n    <tr>\n      <th>48</th>\n      <td>XGBoost_BAG_L1</td>\n      <td>NaN</td>\n      <td>0.870852</td>\n      <td>NaN</td>\n      <td>0.112619</td>\n      <td>12.324926</td>\n      <td>NaN</td>\n      <td>0.112619</td>\n      <td>12.324926</td>\n      <td>1</td>\n      <td>False</td>\n      <td>11</td>\n    </tr>\n    <tr>\n      <th>49</th>\n      <td>NeuralNetFastAI_BAG_L1</td>\n      <td>NaN</td>\n      <td>0.643692</td>\n      <td>NaN</td>\n      <td>2.438470</td>\n      <td>269.012887</td>\n      <td>NaN</td>\n      <td>2.438470</td>\n      <td>269.012887</td>\n      <td>1</td>\n      <td>False</td>\n      <td>10</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictor_high.leaderboard(test_data)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## medium quality"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loaded data from: ./Data/split/train_data.csv | Columns = 31 / 31 | Rows = 121148 -> 121148\n",
      "Warning: path already exists! This predictor may overwrite an existing predictor! path=\"./auto_gl/exp-iot23/medium_q\"\n",
      "Presets specified: ['medium_quality']\n",
      "Warning: Training may take a very long time because `time_limit` was not specified and `train_data` is large (121148 samples, 36.89 MB).\n",
      "\tConsider setting `time_limit` to ensure training finishes within an expected duration or experiment with a small portion of `train_data` to identify an ideal `presets` and `hyperparameters` configuration.\n",
      "Beginning AutoGluon training ...\n",
      "AutoGluon will save models to \"./auto_gl/exp-iot23/medium_q/\"\n",
      "AutoGluon Version:  0.4.0\n",
      "Python Version:     3.8.13\n",
      "Operating System:   Linux\n",
      "Train Data Rows:    121148\n",
      "Train Data Columns: 30\n",
      "Label Column: label\n",
      "Preprocessing data ...\n",
      "AutoGluon infers your prediction problem is: 'binary' (because only two unique label-values observed).\n",
      "\t2 unique label values:  ['Benign', 'Malicious']\n",
      "\tIf 'binary' is not the correct problem_type, please manually specify the problem_type parameter during predictor init (You may specify problem_type as one of: ['binary', 'multiclass', 'regression'])\n",
      "Selected class <--> label mapping:  class 1 = Malicious, class 0 = Benign\n",
      "\tNote: For your binary classification, AutoGluon arbitrarily selected which label-value represents positive (Malicious) vs negative (Benign) class.\n",
      "\tTo explicitly set the positive_class, either rename classes to 1 and 0, or specify positive_class in Predictor init.\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    8500.93 MB\n",
      "\tTrain Data (Original)  Memory Usage: 29.08 MB (0.3% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\t\t\tNote: Converting 21 features to boolean dtype as they only contain 2 unique values.\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('float', []) :  7 | ['duration', 'missed_bytes', 'orig_pkts', 'orig_ip_bytes', 'resp_pkts', ...]\n",
      "\t\t('int', [])   : 23 | ['orig_bytes', 'resp_bytes', 'proto_tcp', 'proto_udp', 'service_-', ...]\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('float', [])     :  7 | ['duration', 'missed_bytes', 'orig_pkts', 'orig_ip_bytes', 'resp_pkts', ...]\n",
      "\t\t('int', [])       :  2 | ['orig_bytes', 'resp_bytes']\n",
      "\t\t('int', ['bool']) : 21 | ['proto_tcp', 'proto_udp', 'service_-', 'service_dhcp', 'service_dns', ...]\n",
      "\t0.2s = Fit runtime\n",
      "\t30 features in original data used to generate 30 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 11.27 MB (0.1% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 0.27s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'accuracy'\n",
      "\tTo change this, specify the eval_metric parameter of Predictor()\n",
      "Automatically generating train/validation split with holdout_frac=0.02063591639977548, Train Rows: 118648, Val Rows: 2500\n",
      "Excluded Model Types: ['GBM', 'RF', 'XT', 'NeuralNetFastAI']\n",
      "\tFound 'GBM' model in hyperparameters, but 'GBM' is present in `excluded_model_types` and will be removed.\n",
      "\tFound 'GBM' model in hyperparameters, but 'GBM' is present in `excluded_model_types` and will be removed.\n",
      "\tFound 'GBM' model in hyperparameters, but 'GBM' is present in `excluded_model_types` and will be removed.\n",
      "\tFound 'RF' model in hyperparameters, but 'RF' is present in `excluded_model_types` and will be removed.\n",
      "\tFound 'RF' model in hyperparameters, but 'RF' is present in `excluded_model_types` and will be removed.\n",
      "\tFound 'RF' model in hyperparameters, but 'RF' is present in `excluded_model_types` and will be removed.\n",
      "\tFound 'XT' model in hyperparameters, but 'XT' is present in `excluded_model_types` and will be removed.\n",
      "\tFound 'XT' model in hyperparameters, but 'XT' is present in `excluded_model_types` and will be removed.\n",
      "\tFound 'XT' model in hyperparameters, but 'XT' is present in `excluded_model_types` and will be removed.\n",
      "Fitting 6 L1 models ...\n",
      "Fitting model: KNeighborsUnif ...\n",
      "\t0.7484\t = Validation score   (accuracy)\n",
      "\t0.13s\t = Training   runtime\n",
      "\t0.52s\t = Validation runtime\n",
      "Fitting model: KNeighborsDist ...\n",
      "\t0.7316\t = Validation score   (accuracy)\n",
      "\t0.16s\t = Training   runtime\n",
      "\t0.15s\t = Validation runtime\n",
      "Fitting model: CatBoost ...\n",
      "\tTraining CatBoost with GPU, note that this may negatively impact model quality compared to CPU training.\n",
      "\tWarning: CatBoost on GPU is experimental. If you encounter issues, use CPU for training CatBoost instead.\n",
      "\t1.0\t = Validation score   (accuracy)\n",
      "\t0.34s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Fitting model: NeuralNetFastAI ...\n",
      "No improvement since epoch 0: early stopping\n",
      "\t0.5988\t = Validation score   (accuracy)\n",
      "\t47.01s\t = Training   runtime\n",
      "\t0.03s\t = Validation runtime\n",
      "Fitting model: XGBoost ...\n",
      "\t0.8792\t = Validation score   (accuracy)\n",
      "\t0.24s\t = Training   runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Fitting model: NeuralNetTorch ...\n",
      "\t0.8792\t = Validation score   (accuracy)\n",
      "\t42.46s\t = Training   runtime\n",
      "\t0.02s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L2 ...\n",
      "\t1.0\t = Validation score   (accuracy)\n",
      "\t0.35s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "AutoGluon training complete, total runtime = 92.94s ... Best model: \"WeightedEnsemble_L2\"\n",
      "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"./auto_gl/exp-iot23/medium_q/\")\n"
     ]
    }
   ],
   "source": [
    "from autogluon.tabular import TabularDataset,TabularPredictor\n",
    "\n",
    "label = 'label'\n",
    "train_data = TabularDataset(\"./Data/split/train_data.csv\")\n",
    "from autogluon.tabular import TabularPredictor\n",
    "save_path = './auto_gl/exp-iot23/medium_q'  # specifies folder to store trained models\n",
    "predictor_medium = TabularPredictor(label=label, path=save_path).fit(train_data, ag_args_fit={'num_gpus': 1},                                                              presets='medium_quality',excluded_model_types=['GBM','RF','XT','NeuralNetFastAI'])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** Summary of fit() ***\n",
      "Estimated performance of each model:\n",
      "                 model  score_val  pred_time_val   fit_time  pred_time_val_marginal  fit_time_marginal  stack_level  can_infer  fit_order\n",
      "0             CatBoost     1.0000       0.003626   0.335761                0.003626           0.335761            1       True          3\n",
      "1  WeightedEnsemble_L2     1.0000       0.006526   0.684912                0.002900           0.349151            2       True          7\n",
      "2              XGBoost     0.8792       0.008306   0.240995                0.008306           0.240995            1       True          5\n",
      "3       NeuralNetTorch     0.8792       0.017197  42.463165                0.017197          42.463165            1       True          6\n",
      "4       KNeighborsUnif     0.7484       0.519294   0.134527                0.519294           0.134527            1       True          1\n",
      "5       KNeighborsDist     0.7316       0.153671   0.156957                0.153671           0.156957            1       True          2\n",
      "6      NeuralNetFastAI     0.5988       0.027571  47.014451                0.027571          47.014451            1       True          4\n",
      "Number of models trained: 7\n",
      "Types of models trained:\n",
      "{'KNNModel', 'CatBoostModel', 'NNFastAiTabularModel', 'XGBoostModel', 'WeightedEnsembleModel', 'TabularNeuralNetTorchModel'}\n",
      "Bagging used: False \n",
      "Multi-layer stack-ensembling used: False \n",
      "Feature Metadata (Processed):\n",
      "(raw dtype, special dtypes):\n",
      "('float', [])     :  7 | ['duration', 'missed_bytes', 'orig_pkts', 'orig_ip_bytes', 'resp_pkts', ...]\n",
      "('int', [])       :  2 | ['orig_bytes', 'resp_bytes']\n",
      "('int', ['bool']) : 21 | ['proto_tcp', 'proto_udp', 'service_-', 'service_dhcp', 'service_dns', ...]\n",
      "*** End of fit() summary ***\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/media/wuguo-buaa/LENOVO_USB_HDD/PycharmProjects/Machine_learning_venv/lib/python3.8/site-packages/autogluon/core/utils/plots.py:138: UserWarning: AutoGluon summary plots cannot be created because bokeh is not installed. To see plots, please do: \"pip install bokeh==2.0.1\"\n",
      "  warnings.warn('AutoGluon summary plots cannot be created because bokeh is not installed. To see plots, please do: \"pip install bokeh==2.0.1\"')\n"
     ]
    }
   ],
   "source": [
    "results_mid = predictor_medium.fit_summary(show_plot=True)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loaded data from: ./Data/split/test_data.csv | Columns = 31 / 31 | Rows = 30287 -> 30287\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                  model  score_test  score_val  pred_time_test  pred_time_val   fit_time  pred_time_test_marginal  pred_time_val_marginal  fit_time_marginal  stack_level  can_infer  fit_order\n",
      "0              CatBoost    1.000000     1.0000        0.003807       0.003750   0.486640                 0.003807                0.003750           0.486640            1       True          7\n",
      "1            LightGBMXT    1.000000     1.0000        0.003923       0.007562   0.794845                 0.003923                0.007562           0.794845            1       True          3\n",
      "2         LightGBMLarge    1.000000     1.0000        0.004310       0.010816   0.426282                 0.004310                0.010816           0.426282            1       True         11\n",
      "3              LightGBM    1.000000     1.0000        0.008456       0.013400   0.273279                 0.008456                0.013400           0.273279            1       True          4\n",
      "4   WeightedEnsemble_L2    1.000000     1.0000        0.009178       0.010406   1.405272                 0.005255                0.002844           0.610427            2       True         12\n",
      "5               XGBoost    0.867435     0.8792        0.013202       0.008277   0.335591                 0.013202                0.008277           0.335591            1       True          9\n",
      "6        NeuralNetTorch    0.867402     0.8792        0.132583       0.018123  42.276970                 0.132583                0.018123          42.276970            1       True         10\n",
      "7      RandomForestGini    0.857299     0.8648        0.215134       0.055871   3.553592                 0.215134                0.055871           3.553592            1       True          5\n",
      "8      RandomForestEntr    0.857265     0.8648        0.235854       0.051896   3.640534                 0.235854                0.051896           3.640534            1       True          6\n",
      "9        KNeighborsUnif    0.727177     0.7484        5.854203       0.165936   0.126042                 5.854203                0.165936           0.126042            1       True          1\n",
      "10       KNeighborsDist    0.716908     0.7316        5.871335       0.519245   0.138507                 5.871335                0.519245           0.138507            1       True          2\n",
      "11      NeuralNetFastAI    0.592036     0.5988        0.244892       0.026506  52.055161                 0.244892                0.026506          52.055161            1       True          8\n"
     ]
    },
    {
     "data": {
      "text/plain": "                  model  score_test  score_val  pred_time_test  pred_time_val  \\\n0              CatBoost    1.000000     1.0000        0.003807       0.003750   \n1            LightGBMXT    1.000000     1.0000        0.003923       0.007562   \n2         LightGBMLarge    1.000000     1.0000        0.004310       0.010816   \n3              LightGBM    1.000000     1.0000        0.008456       0.013400   \n4   WeightedEnsemble_L2    1.000000     1.0000        0.009178       0.010406   \n5               XGBoost    0.867435     0.8792        0.013202       0.008277   \n6        NeuralNetTorch    0.867402     0.8792        0.132583       0.018123   \n7      RandomForestGini    0.857299     0.8648        0.215134       0.055871   \n8      RandomForestEntr    0.857265     0.8648        0.235854       0.051896   \n9        KNeighborsUnif    0.727177     0.7484        5.854203       0.165936   \n10       KNeighborsDist    0.716908     0.7316        5.871335       0.519245   \n11      NeuralNetFastAI    0.592036     0.5988        0.244892       0.026506   \n\n     fit_time  pred_time_test_marginal  pred_time_val_marginal  \\\n0    0.486640                 0.003807                0.003750   \n1    0.794845                 0.003923                0.007562   \n2    0.426282                 0.004310                0.010816   \n3    0.273279                 0.008456                0.013400   \n4    1.405272                 0.005255                0.002844   \n5    0.335591                 0.013202                0.008277   \n6   42.276970                 0.132583                0.018123   \n7    3.553592                 0.215134                0.055871   \n8    3.640534                 0.235854                0.051896   \n9    0.126042                 5.854203                0.165936   \n10   0.138507                 5.871335                0.519245   \n11  52.055161                 0.244892                0.026506   \n\n    fit_time_marginal  stack_level  can_infer  fit_order  \n0            0.486640            1       True          7  \n1            0.794845            1       True          3  \n2            0.426282            1       True         11  \n3            0.273279            1       True          4  \n4            0.610427            2       True         12  \n5            0.335591            1       True          9  \n6           42.276970            1       True         10  \n7            3.553592            1       True          5  \n8            3.640534            1       True          6  \n9            0.126042            1       True          1  \n10           0.138507            1       True          2  \n11          52.055161            1       True          8  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>model</th>\n      <th>score_test</th>\n      <th>score_val</th>\n      <th>pred_time_test</th>\n      <th>pred_time_val</th>\n      <th>fit_time</th>\n      <th>pred_time_test_marginal</th>\n      <th>pred_time_val_marginal</th>\n      <th>fit_time_marginal</th>\n      <th>stack_level</th>\n      <th>can_infer</th>\n      <th>fit_order</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>CatBoost</td>\n      <td>1.000000</td>\n      <td>1.0000</td>\n      <td>0.003807</td>\n      <td>0.003750</td>\n      <td>0.486640</td>\n      <td>0.003807</td>\n      <td>0.003750</td>\n      <td>0.486640</td>\n      <td>1</td>\n      <td>True</td>\n      <td>7</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>LightGBMXT</td>\n      <td>1.000000</td>\n      <td>1.0000</td>\n      <td>0.003923</td>\n      <td>0.007562</td>\n      <td>0.794845</td>\n      <td>0.003923</td>\n      <td>0.007562</td>\n      <td>0.794845</td>\n      <td>1</td>\n      <td>True</td>\n      <td>3</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>LightGBMLarge</td>\n      <td>1.000000</td>\n      <td>1.0000</td>\n      <td>0.004310</td>\n      <td>0.010816</td>\n      <td>0.426282</td>\n      <td>0.004310</td>\n      <td>0.010816</td>\n      <td>0.426282</td>\n      <td>1</td>\n      <td>True</td>\n      <td>11</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>LightGBM</td>\n      <td>1.000000</td>\n      <td>1.0000</td>\n      <td>0.008456</td>\n      <td>0.013400</td>\n      <td>0.273279</td>\n      <td>0.008456</td>\n      <td>0.013400</td>\n      <td>0.273279</td>\n      <td>1</td>\n      <td>True</td>\n      <td>4</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>WeightedEnsemble_L2</td>\n      <td>1.000000</td>\n      <td>1.0000</td>\n      <td>0.009178</td>\n      <td>0.010406</td>\n      <td>1.405272</td>\n      <td>0.005255</td>\n      <td>0.002844</td>\n      <td>0.610427</td>\n      <td>2</td>\n      <td>True</td>\n      <td>12</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>XGBoost</td>\n      <td>0.867435</td>\n      <td>0.8792</td>\n      <td>0.013202</td>\n      <td>0.008277</td>\n      <td>0.335591</td>\n      <td>0.013202</td>\n      <td>0.008277</td>\n      <td>0.335591</td>\n      <td>1</td>\n      <td>True</td>\n      <td>9</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>NeuralNetTorch</td>\n      <td>0.867402</td>\n      <td>0.8792</td>\n      <td>0.132583</td>\n      <td>0.018123</td>\n      <td>42.276970</td>\n      <td>0.132583</td>\n      <td>0.018123</td>\n      <td>42.276970</td>\n      <td>1</td>\n      <td>True</td>\n      <td>10</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>RandomForestGini</td>\n      <td>0.857299</td>\n      <td>0.8648</td>\n      <td>0.215134</td>\n      <td>0.055871</td>\n      <td>3.553592</td>\n      <td>0.215134</td>\n      <td>0.055871</td>\n      <td>3.553592</td>\n      <td>1</td>\n      <td>True</td>\n      <td>5</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>RandomForestEntr</td>\n      <td>0.857265</td>\n      <td>0.8648</td>\n      <td>0.235854</td>\n      <td>0.051896</td>\n      <td>3.640534</td>\n      <td>0.235854</td>\n      <td>0.051896</td>\n      <td>3.640534</td>\n      <td>1</td>\n      <td>True</td>\n      <td>6</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>KNeighborsUnif</td>\n      <td>0.727177</td>\n      <td>0.7484</td>\n      <td>5.854203</td>\n      <td>0.165936</td>\n      <td>0.126042</td>\n      <td>5.854203</td>\n      <td>0.165936</td>\n      <td>0.126042</td>\n      <td>1</td>\n      <td>True</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>10</th>\n      <td>KNeighborsDist</td>\n      <td>0.716908</td>\n      <td>0.7316</td>\n      <td>5.871335</td>\n      <td>0.519245</td>\n      <td>0.138507</td>\n      <td>5.871335</td>\n      <td>0.519245</td>\n      <td>0.138507</td>\n      <td>1</td>\n      <td>True</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>11</th>\n      <td>NeuralNetFastAI</td>\n      <td>0.592036</td>\n      <td>0.5988</td>\n      <td>0.244892</td>\n      <td>0.026506</td>\n      <td>52.055161</td>\n      <td>0.244892</td>\n      <td>0.026506</td>\n      <td>52.055161</td>\n      <td>1</td>\n      <td>True</td>\n      <td>8</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data = TabularDataset(\"./Data/split/test_data.csv\")\n",
    "predictor_medium.leaderboard(test_data)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## deploy quality"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning: path already exists! This predictor may overwrite an existing predictor! path=\"./auto_gl/exp-iot23/edge_deploy\"\n",
      "Presets specified: ['optimize_for_deployment']\n",
      "Warning: Training may take a very long time because `time_limit` was not specified and `train_data` is large (121148 samples, 36.89 MB).\n",
      "\tConsider setting `time_limit` to ensure training finishes within an expected duration or experiment with a small portion of `train_data` to identify an ideal `presets` and `hyperparameters` configuration.\n",
      "Beginning AutoGluon training ...\n",
      "AutoGluon will save models to \"./auto_gl/exp-iot23/edge_deploy/\"\n",
      "AutoGluon Version:  0.4.0\n",
      "Python Version:     3.8.13\n",
      "Operating System:   Linux\n",
      "Train Data Rows:    121148\n",
      "Train Data Columns: 30\n",
      "Label Column: label\n",
      "Preprocessing data ...\n",
      "AutoGluon infers your prediction problem is: 'binary' (because only two unique label-values observed).\n",
      "\t2 unique label values:  ['Benign', 'Malicious']\n",
      "\tIf 'binary' is not the correct problem_type, please manually specify the problem_type parameter during predictor init (You may specify problem_type as one of: ['binary', 'multiclass', 'regression'])\n",
      "Selected class <--> label mapping:  class 1 = Malicious, class 0 = Benign\n",
      "\tNote: For your binary classification, AutoGluon arbitrarily selected which label-value represents positive (Malicious) vs negative (Benign) class.\n",
      "\tTo explicitly set the positive_class, either rename classes to 1 and 0, or specify positive_class in Predictor init.\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    12114.63 MB\n",
      "\tTrain Data (Original)  Memory Usage: 29.08 MB (0.2% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\t\t\tNote: Converting 21 features to boolean dtype as they only contain 2 unique values.\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('float', []) :  7 | ['duration', 'missed_bytes', 'orig_pkts', 'orig_ip_bytes', 'resp_pkts', ...]\n",
      "\t\t('int', [])   : 23 | ['orig_bytes', 'resp_bytes', 'proto_tcp', 'proto_udp', 'service_-', ...]\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('float', [])     :  7 | ['duration', 'missed_bytes', 'orig_pkts', 'orig_ip_bytes', 'resp_pkts', ...]\n",
      "\t\t('int', [])       :  2 | ['orig_bytes', 'resp_bytes']\n",
      "\t\t('int', ['bool']) : 21 | ['proto_tcp', 'proto_udp', 'service_-', 'service_dhcp', 'service_dns', ...]\n",
      "\t0.2s = Fit runtime\n",
      "\t30 features in original data used to generate 30 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 11.27 MB (0.1% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 0.3s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'accuracy'\n",
      "\tTo change this, specify the eval_metric parameter of Predictor()\n",
      "Automatically generating train/validation split with holdout_frac=0.02063591639977548, Train Rows: 118648, Val Rows: 2500\n",
      "Fitting 13 L1 models ...\n",
      "Fitting model: KNeighborsUnif ...\n",
      "\t0.7484\t = Validation score   (accuracy)\n",
      "\t0.14s\t = Training   runtime\n",
      "\t0.14s\t = Validation runtime\n",
      "Fitting model: KNeighborsDist ...\n",
      "\t0.7316\t = Validation score   (accuracy)\n",
      "\t0.12s\t = Training   runtime\n",
      "\t0.46s\t = Validation runtime\n",
      "Fitting model: LightGBMXT ...\n",
      "\tTraining LightGBMXT with GPU, note that this may negatively impact model quality compared to CPU training.\n",
      "\t1.0\t = Validation score   (accuracy)\n",
      "\t5.7s\t = Training   runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Fitting model: LightGBM ...\n",
      "\tTraining LightGBM with GPU, note that this may negatively impact model quality compared to CPU training.\n",
      "\t1.0\t = Validation score   (accuracy)\n",
      "\t0.34s\t = Training   runtime\n",
      "\t0.05s\t = Validation runtime\n",
      "Fitting model: RandomForestGini ...\n",
      "\t0.8648\t = Validation score   (accuracy)\n",
      "\t3.9s\t = Training   runtime\n",
      "\t0.05s\t = Validation runtime\n",
      "Fitting model: RandomForestEntr ...\n",
      "\t0.8648\t = Validation score   (accuracy)\n",
      "\t3.55s\t = Training   runtime\n",
      "\t0.05s\t = Validation runtime\n",
      "Fitting model: CatBoost ...\n",
      "\tTraining CatBoost with GPU, note that this may negatively impact model quality compared to CPU training.\n",
      "\tWarning: CatBoost on GPU is experimental. If you encounter issues, use CPU for training CatBoost instead.\n",
      "\t1.0\t = Validation score   (accuracy)\n",
      "\t5.21s\t = Training   runtime\n",
      "\t0.04s\t = Validation runtime\n",
      "Fitting model: ExtraTreesGini ...\n",
      "\t0.8672\t = Validation score   (accuracy)\n",
      "\t2.85s\t = Training   runtime\n",
      "\t0.05s\t = Validation runtime\n",
      "Fitting model: ExtraTreesEntr ...\n",
      "\t0.868\t = Validation score   (accuracy)\n",
      "\t2.8s\t = Training   runtime\n",
      "\t0.05s\t = Validation runtime\n",
      "Fitting model: NeuralNetFastAI ...\n",
      "No improvement since epoch 0: early stopping\n",
      "\t0.5988\t = Validation score   (accuracy)\n",
      "\t90.93s\t = Training   runtime\n",
      "\t0.14s\t = Validation runtime\n",
      "Fitting model: XGBoost ...\n",
      "\t0.8792\t = Validation score   (accuracy)\n",
      "\t3.24s\t = Training   runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Fitting model: NeuralNetTorch ...\n",
      "\t0.8792\t = Validation score   (accuracy)\n",
      "\t42.85s\t = Training   runtime\n",
      "\t0.02s\t = Validation runtime\n",
      "Fitting model: LightGBMLarge ...\n",
      "\tTraining LightGBMLarge with GPU, note that this may negatively impact model quality compared to CPU training.\n",
      "\t1.0\t = Validation score   (accuracy)\n",
      "\t0.43s\t = Training   runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L2 ...\n",
      "\t1.0\t = Validation score   (accuracy)\n",
      "\t0.77s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "AutoGluon training complete, total runtime = 170.31s ... Best model: \"WeightedEnsemble_L2\"\n",
      "Deleting model KNeighborsUnif. All files under ./auto_gl/exp-iot23/edge_deploy/models/KNeighborsUnif/ will be removed.\n",
      "Deleting model KNeighborsDist. All files under ./auto_gl/exp-iot23/edge_deploy/models/KNeighborsDist/ will be removed.\n",
      "Deleting model LightGBM. All files under ./auto_gl/exp-iot23/edge_deploy/models/LightGBM/ will be removed.\n",
      "Deleting model RandomForestGini. All files under ./auto_gl/exp-iot23/edge_deploy/models/RandomForestGini/ will be removed.\n",
      "Deleting model RandomForestEntr. All files under ./auto_gl/exp-iot23/edge_deploy/models/RandomForestEntr/ will be removed.\n",
      "Deleting model CatBoost. All files under ./auto_gl/exp-iot23/edge_deploy/models/CatBoost/ will be removed.\n",
      "Deleting model ExtraTreesGini. All files under ./auto_gl/exp-iot23/edge_deploy/models/ExtraTreesGini/ will be removed.\n",
      "Deleting model ExtraTreesEntr. All files under ./auto_gl/exp-iot23/edge_deploy/models/ExtraTreesEntr/ will be removed.\n",
      "Deleting model NeuralNetFastAI. All files under ./auto_gl/exp-iot23/edge_deploy/models/NeuralNetFastAI/ will be removed.\n",
      "Deleting model XGBoost. All files under ./auto_gl/exp-iot23/edge_deploy/models/XGBoost/ will be removed.\n",
      "Deleting model NeuralNetTorch. All files under ./auto_gl/exp-iot23/edge_deploy/models/NeuralNetTorch/ will be removed.\n",
      "Deleting model LightGBMLarge. All files under ./auto_gl/exp-iot23/edge_deploy/models/LightGBMLarge/ will be removed.\n",
      "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"./auto_gl/exp-iot23/edge_deploy/\")\n"
     ]
    }
   ],
   "source": [
    "from autogluon.tabular import TabularDataset\n",
    "import autogluon\n",
    "\n",
    "label = 'label'\n",
    "train_data = TabularDataset(\"./Data/split/train_data.csv\")\n",
    "save_path = './auto_gl/exp-iot23/edge_deploy'  # specifies folder to store trained models\n",
    "from autogluon.tabular import TabularPredictor\n",
    "predictor_medium = TabularPredictor(label=label, path=save_path).fit(train_data, ag_args_fit={'num_gpus': 1},                                                              presets='optimize_for_deployment')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** Summary of fit() ***\n",
      "Estimated performance of each model:\n",
      "                 model  score_val  pred_time_val  fit_time  pred_time_val_marginal  fit_time_marginal  stack_level  can_infer  fit_order\n",
      "0           LightGBMXT        1.0       0.006906  5.699357                0.006906           5.699357            1       True          1\n",
      "1  WeightedEnsemble_L2        1.0       0.009811  6.471916                0.002905           0.772559            2       True          2\n",
      "Number of models trained: 2\n",
      "Types of models trained:\n",
      "{'LGBModel', 'WeightedEnsembleModel'}\n",
      "Bagging used: False \n",
      "Multi-layer stack-ensembling used: False \n",
      "Feature Metadata (Processed):\n",
      "(raw dtype, special dtypes):\n",
      "('float', [])     :  7 | ['duration', 'missed_bytes', 'orig_pkts', 'orig_ip_bytes', 'resp_pkts', ...]\n",
      "('int', [])       :  2 | ['orig_bytes', 'resp_bytes']\n",
      "('int', ['bool']) : 21 | ['proto_tcp', 'proto_udp', 'service_-', 'service_dhcp', 'service_dns', ...]\n",
      "*** End of fit() summary ***\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/media/wuguo-buaa/LENOVO_USB_HDD/PycharmProjects/Machine_learning_venv/lib/python3.8/site-packages/autogluon/core/utils/plots.py:138: UserWarning: AutoGluon summary plots cannot be created because bokeh is not installed. To see plots, please do: \"pip install bokeh==2.0.1\"\n",
      "  warnings.warn('AutoGluon summary plots cannot be created because bokeh is not installed. To see plots, please do: \"pip install bokeh==2.0.1\"')\n"
     ]
    }
   ],
   "source": [
    "results_deploy = predictor_medium.fit_summary(show_plot=True)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Fine-tune"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "import autogluon.core as ag\n",
    "\n",
    "nn_options = {  # specifies non-default hyperparameter values for neural network models\n",
    "    'num_epochs': 10,\n",
    "        'learning_rate': ag.space.Real(1e-4, 3e-2, default=3e-4, log=True),\n",
    "        'weight_decay': ag.space.Real(1e-12, 0.1, default=1e-6, log=True),\n",
    "        'dropout_prob': ag.space.Categorical(0.1, 0.0, 0.15, 0.2, 0.3, 0.4),\n",
    "        'embedding_size_factor': ag.space.Categorical(1.0, 0.5, 1.5, 0.7, 0.6, 0.8, 0.9, 1.1, 1.2, 1.3, 1.4),\n",
    "        'proc.embed_min_categories': ag.space.Categorical(4, 3, 10, 100),\n",
    "        'proc.impute_strategy': ag.space.Categorical('median', 'mean', 'most_frequent'),\n",
    "        'proc.max_category_levels': ag.space.Categorical(100, 10, 20, 200, 300, 400, 500, 1000, 10000),\n",
    "        'proc.skew_threshold': ag.space.Categorical(0.99, 0.2, 0.3, 0.5, 0.8, 0.9, 0.999, 1.0, 10.0, 100.0),\n",
    "        'num_layers': ag.space.Categorical(3, 4),\n",
    "        'hidden_size': ag.space.Categorical(128, 256, 512),\n",
    "        'activation': ag.space.Categorical('relu', 'elu'),\n",
    "    'use_batchnorm':True\n",
    "}\n",
    "nn_option_best = {'num_epochs': 10, 'epochs_wo_improve': 20, 'activation': 'relu', 'embedding_size_factor': 0.7, 'embed_exponent': 0.56, 'max_embedding_dim': 100, 'y_range': None, 'y_range_extend': 0.05, 'dropout_prob': 0.2, 'optimizer': 'adam', 'learning_rate': 0.0022071672641819566, 'weight_decay': 2.8047703924341123e-05, 'proc.embed_min_categories': 3, 'proc.impute_strategy': 'mean', 'proc.max_category_levels': 20, 'proc.skew_threshold': 0.99, 'use_ngram_features': False, 'num_layers': 3, 'hidden_size': 256, 'max_batch_size': 512, 'use_batchnorm': True, 'loss_function': 'auto'}\n",
    "CAT_options = {\n",
    "    'learning_rate': ag.space.Real(lower=5e-3, upper=0.2, default=0.05, log=True),\n",
    "        'depth': ag.space.Int(lower=5, upper=8, default=6),\n",
    "        'l2_leaf_reg': ag.space.Real(lower=1, upper=5, default=3),\n",
    "}\n",
    "CAT_option_best ={'iterations': 10000, 'learning_rate': 0.02057151708150835, 'random_seed': 0, 'allow_writing_files': False, 'eval_metric': 'Logloss', 'depth': 5, 'l2_leaf_reg': 4.854651042004117}\n",
    "\n",
    "gbm_options = {  # specifies non-default hyperparameter values for lightGBM gradient boosted trees\n",
    "    'num_boost_round': 100,  # number of boosting rounds (controls training time of GBM models)\n",
    "    'num_leaves': ag.space.Int(lower=26, upper=66, default=36),  # number of leaves in trees (integer hyperparameter)\n",
    "            'learning_rate': ag.space.Real(lower=5e-3, upper=0.2, default=0.05, log=True),\n",
    "        'feature_fraction': ag.space.Real(lower=0.75, upper=1.0, default=1.0),\n",
    "        'min_data_in_leaf': ag.space.Int(lower=2, upper=60, default=20),  # TODO: Use size of dataset to set upper, if row count is small upper should be small\n",
    "}\n",
    "gbm_option_best ={'learning_rate': 0.103335706015396, 'num_boost_round': 100, 'num_leaves': 62, 'feature_fraction': 0.842181292665241, 'min_data_in_leaf': 2}\n",
    "\n",
    "XGB_option_best = {'n_estimators': 10000, 'learning_rate': 0.0066413879388778985, 'n_jobs': -1, 'proc.max_category_levels': 100, 'objective': 'binary:logistic', 'booster': 'gbtree', 'use_label_encoder': False, 'max_depth': 10, 'min_child_weight': 1, 'gamma': 3.99897942285309, 'subsample': 0.9797166704167126, 'colsample_bytree': 0.522306150627057, 'reg_alpha': 3.068100995451961, 'reg_lambda': 5.775429488313755}\n",
    "\n",
    "XGB_option ={\n",
    "            'learning_rate': ag.space.Real(lower=5e-3, upper=0.2, default=0.1, log=True),\n",
    "        'max_depth': ag.space.Int(lower=3, upper=10, default=6),\n",
    "        'min_child_weight': ag.space.Int(lower=1, upper=5, default=1),\n",
    "        'gamma': ag.space.Real(lower=0, upper=5, default=0.01),\n",
    "        'subsample': ag.space.Real(lower=0.5, upper=1.0, default=1.0),\n",
    "        'colsample_bytree': ag.space.Real(lower=0.5, upper=1.0, default=1.0),\n",
    "        'reg_alpha': ag.space.Real(lower=0.0, upper=10.0, default=0.0),\n",
    "        'reg_lambda': ag.space.Real(lower=0.0, upper=10.0, default=1.0),\n",
    "}\n",
    "\n",
    "XT_options = {}\n",
    "RF_option = {}\n",
    "FASTAI_options = {\n",
    "            # 'layers': ag.space.Categorical(None, [200, 100], [200], [500],  [500, 200], [50, 25], [200, 100, 50], [500, 200, 100]),\n",
    "        'emb_drop': ag.space.Real(0.0, 0.5, default=0.2),\n",
    "        'ps': ag.space.Real(0.0, 0.5, default=0.1),\n",
    "        'bs': ag.space.Categorical(256, 64, 128, 512, 1024, 2048, 4096),\n",
    "        'lr': ag.space.Real(5e-5, 1e-1, default=1e-3, log=True),\n",
    "}\n",
    "hyperparameters = {  # hyperparameters of each model type\n",
    "    # 'XGB': XGB_option\n",
    "    # 'RF':RF_option,\n",
    "    # 'XT' : XT_options,\n",
    "    'GBM': gbm_option_best,\n",
    "     'CAT' : CAT_option_best,\n",
    "    #  'NN_TORCH': nn_options,  # NOTE: comment this line out if you get errors on Mac OSX\n",
    "\n",
    "}  # When these keys are missing from hyperparameters dict, no models of that type are trained\n",
    "\n",
    "time_limit = 600 * 60  # train various models for ~2 min\n",
    "num_trials = 50  # try at most 5 different hyperparameter configurations for each type of model\n",
    "search_strategy = 'auto'  # to tune hyperparameters using random search routine with a local scheduler\n",
    "\n",
    "hyperparameter_tune_kwargs = {  # HPO is not performed unless hyperparameter_tune_kwargs is specified\n",
    "    'num_trials': num_trials,\n",
    "    'scheduler': 'local',\n",
    "    'searcher': search_strategy,\n",
    "}"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning: path already exists! This predictor may overwrite an existing predictor! path=\"./auto_gl/exp-iot23-oversample/deploy-exp/STTACKING2_layer1_search\"\n",
      "Presets specified: ['optimize_for_deployment']\n",
      "============ fit kwarg info ============\n",
      "User Specified kwargs:\n",
      "{'hyperparameter_tune_kwargs': {'num_trials': 50,\n",
      "                                'scheduler': 'local',\n",
      "                                'searcher': 'auto'},\n",
      " 'keep_only_best': True,\n",
      " 'num_bag_folds': 5,\n",
      " 'num_bag_sets': 1,\n",
      " 'num_stack_levels': 0,\n",
      " 'save_space': True,\n",
      " 'verbosity': 4}\n",
      "Full kwargs:\n",
      "{'_feature_generator_kwargs': None,\n",
      " '_save_bag_folds': None,\n",
      " 'ag_args': None,\n",
      " 'ag_args_ensemble': None,\n",
      " 'ag_args_fit': None,\n",
      " 'auto_stack': False,\n",
      " 'calibrate': 'auto',\n",
      " 'excluded_model_types': None,\n",
      " 'feature_generator': 'auto',\n",
      " 'feature_prune_kwargs': None,\n",
      " 'holdout_frac': None,\n",
      " 'hyperparameter_tune_kwargs': {'num_trials': 50,\n",
      "                                'scheduler': 'local',\n",
      "                                'searcher': 'auto'},\n",
      " 'keep_only_best': True,\n",
      " 'name_suffix': None,\n",
      " 'num_bag_folds': 5,\n",
      " 'num_bag_sets': 1,\n",
      " 'num_stack_levels': 0,\n",
      " 'pseudo_data': None,\n",
      " 'quantile_levels': None,\n",
      " 'refit_full': False,\n",
      " 'save_space': True,\n",
      " 'set_best_to_refit_full': False,\n",
      " 'unlabeled_data': None,\n",
      " 'use_bag_holdout': False,\n",
      " 'verbosity': 4}\n",
      "========================================\n",
      "Warning: hyperparameter tuning is currently experimental and may cause the process to hang.\n",
      "Saving ./auto_gl/exp-iot23-oversample/deploy-exp/STTACKING2_layer1_search/learner.pkl\n",
      "Saving ./auto_gl/exp-iot23-oversample/deploy-exp/STTACKING2_layer1_search/predictor.pkl\n",
      "Beginning AutoGluon training ... Time limit = 36000s\n",
      "AutoGluon will save models to \"./auto_gl/exp-iot23-oversample/deploy-exp/STTACKING2_layer1_search/\"\n",
      "AutoGluon Version:  0.4.0\n",
      "Python Version:     3.8.13\n",
      "Operating System:   Linux\n",
      "Train Data Rows:    5469674\n",
      "Train Data Columns: 30\n",
      "Label Column: label\n",
      "Preprocessing data ...\n",
      "AutoGluon infers your prediction problem is: 'binary' (because only two unique label-values observed).\n",
      "\t2 unique label values:  ['Benign', 'Malicious']\n",
      "\tIf 'binary' is not the correct problem_type, please manually specify the problem_type parameter during predictor init (You may specify problem_type as one of: ['binary', 'multiclass', 'regression'])\n",
      "Selected class <--> label mapping:  class 1 = Malicious, class 0 = Benign\n",
      "\tNote: For your binary classification, AutoGluon arbitrarily selected which label-value represents positive (Malicious) vs negative (Benign) class.\n",
      "\tTo explicitly set the positive_class, either rename classes to 1 and 0, or specify positive_class in Predictor init.\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    7873.33 MB\n",
      "\tTrain Data (Original)  Memory Usage: 1312.72 MB (16.7% of available memory)\n",
      "\tWarning: Data size prior to feature transformation consumes 16.7% of available memory. Consider increasing memory or subsampling the data to avoid instability.\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\t\t\tNote: Converting 16 features to boolean dtype as they only contain 2 unique values.\n",
      "\t\t\tOriginal Features (exact raw dtype, raw dtype):\n",
      "\t\t\t\t('float64', 'float') : 30 | ['duration', 'orig_bytes', 'resp_bytes', 'missed_bytes', 'orig_pkts', ...]\n",
      "\t\t\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t\t\t('float', []) : 30 | ['duration', 'orig_bytes', 'resp_bytes', 'missed_bytes', 'orig_pkts', ...]\n",
      "\t\t\tTypes of features in processed data (exact raw dtype, raw dtype):\n",
      "\t\t\t\t('float64', 'float') : 14 | ['duration', 'orig_bytes', 'resp_bytes', 'missed_bytes', 'orig_pkts', ...]\n",
      "\t\t\t\t('int8', 'int')      : 16 | ['proto_tcp', 'service_dhcp', 'service_http', 'service_ssh', 'service_ssl', ...]\n",
      "\t\t\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t\t\t('float', [])     : 14 | ['duration', 'orig_bytes', 'resp_bytes', 'missed_bytes', 'orig_pkts', ...]\n",
      "\t\t\t\t('int', ['bool']) : 16 | ['proto_tcp', 'service_dhcp', 'service_http', 'service_ssh', 'service_ssl', ...]\n",
      "\t\t\t15.2s = Fit runtime\n",
      "\t\t\t30 features in original data used to generate 30 features in processed data.\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\t\t\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t\t\t('float', [])     : 14 | ['duration', 'orig_bytes', 'resp_bytes', 'missed_bytes', 'orig_pkts', ...]\n",
      "\t\t\t\t('int', ['bool']) : 16 | ['proto_tcp', 'service_dhcp', 'service_http', 'service_ssh', 'service_ssl', ...]\n",
      "\t\t\tTypes of features in processed data (exact raw dtype, raw dtype):\n",
      "\t\t\t\t('float64', 'float') : 14 | ['duration', 'orig_bytes', 'resp_bytes', 'missed_bytes', 'orig_pkts', ...]\n",
      "\t\t\t\t('int8', 'int')      : 16 | ['proto_tcp', 'service_dhcp', 'service_http', 'service_ssh', 'service_ssl', ...]\n",
      "\t\t\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t\t\t('float', [])     : 14 | ['duration', 'orig_bytes', 'resp_bytes', 'missed_bytes', 'orig_pkts', ...]\n",
      "\t\t\t\t('int', ['bool']) : 16 | ['proto_tcp', 'service_dhcp', 'service_http', 'service_ssh', 'service_ssl', ...]\n",
      "\t\t\t1.0s = Fit runtime\n",
      "\t\t\t30 features in original data used to generate 30 features in processed data.\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\t\t\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t\t\t('float', [])     : 14 | ['duration', 'orig_bytes', 'resp_bytes', 'missed_bytes', 'orig_pkts', ...]\n",
      "\t\t\t\t('int', ['bool']) : 16 | ['proto_tcp', 'service_dhcp', 'service_http', 'service_ssh', 'service_ssl', ...]\n",
      "\t\t\tTypes of features in processed data (exact raw dtype, raw dtype):\n",
      "\t\t\t\t('float64', 'float') : 14 | ['duration', 'orig_bytes', 'resp_bytes', 'missed_bytes', 'orig_pkts', ...]\n",
      "\t\t\t\t('int8', 'int')      : 16 | ['proto_tcp', 'service_dhcp', 'service_http', 'service_ssh', 'service_ssl', ...]\n",
      "\t\t\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t\t\t('float', [])     : 14 | ['duration', 'orig_bytes', 'resp_bytes', 'missed_bytes', 'orig_pkts', ...]\n",
      "\t\t\t\t('int', ['bool']) : 16 | ['proto_tcp', 'service_dhcp', 'service_http', 'service_ssh', 'service_ssl', ...]\n",
      "\t\t\t1.0s = Fit runtime\n",
      "\t\t\t30 features in original data used to generate 30 features in processed data.\n",
      "\t\tSkipping CategoryFeatureGenerator: No input feature with required dtypes.\n",
      "\t\tSkipping DatetimeFeatureGenerator: No input feature with required dtypes.\n",
      "\t\tSkipping TextSpecialFeatureGenerator: No input feature with required dtypes.\n",
      "\t\tSkipping TextNgramFeatureGenerator: No input feature with required dtypes.\n",
      "\t\tSkipping IdentityFeatureGenerator: No input feature with required dtypes.\n",
      "\t\tSkipping IsNanFeatureGenerator: No input feature with required dtypes.\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\t\t\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t\t\t('float', [])     : 14 | ['duration', 'orig_bytes', 'resp_bytes', 'missed_bytes', 'orig_pkts', ...]\n",
      "\t\t\t\t('int', ['bool']) : 16 | ['proto_tcp', 'service_dhcp', 'service_http', 'service_ssh', 'service_ssl', ...]\n",
      "\t\t\tTypes of features in processed data (exact raw dtype, raw dtype):\n",
      "\t\t\t\t('float64', 'float') : 14 | ['duration', 'orig_bytes', 'resp_bytes', 'missed_bytes', 'orig_pkts', ...]\n",
      "\t\t\t\t('int8', 'int')      : 16 | ['proto_tcp', 'service_dhcp', 'service_http', 'service_ssh', 'service_ssl', ...]\n",
      "\t\t\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t\t\t('float', [])     : 14 | ['duration', 'orig_bytes', 'resp_bytes', 'missed_bytes', 'orig_pkts', ...]\n",
      "\t\t\t\t('int', ['bool']) : 16 | ['proto_tcp', 'service_dhcp', 'service_http', 'service_ssh', 'service_ssl', ...]\n",
      "\t\t\t2.1s = Fit runtime\n",
      "\t\t\t30 features in original data used to generate 30 features in processed data.\n",
      "\tTypes of features in original data (exact raw dtype, raw dtype):\n",
      "\t\t('float64', 'float') : 30 | ['duration', 'orig_bytes', 'resp_bytes', 'missed_bytes', 'orig_pkts', ...]\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('float', []) : 30 | ['duration', 'orig_bytes', 'resp_bytes', 'missed_bytes', 'orig_pkts', ...]\n",
      "\tTypes of features in processed data (exact raw dtype, raw dtype):\n",
      "\t\t('float64', 'float') : 14 | ['duration', 'orig_bytes', 'resp_bytes', 'missed_bytes', 'orig_pkts', ...]\n",
      "\t\t('int8', 'int')      : 16 | ['proto_tcp', 'service_dhcp', 'service_http', 'service_ssh', 'service_ssl', ...]\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('float', [])     : 14 | ['duration', 'orig_bytes', 'resp_bytes', 'missed_bytes', 'orig_pkts', ...]\n",
      "\t\t('int', ['bool']) : 16 | ['proto_tcp', 'service_dhcp', 'service_http', 'service_ssh', 'service_ssl', ...]\n",
      "\t22.7s = Fit runtime\n",
      "\t30 features in original data used to generate 30 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 700.12 MB (8.9% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 26.01s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'roc_auc'\n",
      "\tThis metric expects predicted probabilities rather than predicted class labels, so you'll need to use predict_proba() instead of predict()\n",
      "\tTo change this, specify the eval_metric parameter of Predictor()\n",
      "Saving ./auto_gl/exp-iot23-oversample/deploy-exp/STTACKING2_layer1_search/learner.pkl\n",
      "Saving ./auto_gl/exp-iot23-oversample/deploy-exp/STTACKING2_layer1_search/utils/data/X.pkl\n",
      "Saving ./auto_gl/exp-iot23-oversample/deploy-exp/STTACKING2_layer1_search/utils/data/y.pkl\n",
      "Model configs that will be trained (in order):\n",
      "\tLightGBM_BAG_L1: \t{'learning_rate': 0.103335706015396, 'num_boost_round': 100, 'num_leaves': 62, 'feature_fraction': 0.842181292665241, 'min_data_in_leaf': 2, 'ag_args': {'hyperparameter_tune_kwargs': {'num_trials': 50, 'scheduler': 'local', 'searcher': 'auto'}, 'model_type': <class 'autogluon.tabular.models.lgb.lgb_model.LGBModel'>, 'priority': 90}}\n",
      "\tCatBoost_BAG_L1: \t{'iterations': 10000, 'learning_rate': 0.02057151708150835, 'random_seed': 0, 'allow_writing_files': False, 'eval_metric': 'Logloss', 'depth': 5, 'l2_leaf_reg': 4.854651042004117, 'ag_args': {'hyperparameter_tune_kwargs': {'num_trials': 50, 'scheduler': 'local', 'searcher': 'auto'}, 'model_type': <class 'autogluon.tabular.models.catboost.catboost_model.CatBoostModel'>, 'priority': 70}}\n",
      "Fitting 2 L1 models ...\n",
      "Hyperparameter tuning model: LightGBM_BAG_L1 ... Tuning model for up to 3237.66s of the 35973.99s of remaining time.\n",
      "\tDropped 0 of 30 features.\n",
      "\tDropped 0 of 30 features.\n",
      "\tDropped 0 of 30 features.\n",
      "Starting generic AbstractModel hyperparameter tuning for LightGBM model...\n",
      "\tNo hyperparameter search space specified for LightGBM. Skipping HPO. Will train one model based on the provided hyperparameters.\n",
      "\tFitting LightGBM with 'num_gpus': 0, 'num_cpus': 8\n",
      "\tFitting 100 rounds... Hyperparameters: {'learning_rate': 0.103335706015396, 'num_leaves': 62, 'feature_fraction': 0.842181292665241, 'min_data_in_leaf': 2}\n",
      "Saving ./auto_gl/exp-iot23-oversample/deploy-exp/STTACKING2_layer1_search/models/LightGBM_BAG_L1/hpo/model.pkl\n",
      "Loading: ./auto_gl/exp-iot23-oversample/deploy-exp/STTACKING2_layer1_search/models/LightGBM_BAG_L1/hpo/model.pkl\n",
      "Saving ./auto_gl/exp-iot23-oversample/deploy-exp/STTACKING2_layer1_search/models/LightGBM_BAG_L1/T1/utils/model_template.pkl\n",
      "Saving ./auto_gl/exp-iot23-oversample/deploy-exp/STTACKING2_layer1_search/models/LightGBM_BAG_L1/T1/utils/oof.pkl\n",
      "Saving ./auto_gl/exp-iot23-oversample/deploy-exp/STTACKING2_layer1_search/models/LightGBM_BAG_L1/T1/model.pkl\n",
      "Loading: ./auto_gl/exp-iot23-oversample/deploy-exp/STTACKING2_layer1_search/models/LightGBM_BAG_L1/T1/model.pkl\n",
      "Fitted model: LightGBM_BAG_L1/T1 ...\n",
      "\t0.9953\t = Validation score   (roc_auc)\n",
      "\t20.45s\t = Training   runtime\n",
      "\t0.87s\t = Validation runtime\n",
      "Saving ./auto_gl/exp-iot23-oversample/deploy-exp/STTACKING2_layer1_search/models/trainer.pkl\n",
      "Hyperparameter tuning model: CatBoost_BAG_L1 ... Tuning model for up to 3237.66s of the 35947.87s of remaining time.\n",
      "\tDropped 0 of 30 features.\n",
      "\tDropped 0 of 30 features.\n",
      "\tDropped 0 of 30 features.\n",
      "\tWarning: Potentially not enough memory to safely train CatBoost model, roughly requires: 4.463 GB, but only 7.388 GB is available...\n",
      "Starting generic AbstractModel hyperparameter tuning for CatBoost model...\n",
      "\tNo hyperparameter search space specified for CatBoost. Skipping HPO. Will train one model based on the provided hyperparameters.\n",
      "\tFitting CatBoost with 'num_gpus': 0, 'num_cpus': 8\n",
      "\tWarning: Potentially not enough memory to safely train CatBoost model, roughly requires: 4.463 GB, but only 7.388 GB is available...\n",
      "\tCatboost model hyperparameters: {'iterations': 10000, 'learning_rate': 0.02057151708150835, 'random_seed': 0, 'allow_writing_files': False, 'eval_metric': 'Logloss', 'depth': 5, 'l2_leaf_reg': 4.854651042004117, 'thread_count': 8}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:\tlearn: 0.6171594\ttotal: 347ms\tremaining: 57m 44s\n",
      "1:\tlearn: 0.5530494\ttotal: 551ms\tremaining: 45m 53s\n",
      "2:\tlearn: 0.4942617\ttotal: 773ms\tremaining: 42m 56s\n",
      "3:\tlearn: 0.4419394\ttotal: 1s\tremaining: 41m 44s\n",
      "4:\tlearn: 0.3967155\ttotal: 1.25s\tremaining: 41m 46s\n",
      "5:\tlearn: 0.3575590\ttotal: 1.49s\tremaining: 41m 13s\n",
      "6:\tlearn: 0.3231186\ttotal: 1.72s\tremaining: 40m 52s\n",
      "7:\tlearn: 0.2936566\ttotal: 1.95s\tremaining: 40m 35s\n",
      "8:\tlearn: 0.2673978\ttotal: 2.17s\tremaining: 40m 15s\n",
      "9:\tlearn: 0.2482534\ttotal: 2.39s\tremaining: 39m 51s\n",
      "10:\tlearn: 0.2282519\ttotal: 2.63s\tremaining: 39m 46s\n",
      "11:\tlearn: 0.2108790\ttotal: 2.87s\tremaining: 39m 45s\n",
      "12:\tlearn: 0.1957165\ttotal: 3.11s\tremaining: 39m 48s\n",
      "13:\tlearn: 0.1824827\ttotal: 3.37s\tremaining: 40m 2s\n",
      "14:\tlearn: 0.1709599\ttotal: 3.61s\tremaining: 40m\n",
      "15:\tlearn: 0.1607004\ttotal: 3.84s\tremaining: 39m 57s\n",
      "16:\tlearn: 0.1514922\ttotal: 4.07s\tremaining: 39m 49s\n",
      "17:\tlearn: 0.1445360\ttotal: 4.28s\tremaining: 39m 34s\n",
      "18:\tlearn: 0.1380064\ttotal: 4.49s\tremaining: 39m 17s\n",
      "19:\tlearn: 0.1312158\ttotal: 4.71s\tremaining: 39m 9s\n",
      "20:\tlearn: 0.1257333\ttotal: 4.92s\tremaining: 38m 59s\n",
      "21:\tlearn: 0.1208632\ttotal: 5.13s\tremaining: 38m 45s\n",
      "22:\tlearn: 0.1153219\ttotal: 5.37s\tremaining: 38m 48s\n",
      "23:\tlearn: 0.1111419\ttotal: 5.58s\tremaining: 38m 37s\n",
      "24:\tlearn: 0.1064330\ttotal: 5.82s\tremaining: 38m 42s\n",
      "25:\tlearn: 0.1025902\ttotal: 6.04s\tremaining: 38m 36s\n",
      "26:\tlearn: 0.0996998\ttotal: 6.25s\tremaining: 38m 30s\n",
      "27:\tlearn: 0.0968372\ttotal: 6.46s\tremaining: 38m 20s\n",
      "28:\tlearn: 0.0937090\ttotal: 6.7s\tremaining: 38m 24s\n",
      "29:\tlearn: 0.0911773\ttotal: 6.92s\tremaining: 38m 19s\n",
      "30:\tlearn: 0.0888836\ttotal: 7.14s\tremaining: 38m 17s\n",
      "31:\tlearn: 0.0873006\ttotal: 7.38s\tremaining: 38m 17s\n",
      "32:\tlearn: 0.0857754\ttotal: 7.61s\tremaining: 38m 18s\n",
      "33:\tlearn: 0.0837794\ttotal: 7.83s\tremaining: 38m 13s\n",
      "34:\tlearn: 0.0819171\ttotal: 8.05s\tremaining: 38m 11s\n",
      "35:\tlearn: 0.0806915\ttotal: 8.27s\tremaining: 38m 10s\n",
      "36:\tlearn: 0.0789642\ttotal: 8.5s\tremaining: 38m 8s\n",
      "37:\tlearn: 0.0779042\ttotal: 8.73s\tremaining: 38m 8s\n",
      "38:\tlearn: 0.0765275\ttotal: 8.95s\tremaining: 38m 6s\n",
      "39:\tlearn: 0.0755822\ttotal: 9.14s\tremaining: 37m 57s\n",
      "40:\tlearn: 0.0744622\ttotal: 9.36s\tremaining: 37m 53s\n",
      "41:\tlearn: 0.0732781\ttotal: 9.56s\tremaining: 37m 47s\n",
      "42:\tlearn: 0.0724302\ttotal: 9.8s\tremaining: 37m 48s\n",
      "43:\tlearn: 0.0717335\ttotal: 10s\tremaining: 37m 47s\n",
      "44:\tlearn: 0.0704999\ttotal: 10.3s\tremaining: 37m 50s\n",
      "45:\tlearn: 0.0698250\ttotal: 10.5s\tremaining: 37m 50s\n",
      "46:\tlearn: 0.0690284\ttotal: 10.7s\tremaining: 37m 48s\n",
      "47:\tlearn: 0.0682901\ttotal: 10.9s\tremaining: 37m 43s\n",
      "48:\tlearn: 0.0676251\ttotal: 11.1s\tremaining: 37m 36s\n",
      "49:\tlearn: 0.0669621\ttotal: 11.3s\tremaining: 37m 36s\n",
      "50:\tlearn: 0.0660725\ttotal: 11.6s\tremaining: 37m 35s\n",
      "51:\tlearn: 0.0654960\ttotal: 11.8s\tremaining: 37m 35s\n",
      "52:\tlearn: 0.0648779\ttotal: 12s\tremaining: 37m 37s\n",
      "53:\tlearn: 0.0643054\ttotal: 12.2s\tremaining: 37m 35s\n",
      "54:\tlearn: 0.0637239\ttotal: 12.5s\tremaining: 37m 33s\n",
      "55:\tlearn: 0.0632176\ttotal: 12.7s\tremaining: 37m 31s\n",
      "56:\tlearn: 0.0628236\ttotal: 12.9s\tremaining: 37m 30s\n",
      "57:\tlearn: 0.0622868\ttotal: 13.1s\tremaining: 37m 25s\n",
      "58:\tlearn: 0.0618878\ttotal: 13.3s\tremaining: 37m 21s\n",
      "59:\tlearn: 0.0614945\ttotal: 13.5s\tremaining: 37m 18s\n",
      "60:\tlearn: 0.0611776\ttotal: 13.7s\tremaining: 37m 13s\n",
      "61:\tlearn: 0.0607864\ttotal: 13.9s\tremaining: 37m 13s\n",
      "62:\tlearn: 0.0604520\ttotal: 14.1s\tremaining: 37m 9s\n",
      "63:\tlearn: 0.0602038\ttotal: 14.3s\tremaining: 37m 4s\n",
      "64:\tlearn: 0.0598276\ttotal: 14.5s\tremaining: 37m 2s\n",
      "65:\tlearn: 0.0595337\ttotal: 14.8s\tremaining: 37m 1s\n",
      "66:\tlearn: 0.0593360\ttotal: 14.9s\tremaining: 36m 54s\n",
      "67:\tlearn: 0.0590734\ttotal: 15.1s\tremaining: 36m 51s\n",
      "68:\tlearn: 0.0588420\ttotal: 15.4s\tremaining: 36m 49s\n",
      "69:\tlearn: 0.0586404\ttotal: 15.5s\tremaining: 36m 45s\n",
      "70:\tlearn: 0.0584085\ttotal: 15.7s\tremaining: 36m 42s\n",
      "71:\tlearn: 0.0582101\ttotal: 15.9s\tremaining: 36m 39s\n",
      "72:\tlearn: 0.0580292\ttotal: 16.2s\tremaining: 36m 37s\n",
      "73:\tlearn: 0.0578471\ttotal: 16.4s\tremaining: 36m 37s\n",
      "74:\tlearn: 0.0577013\ttotal: 16.6s\tremaining: 36m 35s\n",
      "75:\tlearn: 0.0575938\ttotal: 16.8s\tremaining: 36m 34s\n",
      "76:\tlearn: 0.0574490\ttotal: 17s\tremaining: 36m 29s\n",
      "77:\tlearn: 0.0572856\ttotal: 17.2s\tremaining: 36m 24s\n",
      "78:\tlearn: 0.0571366\ttotal: 17.4s\tremaining: 36m 19s\n",
      "79:\tlearn: 0.0569719\ttotal: 17.5s\tremaining: 36m 15s\n",
      "80:\tlearn: 0.0568595\ttotal: 17.8s\tremaining: 36m 15s\n",
      "81:\tlearn: 0.0566982\ttotal: 18s\tremaining: 36m 13s\n",
      "82:\tlearn: 0.0566258\ttotal: 18.2s\tremaining: 36m 12s\n",
      "83:\tlearn: 0.0564360\ttotal: 18.4s\tremaining: 36m 11s\n",
      "84:\tlearn: 0.0563321\ttotal: 18.6s\tremaining: 36m 10s\n",
      "85:\tlearn: 0.0562438\ttotal: 18.8s\tremaining: 36m 11s\n",
      "86:\tlearn: 0.0560978\ttotal: 19s\tremaining: 36m 10s\n",
      "87:\tlearn: 0.0560208\ttotal: 19.3s\tremaining: 36m 11s\n",
      "88:\tlearn: 0.0559584\ttotal: 19.5s\tremaining: 36m 9s\n",
      "89:\tlearn: 0.0558801\ttotal: 19.7s\tremaining: 36m 11s\n",
      "90:\tlearn: 0.0557905\ttotal: 20s\tremaining: 36m 12s\n",
      "91:\tlearn: 0.0556557\ttotal: 20.2s\tremaining: 36m 12s\n",
      "92:\tlearn: 0.0555887\ttotal: 20.4s\tremaining: 36m 11s\n",
      "93:\tlearn: 0.0555296\ttotal: 20.6s\tremaining: 36m 11s\n",
      "94:\tlearn: 0.0554432\ttotal: 20.8s\tremaining: 36m 11s\n",
      "95:\tlearn: 0.0553841\ttotal: 21s\tremaining: 36m 7s\n",
      "96:\tlearn: 0.0553089\ttotal: 21.2s\tremaining: 36m 7s\n",
      "97:\tlearn: 0.0552349\ttotal: 21.4s\tremaining: 36m 4s\n",
      "98:\tlearn: 0.0551775\ttotal: 21.6s\tremaining: 36m 3s\n",
      "99:\tlearn: 0.0551577\ttotal: 21.8s\tremaining: 36m 2s\n",
      "100:\tlearn: 0.0550771\ttotal: 22s\tremaining: 35m 59s\n",
      "101:\tlearn: 0.0550265\ttotal: 22.2s\tremaining: 35m 56s\n",
      "102:\tlearn: 0.0549668\ttotal: 22.4s\tremaining: 35m 54s\n",
      "103:\tlearn: 0.0549046\ttotal: 22.6s\tremaining: 35m 51s\n",
      "104:\tlearn: 0.0549090\ttotal: 22.8s\tremaining: 35m 46s\n",
      "105:\tlearn: 0.0548642\ttotal: 23s\tremaining: 35m 45s\n",
      "106:\tlearn: 0.0547949\ttotal: 23.2s\tremaining: 35m 44s\n",
      "107:\tlearn: 0.0547504\ttotal: 23.4s\tremaining: 35m 43s\n",
      "108:\tlearn: 0.0547537\ttotal: 23.6s\tremaining: 35m 38s\n",
      "109:\tlearn: 0.0546744\ttotal: 23.8s\tremaining: 35m 37s\n",
      "110:\tlearn: 0.0546189\ttotal: 23.9s\tremaining: 35m 32s\n",
      "111:\tlearn: 0.0546267\ttotal: 24.1s\tremaining: 35m 31s\n",
      "112:\tlearn: 0.0545522\ttotal: 24.4s\tremaining: 35m 31s\n",
      "113:\tlearn: 0.0545490\ttotal: 24.6s\tremaining: 35m 29s\n",
      "114:\tlearn: 0.0544924\ttotal: 24.7s\tremaining: 35m 25s\n",
      "115:\tlearn: 0.0544391\ttotal: 24.9s\tremaining: 35m 21s\n",
      "116:\tlearn: 0.0544437\ttotal: 25.1s\tremaining: 35m 18s\n",
      "117:\tlearn: 0.0544174\ttotal: 25.3s\tremaining: 35m 15s\n",
      "118:\tlearn: 0.0543899\ttotal: 25.5s\tremaining: 35m 14s\n",
      "119:\tlearn: 0.0543401\ttotal: 25.6s\tremaining: 35m 11s\n",
      "120:\tlearn: 0.0543357\ttotal: 25.9s\tremaining: 35m 11s\n",
      "121:\tlearn: 0.0542848\ttotal: 26.1s\tremaining: 35m 9s\n",
      "122:\tlearn: 0.0543267\ttotal: 26.3s\tremaining: 35m 8s\n",
      "123:\tlearn: 0.0542241\ttotal: 26.5s\tremaining: 35m 7s\n",
      "124:\tlearn: 0.0542257\ttotal: 26.7s\tremaining: 35m 6s\n",
      "125:\tlearn: 0.0542233\ttotal: 26.8s\tremaining: 35m 3s\n",
      "126:\tlearn: 0.0541587\ttotal: 27s\tremaining: 35m\n",
      "127:\tlearn: 0.0541722\ttotal: 27.2s\tremaining: 34m 56s\n",
      "128:\tlearn: 0.0541184\ttotal: 27.4s\tremaining: 34m 58s\n",
      "129:\tlearn: 0.0541109\ttotal: 27.6s\tremaining: 34m 57s\n",
      "130:\tlearn: 0.0540976\ttotal: 27.9s\tremaining: 34m 59s\n",
      "131:\tlearn: 0.0540497\ttotal: 28.1s\tremaining: 35m 1s\n",
      "132:\tlearn: 0.0540574\ttotal: 28.4s\tremaining: 35m 4s\n",
      "133:\tlearn: 0.0540080\ttotal: 28.6s\tremaining: 35m 5s\n",
      "134:\tlearn: 0.0540080\ttotal: 28.8s\tremaining: 35m 6s\n",
      "135:\tlearn: 0.0540268\ttotal: 29s\tremaining: 35m 4s\n",
      "136:\tlearn: 0.0539712\ttotal: 29.2s\tremaining: 35m 3s\n",
      "137:\tlearn: 0.0539681\ttotal: 29.4s\tremaining: 35m 2s\n",
      "138:\tlearn: 0.0539620\ttotal: 29.6s\tremaining: 35m 2s\n",
      "139:\tlearn: 0.0539032\ttotal: 29.8s\tremaining: 34m 58s\n",
      "140:\tlearn: 0.0538979\ttotal: 30s\tremaining: 34m 57s\n",
      "141:\tlearn: 0.0539075\ttotal: 30.2s\tremaining: 34m 54s\n",
      "142:\tlearn: 0.0538942\ttotal: 30.3s\tremaining: 34m 51s\n",
      "143:\tlearn: 0.0538926\ttotal: 30.5s\tremaining: 34m 50s\n",
      "144:\tlearn: 0.0538443\ttotal: 30.7s\tremaining: 34m 48s\n",
      "145:\tlearn: 0.0538590\ttotal: 30.9s\tremaining: 34m 47s\n",
      "146:\tlearn: 0.0538217\ttotal: 31.1s\tremaining: 34m 47s\n",
      "147:\tlearn: 0.0537761\ttotal: 31.4s\tremaining: 34m 46s\n",
      "148:\tlearn: 0.0537730\ttotal: 31.5s\tremaining: 34m 44s\n",
      "149:\tlearn: 0.0537781\ttotal: 31.7s\tremaining: 34m 43s\n",
      "150:\tlearn: 0.0537712\ttotal: 31.9s\tremaining: 34m 41s\n",
      "151:\tlearn: 0.0537201\ttotal: 32.1s\tremaining: 34m 41s\n",
      "152:\tlearn: 0.0537104\ttotal: 32.3s\tremaining: 34m 40s\n",
      "153:\tlearn: 0.0537276\ttotal: 32.5s\tremaining: 34m 38s\n",
      "154:\tlearn: 0.0537224\ttotal: 32.7s\tremaining: 34m 37s\n",
      "155:\tlearn: 0.0536782\ttotal: 32.9s\tremaining: 34m 37s\n",
      "156:\tlearn: 0.0536845\ttotal: 33.1s\tremaining: 34m 35s\n",
      "157:\tlearn: 0.0536622\ttotal: 33.3s\tremaining: 34m 35s\n",
      "158:\tlearn: 0.0536582\ttotal: 33.5s\tremaining: 34m 35s\n",
      "159:\tlearn: 0.0536478\ttotal: 33.8s\tremaining: 34m 36s\n",
      "160:\tlearn: 0.0536551\ttotal: 33.9s\tremaining: 34m 34s\n",
      "161:\tlearn: 0.0536085\ttotal: 34.2s\tremaining: 34m 34s\n",
      "162:\tlearn: 0.0536039\ttotal: 34.4s\tremaining: 34m 34s\n",
      "163:\tlearn: 0.0536122\ttotal: 34.6s\tremaining: 34m 33s\n",
      "164:\tlearn: 0.0536159\ttotal: 34.8s\tremaining: 34m 33s\n",
      "165:\tlearn: 0.0536016\ttotal: 35s\tremaining: 34m 32s\n",
      "166:\tlearn: 0.0535523\ttotal: 35.2s\tremaining: 34m 33s\n",
      "167:\tlearn: 0.0535538\ttotal: 35.4s\tremaining: 34m 32s\n",
      "168:\tlearn: 0.0535460\ttotal: 35.6s\tremaining: 34m 33s\n",
      "169:\tlearn: 0.0535485\ttotal: 35.8s\tremaining: 34m 31s\n",
      "170:\tlearn: 0.0535528\ttotal: 36s\tremaining: 34m 30s\n",
      "171:\tlearn: 0.0535599\ttotal: 36.3s\tremaining: 34m 31s\n",
      "172:\tlearn: 0.0535491\ttotal: 36.5s\tremaining: 34m 31s\n",
      "173:\tlearn: 0.0534164\ttotal: 36.7s\tremaining: 34m 30s\n",
      "174:\tlearn: 0.0534119\ttotal: 36.9s\tremaining: 34m 29s\n",
      "175:\tlearn: 0.0533781\ttotal: 37.1s\tremaining: 34m 28s\n",
      "176:\tlearn: 0.0533804\ttotal: 37.3s\tremaining: 34m 28s\n",
      "177:\tlearn: 0.0533849\ttotal: 37.5s\tremaining: 34m 27s\n",
      "178:\tlearn: 0.0533751\ttotal: 37.7s\tremaining: 34m 27s\n",
      "179:\tlearn: 0.0533618\ttotal: 37.9s\tremaining: 34m 26s\n",
      "180:\tlearn: 0.0533610\ttotal: 38.1s\tremaining: 34m 26s\n",
      "181:\tlearn: 0.0533232\ttotal: 38.3s\tremaining: 34m 26s\n",
      "182:\tlearn: 0.0532663\ttotal: 38.5s\tremaining: 34m 26s\n",
      "183:\tlearn: 0.0532661\ttotal: 38.7s\tremaining: 34m 25s\n",
      "184:\tlearn: 0.0532652\ttotal: 38.9s\tremaining: 34m 24s\n",
      "185:\tlearn: 0.0532556\ttotal: 39.1s\tremaining: 34m 22s\n",
      "186:\tlearn: 0.0532442\ttotal: 39.3s\tremaining: 34m 22s\n",
      "187:\tlearn: 0.0532455\ttotal: 39.5s\tremaining: 34m 19s\n",
      "188:\tlearn: 0.0532500\ttotal: 39.6s\tremaining: 34m 18s\n",
      "189:\tlearn: 0.0532467\ttotal: 39.8s\tremaining: 34m 16s\n",
      "190:\tlearn: 0.0532421\ttotal: 40s\tremaining: 34m 15s\n",
      "191:\tlearn: 0.0532410\ttotal: 40.2s\tremaining: 34m 12s\n",
      "192:\tlearn: 0.0531997\ttotal: 40.4s\tremaining: 34m 12s\n",
      "193:\tlearn: 0.0532012\ttotal: 40.6s\tremaining: 34m 10s\n",
      "194:\tlearn: 0.0532013\ttotal: 40.8s\tremaining: 34m 9s\n",
      "195:\tlearn: 0.0532001\ttotal: 40.9s\tremaining: 34m 8s\n",
      "196:\tlearn: 0.0531499\ttotal: 41.2s\tremaining: 34m 8s\n",
      "197:\tlearn: 0.0531544\ttotal: 41.4s\tremaining: 34m 7s\n",
      "198:\tlearn: 0.0531507\ttotal: 41.5s\tremaining: 34m 6s\n",
      "199:\tlearn: 0.0531528\ttotal: 41.8s\tremaining: 34m 5s\n",
      "200:\tlearn: 0.0531516\ttotal: 41.9s\tremaining: 34m 3s\n",
      "201:\tlearn: 0.0531331\ttotal: 42.1s\tremaining: 34m 2s\n",
      "202:\tlearn: 0.0531376\ttotal: 42.3s\tremaining: 34m 2s\n",
      "203:\tlearn: 0.0531384\ttotal: 42.5s\tremaining: 34m 2s\n",
      "204:\tlearn: 0.0531367\ttotal: 42.7s\tremaining: 34m\n",
      "205:\tlearn: 0.0531375\ttotal: 42.9s\tremaining: 33m 57s\n",
      "206:\tlearn: 0.0531383\ttotal: 43s\tremaining: 33m 56s\n",
      "207:\tlearn: 0.0531398\ttotal: 43.2s\tremaining: 33m 55s\n",
      "208:\tlearn: 0.0531357\ttotal: 43.4s\tremaining: 33m 53s\n",
      "209:\tlearn: 0.0531238\ttotal: 43.6s\tremaining: 33m 52s\n",
      "210:\tlearn: 0.0531206\ttotal: 43.8s\tremaining: 33m 51s\n",
      "211:\tlearn: 0.0531208\ttotal: 44s\tremaining: 33m 50s\n",
      "212:\tlearn: 0.0531066\ttotal: 44.2s\tremaining: 33m 49s\n",
      "213:\tlearn: 0.0531057\ttotal: 44.4s\tremaining: 33m 48s\n",
      "214:\tlearn: 0.0531103\ttotal: 44.5s\tremaining: 33m 47s\n",
      "215:\tlearn: 0.0531030\ttotal: 44.8s\tremaining: 33m 47s\n",
      "216:\tlearn: 0.0531024\ttotal: 44.9s\tremaining: 33m 45s\n",
      "217:\tlearn: 0.0530551\ttotal: 45.1s\tremaining: 33m 43s\n",
      "218:\tlearn: 0.0530425\ttotal: 45.3s\tremaining: 33m 44s\n",
      "219:\tlearn: 0.0530460\ttotal: 45.5s\tremaining: 33m 43s\n",
      "220:\tlearn: 0.0530411\ttotal: 45.7s\tremaining: 33m 40s\n",
      "221:\tlearn: 0.0530432\ttotal: 45.8s\tremaining: 33m 37s\n",
      "222:\tlearn: 0.0530388\ttotal: 46s\tremaining: 33m 36s\n",
      "223:\tlearn: 0.0530401\ttotal: 46.2s\tremaining: 33m 34s\n",
      "224:\tlearn: 0.0530427\ttotal: 46.4s\tremaining: 33m 34s\n",
      "225:\tlearn: 0.0529481\ttotal: 46.6s\tremaining: 33m 33s\n",
      "226:\tlearn: 0.0529498\ttotal: 46.7s\tremaining: 33m 32s\n",
      "227:\tlearn: 0.0529467\ttotal: 46.9s\tremaining: 33m 30s\n",
      "228:\tlearn: 0.0529474\ttotal: 47.1s\tremaining: 33m 29s\n",
      "229:\tlearn: 0.0529464\ttotal: 47.3s\tremaining: 33m 28s\n",
      "230:\tlearn: 0.0529437\ttotal: 47.5s\tremaining: 33m 27s\n",
      "231:\tlearn: 0.0529459\ttotal: 47.7s\tremaining: 33m 27s\n",
      "232:\tlearn: 0.0529242\ttotal: 47.8s\tremaining: 33m 25s\n",
      "233:\tlearn: 0.0529248\ttotal: 48s\tremaining: 33m 22s\n",
      "234:\tlearn: 0.0529220\ttotal: 48.2s\tremaining: 33m 21s\n",
      "235:\tlearn: 0.0529224\ttotal: 48.4s\tremaining: 33m 21s\n",
      "236:\tlearn: 0.0529181\ttotal: 48.6s\tremaining: 33m 20s\n",
      "237:\tlearn: 0.0529202\ttotal: 48.8s\tremaining: 33m 19s\n",
      "238:\tlearn: 0.0529193\ttotal: 48.9s\tremaining: 33m 18s\n",
      "239:\tlearn: 0.0529159\ttotal: 49.1s\tremaining: 33m 17s\n",
      "240:\tlearn: 0.0529178\ttotal: 49.3s\tremaining: 33m 15s\n",
      "241:\tlearn: 0.0529152\ttotal: 49.5s\tremaining: 33m 14s\n",
      "242:\tlearn: 0.0529163\ttotal: 49.6s\tremaining: 33m 13s\n",
      "243:\tlearn: 0.0529173\ttotal: 49.8s\tremaining: 33m 11s\n",
      "244:\tlearn: 0.0529006\ttotal: 50s\tremaining: 33m 10s\n",
      "245:\tlearn: 0.0529045\ttotal: 50.1s\tremaining: 33m 8s\n",
      "246:\tlearn: 0.0529030\ttotal: 50.3s\tremaining: 33m 7s\n",
      "247:\tlearn: 0.0529023\ttotal: 50.5s\tremaining: 33m 6s\n",
      "248:\tlearn: 0.0529021\ttotal: 50.7s\tremaining: 33m 5s\n",
      "249:\tlearn: 0.0528997\ttotal: 50.9s\tremaining: 33m 5s\n",
      "250:\tlearn: 0.0529003\ttotal: 51.1s\tremaining: 33m 4s\n",
      "251:\tlearn: 0.0529044\ttotal: 51.3s\tremaining: 33m 4s\n",
      "252:\tlearn: 0.0529051\ttotal: 51.5s\tremaining: 33m 3s\n",
      "253:\tlearn: 0.0528529\ttotal: 51.6s\tremaining: 33m 1s\n",
      "254:\tlearn: 0.0528559\ttotal: 51.8s\tremaining: 33m 1s\n",
      "255:\tlearn: 0.0528543\ttotal: 52s\tremaining: 32m 59s\n",
      "256:\tlearn: 0.0528036\ttotal: 52.2s\tremaining: 33m\n",
      "257:\tlearn: 0.0528018\ttotal: 52.4s\tremaining: 32m 59s\n",
      "258:\tlearn: 0.0528324\ttotal: 52.6s\tremaining: 32m 57s\n",
      "259:\tlearn: 0.0528129\ttotal: 52.8s\tremaining: 32m 57s\n",
      "260:\tlearn: 0.0528119\ttotal: 53s\tremaining: 32m 56s\n",
      "261:\tlearn: 0.0528118\ttotal: 53.1s\tremaining: 32m 53s\n",
      "262:\tlearn: 0.0528121\ttotal: 53.2s\tremaining: 32m 51s\n",
      "263:\tlearn: 0.0527584\ttotal: 53.4s\tremaining: 32m 50s\n",
      "264:\tlearn: 0.0527607\ttotal: 53.6s\tremaining: 32m 47s\n",
      "265:\tlearn: 0.0527571\ttotal: 53.8s\tremaining: 32m 47s\n",
      "266:\tlearn: 0.0527576\ttotal: 53.9s\tremaining: 32m 45s\n",
      "267:\tlearn: 0.0527569\ttotal: 54.1s\tremaining: 32m 45s\n",
      "268:\tlearn: 0.0527551\ttotal: 54.3s\tremaining: 32m 44s\n",
      "269:\tlearn: 0.0527554\ttotal: 54.5s\tremaining: 32m 43s\n",
      "270:\tlearn: 0.0527572\ttotal: 54.7s\tremaining: 32m 43s\n",
      "271:\tlearn: 0.0527552\ttotal: 54.9s\tremaining: 32m 43s\n",
      "272:\tlearn: 0.0527540\ttotal: 55.1s\tremaining: 32m 41s\n",
      "273:\tlearn: 0.0527547\ttotal: 55.2s\tremaining: 32m 40s\n",
      "274:\tlearn: 0.0527578\ttotal: 55.4s\tremaining: 32m 40s\n",
      "275:\tlearn: 0.0527396\ttotal: 55.6s\tremaining: 32m 38s\n",
      "276:\tlearn: 0.0527373\ttotal: 55.8s\tremaining: 32m 37s\n",
      "277:\tlearn: 0.0527398\ttotal: 56s\tremaining: 32m 37s\n",
      "278:\tlearn: 0.0527405\ttotal: 56.1s\tremaining: 32m 35s\n",
      "279:\tlearn: 0.0527380\ttotal: 56.3s\tremaining: 32m 33s\n",
      "280:\tlearn: 0.0527317\ttotal: 56.4s\tremaining: 32m 32s\n",
      "281:\tlearn: 0.0527323\ttotal: 56.6s\tremaining: 32m 30s\n",
      "282:\tlearn: 0.0527285\ttotal: 56.8s\tremaining: 32m 30s\n",
      "283:\tlearn: 0.0527213\ttotal: 57s\tremaining: 32m 29s\n",
      "284:\tlearn: 0.0527192\ttotal: 57.1s\tremaining: 32m 28s\n",
      "285:\tlearn: 0.0527200\ttotal: 57.3s\tremaining: 32m 27s\n",
      "286:\tlearn: 0.0526959\ttotal: 57.5s\tremaining: 32m 27s\n",
      "287:\tlearn: 0.0526963\ttotal: 57.7s\tremaining: 32m 26s\n",
      "288:\tlearn: 0.0526950\ttotal: 57.9s\tremaining: 32m 25s\n",
      "289:\tlearn: 0.0526966\ttotal: 58s\tremaining: 32m 23s\n",
      "290:\tlearn: 0.0526980\ttotal: 58.2s\tremaining: 32m 23s\n",
      "291:\tlearn: 0.0526970\ttotal: 58.4s\tremaining: 32m 22s\n",
      "292:\tlearn: 0.0526912\ttotal: 58.6s\tremaining: 32m 22s\n",
      "293:\tlearn: 0.0526914\ttotal: 58.8s\tremaining: 32m 21s\n",
      "294:\tlearn: 0.0526912\ttotal: 58.9s\tremaining: 32m 19s\n",
      "295:\tlearn: 0.0526932\ttotal: 59.1s\tremaining: 32m 18s\n",
      "296:\tlearn: 0.0526922\ttotal: 59.3s\tremaining: 32m 17s\n",
      "297:\tlearn: 0.0526917\ttotal: 59.5s\tremaining: 32m 17s\n",
      "298:\tlearn: 0.0526340\ttotal: 59.7s\tremaining: 32m 16s\n",
      "299:\tlearn: 0.0526264\ttotal: 59.9s\tremaining: 32m 15s\n",
      "300:\tlearn: 0.0526275\ttotal: 1m\tremaining: 32m 15s\n",
      "301:\tlearn: 0.0526182\ttotal: 1m\tremaining: 32m 14s\n",
      "302:\tlearn: 0.0526187\ttotal: 1m\tremaining: 32m 13s\n",
      "303:\tlearn: 0.0525995\ttotal: 1m\tremaining: 32m 12s\n",
      "304:\tlearn: 0.0525981\ttotal: 1m\tremaining: 32m 11s\n",
      "305:\tlearn: 0.0525877\ttotal: 1m\tremaining: 32m 10s\n",
      "306:\tlearn: 0.0525789\ttotal: 1m 1s\tremaining: 32m 9s\n",
      "307:\tlearn: 0.0525798\ttotal: 1m 1s\tremaining: 32m 9s\n",
      "308:\tlearn: 0.0525777\ttotal: 1m 1s\tremaining: 32m 9s\n",
      "309:\tlearn: 0.0525784\ttotal: 1m 1s\tremaining: 32m 9s\n",
      "310:\tlearn: 0.0525753\ttotal: 1m 1s\tremaining: 32m 8s\n",
      "311:\tlearn: 0.0525736\ttotal: 1m 2s\tremaining: 32m 8s\n",
      "312:\tlearn: 0.0525744\ttotal: 1m 2s\tremaining: 32m 8s\n",
      "313:\tlearn: 0.0525753\ttotal: 1m 2s\tremaining: 32m 8s\n",
      "314:\tlearn: 0.0525736\ttotal: 1m 2s\tremaining: 32m 7s\n",
      "315:\tlearn: 0.0525747\ttotal: 1m 2s\tremaining: 32m 8s\n",
      "316:\tlearn: 0.0525640\ttotal: 1m 3s\tremaining: 32m 8s\n",
      "317:\tlearn: 0.0525625\ttotal: 1m 3s\tremaining: 32m 7s\n",
      "318:\tlearn: 0.0525646\ttotal: 1m 3s\tremaining: 32m 7s\n",
      "319:\tlearn: 0.0525661\ttotal: 1m 3s\tremaining: 32m 7s\n",
      "320:\tlearn: 0.0525646\ttotal: 1m 3s\tremaining: 32m 7s\n",
      "321:\tlearn: 0.0525641\ttotal: 1m 4s\tremaining: 32m 7s\n",
      "322:\tlearn: 0.0525641\ttotal: 1m 4s\tremaining: 32m 7s\n",
      "323:\tlearn: 0.0525623\ttotal: 1m 4s\tremaining: 32m 7s\n",
      "324:\tlearn: 0.0525583\ttotal: 1m 4s\tremaining: 32m 6s\n",
      "325:\tlearn: 0.0525584\ttotal: 1m 4s\tremaining: 32m 5s\n",
      "326:\tlearn: 0.0525568\ttotal: 1m 5s\tremaining: 32m 5s\n",
      "327:\tlearn: 0.0525554\ttotal: 1m 5s\tremaining: 32m 4s\n",
      "328:\tlearn: 0.0525542\ttotal: 1m 5s\tremaining: 32m 4s\n",
      "329:\tlearn: 0.0525531\ttotal: 1m 5s\tremaining: 32m 3s\n",
      "330:\tlearn: 0.0525551\ttotal: 1m 5s\tremaining: 32m 3s\n",
      "331:\tlearn: 0.0525544\ttotal: 1m 5s\tremaining: 32m 1s\n",
      "332:\tlearn: 0.0525535\ttotal: 1m 6s\tremaining: 32m 1s\n",
      "333:\tlearn: 0.0525523\ttotal: 1m 6s\tremaining: 32m\n",
      "334:\tlearn: 0.0525515\ttotal: 1m 6s\tremaining: 32m\n",
      "335:\tlearn: 0.0525379\ttotal: 1m 6s\tremaining: 31m 59s\n",
      "336:\tlearn: 0.0525371\ttotal: 1m 6s\tremaining: 31m 58s\n",
      "337:\tlearn: 0.0525368\ttotal: 1m 7s\tremaining: 31m 58s\n",
      "338:\tlearn: 0.0525355\ttotal: 1m 7s\tremaining: 31m 58s\n",
      "339:\tlearn: 0.0525341\ttotal: 1m 7s\tremaining: 31m 57s\n",
      "340:\tlearn: 0.0525322\ttotal: 1m 7s\tremaining: 31m 56s\n",
      "341:\tlearn: 0.0525317\ttotal: 1m 7s\tremaining: 31m 55s\n",
      "342:\tlearn: 0.0525284\ttotal: 1m 8s\tremaining: 31m 54s\n",
      "343:\tlearn: 0.0525273\ttotal: 1m 8s\tremaining: 31m 54s\n",
      "344:\tlearn: 0.0525262\ttotal: 1m 8s\tremaining: 31m 53s\n",
      "345:\tlearn: 0.0525300\ttotal: 1m 8s\tremaining: 31m 53s\n",
      "346:\tlearn: 0.0525286\ttotal: 1m 8s\tremaining: 31m 53s\n",
      "347:\tlearn: 0.0525274\ttotal: 1m 8s\tremaining: 31m 52s\n",
      "348:\tlearn: 0.0525265\ttotal: 1m 9s\tremaining: 31m 52s\n",
      "349:\tlearn: 0.0525250\ttotal: 1m 9s\tremaining: 31m 51s\n",
      "350:\tlearn: 0.0525241\ttotal: 1m 9s\tremaining: 31m 51s\n",
      "351:\tlearn: 0.0525199\ttotal: 1m 9s\tremaining: 31m 50s\n",
      "352:\tlearn: 0.0525185\ttotal: 1m 9s\tremaining: 31m 50s\n",
      "353:\tlearn: 0.0525172\ttotal: 1m 10s\tremaining: 31m 49s\n",
      "354:\tlearn: 0.0525116\ttotal: 1m 10s\tremaining: 31m 48s\n",
      "355:\tlearn: 0.0525077\ttotal: 1m 10s\tremaining: 31m 47s\n",
      "356:\tlearn: 0.0525073\ttotal: 1m 10s\tremaining: 31m 47s\n",
      "357:\tlearn: 0.0525067\ttotal: 1m 10s\tremaining: 31m 45s\n",
      "358:\tlearn: 0.0525057\ttotal: 1m 10s\tremaining: 31m 45s\n",
      "359:\tlearn: 0.0525055\ttotal: 1m 11s\tremaining: 31m 44s\n",
      "360:\tlearn: 0.0525040\ttotal: 1m 11s\tremaining: 31m 44s\n",
      "361:\tlearn: 0.0525005\ttotal: 1m 11s\tremaining: 31m 44s\n",
      "362:\tlearn: 0.0525029\ttotal: 1m 11s\tremaining: 31m 44s\n",
      "363:\tlearn: 0.0524911\ttotal: 1m 11s\tremaining: 31m 43s\n",
      "364:\tlearn: 0.0524836\ttotal: 1m 12s\tremaining: 31m 42s\n",
      "365:\tlearn: 0.0524831\ttotal: 1m 12s\tremaining: 31m 42s\n",
      "366:\tlearn: 0.0524815\ttotal: 1m 12s\tremaining: 31m 42s\n",
      "367:\tlearn: 0.0524787\ttotal: 1m 12s\tremaining: 31m 41s\n",
      "368:\tlearn: 0.0524777\ttotal: 1m 12s\tremaining: 31m 40s\n",
      "369:\tlearn: 0.0524778\ttotal: 1m 13s\tremaining: 31m 40s\n",
      "370:\tlearn: 0.0524797\ttotal: 1m 13s\tremaining: 31m 40s\n",
      "371:\tlearn: 0.0524788\ttotal: 1m 13s\tremaining: 31m 40s\n",
      "372:\tlearn: 0.0524706\ttotal: 1m 13s\tremaining: 31m 40s\n",
      "373:\tlearn: 0.0524707\ttotal: 1m 13s\tremaining: 31m 39s\n",
      "374:\tlearn: 0.0524693\ttotal: 1m 13s\tremaining: 31m 38s\n",
      "375:\tlearn: 0.0524687\ttotal: 1m 14s\tremaining: 31m 38s\n",
      "376:\tlearn: 0.0524675\ttotal: 1m 14s\tremaining: 31m 38s\n",
      "377:\tlearn: 0.0524656\ttotal: 1m 14s\tremaining: 31m 38s\n",
      "378:\tlearn: 0.0524652\ttotal: 1m 14s\tremaining: 31m 37s\n",
      "379:\tlearn: 0.0524665\ttotal: 1m 14s\tremaining: 31m 37s\n",
      "380:\tlearn: 0.0524628\ttotal: 1m 15s\tremaining: 31m 36s\n",
      "381:\tlearn: 0.0524551\ttotal: 1m 15s\tremaining: 31m 35s\n",
      "382:\tlearn: 0.0524548\ttotal: 1m 15s\tremaining: 31m 34s\n",
      "383:\tlearn: 0.0524563\ttotal: 1m 15s\tremaining: 31m 34s\n",
      "384:\tlearn: 0.0524554\ttotal: 1m 15s\tremaining: 31m 34s\n",
      "385:\tlearn: 0.0524529\ttotal: 1m 16s\tremaining: 31m 34s\n",
      "386:\tlearn: 0.0524522\ttotal: 1m 16s\tremaining: 31m 33s\n",
      "387:\tlearn: 0.0524518\ttotal: 1m 16s\tremaining: 31m 33s\n",
      "388:\tlearn: 0.0524501\ttotal: 1m 16s\tremaining: 31m 32s\n",
      "389:\tlearn: 0.0524523\ttotal: 1m 16s\tremaining: 31m 31s\n",
      "390:\tlearn: 0.0524482\ttotal: 1m 16s\tremaining: 31m 31s\n",
      "391:\tlearn: 0.0524483\ttotal: 1m 17s\tremaining: 31m 30s\n",
      "392:\tlearn: 0.0524474\ttotal: 1m 17s\tremaining: 31m 30s\n",
      "393:\tlearn: 0.0524471\ttotal: 1m 17s\tremaining: 31m 29s\n",
      "394:\tlearn: 0.0524468\ttotal: 1m 17s\tremaining: 31m 29s\n",
      "395:\tlearn: 0.0524051\ttotal: 1m 17s\tremaining: 31m 29s\n",
      "396:\tlearn: 0.0524083\ttotal: 1m 18s\tremaining: 31m 28s\n",
      "397:\tlearn: 0.0524083\ttotal: 1m 18s\tremaining: 31m 27s\n",
      "398:\tlearn: 0.0524079\ttotal: 1m 18s\tremaining: 31m 27s\n",
      "399:\tlearn: 0.0524076\ttotal: 1m 18s\tremaining: 31m 27s\n",
      "400:\tlearn: 0.0524070\ttotal: 1m 18s\tremaining: 31m 26s\n",
      "401:\tlearn: 0.0524090\ttotal: 1m 18s\tremaining: 31m 25s\n",
      "402:\tlearn: 0.0524064\ttotal: 1m 19s\tremaining: 31m 25s\n",
      "403:\tlearn: 0.0524055\ttotal: 1m 19s\tremaining: 31m 24s\n",
      "404:\tlearn: 0.0524065\ttotal: 1m 19s\tremaining: 31m 24s\n",
      "405:\tlearn: 0.0524060\ttotal: 1m 19s\tremaining: 31m 24s\n",
      "406:\tlearn: 0.0523531\ttotal: 1m 19s\tremaining: 31m 23s\n",
      "407:\tlearn: 0.0523703\ttotal: 1m 20s\tremaining: 31m 21s\n",
      "408:\tlearn: 0.0523519\ttotal: 1m 20s\tremaining: 31m 21s\n",
      "409:\tlearn: 0.0523496\ttotal: 1m 20s\tremaining: 31m 21s\n",
      "410:\tlearn: 0.0523490\ttotal: 1m 20s\tremaining: 31m 19s\n",
      "411:\tlearn: 0.0523514\ttotal: 1m 20s\tremaining: 31m 19s\n",
      "412:\tlearn: 0.0523446\ttotal: 1m 20s\tremaining: 31m 18s\n",
      "413:\tlearn: 0.0523442\ttotal: 1m 21s\tremaining: 31m 17s\n",
      "414:\tlearn: 0.0523467\ttotal: 1m 21s\tremaining: 31m 17s\n",
      "415:\tlearn: 0.0523465\ttotal: 1m 21s\tremaining: 31m 16s\n",
      "416:\tlearn: 0.0523475\ttotal: 1m 21s\tremaining: 31m 15s\n",
      "417:\tlearn: 0.0523469\ttotal: 1m 21s\tremaining: 31m 15s\n",
      "418:\tlearn: 0.0523477\ttotal: 1m 22s\tremaining: 31m 15s\n",
      "419:\tlearn: 0.0523458\ttotal: 1m 22s\tremaining: 31m 15s\n",
      "420:\tlearn: 0.0523455\ttotal: 1m 22s\tremaining: 31m 15s\n",
      "421:\tlearn: 0.0523455\ttotal: 1m 22s\tremaining: 31m 15s\n",
      "422:\tlearn: 0.0523459\ttotal: 1m 22s\tremaining: 31m 14s\n",
      "423:\tlearn: 0.0523482\ttotal: 1m 22s\tremaining: 31m 14s\n",
      "424:\tlearn: 0.0523481\ttotal: 1m 23s\tremaining: 31m 13s\n",
      "425:\tlearn: 0.0523482\ttotal: 1m 23s\tremaining: 31m 13s\n",
      "426:\tlearn: 0.0523451\ttotal: 1m 23s\tremaining: 31m 12s\n",
      "427:\tlearn: 0.0523441\ttotal: 1m 23s\tremaining: 31m 12s\n",
      "428:\tlearn: 0.0523455\ttotal: 1m 23s\tremaining: 31m 10s\n",
      "429:\tlearn: 0.0523426\ttotal: 1m 24s\tremaining: 31m 11s\n",
      "430:\tlearn: 0.0523420\ttotal: 1m 24s\tremaining: 31m 10s\n",
      "431:\tlearn: 0.0523390\ttotal: 1m 24s\tremaining: 31m 10s\n",
      "432:\tlearn: 0.0523381\ttotal: 1m 24s\tremaining: 31m 9s\n",
      "433:\tlearn: 0.0523381\ttotal: 1m 24s\tremaining: 31m 9s\n",
      "434:\tlearn: 0.0523377\ttotal: 1m 24s\tremaining: 31m 8s\n",
      "435:\tlearn: 0.0523377\ttotal: 1m 25s\tremaining: 31m 8s\n",
      "436:\tlearn: 0.0523358\ttotal: 1m 25s\tremaining: 31m 7s\n",
      "437:\tlearn: 0.0523349\ttotal: 1m 25s\tremaining: 31m 7s\n",
      "438:\tlearn: 0.0523359\ttotal: 1m 25s\tremaining: 31m 7s\n",
      "439:\tlearn: 0.0523353\ttotal: 1m 25s\tremaining: 31m 7s\n",
      "440:\tlearn: 0.0523347\ttotal: 1m 26s\tremaining: 31m 6s\n",
      "441:\tlearn: 0.0523339\ttotal: 1m 26s\tremaining: 31m 6s\n",
      "442:\tlearn: 0.0523338\ttotal: 1m 26s\tremaining: 31m 5s\n",
      "443:\tlearn: 0.0523322\ttotal: 1m 26s\tremaining: 31m 5s\n",
      "444:\tlearn: 0.0523315\ttotal: 1m 26s\tremaining: 31m 5s\n",
      "445:\tlearn: 0.0523164\ttotal: 1m 27s\tremaining: 31m 5s\n",
      "446:\tlearn: 0.0523153\ttotal: 1m 27s\tremaining: 31m 4s\n",
      "447:\tlearn: 0.0523141\ttotal: 1m 27s\tremaining: 31m 4s\n",
      "448:\tlearn: 0.0523128\ttotal: 1m 27s\tremaining: 31m 3s\n",
      "449:\tlearn: 0.0523127\ttotal: 1m 27s\tremaining: 31m 3s\n",
      "450:\tlearn: 0.0523127\ttotal: 1m 27s\tremaining: 31m 2s\n",
      "451:\tlearn: 0.0523137\ttotal: 1m 28s\tremaining: 31m 2s\n",
      "452:\tlearn: 0.0523134\ttotal: 1m 28s\tremaining: 31m 1s\n",
      "453:\tlearn: 0.0523085\ttotal: 1m 28s\tremaining: 31m 1s\n",
      "454:\tlearn: 0.0522870\ttotal: 1m 28s\tremaining: 31m 1s\n",
      "455:\tlearn: 0.0522863\ttotal: 1m 28s\tremaining: 31m\n",
      "456:\tlearn: 0.0522860\ttotal: 1m 29s\tremaining: 31m\n",
      "457:\tlearn: 0.0522851\ttotal: 1m 29s\tremaining: 30m 59s\n",
      "458:\tlearn: 0.0522851\ttotal: 1m 29s\tremaining: 30m 59s\n",
      "459:\tlearn: 0.0522776\ttotal: 1m 29s\tremaining: 30m 58s\n",
      "460:\tlearn: 0.0522772\ttotal: 1m 29s\tremaining: 30m 58s\n",
      "461:\tlearn: 0.0522772\ttotal: 1m 29s\tremaining: 30m 56s\n",
      "462:\tlearn: 0.0522769\ttotal: 1m 30s\tremaining: 30m 57s\n",
      "463:\tlearn: 0.0522787\ttotal: 1m 30s\tremaining: 30m 56s\n",
      "464:\tlearn: 0.0522774\ttotal: 1m 30s\tremaining: 30m 56s\n",
      "465:\tlearn: 0.0522765\ttotal: 1m 30s\tremaining: 30m 56s\n",
      "466:\tlearn: 0.0522758\ttotal: 1m 30s\tremaining: 30m 56s\n",
      "467:\tlearn: 0.0522755\ttotal: 1m 31s\tremaining: 30m 56s\n",
      "468:\tlearn: 0.0522749\ttotal: 1m 31s\tremaining: 30m 56s\n",
      "469:\tlearn: 0.0522758\ttotal: 1m 31s\tremaining: 30m 56s\n",
      "470:\tlearn: 0.0522766\ttotal: 1m 31s\tremaining: 30m 55s\n",
      "471:\tlearn: 0.0522766\ttotal: 1m 31s\tremaining: 30m 55s\n",
      "472:\tlearn: 0.0522757\ttotal: 1m 32s\tremaining: 30m 54s\n",
      "473:\tlearn: 0.0522755\ttotal: 1m 32s\tremaining: 30m 54s\n",
      "474:\tlearn: 0.0522743\ttotal: 1m 32s\tremaining: 30m 53s\n",
      "475:\tlearn: 0.0522737\ttotal: 1m 32s\tremaining: 30m 53s\n",
      "476:\tlearn: 0.0522731\ttotal: 1m 32s\tremaining: 30m 53s\n",
      "477:\tlearn: 0.0522729\ttotal: 1m 32s\tremaining: 30m 52s\n",
      "478:\tlearn: 0.0522570\ttotal: 1m 33s\tremaining: 30m 51s\n",
      "479:\tlearn: 0.0522564\ttotal: 1m 33s\tremaining: 30m 51s\n",
      "480:\tlearn: 0.0522557\ttotal: 1m 33s\tremaining: 30m 51s\n",
      "481:\tlearn: 0.0522674\ttotal: 1m 33s\tremaining: 30m 51s\n",
      "482:\tlearn: 0.0522674\ttotal: 1m 33s\tremaining: 30m 50s\n",
      "483:\tlearn: 0.0522670\ttotal: 1m 34s\tremaining: 30m 50s\n",
      "484:\tlearn: 0.0522660\ttotal: 1m 34s\tremaining: 30m 49s\n",
      "485:\tlearn: 0.0522660\ttotal: 1m 34s\tremaining: 30m 48s\n",
      "486:\tlearn: 0.0522454\ttotal: 1m 34s\tremaining: 30m 48s\n",
      "487:\tlearn: 0.0522456\ttotal: 1m 34s\tremaining: 30m 47s\n",
      "488:\tlearn: 0.0522472\ttotal: 1m 34s\tremaining: 30m 47s\n",
      "489:\tlearn: 0.0522461\ttotal: 1m 35s\tremaining: 30m 46s\n",
      "490:\tlearn: 0.0522468\ttotal: 1m 35s\tremaining: 30m 46s\n",
      "491:\tlearn: 0.0522462\ttotal: 1m 35s\tremaining: 30m 45s\n",
      "492:\tlearn: 0.0522462\ttotal: 1m 35s\tremaining: 30m 44s\n",
      "493:\tlearn: 0.0522433\ttotal: 1m 35s\tremaining: 30m 43s\n",
      "494:\tlearn: 0.0522430\ttotal: 1m 35s\tremaining: 30m 43s\n",
      "495:\tlearn: 0.0522429\ttotal: 1m 36s\tremaining: 30m 42s\n",
      "496:\tlearn: 0.0522426\ttotal: 1m 36s\tremaining: 30m 41s\n",
      "497:\tlearn: 0.0522421\ttotal: 1m 36s\tremaining: 30m 41s\n",
      "498:\tlearn: 0.0522420\ttotal: 1m 36s\tremaining: 30m 40s\n",
      "499:\tlearn: 0.0522415\ttotal: 1m 36s\tremaining: 30m 39s\n",
      "500:\tlearn: 0.0522399\ttotal: 1m 37s\tremaining: 30m 39s\n",
      "501:\tlearn: 0.0522399\ttotal: 1m 37s\tremaining: 30m 39s\n",
      "502:\tlearn: 0.0522412\ttotal: 1m 37s\tremaining: 30m 39s\n",
      "503:\tlearn: 0.0522372\ttotal: 1m 37s\tremaining: 30m 39s\n",
      "504:\tlearn: 0.0522372\ttotal: 1m 37s\tremaining: 30m 38s\n",
      "505:\tlearn: 0.0522372\ttotal: 1m 37s\tremaining: 30m 37s\n",
      "506:\tlearn: 0.0522368\ttotal: 1m 38s\tremaining: 30m 37s\n",
      "507:\tlearn: 0.0522396\ttotal: 1m 38s\tremaining: 30m 37s\n",
      "508:\tlearn: 0.0522389\ttotal: 1m 38s\tremaining: 30m 36s\n",
      "509:\tlearn: 0.0522387\ttotal: 1m 38s\tremaining: 30m 36s\n",
      "510:\tlearn: 0.0522404\ttotal: 1m 38s\tremaining: 30m 36s\n",
      "511:\tlearn: 0.0522381\ttotal: 1m 39s\tremaining: 30m 36s\n",
      "512:\tlearn: 0.0522377\ttotal: 1m 39s\tremaining: 30m 36s\n",
      "513:\tlearn: 0.0522372\ttotal: 1m 39s\tremaining: 30m 35s\n",
      "514:\tlearn: 0.0522379\ttotal: 1m 39s\tremaining: 30m 34s\n",
      "515:\tlearn: 0.0522366\ttotal: 1m 39s\tremaining: 30m 34s\n",
      "516:\tlearn: 0.0522355\ttotal: 1m 39s\tremaining: 30m 34s\n",
      "517:\tlearn: 0.0522355\ttotal: 1m 40s\tremaining: 30m 33s\n",
      "518:\tlearn: 0.0522352\ttotal: 1m 40s\tremaining: 30m 33s\n",
      "519:\tlearn: 0.0522344\ttotal: 1m 40s\tremaining: 30m 32s\n",
      "520:\tlearn: 0.0522356\ttotal: 1m 40s\tremaining: 30m 32s\n",
      "521:\tlearn: 0.0522347\ttotal: 1m 40s\tremaining: 30m 32s\n",
      "522:\tlearn: 0.0522340\ttotal: 1m 41s\tremaining: 30m 32s\n",
      "523:\tlearn: 0.0522343\ttotal: 1m 41s\tremaining: 30m 31s\n",
      "524:\tlearn: 0.0522336\ttotal: 1m 41s\tremaining: 30m 30s\n",
      "525:\tlearn: 0.0522335\ttotal: 1m 41s\tremaining: 30m 30s\n",
      "526:\tlearn: 0.0522331\ttotal: 1m 41s\tremaining: 30m 30s\n",
      "527:\tlearn: 0.0522333\ttotal: 1m 41s\tremaining: 30m 29s\n",
      "528:\tlearn: 0.0522325\ttotal: 1m 42s\tremaining: 30m 29s\n",
      "529:\tlearn: 0.0522318\ttotal: 1m 42s\tremaining: 30m 29s\n",
      "530:\tlearn: 0.0522318\ttotal: 1m 42s\tremaining: 30m 28s\n",
      "531:\tlearn: 0.0522316\ttotal: 1m 42s\tremaining: 30m 28s\n",
      "532:\tlearn: 0.0522315\ttotal: 1m 42s\tremaining: 30m 27s\n",
      "533:\tlearn: 0.0522310\ttotal: 1m 43s\tremaining: 30m 27s\n",
      "534:\tlearn: 0.0522334\ttotal: 1m 43s\tremaining: 30m 27s\n",
      "535:\tlearn: 0.0522329\ttotal: 1m 43s\tremaining: 30m 26s\n",
      "536:\tlearn: 0.0522337\ttotal: 1m 43s\tremaining: 30m 25s\n",
      "537:\tlearn: 0.0522327\ttotal: 1m 43s\tremaining: 30m 25s\n",
      "538:\tlearn: 0.0522319\ttotal: 1m 43s\tremaining: 30m 24s\n",
      "539:\tlearn: 0.0522319\ttotal: 1m 44s\tremaining: 30m 23s\n",
      "540:\tlearn: 0.0522320\ttotal: 1m 44s\tremaining: 30m 23s\n",
      "541:\tlearn: 0.0522319\ttotal: 1m 44s\tremaining: 30m 22s\n",
      "542:\tlearn: 0.0522314\ttotal: 1m 44s\tremaining: 30m 22s\n",
      "543:\tlearn: 0.0522251\ttotal: 1m 44s\tremaining: 30m 21s\n",
      "544:\tlearn: 0.0522251\ttotal: 1m 44s\tremaining: 30m 20s\n",
      "545:\tlearn: 0.0522262\ttotal: 1m 45s\tremaining: 30m 20s\n",
      "546:\tlearn: 0.0522294\ttotal: 1m 45s\tremaining: 30m 20s\n",
      "547:\tlearn: 0.0522234\ttotal: 1m 45s\tremaining: 30m 19s\n",
      "548:\tlearn: 0.0522238\ttotal: 1m 45s\tremaining: 30m 20s\n",
      "549:\tlearn: 0.0522233\ttotal: 1m 45s\tremaining: 30m 20s\n",
      "550:\tlearn: 0.0522224\ttotal: 1m 46s\tremaining: 30m 19s\n",
      "551:\tlearn: 0.0522222\ttotal: 1m 46s\tremaining: 30m 19s\n",
      "552:\tlearn: 0.0522222\ttotal: 1m 46s\tremaining: 30m 18s\n",
      "553:\tlearn: 0.0522215\ttotal: 1m 46s\tremaining: 30m 18s\n",
      "554:\tlearn: 0.0522210\ttotal: 1m 46s\tremaining: 30m 18s\n",
      "555:\tlearn: 0.0522202\ttotal: 1m 47s\tremaining: 30m 18s\n",
      "556:\tlearn: 0.0522203\ttotal: 1m 47s\tremaining: 30m 18s\n",
      "557:\tlearn: 0.0522200\ttotal: 1m 47s\tremaining: 30m 17s\n",
      "558:\tlearn: 0.0522202\ttotal: 1m 47s\tremaining: 30m 16s\n",
      "559:\tlearn: 0.0522190\ttotal: 1m 47s\tremaining: 30m 16s\n",
      "560:\tlearn: 0.0522192\ttotal: 1m 47s\tremaining: 30m 15s\n",
      "561:\tlearn: 0.0522178\ttotal: 1m 48s\tremaining: 30m 15s\n",
      "562:\tlearn: 0.0522178\ttotal: 1m 48s\tremaining: 30m 14s\n",
      "563:\tlearn: 0.0522182\ttotal: 1m 48s\tremaining: 30m 14s\n",
      "564:\tlearn: 0.0522177\ttotal: 1m 48s\tremaining: 30m 14s\n",
      "565:\tlearn: 0.0522173\ttotal: 1m 48s\tremaining: 30m 14s\n",
      "566:\tlearn: 0.0522147\ttotal: 1m 49s\tremaining: 30m 13s\n",
      "567:\tlearn: 0.0522146\ttotal: 1m 49s\tremaining: 30m 13s\n",
      "568:\tlearn: 0.0522145\ttotal: 1m 49s\tremaining: 30m 12s\n",
      "569:\tlearn: 0.0522140\ttotal: 1m 49s\tremaining: 30m 12s\n",
      "570:\tlearn: 0.0522152\ttotal: 1m 49s\tremaining: 30m 11s\n",
      "571:\tlearn: 0.0522152\ttotal: 1m 49s\tremaining: 30m 11s\n",
      "572:\tlearn: 0.0522152\ttotal: 1m 50s\tremaining: 30m 10s\n",
      "573:\tlearn: 0.0522134\ttotal: 1m 50s\tremaining: 30m 10s\n",
      "574:\tlearn: 0.0522126\ttotal: 1m 50s\tremaining: 30m 10s\n",
      "575:\tlearn: 0.0522121\ttotal: 1m 50s\tremaining: 30m 9s\n",
      "576:\tlearn: 0.0522120\ttotal: 1m 50s\tremaining: 30m 9s\n",
      "577:\tlearn: 0.0522110\ttotal: 1m 50s\tremaining: 30m 9s\n",
      "578:\tlearn: 0.0522100\ttotal: 1m 51s\tremaining: 30m 9s\n",
      "579:\tlearn: 0.0522095\ttotal: 1m 51s\tremaining: 30m 8s\n",
      "580:\tlearn: 0.0522087\ttotal: 1m 51s\tremaining: 30m 8s\n",
      "581:\tlearn: 0.0522086\ttotal: 1m 51s\tremaining: 30m 7s\n",
      "582:\tlearn: 0.0522082\ttotal: 1m 51s\tremaining: 30m 6s\n",
      "583:\tlearn: 0.0522075\ttotal: 1m 52s\tremaining: 30m 6s\n",
      "584:\tlearn: 0.0522081\ttotal: 1m 52s\tremaining: 30m 6s\n",
      "585:\tlearn: 0.0522078\ttotal: 1m 52s\tremaining: 30m 5s\n",
      "586:\tlearn: 0.0522033\ttotal: 1m 52s\tremaining: 30m 4s\n",
      "587:\tlearn: 0.0522029\ttotal: 1m 52s\tremaining: 30m 4s\n",
      "588:\tlearn: 0.0522023\ttotal: 1m 52s\tremaining: 30m 4s\n",
      "589:\tlearn: 0.0522016\ttotal: 1m 53s\tremaining: 30m 4s\n",
      "590:\tlearn: 0.0522014\ttotal: 1m 53s\tremaining: 30m 3s\n",
      "591:\tlearn: 0.0522018\ttotal: 1m 53s\tremaining: 30m 3s\n",
      "592:\tlearn: 0.0522002\ttotal: 1m 53s\tremaining: 30m 3s\n",
      "593:\tlearn: 0.0521999\ttotal: 1m 53s\tremaining: 30m 3s\n",
      "594:\tlearn: 0.0521993\ttotal: 1m 54s\tremaining: 30m 3s\n",
      "595:\tlearn: 0.0521993\ttotal: 1m 54s\tremaining: 30m 2s\n",
      "596:\tlearn: 0.0521989\ttotal: 1m 54s\tremaining: 30m 2s\n",
      "597:\tlearn: 0.0521989\ttotal: 1m 54s\tremaining: 30m 2s\n",
      "598:\tlearn: 0.0521980\ttotal: 1m 54s\tremaining: 30m 1s\n",
      "599:\tlearn: 0.0521980\ttotal: 1m 54s\tremaining: 30m\n",
      "600:\tlearn: 0.0521964\ttotal: 1m 55s\tremaining: 30m\n",
      "601:\tlearn: 0.0521985\ttotal: 1m 55s\tremaining: 30m\n",
      "602:\tlearn: 0.0521980\ttotal: 1m 55s\tremaining: 29m 59s\n",
      "603:\tlearn: 0.0521996\ttotal: 1m 55s\tremaining: 29m 59s\n",
      "604:\tlearn: 0.0521991\ttotal: 1m 55s\tremaining: 29m 59s\n",
      "605:\tlearn: 0.0521990\ttotal: 1m 56s\tremaining: 29m 59s\n",
      "606:\tlearn: 0.0521987\ttotal: 1m 56s\tremaining: 29m 59s\n",
      "607:\tlearn: 0.0521987\ttotal: 1m 56s\tremaining: 29m 58s\n",
      "608:\tlearn: 0.0521995\ttotal: 1m 56s\tremaining: 29m 58s\n",
      "609:\tlearn: 0.0521995\ttotal: 1m 56s\tremaining: 29m 57s\n",
      "610:\tlearn: 0.0521995\ttotal: 1m 56s\tremaining: 29m 56s\n",
      "611:\tlearn: 0.0521992\ttotal: 1m 57s\tremaining: 29m 56s\n",
      "612:\tlearn: 0.0521992\ttotal: 1m 57s\tremaining: 29m 56s\n",
      "613:\tlearn: 0.0521983\ttotal: 1m 57s\tremaining: 29m 55s\n",
      "614:\tlearn: 0.0521982\ttotal: 1m 57s\tremaining: 29m 55s\n",
      "615:\tlearn: 0.0521980\ttotal: 1m 57s\tremaining: 29m 55s\n",
      "616:\tlearn: 0.0521985\ttotal: 1m 58s\tremaining: 29m 54s\n",
      "617:\tlearn: 0.0521983\ttotal: 1m 58s\tremaining: 29m 53s\n",
      "618:\tlearn: 0.0521977\ttotal: 1m 58s\tremaining: 29m 53s\n",
      "619:\tlearn: 0.0521973\ttotal: 1m 58s\tremaining: 29m 53s\n",
      "620:\tlearn: 0.0521973\ttotal: 1m 58s\tremaining: 29m 52s\n",
      "621:\tlearn: 0.0521971\ttotal: 1m 58s\tremaining: 29m 52s\n",
      "622:\tlearn: 0.0521977\ttotal: 1m 59s\tremaining: 29m 51s\n",
      "623:\tlearn: 0.0521966\ttotal: 1m 59s\tremaining: 29m 51s\n",
      "624:\tlearn: 0.0521966\ttotal: 1m 59s\tremaining: 29m 50s\n",
      "625:\tlearn: 0.0521963\ttotal: 1m 59s\tremaining: 29m 50s\n",
      "626:\tlearn: 0.0521962\ttotal: 1m 59s\tremaining: 29m 49s\n",
      "627:\tlearn: 0.0521963\ttotal: 1m 59s\tremaining: 29m 48s\n",
      "628:\tlearn: 0.0521962\ttotal: 2m\tremaining: 29m 48s\n",
      "629:\tlearn: 0.0521962\ttotal: 2m\tremaining: 29m 47s\n",
      "630:\tlearn: 0.0521957\ttotal: 2m\tremaining: 29m 47s\n",
      "631:\tlearn: 0.0521953\ttotal: 2m\tremaining: 29m 47s\n",
      "632:\tlearn: 0.0521953\ttotal: 2m\tremaining: 29m 47s\n",
      "633:\tlearn: 0.0521956\ttotal: 2m\tremaining: 29m 46s\n",
      "634:\tlearn: 0.0521942\ttotal: 2m 1s\tremaining: 29m 46s\n",
      "635:\tlearn: 0.0521950\ttotal: 2m 1s\tremaining: 29m 45s\n",
      "636:\tlearn: 0.0521946\ttotal: 2m 1s\tremaining: 29m 44s\n",
      "637:\tlearn: 0.0521944\ttotal: 2m 1s\tremaining: 29m 44s\n",
      "638:\tlearn: 0.0521940\ttotal: 2m 1s\tremaining: 29m 44s\n",
      "639:\tlearn: 0.0521918\ttotal: 2m 1s\tremaining: 29m 43s\n",
      "640:\tlearn: 0.0521911\ttotal: 2m 2s\tremaining: 29m 43s\n",
      "641:\tlearn: 0.0521906\ttotal: 2m 2s\tremaining: 29m 42s\n",
      "642:\tlearn: 0.0521922\ttotal: 2m 2s\tremaining: 29m 42s\n",
      "643:\tlearn: 0.0521936\ttotal: 2m 2s\tremaining: 29m 42s\n",
      "644:\tlearn: 0.0521936\ttotal: 2m 2s\tremaining: 29m 41s\n",
      "645:\tlearn: 0.0521936\ttotal: 2m 3s\tremaining: 29m 41s\n",
      "646:\tlearn: 0.0521930\ttotal: 2m 3s\tremaining: 29m 41s\n",
      "647:\tlearn: 0.0521927\ttotal: 2m 3s\tremaining: 29m 40s\n",
      "648:\tlearn: 0.0521928\ttotal: 2m 3s\tremaining: 29m 40s\n",
      "649:\tlearn: 0.0521921\ttotal: 2m 3s\tremaining: 29m 40s\n",
      "650:\tlearn: 0.0521922\ttotal: 2m 3s\tremaining: 29m 39s\n",
      "651:\tlearn: 0.0521921\ttotal: 2m 4s\tremaining: 29m 38s\n",
      "652:\tlearn: 0.0521920\ttotal: 2m 4s\tremaining: 29m 37s\n",
      "653:\tlearn: 0.0521920\ttotal: 2m 4s\tremaining: 29m 36s\n",
      "654:\tlearn: 0.0521919\ttotal: 2m 4s\tremaining: 29m 36s\n",
      "655:\tlearn: 0.0521923\ttotal: 2m 4s\tremaining: 29m 36s\n",
      "656:\tlearn: 0.0521910\ttotal: 2m 4s\tremaining: 29m 35s\n",
      "657:\tlearn: 0.0521905\ttotal: 2m 5s\tremaining: 29m 34s\n",
      "658:\tlearn: 0.0521898\ttotal: 2m 5s\tremaining: 29m 34s\n",
      "659:\tlearn: 0.0521882\ttotal: 2m 5s\tremaining: 29m 34s\n",
      "660:\tlearn: 0.0521879\ttotal: 2m 5s\tremaining: 29m 33s\n",
      "661:\tlearn: 0.0521875\ttotal: 2m 5s\tremaining: 29m 33s\n",
      "662:\tlearn: 0.0521878\ttotal: 2m 5s\tremaining: 29m 32s\n",
      "663:\tlearn: 0.0521845\ttotal: 2m 6s\tremaining: 29m 32s\n",
      "664:\tlearn: 0.0521843\ttotal: 2m 6s\tremaining: 29m 32s\n",
      "665:\tlearn: 0.0521844\ttotal: 2m 6s\tremaining: 29m 31s\n",
      "666:\tlearn: 0.0521839\ttotal: 2m 6s\tremaining: 29m 31s\n",
      "667:\tlearn: 0.0521702\ttotal: 2m 6s\tremaining: 29m 30s\n",
      "668:\tlearn: 0.0521700\ttotal: 2m 6s\tremaining: 29m 30s\n",
      "669:\tlearn: 0.0521687\ttotal: 2m 7s\tremaining: 29m 30s\n",
      "670:\tlearn: 0.0521687\ttotal: 2m 7s\tremaining: 29m 29s\n",
      "671:\tlearn: 0.0521680\ttotal: 2m 7s\tremaining: 29m 29s\n",
      "672:\tlearn: 0.0521680\ttotal: 2m 7s\tremaining: 29m 28s\n",
      "673:\tlearn: 0.0521679\ttotal: 2m 7s\tremaining: 29m 27s\n",
      "674:\tlearn: 0.0521676\ttotal: 2m 7s\tremaining: 29m 27s\n",
      "675:\tlearn: 0.0521672\ttotal: 2m 8s\tremaining: 29m 27s\n",
      "676:\tlearn: 0.0521615\ttotal: 2m 8s\tremaining: 29m 26s\n",
      "677:\tlearn: 0.0521614\ttotal: 2m 8s\tremaining: 29m 26s\n",
      "678:\tlearn: 0.0521611\ttotal: 2m 8s\tremaining: 29m 26s\n",
      "679:\tlearn: 0.0521619\ttotal: 2m 8s\tremaining: 29m 25s\n",
      "680:\tlearn: 0.0521619\ttotal: 2m 8s\tremaining: 29m 25s\n",
      "681:\tlearn: 0.0521618\ttotal: 2m 9s\tremaining: 29m 24s\n",
      "682:\tlearn: 0.0521618\ttotal: 2m 9s\tremaining: 29m 24s\n",
      "683:\tlearn: 0.0521618\ttotal: 2m 9s\tremaining: 29m 23s\n",
      "684:\tlearn: 0.0521618\ttotal: 2m 9s\tremaining: 29m 22s\n",
      "685:\tlearn: 0.0521609\ttotal: 2m 9s\tremaining: 29m 22s\n",
      "686:\tlearn: 0.0521599\ttotal: 2m 10s\tremaining: 29m 22s\n",
      "687:\tlearn: 0.0521594\ttotal: 2m 10s\tremaining: 29m 21s\n",
      "688:\tlearn: 0.0521610\ttotal: 2m 10s\tremaining: 29m 21s\n",
      "689:\tlearn: 0.0521609\ttotal: 2m 10s\tremaining: 29m 20s\n",
      "690:\tlearn: 0.0521606\ttotal: 2m 10s\tremaining: 29m 20s\n",
      "691:\tlearn: 0.0521606\ttotal: 2m 10s\tremaining: 29m 19s\n",
      "692:\tlearn: 0.0521606\ttotal: 2m 10s\tremaining: 29m 18s\n",
      "693:\tlearn: 0.0521603\ttotal: 2m 11s\tremaining: 29m 18s\n",
      "694:\tlearn: 0.0521600\ttotal: 2m 11s\tremaining: 29m 18s\n",
      "695:\tlearn: 0.0521597\ttotal: 2m 11s\tremaining: 29m 17s\n",
      "696:\tlearn: 0.0521586\ttotal: 2m 11s\tremaining: 29m 17s\n",
      "697:\tlearn: 0.0521586\ttotal: 2m 11s\tremaining: 29m 16s\n",
      "698:\tlearn: 0.0521587\ttotal: 2m 11s\tremaining: 29m 16s\n",
      "699:\tlearn: 0.0521586\ttotal: 2m 12s\tremaining: 29m 15s\n",
      "700:\tlearn: 0.0521579\ttotal: 2m 12s\tremaining: 29m 14s\n",
      "701:\tlearn: 0.0521577\ttotal: 2m 12s\tremaining: 29m 14s\n",
      "702:\tlearn: 0.0521575\ttotal: 2m 12s\tremaining: 29m 13s\n",
      "703:\tlearn: 0.0521575\ttotal: 2m 12s\tremaining: 29m 13s\n",
      "704:\tlearn: 0.0521575\ttotal: 2m 12s\tremaining: 29m 12s\n",
      "705:\tlearn: 0.0521568\ttotal: 2m 13s\tremaining: 29m 12s\n",
      "706:\tlearn: 0.0521566\ttotal: 2m 13s\tremaining: 29m 12s\n",
      "707:\tlearn: 0.0521564\ttotal: 2m 13s\tremaining: 29m 11s\n",
      "708:\tlearn: 0.0521564\ttotal: 2m 13s\tremaining: 29m 11s\n",
      "709:\tlearn: 0.0521567\ttotal: 2m 13s\tremaining: 29m 10s\n",
      "710:\tlearn: 0.0521565\ttotal: 2m 13s\tremaining: 29m 10s\n",
      "711:\tlearn: 0.0521555\ttotal: 2m 14s\tremaining: 29m 10s\n",
      "712:\tlearn: 0.0521553\ttotal: 2m 14s\tremaining: 29m 9s\n",
      "713:\tlearn: 0.0521553\ttotal: 2m 14s\tremaining: 29m 8s\n",
      "714:\tlearn: 0.0521544\ttotal: 2m 14s\tremaining: 29m 8s\n",
      "715:\tlearn: 0.0521550\ttotal: 2m 14s\tremaining: 29m 8s\n",
      "716:\tlearn: 0.0521550\ttotal: 2m 14s\tremaining: 29m 7s\n",
      "717:\tlearn: 0.0521544\ttotal: 2m 15s\tremaining: 29m 7s\n",
      "718:\tlearn: 0.0521540\ttotal: 2m 15s\tremaining: 29m 7s\n",
      "719:\tlearn: 0.0521535\ttotal: 2m 15s\tremaining: 29m 7s\n",
      "720:\tlearn: 0.0521535\ttotal: 2m 15s\tremaining: 29m 6s\n",
      "721:\tlearn: 0.0521533\ttotal: 2m 15s\tremaining: 29m 6s\n",
      "722:\tlearn: 0.0521530\ttotal: 2m 16s\tremaining: 29m 5s\n",
      "723:\tlearn: 0.0521530\ttotal: 2m 16s\tremaining: 29m 4s\n",
      "724:\tlearn: 0.0521531\ttotal: 2m 16s\tremaining: 29m 4s\n",
      "725:\tlearn: 0.0521530\ttotal: 2m 16s\tremaining: 29m 4s\n",
      "726:\tlearn: 0.0521529\ttotal: 2m 16s\tremaining: 29m 3s\n",
      "727:\tlearn: 0.0521530\ttotal: 2m 16s\tremaining: 29m 3s\n",
      "728:\tlearn: 0.0521533\ttotal: 2m 17s\tremaining: 29m 2s\n",
      "729:\tlearn: 0.0521532\ttotal: 2m 17s\tremaining: 29m 2s\n",
      "730:\tlearn: 0.0521531\ttotal: 2m 17s\tremaining: 29m 1s\n",
      "731:\tlearn: 0.0521525\ttotal: 2m 17s\tremaining: 29m 1s\n",
      "732:\tlearn: 0.0521525\ttotal: 2m 17s\tremaining: 29m\n",
      "733:\tlearn: 0.0521525\ttotal: 2m 17s\tremaining: 29m\n",
      "734:\tlearn: 0.0521520\ttotal: 2m 18s\tremaining: 28m 59s\n",
      "735:\tlearn: 0.0521520\ttotal: 2m 18s\tremaining: 28m 59s\n",
      "736:\tlearn: 0.0521518\ttotal: 2m 18s\tremaining: 28m 58s\n",
      "737:\tlearn: 0.0521510\ttotal: 2m 18s\tremaining: 28m 58s\n",
      "738:\tlearn: 0.0521510\ttotal: 2m 18s\tremaining: 28m 58s\n",
      "739:\tlearn: 0.0521510\ttotal: 2m 18s\tremaining: 28m 57s\n",
      "740:\tlearn: 0.0521507\ttotal: 2m 19s\tremaining: 28m 57s\n",
      "741:\tlearn: 0.0521507\ttotal: 2m 19s\tremaining: 28m 57s\n",
      "742:\tlearn: 0.0521504\ttotal: 2m 19s\tremaining: 28m 56s\n",
      "743:\tlearn: 0.0521504\ttotal: 2m 19s\tremaining: 28m 56s\n",
      "744:\tlearn: 0.0521488\ttotal: 2m 19s\tremaining: 28m 56s\n",
      "745:\tlearn: 0.0521488\ttotal: 2m 19s\tremaining: 28m 55s\n",
      "746:\tlearn: 0.0521511\ttotal: 2m 20s\tremaining: 28m 56s\n",
      "747:\tlearn: 0.0521511\ttotal: 2m 20s\tremaining: 28m 55s\n",
      "748:\tlearn: 0.0521488\ttotal: 2m 20s\tremaining: 28m 55s\n",
      "749:\tlearn: 0.0521488\ttotal: 2m 20s\tremaining: 28m 54s\n",
      "750:\tlearn: 0.0521500\ttotal: 2m 20s\tremaining: 28m 53s\n",
      "751:\tlearn: 0.0521501\ttotal: 2m 20s\tremaining: 28m 53s\n",
      "752:\tlearn: 0.0521494\ttotal: 2m 21s\tremaining: 28m 53s\n",
      "753:\tlearn: 0.0521491\ttotal: 2m 21s\tremaining: 28m 52s\n",
      "754:\tlearn: 0.0521488\ttotal: 2m 21s\tremaining: 28m 52s\n",
      "755:\tlearn: 0.0521483\ttotal: 2m 21s\tremaining: 28m 52s\n",
      "756:\tlearn: 0.0521476\ttotal: 2m 21s\tremaining: 28m 51s\n",
      "757:\tlearn: 0.0521476\ttotal: 2m 21s\tremaining: 28m 50s\n",
      "758:\tlearn: 0.0521477\ttotal: 2m 22s\tremaining: 28m 50s\n",
      "759:\tlearn: 0.0521477\ttotal: 2m 22s\tremaining: 28m 49s\n",
      "760:\tlearn: 0.0521477\ttotal: 2m 22s\tremaining: 28m 49s\n",
      "761:\tlearn: 0.0521479\ttotal: 2m 22s\tremaining: 28m 49s\n",
      "762:\tlearn: 0.0521476\ttotal: 2m 22s\tremaining: 28m 48s\n",
      "763:\tlearn: 0.0521468\ttotal: 2m 23s\tremaining: 28m 48s\n",
      "764:\tlearn: 0.0521469\ttotal: 2m 23s\tremaining: 28m 48s\n",
      "765:\tlearn: 0.0521463\ttotal: 2m 23s\tremaining: 28m 48s\n",
      "766:\tlearn: 0.0521443\ttotal: 2m 23s\tremaining: 28m 48s\n",
      "767:\tlearn: 0.0521442\ttotal: 2m 23s\tremaining: 28m 47s\n",
      "768:\tlearn: 0.0521442\ttotal: 2m 23s\tremaining: 28m 47s\n",
      "769:\tlearn: 0.0521443\ttotal: 2m 24s\tremaining: 28m 46s\n",
      "770:\tlearn: 0.0521443\ttotal: 2m 24s\tremaining: 28m 46s\n",
      "771:\tlearn: 0.0521435\ttotal: 2m 24s\tremaining: 28m 46s\n",
      "772:\tlearn: 0.0521432\ttotal: 2m 24s\tremaining: 28m 45s\n",
      "773:\tlearn: 0.0521432\ttotal: 2m 24s\tremaining: 28m 45s\n",
      "774:\tlearn: 0.0521428\ttotal: 2m 24s\tremaining: 28m 45s\n",
      "775:\tlearn: 0.0521428\ttotal: 2m 25s\tremaining: 28m 44s\n",
      "776:\tlearn: 0.0521432\ttotal: 2m 25s\tremaining: 28m 44s\n",
      "777:\tlearn: 0.0521429\ttotal: 2m 25s\tremaining: 28m 43s\n",
      "778:\tlearn: 0.0521427\ttotal: 2m 25s\tremaining: 28m 43s\n",
      "779:\tlearn: 0.0521426\ttotal: 2m 25s\tremaining: 28m 43s\n",
      "780:\tlearn: 0.0521415\ttotal: 2m 26s\tremaining: 28m 43s\n",
      "781:\tlearn: 0.0521415\ttotal: 2m 26s\tremaining: 28m 43s\n",
      "782:\tlearn: 0.0521412\ttotal: 2m 26s\tremaining: 28m 43s\n",
      "783:\tlearn: 0.0521411\ttotal: 2m 26s\tremaining: 28m 43s\n",
      "784:\tlearn: 0.0521410\ttotal: 2m 26s\tremaining: 28m 43s\n",
      "785:\tlearn: 0.0521410\ttotal: 2m 26s\tremaining: 28m 42s\n",
      "786:\tlearn: 0.0521410\ttotal: 2m 27s\tremaining: 28m 41s\n",
      "787:\tlearn: 0.0521408\ttotal: 2m 27s\tremaining: 28m 41s\n",
      "788:\tlearn: 0.0521409\ttotal: 2m 27s\tremaining: 28m 41s\n",
      "789:\tlearn: 0.0521406\ttotal: 2m 27s\tremaining: 28m 41s\n",
      "790:\tlearn: 0.0521402\ttotal: 2m 27s\tremaining: 28m 41s\n",
      "791:\tlearn: 0.0521402\ttotal: 2m 27s\tremaining: 28m 40s\n",
      "792:\tlearn: 0.0521409\ttotal: 2m 28s\tremaining: 28m 40s\n",
      "793:\tlearn: 0.0521409\ttotal: 2m 28s\tremaining: 28m 40s\n",
      "794:\tlearn: 0.0521401\ttotal: 2m 28s\tremaining: 28m 39s\n",
      "795:\tlearn: 0.0521401\ttotal: 2m 28s\tremaining: 28m 39s\n",
      "796:\tlearn: 0.0521401\ttotal: 2m 28s\tremaining: 28m 39s\n",
      "797:\tlearn: 0.0521398\ttotal: 2m 29s\tremaining: 28m 38s\n",
      "798:\tlearn: 0.0521395\ttotal: 2m 29s\tremaining: 28m 38s\n",
      "799:\tlearn: 0.0521396\ttotal: 2m 29s\tremaining: 28m 37s\n",
      "800:\tlearn: 0.0521394\ttotal: 2m 29s\tremaining: 28m 37s\n",
      "801:\tlearn: 0.0521392\ttotal: 2m 29s\tremaining: 28m 36s\n",
      "802:\tlearn: 0.0521407\ttotal: 2m 29s\tremaining: 28m 36s\n",
      "803:\tlearn: 0.0521410\ttotal: 2m 30s\tremaining: 28m 36s\n",
      "804:\tlearn: 0.0521407\ttotal: 2m 30s\tremaining: 28m 36s\n",
      "805:\tlearn: 0.0521409\ttotal: 2m 30s\tremaining: 28m 35s\n",
      "806:\tlearn: 0.0521400\ttotal: 2m 30s\tremaining: 28m 35s\n",
      "807:\tlearn: 0.0521397\ttotal: 2m 30s\tremaining: 28m 35s\n",
      "808:\tlearn: 0.0521397\ttotal: 2m 30s\tremaining: 28m 34s\n",
      "809:\tlearn: 0.0521398\ttotal: 2m 31s\tremaining: 28m 34s\n",
      "810:\tlearn: 0.0521396\ttotal: 2m 31s\tremaining: 28m 35s\n",
      "811:\tlearn: 0.0521388\ttotal: 2m 31s\tremaining: 28m 35s\n",
      "812:\tlearn: 0.0521367\ttotal: 2m 31s\tremaining: 28m 35s\n",
      "813:\tlearn: 0.0521360\ttotal: 2m 31s\tremaining: 28m 34s\n",
      "814:\tlearn: 0.0521368\ttotal: 2m 32s\tremaining: 28m 33s\n",
      "815:\tlearn: 0.0521365\ttotal: 2m 32s\tremaining: 28m 33s\n",
      "816:\tlearn: 0.0521364\ttotal: 2m 32s\tremaining: 28m 32s\n",
      "817:\tlearn: 0.0521367\ttotal: 2m 32s\tremaining: 28m 32s\n",
      "818:\tlearn: 0.0521367\ttotal: 2m 32s\tremaining: 28m 31s\n",
      "819:\tlearn: 0.0521367\ttotal: 2m 32s\tremaining: 28m 31s\n",
      "820:\tlearn: 0.0521367\ttotal: 2m 33s\tremaining: 28m 31s\n",
      "821:\tlearn: 0.0521367\ttotal: 2m 33s\tremaining: 28m 30s\n",
      "822:\tlearn: 0.0521365\ttotal: 2m 33s\tremaining: 28m 30s\n",
      "823:\tlearn: 0.0521364\ttotal: 2m 33s\tremaining: 28m 30s\n",
      "824:\tlearn: 0.0521364\ttotal: 2m 33s\tremaining: 28m 29s\n",
      "825:\tlearn: 0.0521364\ttotal: 2m 33s\tremaining: 28m 29s\n",
      "826:\tlearn: 0.0521364\ttotal: 2m 34s\tremaining: 28m 29s\n",
      "827:\tlearn: 0.0521364\ttotal: 2m 34s\tremaining: 28m 28s\n",
      "828:\tlearn: 0.0521359\ttotal: 2m 34s\tremaining: 28m 28s\n",
      "829:\tlearn: 0.0521363\ttotal: 2m 34s\tremaining: 28m 27s\n",
      "830:\tlearn: 0.0521357\ttotal: 2m 34s\tremaining: 28m 27s\n",
      "831:\tlearn: 0.0521355\ttotal: 2m 34s\tremaining: 28m 27s\n",
      "832:\tlearn: 0.0521352\ttotal: 2m 35s\tremaining: 28m 27s\n",
      "833:\tlearn: 0.0521352\ttotal: 2m 35s\tremaining: 28m 26s\n",
      "834:\tlearn: 0.0521349\ttotal: 2m 35s\tremaining: 28m 26s\n",
      "835:\tlearn: 0.0521354\ttotal: 2m 35s\tremaining: 28m 25s\n",
      "836:\tlearn: 0.0521345\ttotal: 2m 35s\tremaining: 28m 25s\n",
      "837:\tlearn: 0.0521342\ttotal: 2m 35s\tremaining: 28m 25s\n",
      "838:\tlearn: 0.0521338\ttotal: 2m 36s\tremaining: 28m 24s\n",
      "839:\tlearn: 0.0521338\ttotal: 2m 36s\tremaining: 28m 24s\n",
      "840:\tlearn: 0.0521338\ttotal: 2m 36s\tremaining: 28m 23s\n",
      "841:\tlearn: 0.0521347\ttotal: 2m 36s\tremaining: 28m 23s\n",
      "842:\tlearn: 0.0521347\ttotal: 2m 36s\tremaining: 28m 23s\n",
      "843:\tlearn: 0.0521334\ttotal: 2m 37s\tremaining: 28m 23s\n",
      "844:\tlearn: 0.0521319\ttotal: 2m 37s\tremaining: 28m 22s\n",
      "845:\tlearn: 0.0521319\ttotal: 2m 37s\tremaining: 28m 22s\n",
      "846:\tlearn: 0.0521310\ttotal: 2m 37s\tremaining: 28m 22s\n",
      "847:\tlearn: 0.0521309\ttotal: 2m 37s\tremaining: 28m 22s\n",
      "848:\tlearn: 0.0521308\ttotal: 2m 37s\tremaining: 28m 21s\n",
      "849:\tlearn: 0.0521304\ttotal: 2m 38s\tremaining: 28m 20s\n",
      "850:\tlearn: 0.0521321\ttotal: 2m 38s\tremaining: 28m 20s\n",
      "851:\tlearn: 0.0521316\ttotal: 2m 38s\tremaining: 28m 20s\n",
      "852:\tlearn: 0.0521314\ttotal: 2m 38s\tremaining: 28m 19s\n",
      "853:\tlearn: 0.0521313\ttotal: 2m 38s\tremaining: 28m 19s\n",
      "854:\tlearn: 0.0521313\ttotal: 2m 38s\tremaining: 28m 18s\n",
      "855:\tlearn: 0.0521310\ttotal: 2m 39s\tremaining: 28m 18s\n",
      "856:\tlearn: 0.0521310\ttotal: 2m 39s\tremaining: 28m 18s\n",
      "857:\tlearn: 0.0521317\ttotal: 2m 39s\tremaining: 28m 17s\n",
      "858:\tlearn: 0.0521306\ttotal: 2m 39s\tremaining: 28m 17s\n",
      "859:\tlearn: 0.0521306\ttotal: 2m 39s\tremaining: 28m 17s\n",
      "860:\tlearn: 0.0521298\ttotal: 2m 39s\tremaining: 28m 16s\n",
      "861:\tlearn: 0.0521301\ttotal: 2m 40s\tremaining: 28m 16s\n",
      "862:\tlearn: 0.0521321\ttotal: 2m 40s\tremaining: 28m 15s\n",
      "863:\tlearn: 0.0521321\ttotal: 2m 40s\tremaining: 28m 15s\n",
      "864:\tlearn: 0.0521318\ttotal: 2m 40s\tremaining: 28m 15s\n",
      "865:\tlearn: 0.0521318\ttotal: 2m 40s\tremaining: 28m 15s\n",
      "866:\tlearn: 0.0521315\ttotal: 2m 40s\tremaining: 28m 15s\n",
      "867:\tlearn: 0.0521313\ttotal: 2m 41s\tremaining: 28m 15s\n",
      "868:\tlearn: 0.0521313\ttotal: 2m 41s\tremaining: 28m 14s\n",
      "869:\tlearn: 0.0521311\ttotal: 2m 41s\tremaining: 28m 14s\n",
      "870:\tlearn: 0.0521310\ttotal: 2m 41s\tremaining: 28m 13s\n",
      "871:\tlearn: 0.0521312\ttotal: 2m 41s\tremaining: 28m 13s\n",
      "872:\tlearn: 0.0521273\ttotal: 2m 41s\tremaining: 28m 13s\n",
      "873:\tlearn: 0.0521280\ttotal: 2m 42s\tremaining: 28m 12s\n",
      "874:\tlearn: 0.0521277\ttotal: 2m 42s\tremaining: 28m 12s\n",
      "875:\tlearn: 0.0521276\ttotal: 2m 42s\tremaining: 28m 12s\n",
      "876:\tlearn: 0.0521278\ttotal: 2m 42s\tremaining: 28m 11s\n",
      "877:\tlearn: 0.0521276\ttotal: 2m 42s\tremaining: 28m 11s\n",
      "878:\tlearn: 0.0521274\ttotal: 2m 43s\tremaining: 28m 11s\n",
      "879:\tlearn: 0.0521247\ttotal: 2m 43s\tremaining: 28m 11s\n",
      "880:\tlearn: 0.0521249\ttotal: 2m 43s\tremaining: 28m 10s\n",
      "881:\tlearn: 0.0521249\ttotal: 2m 43s\tremaining: 28m 10s\n",
      "882:\tlearn: 0.0521249\ttotal: 2m 43s\tremaining: 28m 9s\n",
      "883:\tlearn: 0.0521255\ttotal: 2m 43s\tremaining: 28m 9s\n",
      "884:\tlearn: 0.0521251\ttotal: 2m 44s\tremaining: 28m 9s\n",
      "885:\tlearn: 0.0521251\ttotal: 2m 44s\tremaining: 28m 8s\n",
      "886:\tlearn: 0.0521249\ttotal: 2m 44s\tremaining: 28m 8s\n",
      "887:\tlearn: 0.0521249\ttotal: 2m 44s\tremaining: 28m 8s\n",
      "888:\tlearn: 0.0521251\ttotal: 2m 44s\tremaining: 28m 7s\n",
      "889:\tlearn: 0.0521252\ttotal: 2m 44s\tremaining: 28m 7s\n",
      "890:\tlearn: 0.0521249\ttotal: 2m 45s\tremaining: 28m 7s\n",
      "891:\tlearn: 0.0521249\ttotal: 2m 45s\tremaining: 28m 7s\n",
      "892:\tlearn: 0.0521249\ttotal: 2m 45s\tremaining: 28m 6s\n",
      "893:\tlearn: 0.0521248\ttotal: 2m 45s\tremaining: 28m 6s\n",
      "894:\tlearn: 0.0521249\ttotal: 2m 45s\tremaining: 28m 5s\n",
      "895:\tlearn: 0.0521246\ttotal: 2m 45s\tremaining: 28m 5s\n",
      "896:\tlearn: 0.0521245\ttotal: 2m 46s\tremaining: 28m 5s\n",
      "897:\tlearn: 0.0521244\ttotal: 2m 46s\tremaining: 28m 4s\n",
      "898:\tlearn: 0.0521241\ttotal: 2m 46s\tremaining: 28m 4s\n",
      "899:\tlearn: 0.0521240\ttotal: 2m 46s\tremaining: 28m 4s\n",
      "900:\tlearn: 0.0521232\ttotal: 2m 46s\tremaining: 28m 3s\n",
      "901:\tlearn: 0.0521230\ttotal: 2m 46s\tremaining: 28m 3s\n",
      "902:\tlearn: 0.0521233\ttotal: 2m 47s\tremaining: 28m 3s\n",
      "903:\tlearn: 0.0521232\ttotal: 2m 47s\tremaining: 28m 3s\n",
      "904:\tlearn: 0.0521230\ttotal: 2m 47s\tremaining: 28m 3s\n",
      "905:\tlearn: 0.0521229\ttotal: 2m 47s\tremaining: 28m 3s\n",
      "906:\tlearn: 0.0521227\ttotal: 2m 47s\tremaining: 28m 2s\n",
      "907:\tlearn: 0.0521227\ttotal: 2m 48s\tremaining: 28m 2s\n",
      "908:\tlearn: 0.0521227\ttotal: 2m 48s\tremaining: 28m 1s\n",
      "909:\tlearn: 0.0521225\ttotal: 2m 48s\tremaining: 28m 1s\n",
      "910:\tlearn: 0.0521225\ttotal: 2m 48s\tremaining: 28m 1s\n",
      "911:\tlearn: 0.0521219\ttotal: 2m 48s\tremaining: 28m 1s\n",
      "912:\tlearn: 0.0521215\ttotal: 2m 48s\tremaining: 28m 1s\n",
      "913:\tlearn: 0.0521215\ttotal: 2m 49s\tremaining: 28m\n",
      "914:\tlearn: 0.0521215\ttotal: 2m 49s\tremaining: 28m\n",
      "915:\tlearn: 0.0521214\ttotal: 2m 49s\tremaining: 28m\n",
      "916:\tlearn: 0.0521212\ttotal: 2m 49s\tremaining: 28m\n",
      "917:\tlearn: 0.0521205\ttotal: 2m 49s\tremaining: 28m\n",
      "918:\tlearn: 0.0521207\ttotal: 2m 50s\tremaining: 27m 59s\n",
      "919:\tlearn: 0.0521201\ttotal: 2m 50s\tremaining: 27m 59s\n",
      "920:\tlearn: 0.0521202\ttotal: 2m 50s\tremaining: 27m 58s\n",
      "921:\tlearn: 0.0521200\ttotal: 2m 50s\tremaining: 27m 58s\n",
      "922:\tlearn: 0.0521194\ttotal: 2m 50s\tremaining: 27m 58s\n",
      "923:\tlearn: 0.0521194\ttotal: 2m 50s\tremaining: 27m 57s\n",
      "924:\tlearn: 0.0521194\ttotal: 2m 51s\tremaining: 27m 57s\n",
      "925:\tlearn: 0.0521193\ttotal: 2m 51s\tremaining: 27m 57s\n",
      "926:\tlearn: 0.0521191\ttotal: 2m 51s\tremaining: 27m 57s\n",
      "927:\tlearn: 0.0521185\ttotal: 2m 51s\tremaining: 27m 56s\n",
      "928:\tlearn: 0.0521186\ttotal: 2m 51s\tremaining: 27m 56s\n",
      "929:\tlearn: 0.0521181\ttotal: 2m 51s\tremaining: 27m 55s\n",
      "930:\tlearn: 0.0521180\ttotal: 2m 52s\tremaining: 27m 55s\n",
      "931:\tlearn: 0.0521180\ttotal: 2m 52s\tremaining: 27m 54s\n",
      "932:\tlearn: 0.0521180\ttotal: 2m 52s\tremaining: 27m 54s\n",
      "933:\tlearn: 0.0521179\ttotal: 2m 52s\tremaining: 27m 54s\n",
      "934:\tlearn: 0.0521179\ttotal: 2m 52s\tremaining: 27m 53s\n",
      "935:\tlearn: 0.0521179\ttotal: 2m 52s\tremaining: 27m 53s\n",
      "936:\tlearn: 0.0521179\ttotal: 2m 52s\tremaining: 27m 53s\n",
      "937:\tlearn: 0.0521178\ttotal: 2m 53s\tremaining: 27m 52s\n",
      "938:\tlearn: 0.0521178\ttotal: 2m 53s\tremaining: 27m 52s\n",
      "939:\tlearn: 0.0521172\ttotal: 2m 53s\tremaining: 27m 51s\n",
      "940:\tlearn: 0.0521168\ttotal: 2m 53s\tremaining: 27m 51s\n",
      "941:\tlearn: 0.0521164\ttotal: 2m 53s\tremaining: 27m 51s\n",
      "942:\tlearn: 0.0521160\ttotal: 2m 53s\tremaining: 27m 50s\n",
      "943:\tlearn: 0.0521159\ttotal: 2m 54s\tremaining: 27m 50s\n",
      "944:\tlearn: 0.0521159\ttotal: 2m 54s\tremaining: 27m 50s\n",
      "945:\tlearn: 0.0521159\ttotal: 2m 54s\tremaining: 27m 49s\n",
      "946:\tlearn: 0.0521160\ttotal: 2m 54s\tremaining: 27m 49s\n",
      "947:\tlearn: 0.0521160\ttotal: 2m 54s\tremaining: 27m 48s\n",
      "948:\tlearn: 0.0521160\ttotal: 2m 54s\tremaining: 27m 48s\n",
      "949:\tlearn: 0.0521159\ttotal: 2m 55s\tremaining: 27m 48s\n",
      "950:\tlearn: 0.0521159\ttotal: 2m 55s\tremaining: 27m 47s\n",
      "951:\tlearn: 0.0521158\ttotal: 2m 55s\tremaining: 27m 47s\n",
      "952:\tlearn: 0.0521161\ttotal: 2m 55s\tremaining: 27m 47s\n",
      "953:\tlearn: 0.0521161\ttotal: 2m 55s\tremaining: 27m 47s\n",
      "954:\tlearn: 0.0521159\ttotal: 2m 56s\tremaining: 27m 47s\n",
      "955:\tlearn: 0.0521159\ttotal: 2m 56s\tremaining: 27m 46s\n",
      "956:\tlearn: 0.0521159\ttotal: 2m 56s\tremaining: 27m 46s\n",
      "957:\tlearn: 0.0521161\ttotal: 2m 56s\tremaining: 27m 45s\n",
      "958:\tlearn: 0.0521168\ttotal: 2m 56s\tremaining: 27m 45s\n",
      "959:\tlearn: 0.0521163\ttotal: 2m 56s\tremaining: 27m 45s\n",
      "960:\tlearn: 0.0521167\ttotal: 2m 57s\tremaining: 27m 45s\n",
      "961:\tlearn: 0.0521159\ttotal: 2m 57s\tremaining: 27m 44s\n",
      "962:\tlearn: 0.0521166\ttotal: 2m 57s\tremaining: 27m 44s\n",
      "963:\tlearn: 0.0521163\ttotal: 2m 57s\tremaining: 27m 44s\n",
      "964:\tlearn: 0.0521157\ttotal: 2m 57s\tremaining: 27m 43s\n",
      "965:\tlearn: 0.0521154\ttotal: 2m 57s\tremaining: 27m 43s\n",
      "966:\tlearn: 0.0521141\ttotal: 2m 58s\tremaining: 27m 43s\n",
      "967:\tlearn: 0.0521141\ttotal: 2m 58s\tremaining: 27m 42s\n",
      "968:\tlearn: 0.0521137\ttotal: 2m 58s\tremaining: 27m 42s\n",
      "969:\tlearn: 0.0521108\ttotal: 2m 58s\tremaining: 27m 42s\n",
      "970:\tlearn: 0.0521107\ttotal: 2m 58s\tremaining: 27m 41s\n",
      "971:\tlearn: 0.0521107\ttotal: 2m 58s\tremaining: 27m 41s\n",
      "972:\tlearn: 0.0521103\ttotal: 2m 59s\tremaining: 27m 41s\n",
      "973:\tlearn: 0.0521095\ttotal: 2m 59s\tremaining: 27m 41s\n",
      "974:\tlearn: 0.0521091\ttotal: 2m 59s\tremaining: 27m 40s\n",
      "975:\tlearn: 0.0521091\ttotal: 2m 59s\tremaining: 27m 40s\n",
      "976:\tlearn: 0.0521088\ttotal: 2m 59s\tremaining: 27m 40s\n",
      "977:\tlearn: 0.0521087\ttotal: 2m 59s\tremaining: 27m 40s\n",
      "978:\tlearn: 0.0521085\ttotal: 3m\tremaining: 27m 39s\n",
      "979:\tlearn: 0.0521080\ttotal: 3m\tremaining: 27m 39s\n",
      "980:\tlearn: 0.0521080\ttotal: 3m\tremaining: 27m 39s\n",
      "981:\tlearn: 0.0521080\ttotal: 3m\tremaining: 27m 38s\n",
      "982:\tlearn: 0.0521078\ttotal: 3m\tremaining: 27m 38s\n",
      "983:\tlearn: 0.0521092\ttotal: 3m\tremaining: 27m 38s\n",
      "984:\tlearn: 0.0521089\ttotal: 3m 1s\tremaining: 27m 37s\n",
      "985:\tlearn: 0.0521089\ttotal: 3m 1s\tremaining: 27m 37s\n",
      "986:\tlearn: 0.0521081\ttotal: 3m 1s\tremaining: 27m 36s\n",
      "987:\tlearn: 0.0521089\ttotal: 3m 1s\tremaining: 27m 36s\n",
      "988:\tlearn: 0.0521079\ttotal: 3m 1s\tremaining: 27m 36s\n",
      "989:\tlearn: 0.0521078\ttotal: 3m 2s\tremaining: 27m 36s\n",
      "990:\tlearn: 0.0521077\ttotal: 3m 2s\tremaining: 27m 36s\n",
      "991:\tlearn: 0.0521076\ttotal: 3m 2s\tremaining: 27m 36s\n",
      "992:\tlearn: 0.0521076\ttotal: 3m 2s\tremaining: 27m 36s\n",
      "993:\tlearn: 0.0521073\ttotal: 3m 2s\tremaining: 27m 35s\n",
      "994:\tlearn: 0.0521070\ttotal: 3m 2s\tremaining: 27m 35s\n",
      "995:\tlearn: 0.0521067\ttotal: 3m 3s\tremaining: 27m 35s\n",
      "996:\tlearn: 0.0521062\ttotal: 3m 3s\tremaining: 27m 34s\n",
      "997:\tlearn: 0.0521060\ttotal: 3m 3s\tremaining: 27m 34s\n",
      "998:\tlearn: 0.0521059\ttotal: 3m 3s\tremaining: 27m 33s\n",
      "999:\tlearn: 0.0521058\ttotal: 3m 3s\tremaining: 27m 33s\n",
      "1000:\tlearn: 0.0521054\ttotal: 3m 3s\tremaining: 27m 33s\n",
      "1001:\tlearn: 0.0521050\ttotal: 3m 4s\tremaining: 27m 33s\n",
      "1002:\tlearn: 0.0521050\ttotal: 3m 4s\tremaining: 27m 32s\n",
      "1003:\tlearn: 0.0521049\ttotal: 3m 4s\tremaining: 27m 32s\n",
      "1004:\tlearn: 0.0521049\ttotal: 3m 4s\tremaining: 27m 32s\n",
      "1005:\tlearn: 0.0521050\ttotal: 3m 4s\tremaining: 27m 31s\n",
      "1006:\tlearn: 0.0521049\ttotal: 3m 4s\tremaining: 27m 31s\n",
      "1007:\tlearn: 0.0521047\ttotal: 3m 5s\tremaining: 27m 31s\n",
      "1008:\tlearn: 0.0521050\ttotal: 3m 5s\tremaining: 27m 30s\n",
      "1009:\tlearn: 0.0521041\ttotal: 3m 5s\tremaining: 27m 30s\n",
      "1010:\tlearn: 0.0521040\ttotal: 3m 5s\tremaining: 27m 30s\n",
      "1011:\tlearn: 0.0521037\ttotal: 3m 5s\tremaining: 27m 30s\n",
      "1012:\tlearn: 0.0521035\ttotal: 3m 6s\tremaining: 27m 30s\n",
      "1013:\tlearn: 0.0521039\ttotal: 3m 6s\tremaining: 27m 30s\n",
      "1014:\tlearn: 0.0521035\ttotal: 3m 6s\tremaining: 27m 29s\n",
      "1015:\tlearn: 0.0521036\ttotal: 3m 6s\tremaining: 27m 28s\n",
      "1016:\tlearn: 0.0521033\ttotal: 3m 6s\tremaining: 27m 28s\n",
      "1017:\tlearn: 0.0521033\ttotal: 3m 6s\tremaining: 27m 28s\n",
      "1018:\tlearn: 0.0521031\ttotal: 3m 6s\tremaining: 27m 27s\n",
      "1019:\tlearn: 0.0521028\ttotal: 3m 7s\tremaining: 27m 27s\n",
      "1020:\tlearn: 0.0521028\ttotal: 3m 7s\tremaining: 27m 27s\n",
      "1021:\tlearn: 0.0521023\ttotal: 3m 7s\tremaining: 27m 27s\n",
      "1022:\tlearn: 0.0521019\ttotal: 3m 7s\tremaining: 27m 26s\n",
      "1023:\tlearn: 0.0521022\ttotal: 3m 7s\tremaining: 27m 26s\n",
      "1024:\tlearn: 0.0521021\ttotal: 3m 8s\tremaining: 27m 26s\n",
      "1025:\tlearn: 0.0521020\ttotal: 3m 8s\tremaining: 27m 26s\n",
      "1026:\tlearn: 0.0521022\ttotal: 3m 8s\tremaining: 27m 25s\n",
      "1027:\tlearn: 0.0521022\ttotal: 3m 8s\tremaining: 27m 25s\n",
      "1028:\tlearn: 0.0521019\ttotal: 3m 8s\tremaining: 27m 25s\n",
      "1029:\tlearn: 0.0521018\ttotal: 3m 8s\tremaining: 27m 25s\n",
      "1030:\tlearn: 0.0521014\ttotal: 3m 9s\tremaining: 27m 24s\n",
      "1031:\tlearn: 0.0521013\ttotal: 3m 9s\tremaining: 27m 24s\n",
      "1032:\tlearn: 0.0521013\ttotal: 3m 9s\tremaining: 27m 24s\n",
      "1033:\tlearn: 0.0521009\ttotal: 3m 9s\tremaining: 27m 23s\n",
      "1034:\tlearn: 0.0521009\ttotal: 3m 9s\tremaining: 27m 23s\n",
      "1035:\tlearn: 0.0521006\ttotal: 3m 9s\tremaining: 27m 22s\n",
      "1036:\tlearn: 0.0521003\ttotal: 3m 10s\tremaining: 27m 22s\n",
      "1037:\tlearn: 0.0521000\ttotal: 3m 10s\tremaining: 27m 22s\n",
      "1038:\tlearn: 0.0521002\ttotal: 3m 10s\tremaining: 27m 22s\n",
      "1039:\tlearn: 0.0521002\ttotal: 3m 10s\tremaining: 27m 21s\n",
      "1040:\tlearn: 0.0521002\ttotal: 3m 10s\tremaining: 27m 21s\n",
      "1041:\tlearn: 0.0521004\ttotal: 3m 10s\tremaining: 27m 21s\n",
      "1042:\tlearn: 0.0520996\ttotal: 3m 11s\tremaining: 27m 20s\n",
      "1043:\tlearn: 0.0520994\ttotal: 3m 11s\tremaining: 27m 20s\n",
      "1044:\tlearn: 0.0520992\ttotal: 3m 11s\tremaining: 27m 20s\n",
      "1045:\tlearn: 0.0520989\ttotal: 3m 11s\tremaining: 27m 20s\n",
      "1046:\tlearn: 0.0520991\ttotal: 3m 11s\tremaining: 27m 19s\n",
      "1047:\tlearn: 0.0520989\ttotal: 3m 11s\tremaining: 27m 19s\n",
      "1048:\tlearn: 0.0520988\ttotal: 3m 12s\tremaining: 27m 19s\n",
      "1049:\tlearn: 0.0520969\ttotal: 3m 12s\tremaining: 27m 18s\n",
      "1050:\tlearn: 0.0520967\ttotal: 3m 12s\tremaining: 27m 18s\n",
      "1051:\tlearn: 0.0520967\ttotal: 3m 12s\tremaining: 27m 18s\n",
      "1052:\tlearn: 0.0520965\ttotal: 3m 12s\tremaining: 27m 17s\n",
      "1053:\tlearn: 0.0520965\ttotal: 3m 12s\tremaining: 27m 17s\n",
      "1054:\tlearn: 0.0520963\ttotal: 3m 13s\tremaining: 27m 17s\n",
      "1055:\tlearn: 0.0520959\ttotal: 3m 13s\tremaining: 27m 16s\n",
      "1056:\tlearn: 0.0520959\ttotal: 3m 13s\tremaining: 27m 16s\n",
      "1057:\tlearn: 0.0520960\ttotal: 3m 13s\tremaining: 27m 16s\n",
      "1058:\tlearn: 0.0520960\ttotal: 3m 13s\tremaining: 27m 15s\n",
      "1059:\tlearn: 0.0520960\ttotal: 3m 13s\tremaining: 27m 15s\n",
      "1060:\tlearn: 0.0520955\ttotal: 3m 14s\tremaining: 27m 15s\n",
      "1061:\tlearn: 0.0520953\ttotal: 3m 14s\tremaining: 27m 15s\n",
      "1062:\tlearn: 0.0520952\ttotal: 3m 14s\tremaining: 27m 14s\n",
      "1063:\tlearn: 0.0520952\ttotal: 3m 14s\tremaining: 27m 14s\n",
      "1064:\tlearn: 0.0520952\ttotal: 3m 14s\tremaining: 27m 13s\n",
      "1065:\tlearn: 0.0520951\ttotal: 3m 14s\tremaining: 27m 13s\n",
      "1066:\tlearn: 0.0520953\ttotal: 3m 15s\tremaining: 27m 13s\n",
      "1067:\tlearn: 0.0520951\ttotal: 3m 15s\tremaining: 27m 12s\n",
      "1068:\tlearn: 0.0520947\ttotal: 3m 15s\tremaining: 27m 12s\n",
      "1069:\tlearn: 0.0520948\ttotal: 3m 15s\tremaining: 27m 12s\n",
      "1070:\tlearn: 0.0520943\ttotal: 3m 15s\tremaining: 27m 12s\n",
      "1071:\tlearn: 0.0520944\ttotal: 3m 15s\tremaining: 27m 11s\n",
      "1072:\tlearn: 0.0520944\ttotal: 3m 16s\tremaining: 27m 11s\n",
      "1073:\tlearn: 0.0520935\ttotal: 3m 16s\tremaining: 27m 10s\n",
      "1074:\tlearn: 0.0520939\ttotal: 3m 16s\tremaining: 27m 10s\n",
      "1075:\tlearn: 0.0520939\ttotal: 3m 16s\tremaining: 27m 10s\n",
      "1076:\tlearn: 0.0520938\ttotal: 3m 16s\tremaining: 27m 9s\n",
      "1077:\tlearn: 0.0520938\ttotal: 3m 16s\tremaining: 27m 9s\n",
      "1078:\tlearn: 0.0520528\ttotal: 3m 17s\tremaining: 27m 9s\n",
      "1079:\tlearn: 0.0520528\ttotal: 3m 17s\tremaining: 27m 8s\n",
      "1080:\tlearn: 0.0520528\ttotal: 3m 17s\tremaining: 27m 8s\n",
      "1081:\tlearn: 0.0520523\ttotal: 3m 17s\tremaining: 27m 8s\n",
      "1082:\tlearn: 0.0520465\ttotal: 3m 17s\tremaining: 27m 7s\n",
      "1083:\tlearn: 0.0520523\ttotal: 3m 17s\tremaining: 27m 7s\n",
      "1084:\tlearn: 0.0520519\ttotal: 3m 18s\tremaining: 27m 7s\n",
      "1085:\tlearn: 0.0520519\ttotal: 3m 18s\tremaining: 27m 6s\n",
      "1086:\tlearn: 0.0520520\ttotal: 3m 18s\tremaining: 27m 6s\n",
      "1087:\tlearn: 0.0520517\ttotal: 3m 18s\tremaining: 27m 6s\n",
      "1088:\tlearn: 0.0520517\ttotal: 3m 18s\tremaining: 27m 5s\n",
      "1089:\tlearn: 0.0520518\ttotal: 3m 18s\tremaining: 27m 5s\n",
      "1090:\tlearn: 0.0520515\ttotal: 3m 18s\tremaining: 27m 4s\n",
      "1091:\tlearn: 0.0520515\ttotal: 3m 19s\tremaining: 27m 4s\n",
      "1092:\tlearn: 0.0520515\ttotal: 3m 19s\tremaining: 27m 3s\n",
      "1093:\tlearn: 0.0520515\ttotal: 3m 19s\tremaining: 27m 3s\n",
      "1094:\tlearn: 0.0520515\ttotal: 3m 19s\tremaining: 27m 3s\n",
      "1095:\tlearn: 0.0520515\ttotal: 3m 19s\tremaining: 27m 2s\n",
      "1096:\tlearn: 0.0520513\ttotal: 3m 19s\tremaining: 27m 2s\n",
      "1097:\tlearn: 0.0520340\ttotal: 3m 20s\tremaining: 27m 1s\n",
      "1098:\tlearn: 0.0520455\ttotal: 3m 20s\tremaining: 27m 1s\n",
      "1099:\tlearn: 0.0520455\ttotal: 3m 20s\tremaining: 27m\n",
      "1100:\tlearn: 0.0520455\ttotal: 3m 20s\tremaining: 27m\n",
      "1101:\tlearn: 0.0520455\ttotal: 3m 20s\tremaining: 26m 59s\n",
      "1102:\tlearn: 0.0520455\ttotal: 3m 20s\tremaining: 26m 59s\n",
      "1103:\tlearn: 0.0520339\ttotal: 3m 20s\tremaining: 26m 58s\n",
      "1104:\tlearn: 0.0520514\ttotal: 3m 21s\tremaining: 26m 58s\n",
      "1105:\tlearn: 0.0520341\ttotal: 3m 21s\tremaining: 26m 58s\n",
      "1106:\tlearn: 0.0520341\ttotal: 3m 21s\tremaining: 26m 57s\n",
      "1107:\tlearn: 0.0520341\ttotal: 3m 21s\tremaining: 26m 57s\n",
      "1108:\tlearn: 0.0520341\ttotal: 3m 21s\tremaining: 26m 56s\n",
      "1109:\tlearn: 0.0520341\ttotal: 3m 21s\tremaining: 26m 56s\n",
      "1110:\tlearn: 0.0520509\ttotal: 3m 21s\tremaining: 26m 55s\n",
      "1111:\tlearn: 0.0520509\ttotal: 3m 22s\tremaining: 26m 55s\n",
      "1112:\tlearn: 0.0520509\ttotal: 3m 22s\tremaining: 26m 54s\n",
      "1113:\tlearn: 0.0520451\ttotal: 3m 22s\tremaining: 26m 54s\n",
      "1114:\tlearn: 0.0520510\ttotal: 3m 22s\tremaining: 26m 54s\n",
      "1115:\tlearn: 0.0520510\ttotal: 3m 22s\tremaining: 26m 53s\n",
      "1116:\tlearn: 0.0520512\ttotal: 3m 22s\tremaining: 26m 53s\n",
      "1117:\tlearn: 0.0520338\ttotal: 3m 22s\tremaining: 26m 52s\n",
      "1118:\tlearn: 0.0520338\ttotal: 3m 23s\tremaining: 26m 52s\n",
      "1119:\tlearn: 0.0520338\ttotal: 3m 23s\tremaining: 26m 51s\n",
      "1120:\tlearn: 0.0520338\ttotal: 3m 23s\tremaining: 26m 51s\n",
      "1121:\tlearn: 0.0520338\ttotal: 3m 23s\tremaining: 26m 50s\n",
      "1122:\tlearn: 0.0520338\ttotal: 3m 23s\tremaining: 26m 50s\n",
      "1123:\tlearn: 0.0520512\ttotal: 3m 23s\tremaining: 26m 49s\n",
      "1124:\tlearn: 0.0520512\ttotal: 3m 24s\tremaining: 26m 49s\n",
      "1125:\tlearn: 0.0520512\ttotal: 3m 24s\tremaining: 26m 49s\n",
      "1126:\tlearn: 0.0520512\ttotal: 3m 24s\tremaining: 26m 48s\n",
      "1127:\tlearn: 0.0520512\ttotal: 3m 24s\tremaining: 26m 48s\n",
      "1128:\tlearn: 0.0520512\ttotal: 3m 24s\tremaining: 26m 48s\n",
      "1129:\tlearn: 0.0520512\ttotal: 3m 24s\tremaining: 26m 47s\n",
      "1130:\tlearn: 0.0520512\ttotal: 3m 24s\tremaining: 26m 47s\n",
      "1131:\tlearn: 0.0520512\ttotal: 3m 25s\tremaining: 26m 46s\n",
      "1132:\tlearn: 0.0520512\ttotal: 3m 25s\tremaining: 26m 46s\n",
      "1133:\tlearn: 0.0520512\ttotal: 3m 25s\tremaining: 26m 46s\n",
      "1134:\tlearn: 0.0520512\ttotal: 3m 25s\tremaining: 26m 45s\n",
      "1135:\tlearn: 0.0520512\ttotal: 3m 25s\tremaining: 26m 45s\n",
      "1136:\tlearn: 0.0520512\ttotal: 3m 25s\tremaining: 26m 45s\n",
      "1137:\tlearn: 0.0520512\ttotal: 3m 26s\tremaining: 26m 44s\n",
      "1138:\tlearn: 0.0520512\ttotal: 3m 26s\tremaining: 26m 44s\n",
      "1139:\tlearn: 0.0520512\ttotal: 3m 26s\tremaining: 26m 44s\n",
      "1140:\tlearn: 0.0520512\ttotal: 3m 26s\tremaining: 26m 43s\n",
      "1141:\tlearn: 0.0520512\ttotal: 3m 26s\tremaining: 26m 43s\n",
      "1142:\tlearn: 0.0520512\ttotal: 3m 26s\tremaining: 26m 42s\n",
      "1143:\tlearn: 0.0520512\ttotal: 3m 27s\tremaining: 26m 42s\n",
      "1144:\tlearn: 0.0520512\ttotal: 3m 27s\tremaining: 26m 42s\n",
      "1145:\tlearn: 0.0520512\ttotal: 3m 27s\tremaining: 26m 41s\n",
      "1146:\tlearn: 0.0520512\ttotal: 3m 27s\tremaining: 26m 41s\n",
      "1147:\tlearn: 0.0520512\ttotal: 3m 27s\tremaining: 26m 40s\n",
      "1148:\tlearn: 0.0520512\ttotal: 3m 27s\tremaining: 26m 40s\n",
      "1149:\tlearn: 0.0520512\ttotal: 3m 27s\tremaining: 26m 40s\n",
      "1150:\tlearn: 0.0520512\ttotal: 3m 28s\tremaining: 26m 39s\n",
      "1151:\tlearn: 0.0520512\ttotal: 3m 28s\tremaining: 26m 39s\n",
      "1152:\tlearn: 0.0520512\ttotal: 3m 28s\tremaining: 26m 39s\n",
      "1153:\tlearn: 0.0520512\ttotal: 3m 28s\tremaining: 26m 38s\n",
      "1154:\tlearn: 0.0520512\ttotal: 3m 28s\tremaining: 26m 38s\n",
      "1155:\tlearn: 0.0520512\ttotal: 3m 28s\tremaining: 26m 37s\n",
      "1156:\tlearn: 0.0520512\ttotal: 3m 29s\tremaining: 26m 37s\n",
      "1157:\tlearn: 0.0520512\ttotal: 3m 29s\tremaining: 26m 37s\n",
      "1158:\tlearn: 0.0520512\ttotal: 3m 29s\tremaining: 26m 36s\n",
      "1159:\tlearn: 0.0520512\ttotal: 3m 29s\tremaining: 26m 36s\n",
      "1160:\tlearn: 0.0520512\ttotal: 3m 29s\tremaining: 26m 36s\n",
      "1161:\tlearn: 0.0520512\ttotal: 3m 29s\tremaining: 26m 35s\n",
      "1162:\tlearn: 0.0520512\ttotal: 3m 29s\tremaining: 26m 35s\n",
      "1163:\tlearn: 0.0520512\ttotal: 3m 30s\tremaining: 26m 34s\n",
      "1164:\tlearn: 0.0520512\ttotal: 3m 30s\tremaining: 26m 34s\n",
      "1165:\tlearn: 0.0520512\ttotal: 3m 30s\tremaining: 26m 34s\n",
      "1166:\tlearn: 0.0520512\ttotal: 3m 30s\tremaining: 26m 33s\n",
      "1167:\tlearn: 0.0520512\ttotal: 3m 30s\tremaining: 26m 33s\n",
      "1168:\tlearn: 0.0520512\ttotal: 3m 30s\tremaining: 26m 33s\n",
      "1169:\tlearn: 0.0520512\ttotal: 3m 31s\tremaining: 26m 32s\n",
      "1170:\tlearn: 0.0520512\ttotal: 3m 31s\tremaining: 26m 32s\n",
      "1171:\tlearn: 0.0520512\ttotal: 3m 31s\tremaining: 26m 31s\n",
      "1172:\tlearn: 0.0520512\ttotal: 3m 31s\tremaining: 26m 31s\n",
      "1173:\tlearn: 0.0520512\ttotal: 3m 31s\tremaining: 26m 31s\n",
      "1174:\tlearn: 0.0520512\ttotal: 3m 31s\tremaining: 26m 30s\n",
      "1175:\tlearn: 0.0520512\ttotal: 3m 31s\tremaining: 26m 30s\n",
      "1176:\tlearn: 0.0520512\ttotal: 3m 32s\tremaining: 26m 30s\n",
      "1177:\tlearn: 0.0520512\ttotal: 3m 32s\tremaining: 26m 29s\n",
      "1178:\tlearn: 0.0520512\ttotal: 3m 32s\tremaining: 26m 29s\n",
      "1179:\tlearn: 0.0520512\ttotal: 3m 32s\tremaining: 26m 29s\n",
      "1180:\tlearn: 0.0520512\ttotal: 3m 32s\tremaining: 26m 28s\n",
      "1181:\tlearn: 0.0520512\ttotal: 3m 32s\tremaining: 26m 28s\n",
      "1182:\tlearn: 0.0520512\ttotal: 3m 33s\tremaining: 26m 28s\n",
      "1183:\tlearn: 0.0520512\ttotal: 3m 33s\tremaining: 26m 27s\n",
      "1184:\tlearn: 0.0520512\ttotal: 3m 33s\tremaining: 26m 27s\n",
      "1185:\tlearn: 0.0520512\ttotal: 3m 33s\tremaining: 26m 26s\n",
      "1186:\tlearn: 0.0520512\ttotal: 3m 33s\tremaining: 26m 26s\n",
      "1187:\tlearn: 0.0520512\ttotal: 3m 33s\tremaining: 26m 26s\n",
      "1188:\tlearn: 0.0520512\ttotal: 3m 34s\tremaining: 26m 25s\n",
      "1189:\tlearn: 0.0520512\ttotal: 3m 34s\tremaining: 26m 25s\n",
      "1190:\tlearn: 0.0520512\ttotal: 3m 34s\tremaining: 26m 25s\n",
      "1191:\tlearn: 0.0520512\ttotal: 3m 34s\tremaining: 26m 24s\n",
      "1192:\tlearn: 0.0520512\ttotal: 3m 34s\tremaining: 26m 24s\n",
      "1193:\tlearn: 0.0520512\ttotal: 3m 34s\tremaining: 26m 23s\n",
      "1194:\tlearn: 0.0520512\ttotal: 3m 34s\tremaining: 26m 23s\n",
      "1195:\tlearn: 0.0520512\ttotal: 3m 35s\tremaining: 26m 23s\n",
      "1196:\tlearn: 0.0520512\ttotal: 3m 35s\tremaining: 26m 22s\n",
      "1197:\tlearn: 0.0520512\ttotal: 3m 35s\tremaining: 26m 22s\n",
      "1198:\tlearn: 0.0520512\ttotal: 3m 35s\tremaining: 26m 22s\n",
      "1199:\tlearn: 0.0520512\ttotal: 3m 35s\tremaining: 26m 21s\n",
      "1200:\tlearn: 0.0520512\ttotal: 3m 35s\tremaining: 26m 21s\n",
      "1201:\tlearn: 0.0520512\ttotal: 3m 36s\tremaining: 26m 21s\n",
      "1202:\tlearn: 0.0520512\ttotal: 3m 36s\tremaining: 26m 20s\n",
      "1203:\tlearn: 0.0520512\ttotal: 3m 36s\tremaining: 26m 20s\n",
      "1204:\tlearn: 0.0520512\ttotal: 3m 36s\tremaining: 26m 20s\n",
      "1205:\tlearn: 0.0520512\ttotal: 3m 36s\tremaining: 26m 19s\n",
      "1206:\tlearn: 0.0520512\ttotal: 3m 36s\tremaining: 26m 19s\n",
      "1207:\tlearn: 0.0520512\ttotal: 3m 36s\tremaining: 26m 19s\n",
      "1208:\tlearn: 0.0520512\ttotal: 3m 37s\tremaining: 26m 18s\n",
      "1209:\tlearn: 0.0520512\ttotal: 3m 37s\tremaining: 26m 18s\n",
      "1210:\tlearn: 0.0520512\ttotal: 3m 37s\tremaining: 26m 18s\n",
      "1211:\tlearn: 0.0520512\ttotal: 3m 37s\tremaining: 26m 17s\n",
      "1212:\tlearn: 0.0520512\ttotal: 3m 37s\tremaining: 26m 17s\n",
      "1213:\tlearn: 0.0520512\ttotal: 3m 37s\tremaining: 26m 17s\n",
      "1214:\tlearn: 0.0520512\ttotal: 3m 38s\tremaining: 26m 16s\n",
      "1215:\tlearn: 0.0520512\ttotal: 3m 38s\tremaining: 26m 16s\n",
      "1216:\tlearn: 0.0520512\ttotal: 3m 38s\tremaining: 26m 16s\n",
      "1217:\tlearn: 0.0520512\ttotal: 3m 38s\tremaining: 26m 15s\n",
      "1218:\tlearn: 0.0520512\ttotal: 3m 38s\tremaining: 26m 15s\n",
      "1219:\tlearn: 0.0520512\ttotal: 3m 38s\tremaining: 26m 15s\n",
      "1220:\tlearn: 0.0520512\ttotal: 3m 39s\tremaining: 26m 14s\n",
      "1221:\tlearn: 0.0520512\ttotal: 3m 39s\tremaining: 26m 14s\n",
      "1222:\tlearn: 0.0520512\ttotal: 3m 39s\tremaining: 26m 14s\n",
      "1223:\tlearn: 0.0520512\ttotal: 3m 39s\tremaining: 26m 13s\n",
      "1224:\tlearn: 0.0520512\ttotal: 3m 39s\tremaining: 26m 13s\n",
      "1225:\tlearn: 0.0520512\ttotal: 3m 39s\tremaining: 26m 12s\n",
      "1226:\tlearn: 0.0520512\ttotal: 3m 39s\tremaining: 26m 12s\n",
      "1227:\tlearn: 0.0520512\ttotal: 3m 40s\tremaining: 26m 12s\n",
      "1228:\tlearn: 0.0520512\ttotal: 3m 40s\tremaining: 26m 11s\n",
      "1229:\tlearn: 0.0520512\ttotal: 3m 40s\tremaining: 26m 11s\n",
      "1230:\tlearn: 0.0520512\ttotal: 3m 40s\tremaining: 26m 11s\n",
      "1231:\tlearn: 0.0520512\ttotal: 3m 40s\tremaining: 26m 10s\n",
      "1232:\tlearn: 0.0520512\ttotal: 3m 40s\tremaining: 26m 10s\n",
      "1233:\tlearn: 0.0520512\ttotal: 3m 41s\tremaining: 26m 10s\n",
      "1234:\tlearn: 0.0520512\ttotal: 3m 41s\tremaining: 26m 9s\n",
      "1235:\tlearn: 0.0520512\ttotal: 3m 41s\tremaining: 26m 9s\n",
      "1236:\tlearn: 0.0520512\ttotal: 3m 41s\tremaining: 26m 9s\n",
      "1237:\tlearn: 0.0520512\ttotal: 3m 41s\tremaining: 26m 9s\n",
      "1238:\tlearn: 0.0520512\ttotal: 3m 41s\tremaining: 26m 8s\n",
      "1239:\tlearn: 0.0520512\ttotal: 3m 42s\tremaining: 26m 8s\n",
      "1240:\tlearn: 0.0520512\ttotal: 3m 42s\tremaining: 26m 8s\n",
      "1241:\tlearn: 0.0520512\ttotal: 3m 42s\tremaining: 26m 7s\n",
      "1242:\tlearn: 0.0520512\ttotal: 3m 42s\tremaining: 26m 7s\n",
      "1243:\tlearn: 0.0520512\ttotal: 3m 42s\tremaining: 26m 7s\n",
      "1244:\tlearn: 0.0520512\ttotal: 3m 42s\tremaining: 26m 6s\n",
      "1245:\tlearn: 0.0520512\ttotal: 3m 42s\tremaining: 26m 6s\n",
      "1246:\tlearn: 0.0520512\ttotal: 3m 43s\tremaining: 26m 6s\n",
      "1247:\tlearn: 0.0520512\ttotal: 3m 43s\tremaining: 26m 5s\n",
      "1248:\tlearn: 0.0520512\ttotal: 3m 43s\tremaining: 26m 5s\n",
      "1249:\tlearn: 0.0520512\ttotal: 3m 43s\tremaining: 26m 5s\n",
      "1250:\tlearn: 0.0520512\ttotal: 3m 43s\tremaining: 26m 4s\n",
      "1251:\tlearn: 0.0520512\ttotal: 3m 43s\tremaining: 26m 4s\n",
      "1252:\tlearn: 0.0520512\ttotal: 3m 44s\tremaining: 26m 4s\n",
      "1253:\tlearn: 0.0520512\ttotal: 3m 44s\tremaining: 26m 4s\n",
      "1254:\tlearn: 0.0520512\ttotal: 3m 44s\tremaining: 26m 3s\n",
      "1255:\tlearn: 0.0520512\ttotal: 3m 44s\tremaining: 26m 3s\n",
      "1256:\tlearn: 0.0520512\ttotal: 3m 44s\tremaining: 26m 3s\n",
      "1257:\tlearn: 0.0520512\ttotal: 3m 44s\tremaining: 26m 2s\n",
      "1258:\tlearn: 0.0520512\ttotal: 3m 45s\tremaining: 26m 2s\n",
      "1259:\tlearn: 0.0520512\ttotal: 3m 45s\tremaining: 26m 2s\n",
      "1260:\tlearn: 0.0520512\ttotal: 3m 45s\tremaining: 26m 2s\n",
      "1261:\tlearn: 0.0520512\ttotal: 3m 45s\tremaining: 26m 1s\n",
      "1262:\tlearn: 0.0520512\ttotal: 3m 45s\tremaining: 26m 1s\n",
      "1263:\tlearn: 0.0520512\ttotal: 3m 45s\tremaining: 26m 1s\n",
      "1264:\tlearn: 0.0520512\ttotal: 3m 46s\tremaining: 26m\n",
      "1265:\tlearn: 0.0520512\ttotal: 3m 46s\tremaining: 26m\n",
      "1266:\tlearn: 0.0520512\ttotal: 3m 46s\tremaining: 26m\n",
      "1267:\tlearn: 0.0520512\ttotal: 3m 46s\tremaining: 25m 59s\n",
      "1268:\tlearn: 0.0520512\ttotal: 3m 46s\tremaining: 25m 59s\n",
      "1269:\tlearn: 0.0520512\ttotal: 3m 46s\tremaining: 25m 59s\n",
      "1270:\tlearn: 0.0520512\ttotal: 3m 46s\tremaining: 25m 58s\n",
      "1271:\tlearn: 0.0520512\ttotal: 3m 47s\tremaining: 25m 58s\n",
      "1272:\tlearn: 0.0520512\ttotal: 3m 47s\tremaining: 25m 58s\n",
      "1273:\tlearn: 0.0520512\ttotal: 3m 47s\tremaining: 25m 58s\n",
      "1274:\tlearn: 0.0520512\ttotal: 3m 47s\tremaining: 25m 57s\n",
      "1275:\tlearn: 0.0520512\ttotal: 3m 47s\tremaining: 25m 57s\n",
      "1276:\tlearn: 0.0520512\ttotal: 3m 47s\tremaining: 25m 57s\n",
      "1277:\tlearn: 0.0520512\ttotal: 3m 48s\tremaining: 25m 56s\n",
      "1278:\tlearn: 0.0520512\ttotal: 3m 48s\tremaining: 25m 56s\n",
      "1279:\tlearn: 0.0520512\ttotal: 3m 48s\tremaining: 25m 56s\n",
      "1280:\tlearn: 0.0520512\ttotal: 3m 48s\tremaining: 25m 55s\n",
      "1281:\tlearn: 0.0520512\ttotal: 3m 48s\tremaining: 25m 55s\n",
      "1282:\tlearn: 0.0520512\ttotal: 3m 48s\tremaining: 25m 55s\n",
      "1283:\tlearn: 0.0520512\ttotal: 3m 49s\tremaining: 25m 55s\n",
      "1284:\tlearn: 0.0520512\ttotal: 3m 49s\tremaining: 25m 54s\n",
      "1285:\tlearn: 0.0520512\ttotal: 3m 49s\tremaining: 25m 54s\n",
      "1286:\tlearn: 0.0520512\ttotal: 3m 49s\tremaining: 25m 53s\n",
      "1287:\tlearn: 0.0520512\ttotal: 3m 49s\tremaining: 25m 53s\n",
      "1288:\tlearn: 0.0520512\ttotal: 3m 49s\tremaining: 25m 53s\n",
      "1289:\tlearn: 0.0520512\ttotal: 3m 49s\tremaining: 25m 52s\n",
      "1290:\tlearn: 0.0520512\ttotal: 3m 50s\tremaining: 25m 52s\n",
      "1291:\tlearn: 0.0520512\ttotal: 3m 50s\tremaining: 25m 52s\n",
      "1292:\tlearn: 0.0520512\ttotal: 3m 50s\tremaining: 25m 51s\n",
      "1293:\tlearn: 0.0520512\ttotal: 3m 50s\tremaining: 25m 51s\n",
      "1294:\tlearn: 0.0520512\ttotal: 3m 50s\tremaining: 25m 51s\n",
      "1295:\tlearn: 0.0520512\ttotal: 3m 50s\tremaining: 25m 50s\n",
      "1296:\tlearn: 0.0520512\ttotal: 3m 51s\tremaining: 25m 50s\n",
      "1297:\tlearn: 0.0520512\ttotal: 3m 51s\tremaining: 25m 50s\n",
      "1298:\tlearn: 0.0520512\ttotal: 3m 51s\tremaining: 25m 49s\n",
      "1299:\tlearn: 0.0520512\ttotal: 3m 51s\tremaining: 25m 49s\n",
      "1300:\tlearn: 0.0520512\ttotal: 3m 51s\tremaining: 25m 49s\n",
      "1301:\tlearn: 0.0520512\ttotal: 3m 51s\tremaining: 25m 48s\n",
      "1302:\tlearn: 0.0520512\ttotal: 3m 51s\tremaining: 25m 48s\n",
      "1303:\tlearn: 0.0520512\ttotal: 3m 52s\tremaining: 25m 48s\n",
      "1304:\tlearn: 0.0520512\ttotal: 3m 52s\tremaining: 25m 47s\n",
      "1305:\tlearn: 0.0520512\ttotal: 3m 52s\tremaining: 25m 47s\n",
      "1306:\tlearn: 0.0520512\ttotal: 3m 52s\tremaining: 25m 47s\n",
      "1307:\tlearn: 0.0520512\ttotal: 3m 52s\tremaining: 25m 47s\n",
      "1308:\tlearn: 0.0520512\ttotal: 3m 52s\tremaining: 25m 46s\n",
      "1309:\tlearn: 0.0520512\ttotal: 3m 53s\tremaining: 25m 46s\n",
      "1310:\tlearn: 0.0520512\ttotal: 3m 53s\tremaining: 25m 46s\n",
      "1311:\tlearn: 0.0520512\ttotal: 3m 53s\tremaining: 25m 46s\n",
      "1312:\tlearn: 0.0520512\ttotal: 3m 53s\tremaining: 25m 45s\n",
      "1313:\tlearn: 0.0520512\ttotal: 3m 53s\tremaining: 25m 45s\n",
      "1314:\tlearn: 0.0520512\ttotal: 3m 53s\tremaining: 25m 45s\n",
      "1315:\tlearn: 0.0520512\ttotal: 3m 54s\tremaining: 25m 44s\n",
      "1316:\tlearn: 0.0520512\ttotal: 3m 54s\tremaining: 25m 44s\n",
      "1317:\tlearn: 0.0520512\ttotal: 3m 54s\tremaining: 25m 44s\n",
      "1318:\tlearn: 0.0520512\ttotal: 3m 54s\tremaining: 25m 44s\n",
      "1319:\tlearn: 0.0520512\ttotal: 3m 54s\tremaining: 25m 43s\n",
      "1320:\tlearn: 0.0520512\ttotal: 3m 54s\tremaining: 25m 43s\n",
      "1321:\tlearn: 0.0520512\ttotal: 3m 55s\tremaining: 25m 43s\n",
      "1322:\tlearn: 0.0520512\ttotal: 3m 55s\tremaining: 25m 42s\n",
      "1323:\tlearn: 0.0520512\ttotal: 3m 55s\tremaining: 25m 42s\n",
      "1324:\tlearn: 0.0520512\ttotal: 3m 55s\tremaining: 25m 42s\n",
      "1325:\tlearn: 0.0520512\ttotal: 3m 55s\tremaining: 25m 42s\n",
      "1326:\tlearn: 0.0520512\ttotal: 3m 55s\tremaining: 25m 41s\n",
      "1327:\tlearn: 0.0520512\ttotal: 3m 56s\tremaining: 25m 41s\n",
      "1328:\tlearn: 0.0520512\ttotal: 3m 56s\tremaining: 25m 41s\n",
      "1329:\tlearn: 0.0520512\ttotal: 3m 56s\tremaining: 25m 40s\n",
      "1330:\tlearn: 0.0520512\ttotal: 3m 56s\tremaining: 25m 40s\n",
      "1331:\tlearn: 0.0520512\ttotal: 3m 56s\tremaining: 25m 40s\n",
      "1332:\tlearn: 0.0520512\ttotal: 3m 56s\tremaining: 25m 40s\n",
      "1333:\tlearn: 0.0520512\ttotal: 3m 57s\tremaining: 25m 39s\n",
      "1334:\tlearn: 0.0520512\ttotal: 3m 57s\tremaining: 25m 39s\n",
      "1335:\tlearn: 0.0520512\ttotal: 3m 57s\tremaining: 25m 39s\n",
      "1336:\tlearn: 0.0520512\ttotal: 3m 57s\tremaining: 25m 38s\n",
      "1337:\tlearn: 0.0520512\ttotal: 3m 57s\tremaining: 25m 38s\n",
      "1338:\tlearn: 0.0520512\ttotal: 3m 57s\tremaining: 25m 38s\n",
      "1339:\tlearn: 0.0520512\ttotal: 3m 57s\tremaining: 25m 37s\n",
      "1340:\tlearn: 0.0520512\ttotal: 3m 58s\tremaining: 25m 37s\n",
      "1341:\tlearn: 0.0520512\ttotal: 3m 58s\tremaining: 25m 37s\n",
      "1342:\tlearn: 0.0520512\ttotal: 3m 58s\tremaining: 25m 36s\n",
      "1343:\tlearn: 0.0520512\ttotal: 3m 58s\tremaining: 25m 36s\n",
      "1344:\tlearn: 0.0520512\ttotal: 3m 58s\tremaining: 25m 36s\n",
      "1345:\tlearn: 0.0520512\ttotal: 3m 58s\tremaining: 25m 35s\n",
      "1346:\tlearn: 0.0520512\ttotal: 3m 59s\tremaining: 25m 35s\n",
      "1347:\tlearn: 0.0520512\ttotal: 3m 59s\tremaining: 25m 35s\n",
      "1348:\tlearn: 0.0520512\ttotal: 3m 59s\tremaining: 25m 35s\n",
      "1349:\tlearn: 0.0520512\ttotal: 3m 59s\tremaining: 25m 34s\n",
      "1350:\tlearn: 0.0520512\ttotal: 3m 59s\tremaining: 25m 34s\n",
      "1351:\tlearn: 0.0520512\ttotal: 3m 59s\tremaining: 25m 34s\n",
      "1352:\tlearn: 0.0520512\ttotal: 3m 59s\tremaining: 25m 33s\n",
      "1353:\tlearn: 0.0520512\ttotal: 4m\tremaining: 25m 33s\n",
      "1354:\tlearn: 0.0520512\ttotal: 4m\tremaining: 25m 33s\n",
      "1355:\tlearn: 0.0520512\ttotal: 4m\tremaining: 25m 32s\n",
      "1356:\tlearn: 0.0520512\ttotal: 4m\tremaining: 25m 32s\n",
      "1357:\tlearn: 0.0520512\ttotal: 4m\tremaining: 25m 32s\n",
      "1358:\tlearn: 0.0520512\ttotal: 4m\tremaining: 25m 31s\n",
      "1359:\tlearn: 0.0520512\ttotal: 4m 1s\tremaining: 25m 31s\n",
      "1360:\tlearn: 0.0520512\ttotal: 4m 1s\tremaining: 25m 31s\n",
      "1361:\tlearn: 0.0520512\ttotal: 4m 1s\tremaining: 25m 30s\n",
      "1362:\tlearn: 0.0520512\ttotal: 4m 1s\tremaining: 25m 30s\n",
      "1363:\tlearn: 0.0520512\ttotal: 4m 1s\tremaining: 25m 30s\n",
      "1364:\tlearn: 0.0520512\ttotal: 4m 1s\tremaining: 25m 30s\n",
      "1365:\tlearn: 0.0520512\ttotal: 4m 2s\tremaining: 25m 29s\n",
      "1366:\tlearn: 0.0520512\ttotal: 4m 2s\tremaining: 25m 29s\n",
      "1367:\tlearn: 0.0520512\ttotal: 4m 2s\tremaining: 25m 29s\n",
      "1368:\tlearn: 0.0520512\ttotal: 4m 2s\tremaining: 25m 28s\n",
      "1369:\tlearn: 0.0520512\ttotal: 4m 2s\tremaining: 25m 28s\n",
      "1370:\tlearn: 0.0520512\ttotal: 4m 2s\tremaining: 25m 28s\n",
      "1371:\tlearn: 0.0520512\ttotal: 4m 2s\tremaining: 25m 27s\n",
      "1372:\tlearn: 0.0520512\ttotal: 4m 3s\tremaining: 25m 27s\n",
      "1373:\tlearn: 0.0520512\ttotal: 4m 3s\tremaining: 25m 27s\n",
      "1374:\tlearn: 0.0520512\ttotal: 4m 3s\tremaining: 25m 26s\n",
      "1375:\tlearn: 0.0520512\ttotal: 4m 3s\tremaining: 25m 26s\n",
      "1376:\tlearn: 0.0520512\ttotal: 4m 3s\tremaining: 25m 26s\n",
      "1377:\tlearn: 0.0520512\ttotal: 4m 3s\tremaining: 25m 26s\n",
      "1378:\tlearn: 0.0520512\ttotal: 4m 4s\tremaining: 25m 25s\n",
      "1379:\tlearn: 0.0520512\ttotal: 4m 4s\tremaining: 25m 25s\n",
      "1380:\tlearn: 0.0520512\ttotal: 4m 4s\tremaining: 25m 25s\n",
      "1381:\tlearn: 0.0520512\ttotal: 4m 4s\tremaining: 25m 24s\n",
      "1382:\tlearn: 0.0520512\ttotal: 4m 4s\tremaining: 25m 24s\n",
      "1383:\tlearn: 0.0520512\ttotal: 4m 4s\tremaining: 25m 24s\n",
      "1384:\tlearn: 0.0520512\ttotal: 4m 5s\tremaining: 25m 23s\n",
      "1385:\tlearn: 0.0520512\ttotal: 4m 5s\tremaining: 25m 23s\n",
      "1386:\tlearn: 0.0520512\ttotal: 4m 5s\tremaining: 25m 23s\n",
      "1387:\tlearn: 0.0520512\ttotal: 4m 5s\tremaining: 25m 23s\n",
      "1388:\tlearn: 0.0520512\ttotal: 4m 5s\tremaining: 25m 22s\n",
      "1389:\tlearn: 0.0520512\ttotal: 4m 5s\tremaining: 25m 22s\n",
      "1390:\tlearn: 0.0520512\ttotal: 4m 5s\tremaining: 25m 22s\n",
      "1391:\tlearn: 0.0520512\ttotal: 4m 6s\tremaining: 25m 21s\n",
      "1392:\tlearn: 0.0520512\ttotal: 4m 6s\tremaining: 25m 21s\n",
      "1393:\tlearn: 0.0520512\ttotal: 4m 6s\tremaining: 25m 21s\n",
      "1394:\tlearn: 0.0520512\ttotal: 4m 6s\tremaining: 25m 20s\n",
      "1395:\tlearn: 0.0520512\ttotal: 4m 6s\tremaining: 25m 20s\n",
      "1396:\tlearn: 0.0520512\ttotal: 4m 6s\tremaining: 25m 20s\n",
      "1397:\tlearn: 0.0520512\ttotal: 4m 7s\tremaining: 25m 19s\n",
      "1398:\tlearn: 0.0520512\ttotal: 4m 7s\tremaining: 25m 19s\n",
      "1399:\tlearn: 0.0520512\ttotal: 4m 7s\tremaining: 25m 19s\n",
      "1400:\tlearn: 0.0520512\ttotal: 4m 7s\tremaining: 25m 19s\n",
      "1401:\tlearn: 0.0520512\ttotal: 4m 7s\tremaining: 25m 18s\n",
      "1402:\tlearn: 0.0520512\ttotal: 4m 7s\tremaining: 25m 18s\n",
      "1403:\tlearn: 0.0520512\ttotal: 4m 7s\tremaining: 25m 18s\n",
      "1404:\tlearn: 0.0520512\ttotal: 4m 8s\tremaining: 25m 17s\n",
      "1405:\tlearn: 0.0520512\ttotal: 4m 8s\tremaining: 25m 17s\n",
      "1406:\tlearn: 0.0520512\ttotal: 4m 8s\tremaining: 25m 17s\n",
      "1407:\tlearn: 0.0520512\ttotal: 4m 8s\tremaining: 25m 17s\n",
      "1408:\tlearn: 0.0520512\ttotal: 4m 8s\tremaining: 25m 17s\n",
      "1409:\tlearn: 0.0520512\ttotal: 4m 9s\tremaining: 25m 16s\n",
      "1410:\tlearn: 0.0520512\ttotal: 4m 9s\tremaining: 25m 16s\n",
      "1411:\tlearn: 0.0520512\ttotal: 4m 9s\tremaining: 25m 16s\n",
      "1412:\tlearn: 0.0520512\ttotal: 4m 9s\tremaining: 25m 16s\n",
      "1413:\tlearn: 0.0520512\ttotal: 4m 9s\tremaining: 25m 15s\n",
      "1414:\tlearn: 0.0520512\ttotal: 4m 9s\tremaining: 25m 15s\n",
      "1415:\tlearn: 0.0520512\ttotal: 4m 9s\tremaining: 25m 15s\n",
      "1416:\tlearn: 0.0520512\ttotal: 4m 10s\tremaining: 25m 15s\n",
      "1417:\tlearn: 0.0520512\ttotal: 4m 10s\tremaining: 25m 14s\n",
      "1418:\tlearn: 0.0520512\ttotal: 4m 10s\tremaining: 25m 14s\n",
      "1419:\tlearn: 0.0520512\ttotal: 4m 10s\tremaining: 25m 14s\n",
      "1420:\tlearn: 0.0520512\ttotal: 4m 10s\tremaining: 25m 14s\n",
      "1421:\tlearn: 0.0520512\ttotal: 4m 10s\tremaining: 25m 13s\n",
      "1422:\tlearn: 0.0520512\ttotal: 4m 11s\tremaining: 25m 13s\n",
      "1423:\tlearn: 0.0520512\ttotal: 4m 11s\tremaining: 25m 13s\n",
      "1424:\tlearn: 0.0520512\ttotal: 4m 11s\tremaining: 25m 13s\n",
      "1425:\tlearn: 0.0520512\ttotal: 4m 11s\tremaining: 25m 12s\n",
      "1426:\tlearn: 0.0520512\ttotal: 4m 11s\tremaining: 25m 12s\n",
      "1427:\tlearn: 0.0520512\ttotal: 4m 11s\tremaining: 25m 12s\n",
      "1428:\tlearn: 0.0520512\ttotal: 4m 12s\tremaining: 25m 12s\n",
      "1429:\tlearn: 0.0520512\ttotal: 4m 12s\tremaining: 25m 11s\n",
      "1430:\tlearn: 0.0520512\ttotal: 4m 12s\tremaining: 25m 11s\n",
      "1431:\tlearn: 0.0520512\ttotal: 4m 12s\tremaining: 25m 11s\n",
      "1432:\tlearn: 0.0520512\ttotal: 4m 12s\tremaining: 25m 11s\n",
      "1433:\tlearn: 0.0520512\ttotal: 4m 13s\tremaining: 25m 11s\n",
      "1434:\tlearn: 0.0520512\ttotal: 4m 13s\tremaining: 25m 11s\n",
      "1435:\tlearn: 0.0520512\ttotal: 4m 13s\tremaining: 25m 11s\n",
      "1436:\tlearn: 0.0520512\ttotal: 4m 13s\tremaining: 25m 10s\n",
      "1437:\tlearn: 0.0520512\ttotal: 4m 13s\tremaining: 25m 10s\n",
      "1438:\tlearn: 0.0520512\ttotal: 4m 13s\tremaining: 25m 10s\n",
      "1439:\tlearn: 0.0520512\ttotal: 4m 14s\tremaining: 25m 10s\n",
      "1440:\tlearn: 0.0520512\ttotal: 4m 14s\tremaining: 25m 10s\n",
      "1441:\tlearn: 0.0520512\ttotal: 4m 14s\tremaining: 25m 9s\n",
      "1442:\tlearn: 0.0520512\ttotal: 4m 14s\tremaining: 25m 9s\n",
      "1443:\tlearn: 0.0520512\ttotal: 4m 14s\tremaining: 25m 9s\n",
      "1444:\tlearn: 0.0520512\ttotal: 4m 14s\tremaining: 25m 9s\n",
      "1445:\tlearn: 0.0520512\ttotal: 4m 15s\tremaining: 25m 9s\n",
      "1446:\tlearn: 0.0520512\ttotal: 4m 15s\tremaining: 25m 9s\n",
      "1447:\tlearn: 0.0520512\ttotal: 4m 15s\tremaining: 25m 8s\n",
      "1448:\tlearn: 0.0520512\ttotal: 4m 15s\tremaining: 25m 8s\n",
      "1449:\tlearn: 0.0520512\ttotal: 4m 15s\tremaining: 25m 8s\n",
      "1450:\tlearn: 0.0520512\ttotal: 4m 15s\tremaining: 25m 8s\n",
      "1451:\tlearn: 0.0520512\ttotal: 4m 16s\tremaining: 25m 7s\n",
      "1452:\tlearn: 0.0520512\ttotal: 4m 16s\tremaining: 25m 7s\n",
      "1453:\tlearn: 0.0520512\ttotal: 4m 16s\tremaining: 25m 7s\n",
      "1454:\tlearn: 0.0520512\ttotal: 4m 16s\tremaining: 25m 7s\n",
      "1455:\tlearn: 0.0520512\ttotal: 4m 16s\tremaining: 25m 6s\n",
      "1456:\tlearn: 0.0520512\ttotal: 4m 16s\tremaining: 25m 6s\n",
      "1457:\tlearn: 0.0520512\ttotal: 4m 17s\tremaining: 25m 6s\n",
      "1458:\tlearn: 0.0520512\ttotal: 4m 17s\tremaining: 25m 5s\n",
      "1459:\tlearn: 0.0520512\ttotal: 4m 17s\tremaining: 25m 5s\n",
      "1460:\tlearn: 0.0520512\ttotal: 4m 17s\tremaining: 25m 5s\n",
      "1461:\tlearn: 0.0520512\ttotal: 4m 17s\tremaining: 25m 5s\n",
      "1462:\tlearn: 0.0520512\ttotal: 4m 17s\tremaining: 25m 4s\n",
      "1463:\tlearn: 0.0520512\ttotal: 4m 18s\tremaining: 25m 4s\n",
      "1464:\tlearn: 0.0520512\ttotal: 4m 18s\tremaining: 25m 4s\n",
      "1465:\tlearn: 0.0520512\ttotal: 4m 18s\tremaining: 25m 4s\n",
      "1466:\tlearn: 0.0520512\ttotal: 4m 18s\tremaining: 25m 3s\n",
      "1467:\tlearn: 0.0520512\ttotal: 4m 18s\tremaining: 25m 3s\n",
      "1468:\tlearn: 0.0520512\ttotal: 4m 18s\tremaining: 25m 3s\n",
      "1469:\tlearn: 0.0520512\ttotal: 4m 19s\tremaining: 25m 2s\n",
      "1470:\tlearn: 0.0520512\ttotal: 4m 19s\tremaining: 25m 2s\n",
      "1471:\tlearn: 0.0520512\ttotal: 4m 19s\tremaining: 25m 2s\n",
      "1472:\tlearn: 0.0520512\ttotal: 4m 19s\tremaining: 25m 2s\n",
      "1473:\tlearn: 0.0520512\ttotal: 4m 19s\tremaining: 25m 1s\n",
      "1474:\tlearn: 0.0520512\ttotal: 4m 19s\tremaining: 25m 1s\n",
      "1475:\tlearn: 0.0520512\ttotal: 4m 19s\tremaining: 25m\n",
      "1476:\tlearn: 0.0520512\ttotal: 4m 20s\tremaining: 25m\n",
      "1477:\tlearn: 0.0520512\ttotal: 4m 20s\tremaining: 25m\n",
      "1478:\tlearn: 0.0520512\ttotal: 4m 20s\tremaining: 24m 59s\n",
      "1479:\tlearn: 0.0520512\ttotal: 4m 20s\tremaining: 24m 59s\n",
      "1480:\tlearn: 0.0520512\ttotal: 4m 20s\tremaining: 24m 59s\n",
      "1481:\tlearn: 0.0520512\ttotal: 4m 20s\tremaining: 24m 58s\n",
      "1482:\tlearn: 0.0520512\ttotal: 4m 20s\tremaining: 24m 58s\n",
      "1483:\tlearn: 0.0520512\ttotal: 4m 21s\tremaining: 24m 58s\n",
      "1484:\tlearn: 0.0520512\ttotal: 4m 21s\tremaining: 24m 58s\n",
      "1485:\tlearn: 0.0520512\ttotal: 4m 21s\tremaining: 24m 57s\n",
      "1486:\tlearn: 0.0520512\ttotal: 4m 21s\tremaining: 24m 57s\n",
      "1487:\tlearn: 0.0520512\ttotal: 4m 21s\tremaining: 24m 57s\n",
      "1488:\tlearn: 0.0520512\ttotal: 4m 21s\tremaining: 24m 56s\n",
      "1489:\tlearn: 0.0520512\ttotal: 4m 22s\tremaining: 24m 56s\n",
      "1490:\tlearn: 0.0520512\ttotal: 4m 22s\tremaining: 24m 56s\n",
      "1491:\tlearn: 0.0520512\ttotal: 4m 22s\tremaining: 24m 55s\n",
      "1492:\tlearn: 0.0520512\ttotal: 4m 22s\tremaining: 24m 55s\n",
      "1493:\tlearn: 0.0520512\ttotal: 4m 22s\tremaining: 24m 55s\n",
      "1494:\tlearn: 0.0520512\ttotal: 4m 22s\tremaining: 24m 54s\n",
      "1495:\tlearn: 0.0520512\ttotal: 4m 22s\tremaining: 24m 54s\n",
      "1496:\tlearn: 0.0520512\ttotal: 4m 23s\tremaining: 24m 54s\n",
      "1497:\tlearn: 0.0520512\ttotal: 4m 23s\tremaining: 24m 54s\n",
      "1498:\tlearn: 0.0520512\ttotal: 4m 23s\tremaining: 24m 53s\n",
      "1499:\tlearn: 0.0520512\ttotal: 4m 23s\tremaining: 24m 53s\n",
      "1500:\tlearn: 0.0520512\ttotal: 4m 23s\tremaining: 24m 53s\n",
      "1501:\tlearn: 0.0520512\ttotal: 4m 23s\tremaining: 24m 52s\n",
      "1502:\tlearn: 0.0520512\ttotal: 4m 24s\tremaining: 24m 52s\n",
      "1503:\tlearn: 0.0520512\ttotal: 4m 24s\tremaining: 24m 52s\n",
      "1504:\tlearn: 0.0520512\ttotal: 4m 24s\tremaining: 24m 52s\n",
      "1505:\tlearn: 0.0520512\ttotal: 4m 24s\tremaining: 24m 51s\n",
      "1506:\tlearn: 0.0520512\ttotal: 4m 24s\tremaining: 24m 51s\n",
      "1507:\tlearn: 0.0520512\ttotal: 4m 24s\tremaining: 24m 51s\n",
      "1508:\tlearn: 0.0520512\ttotal: 4m 24s\tremaining: 24m 50s\n",
      "1509:\tlearn: 0.0520512\ttotal: 4m 25s\tremaining: 24m 50s\n",
      "1510:\tlearn: 0.0520512\ttotal: 4m 25s\tremaining: 24m 50s\n",
      "1511:\tlearn: 0.0520512\ttotal: 4m 25s\tremaining: 24m 49s\n",
      "1512:\tlearn: 0.0520512\ttotal: 4m 25s\tremaining: 24m 49s\n",
      "1513:\tlearn: 0.0520512\ttotal: 4m 25s\tremaining: 24m 49s\n",
      "1514:\tlearn: 0.0520512\ttotal: 4m 25s\tremaining: 24m 48s\n",
      "1515:\tlearn: 0.0520512\ttotal: 4m 25s\tremaining: 24m 48s\n",
      "1516:\tlearn: 0.0520512\ttotal: 4m 26s\tremaining: 24m 48s\n",
      "1517:\tlearn: 0.0520512\ttotal: 4m 26s\tremaining: 24m 47s\n",
      "1518:\tlearn: 0.0520512\ttotal: 4m 26s\tremaining: 24m 47s\n",
      "1519:\tlearn: 0.0520512\ttotal: 4m 26s\tremaining: 24m 47s\n",
      "1520:\tlearn: 0.0520512\ttotal: 4m 26s\tremaining: 24m 46s\n",
      "1521:\tlearn: 0.0520512\ttotal: 4m 26s\tremaining: 24m 46s\n",
      "1522:\tlearn: 0.0520512\ttotal: 4m 27s\tremaining: 24m 46s\n",
      "1523:\tlearn: 0.0520512\ttotal: 4m 27s\tremaining: 24m 46s\n",
      "1524:\tlearn: 0.0520512\ttotal: 4m 27s\tremaining: 24m 45s\n",
      "1525:\tlearn: 0.0520512\ttotal: 4m 27s\tremaining: 24m 45s\n",
      "1526:\tlearn: 0.0520512\ttotal: 4m 27s\tremaining: 24m 45s\n",
      "1527:\tlearn: 0.0520512\ttotal: 4m 27s\tremaining: 24m 44s\n",
      "1528:\tlearn: 0.0520512\ttotal: 4m 28s\tremaining: 24m 44s\n",
      "1529:\tlearn: 0.0520512\ttotal: 4m 28s\tremaining: 24m 44s\n",
      "1530:\tlearn: 0.0520512\ttotal: 4m 28s\tremaining: 24m 44s\n",
      "1531:\tlearn: 0.0520512\ttotal: 4m 28s\tremaining: 24m 44s\n",
      "1532:\tlearn: 0.0520512\ttotal: 4m 28s\tremaining: 24m 43s\n",
      "1533:\tlearn: 0.0520512\ttotal: 4m 28s\tremaining: 24m 43s\n",
      "1534:\tlearn: 0.0520512\ttotal: 4m 28s\tremaining: 24m 43s\n",
      "1535:\tlearn: 0.0520512\ttotal: 4m 29s\tremaining: 24m 43s\n",
      "1536:\tlearn: 0.0520512\ttotal: 4m 29s\tremaining: 24m 42s\n",
      "1537:\tlearn: 0.0520512\ttotal: 4m 29s\tremaining: 24m 42s\n",
      "1538:\tlearn: 0.0520512\ttotal: 4m 29s\tremaining: 24m 42s\n",
      "1539:\tlearn: 0.0520512\ttotal: 4m 29s\tremaining: 24m 41s\n",
      "1540:\tlearn: 0.0520512\ttotal: 4m 29s\tremaining: 24m 41s\n",
      "1541:\tlearn: 0.0520512\ttotal: 4m 30s\tremaining: 24m 41s\n",
      "1542:\tlearn: 0.0520512\ttotal: 4m 30s\tremaining: 24m 41s\n",
      "1543:\tlearn: 0.0520512\ttotal: 4m 30s\tremaining: 24m 40s\n",
      "1544:\tlearn: 0.0520512\ttotal: 4m 30s\tremaining: 24m 40s\n",
      "1545:\tlearn: 0.0520512\ttotal: 4m 30s\tremaining: 24m 40s\n",
      "1546:\tlearn: 0.0520512\ttotal: 4m 30s\tremaining: 24m 39s\n",
      "1547:\tlearn: 0.0520512\ttotal: 4m 30s\tremaining: 24m 39s\n",
      "1548:\tlearn: 0.0520512\ttotal: 4m 31s\tremaining: 24m 39s\n",
      "1549:\tlearn: 0.0520512\ttotal: 4m 31s\tremaining: 24m 38s\n",
      "1550:\tlearn: 0.0520512\ttotal: 4m 31s\tremaining: 24m 38s\n",
      "1551:\tlearn: 0.0520512\ttotal: 4m 31s\tremaining: 24m 38s\n",
      "1552:\tlearn: 0.0520512\ttotal: 4m 31s\tremaining: 24m 37s\n",
      "1553:\tlearn: 0.0520512\ttotal: 4m 31s\tremaining: 24m 37s\n",
      "1554:\tlearn: 0.0520512\ttotal: 4m 32s\tremaining: 24m 37s\n",
      "1555:\tlearn: 0.0520512\ttotal: 4m 32s\tremaining: 24m 37s\n",
      "1556:\tlearn: 0.0520512\ttotal: 4m 32s\tremaining: 24m 36s\n",
      "1557:\tlearn: 0.0520512\ttotal: 4m 32s\tremaining: 24m 36s\n",
      "1558:\tlearn: 0.0520512\ttotal: 4m 32s\tremaining: 24m 36s\n",
      "1559:\tlearn: 0.0520512\ttotal: 4m 32s\tremaining: 24m 35s\n",
      "1560:\tlearn: 0.0520512\ttotal: 4m 32s\tremaining: 24m 35s\n",
      "1561:\tlearn: 0.0520512\ttotal: 4m 33s\tremaining: 24m 35s\n",
      "1562:\tlearn: 0.0520512\ttotal: 4m 33s\tremaining: 24m 34s\n",
      "1563:\tlearn: 0.0520512\ttotal: 4m 33s\tremaining: 24m 34s\n",
      "1564:\tlearn: 0.0520512\ttotal: 4m 33s\tremaining: 24m 34s\n",
      "1565:\tlearn: 0.0520512\ttotal: 4m 33s\tremaining: 24m 34s\n",
      "1566:\tlearn: 0.0520512\ttotal: 4m 33s\tremaining: 24m 33s\n",
      "1567:\tlearn: 0.0520512\ttotal: 4m 34s\tremaining: 24m 33s\n",
      "1568:\tlearn: 0.0520512\ttotal: 4m 34s\tremaining: 24m 33s\n",
      "1569:\tlearn: 0.0520512\ttotal: 4m 34s\tremaining: 24m 32s\n",
      "1570:\tlearn: 0.0520512\ttotal: 4m 34s\tremaining: 24m 32s\n",
      "1571:\tlearn: 0.0520512\ttotal: 4m 34s\tremaining: 24m 32s\n",
      "1572:\tlearn: 0.0520512\ttotal: 4m 34s\tremaining: 24m 32s\n",
      "1573:\tlearn: 0.0520512\ttotal: 4m 34s\tremaining: 24m 31s\n",
      "1574:\tlearn: 0.0520512\ttotal: 4m 35s\tremaining: 24m 31s\n",
      "1575:\tlearn: 0.0520512\ttotal: 4m 35s\tremaining: 24m 31s\n",
      "1576:\tlearn: 0.0520512\ttotal: 4m 35s\tremaining: 24m 30s\n",
      "1577:\tlearn: 0.0520512\ttotal: 4m 35s\tremaining: 24m 30s\n",
      "1578:\tlearn: 0.0520512\ttotal: 4m 35s\tremaining: 24m 30s\n",
      "1579:\tlearn: 0.0520512\ttotal: 4m 35s\tremaining: 24m 30s\n",
      "1580:\tlearn: 0.0520512\ttotal: 4m 36s\tremaining: 24m 30s\n",
      "1581:\tlearn: 0.0520512\ttotal: 4m 36s\tremaining: 24m 29s\n",
      "1582:\tlearn: 0.0520512\ttotal: 4m 36s\tremaining: 24m 29s\n",
      "1583:\tlearn: 0.0520512\ttotal: 4m 36s\tremaining: 24m 29s\n",
      "1584:\tlearn: 0.0520512\ttotal: 4m 36s\tremaining: 24m 29s\n",
      "1585:\tlearn: 0.0520512\ttotal: 4m 36s\tremaining: 24m 28s\n",
      "1586:\tlearn: 0.0520512\ttotal: 4m 37s\tremaining: 24m 28s\n",
      "1587:\tlearn: 0.0520512\ttotal: 4m 37s\tremaining: 24m 28s\n",
      "1588:\tlearn: 0.0520512\ttotal: 4m 37s\tremaining: 24m 28s\n",
      "1589:\tlearn: 0.0520512\ttotal: 4m 37s\tremaining: 24m 27s\n",
      "1590:\tlearn: 0.0520512\ttotal: 4m 37s\tremaining: 24m 27s\n",
      "1591:\tlearn: 0.0520512\ttotal: 4m 37s\tremaining: 24m 27s\n",
      "1592:\tlearn: 0.0520512\ttotal: 4m 38s\tremaining: 24m 27s\n",
      "1593:\tlearn: 0.0520512\ttotal: 4m 38s\tremaining: 24m 26s\n",
      "1594:\tlearn: 0.0520512\ttotal: 4m 38s\tremaining: 24m 26s\n",
      "1595:\tlearn: 0.0520512\ttotal: 4m 38s\tremaining: 24m 26s\n",
      "1596:\tlearn: 0.0520512\ttotal: 4m 38s\tremaining: 24m 26s\n",
      "1597:\tlearn: 0.0520512\ttotal: 4m 38s\tremaining: 24m 25s\n",
      "1598:\tlearn: 0.0520512\ttotal: 4m 38s\tremaining: 24m 25s\n",
      "1599:\tlearn: 0.0520512\ttotal: 4m 39s\tremaining: 24m 25s\n",
      "1600:\tlearn: 0.0520512\ttotal: 4m 39s\tremaining: 24m 24s\n",
      "1601:\tlearn: 0.0520512\ttotal: 4m 39s\tremaining: 24m 24s\n",
      "1602:\tlearn: 0.0520512\ttotal: 4m 39s\tremaining: 24m 24s\n",
      "1603:\tlearn: 0.0520512\ttotal: 4m 39s\tremaining: 24m 24s\n",
      "1604:\tlearn: 0.0520512\ttotal: 4m 39s\tremaining: 24m 23s\n",
      "1605:\tlearn: 0.0520512\ttotal: 4m 40s\tremaining: 24m 23s\n",
      "1606:\tlearn: 0.0520512\ttotal: 4m 40s\tremaining: 24m 23s\n",
      "1607:\tlearn: 0.0520512\ttotal: 4m 40s\tremaining: 24m 23s\n",
      "1608:\tlearn: 0.0520512\ttotal: 4m 40s\tremaining: 24m 22s\n",
      "1609:\tlearn: 0.0520512\ttotal: 4m 40s\tremaining: 24m 22s\n",
      "1610:\tlearn: 0.0520512\ttotal: 4m 40s\tremaining: 24m 22s\n",
      "1611:\tlearn: 0.0520512\ttotal: 4m 40s\tremaining: 24m 21s\n",
      "1612:\tlearn: 0.0520512\ttotal: 4m 41s\tremaining: 24m 21s\n",
      "1613:\tlearn: 0.0520512\ttotal: 4m 41s\tremaining: 24m 21s\n",
      "1614:\tlearn: 0.0520512\ttotal: 4m 41s\tremaining: 24m 20s\n",
      "1615:\tlearn: 0.0520512\ttotal: 4m 41s\tremaining: 24m 20s\n",
      "1616:\tlearn: 0.0520512\ttotal: 4m 41s\tremaining: 24m 20s\n",
      "1617:\tlearn: 0.0520512\ttotal: 4m 41s\tremaining: 24m 19s\n",
      "1618:\tlearn: 0.0520512\ttotal: 4m 41s\tremaining: 24m 19s\n",
      "1619:\tlearn: 0.0520512\ttotal: 4m 42s\tremaining: 24m 19s\n",
      "1620:\tlearn: 0.0520512\ttotal: 4m 42s\tremaining: 24m 18s\n",
      "1621:\tlearn: 0.0520512\ttotal: 4m 42s\tremaining: 24m 18s\n",
      "1622:\tlearn: 0.0520512\ttotal: 4m 42s\tremaining: 24m 18s\n",
      "1623:\tlearn: 0.0520512\ttotal: 4m 42s\tremaining: 24m 17s\n",
      "1624:\tlearn: 0.0520512\ttotal: 4m 42s\tremaining: 24m 17s\n",
      "1625:\tlearn: 0.0520512\ttotal: 4m 43s\tremaining: 24m 17s\n",
      "1626:\tlearn: 0.0520512\ttotal: 4m 43s\tremaining: 24m 17s\n",
      "1627:\tlearn: 0.0520512\ttotal: 4m 43s\tremaining: 24m 17s\n",
      "1628:\tlearn: 0.0520512\ttotal: 4m 43s\tremaining: 24m 16s\n",
      "1629:\tlearn: 0.0520512\ttotal: 4m 43s\tremaining: 24m 16s\n",
      "1630:\tlearn: 0.0520512\ttotal: 4m 43s\tremaining: 24m 16s\n",
      "1631:\tlearn: 0.0520512\ttotal: 4m 43s\tremaining: 24m 16s\n",
      "1632:\tlearn: 0.0520512\ttotal: 4m 44s\tremaining: 24m 15s\n",
      "1633:\tlearn: 0.0520512\ttotal: 4m 44s\tremaining: 24m 15s\n",
      "1634:\tlearn: 0.0520512\ttotal: 4m 44s\tremaining: 24m 15s\n",
      "1635:\tlearn: 0.0520512\ttotal: 4m 44s\tremaining: 24m 14s\n",
      "1636:\tlearn: 0.0520512\ttotal: 4m 44s\tremaining: 24m 14s\n",
      "1637:\tlearn: 0.0520512\ttotal: 4m 44s\tremaining: 24m 14s\n",
      "1638:\tlearn: 0.0520512\ttotal: 4m 45s\tremaining: 24m 13s\n",
      "1639:\tlearn: 0.0520512\ttotal: 4m 45s\tremaining: 24m 13s\n",
      "1640:\tlearn: 0.0520512\ttotal: 4m 45s\tremaining: 24m 13s\n",
      "1641:\tlearn: 0.0520512\ttotal: 4m 45s\tremaining: 24m 12s\n",
      "1642:\tlearn: 0.0520512\ttotal: 4m 45s\tremaining: 24m 12s\n",
      "1643:\tlearn: 0.0520512\ttotal: 4m 45s\tremaining: 24m 12s\n",
      "1644:\tlearn: 0.0520512\ttotal: 4m 45s\tremaining: 24m 11s\n",
      "1645:\tlearn: 0.0520512\ttotal: 4m 46s\tremaining: 24m 11s\n",
      "1646:\tlearn: 0.0520512\ttotal: 4m 46s\tremaining: 24m 11s\n",
      "1647:\tlearn: 0.0520512\ttotal: 4m 46s\tremaining: 24m 10s\n",
      "1648:\tlearn: 0.0520512\ttotal: 4m 46s\tremaining: 24m 10s\n",
      "1649:\tlearn: 0.0520512\ttotal: 4m 46s\tremaining: 24m 10s\n",
      "1650:\tlearn: 0.0520512\ttotal: 4m 46s\tremaining: 24m 10s\n",
      "1651:\tlearn: 0.0520512\ttotal: 4m 46s\tremaining: 24m 9s\n",
      "1652:\tlearn: 0.0520512\ttotal: 4m 47s\tremaining: 24m 9s\n",
      "1653:\tlearn: 0.0520512\ttotal: 4m 47s\tremaining: 24m 9s\n",
      "1654:\tlearn: 0.0520512\ttotal: 4m 47s\tremaining: 24m 8s\n",
      "1655:\tlearn: 0.0520512\ttotal: 4m 47s\tremaining: 24m 8s\n",
      "1656:\tlearn: 0.0520512\ttotal: 4m 47s\tremaining: 24m 8s\n",
      "1657:\tlearn: 0.0520512\ttotal: 4m 47s\tremaining: 24m 7s\n",
      "1658:\tlearn: 0.0520512\ttotal: 4m 47s\tremaining: 24m 7s\n",
      "1659:\tlearn: 0.0520512\ttotal: 4m 48s\tremaining: 24m 7s\n",
      "1660:\tlearn: 0.0520512\ttotal: 4m 48s\tremaining: 24m 7s\n",
      "1661:\tlearn: 0.0520512\ttotal: 4m 48s\tremaining: 24m 6s\n",
      "1662:\tlearn: 0.0520512\ttotal: 4m 48s\tremaining: 24m 6s\n",
      "1663:\tlearn: 0.0520512\ttotal: 4m 48s\tremaining: 24m 6s\n",
      "1664:\tlearn: 0.0520512\ttotal: 4m 48s\tremaining: 24m 5s\n",
      "1665:\tlearn: 0.0520512\ttotal: 4m 49s\tremaining: 24m 5s\n",
      "1666:\tlearn: 0.0520512\ttotal: 4m 49s\tremaining: 24m 5s\n",
      "1667:\tlearn: 0.0520512\ttotal: 4m 49s\tremaining: 24m 5s\n",
      "1668:\tlearn: 0.0520512\ttotal: 4m 49s\tremaining: 24m 5s\n",
      "1669:\tlearn: 0.0520512\ttotal: 4m 49s\tremaining: 24m 4s\n",
      "1670:\tlearn: 0.0520512\ttotal: 4m 49s\tremaining: 24m 4s\n",
      "1671:\tlearn: 0.0520512\ttotal: 4m 49s\tremaining: 24m 4s\n",
      "1672:\tlearn: 0.0520512\ttotal: 4m 50s\tremaining: 24m 4s\n",
      "1673:\tlearn: 0.0520512\ttotal: 4m 50s\tremaining: 24m 3s\n",
      "1674:\tlearn: 0.0520512\ttotal: 4m 50s\tremaining: 24m 3s\n",
      "1675:\tlearn: 0.0520512\ttotal: 4m 50s\tremaining: 24m 3s\n",
      "1676:\tlearn: 0.0520512\ttotal: 4m 50s\tremaining: 24m 2s\n",
      "1677:\tlearn: 0.0520512\ttotal: 4m 50s\tremaining: 24m 2s\n",
      "1678:\tlearn: 0.0520512\ttotal: 4m 51s\tremaining: 24m 2s\n",
      "1679:\tlearn: 0.0520512\ttotal: 4m 51s\tremaining: 24m 2s\n",
      "1680:\tlearn: 0.0520512\ttotal: 4m 51s\tremaining: 24m 1s\n",
      "1681:\tlearn: 0.0520512\ttotal: 4m 51s\tremaining: 24m 1s\n",
      "1682:\tlearn: 0.0520512\ttotal: 4m 51s\tremaining: 24m 1s\n",
      "1683:\tlearn: 0.0520512\ttotal: 4m 51s\tremaining: 24m\n",
      "1684:\tlearn: 0.0520512\ttotal: 4m 51s\tremaining: 24m\n",
      "1685:\tlearn: 0.0520512\ttotal: 4m 52s\tremaining: 24m\n",
      "1686:\tlearn: 0.0520512\ttotal: 4m 52s\tremaining: 23m 59s\n",
      "1687:\tlearn: 0.0520512\ttotal: 4m 52s\tremaining: 23m 59s\n",
      "1688:\tlearn: 0.0520512\ttotal: 4m 52s\tremaining: 23m 59s\n",
      "1689:\tlearn: 0.0520512\ttotal: 4m 52s\tremaining: 23m 59s\n",
      "1690:\tlearn: 0.0520512\ttotal: 4m 52s\tremaining: 23m 58s\n",
      "1691:\tlearn: 0.0520512\ttotal: 4m 53s\tremaining: 23m 58s\n",
      "1692:\tlearn: 0.0520512\ttotal: 4m 53s\tremaining: 23m 58s\n",
      "1693:\tlearn: 0.0520512\ttotal: 4m 53s\tremaining: 23m 58s\n",
      "1694:\tlearn: 0.0520512\ttotal: 4m 53s\tremaining: 23m 57s\n",
      "1695:\tlearn: 0.0520512\ttotal: 4m 53s\tremaining: 23m 57s\n",
      "1696:\tlearn: 0.0520512\ttotal: 4m 53s\tremaining: 23m 57s\n",
      "1697:\tlearn: 0.0520512\ttotal: 4m 53s\tremaining: 23m 56s\n",
      "1698:\tlearn: 0.0520512\ttotal: 4m 54s\tremaining: 23m 56s\n",
      "1699:\tlearn: 0.0520512\ttotal: 4m 54s\tremaining: 23m 56s\n",
      "1700:\tlearn: 0.0520512\ttotal: 4m 54s\tremaining: 23m 56s\n",
      "1701:\tlearn: 0.0520512\ttotal: 4m 54s\tremaining: 23m 55s\n",
      "1702:\tlearn: 0.0520512\ttotal: 4m 54s\tremaining: 23m 55s\n",
      "1703:\tlearn: 0.0520512\ttotal: 4m 54s\tremaining: 23m 55s\n",
      "1704:\tlearn: 0.0520512\ttotal: 4m 54s\tremaining: 23m 55s\n",
      "1705:\tlearn: 0.0520512\ttotal: 4m 55s\tremaining: 23m 54s\n",
      "1706:\tlearn: 0.0520512\ttotal: 4m 55s\tremaining: 23m 54s\n",
      "1707:\tlearn: 0.0520512\ttotal: 4m 55s\tremaining: 23m 54s\n",
      "1708:\tlearn: 0.0520512\ttotal: 4m 55s\tremaining: 23m 54s\n",
      "1709:\tlearn: 0.0520512\ttotal: 4m 55s\tremaining: 23m 53s\n",
      "1710:\tlearn: 0.0520512\ttotal: 4m 55s\tremaining: 23m 53s\n",
      "1711:\tlearn: 0.0520512\ttotal: 4m 56s\tremaining: 23m 53s\n",
      "1712:\tlearn: 0.0520512\ttotal: 4m 56s\tremaining: 23m 53s\n",
      "1713:\tlearn: 0.0520512\ttotal: 4m 56s\tremaining: 23m 52s\n",
      "1714:\tlearn: 0.0520512\ttotal: 4m 56s\tremaining: 23m 52s\n",
      "1715:\tlearn: 0.0520512\ttotal: 4m 56s\tremaining: 23m 52s\n",
      "1716:\tlearn: 0.0520512\ttotal: 4m 56s\tremaining: 23m 51s\n",
      "1717:\tlearn: 0.0520512\ttotal: 4m 56s\tremaining: 23m 51s\n",
      "1718:\tlearn: 0.0520512\ttotal: 4m 57s\tremaining: 23m 51s\n",
      "1719:\tlearn: 0.0520512\ttotal: 4m 57s\tremaining: 23m 50s\n",
      "1720:\tlearn: 0.0520512\ttotal: 4m 57s\tremaining: 23m 50s\n",
      "1721:\tlearn: 0.0520512\ttotal: 4m 57s\tremaining: 23m 50s\n",
      "1722:\tlearn: 0.0520512\ttotal: 4m 57s\tremaining: 23m 49s\n",
      "1723:\tlearn: 0.0520512\ttotal: 4m 57s\tremaining: 23m 49s\n",
      "1724:\tlearn: 0.0520512\ttotal: 4m 57s\tremaining: 23m 49s\n",
      "1725:\tlearn: 0.0520512\ttotal: 4m 58s\tremaining: 23m 48s\n",
      "1726:\tlearn: 0.0520512\ttotal: 4m 58s\tremaining: 23m 48s\n",
      "1727:\tlearn: 0.0520512\ttotal: 4m 58s\tremaining: 23m 48s\n",
      "1728:\tlearn: 0.0520512\ttotal: 4m 58s\tremaining: 23m 47s\n",
      "1729:\tlearn: 0.0520512\ttotal: 4m 58s\tremaining: 23m 47s\n",
      "1730:\tlearn: 0.0520512\ttotal: 4m 58s\tremaining: 23m 47s\n",
      "1731:\tlearn: 0.0520512\ttotal: 4m 58s\tremaining: 23m 47s\n",
      "1732:\tlearn: 0.0520512\ttotal: 4m 59s\tremaining: 23m 46s\n",
      "1733:\tlearn: 0.0520512\ttotal: 4m 59s\tremaining: 23m 46s\n",
      "1734:\tlearn: 0.0520512\ttotal: 4m 59s\tremaining: 23m 46s\n",
      "1735:\tlearn: 0.0520512\ttotal: 4m 59s\tremaining: 23m 45s\n",
      "1736:\tlearn: 0.0520512\ttotal: 4m 59s\tremaining: 23m 45s\n",
      "1737:\tlearn: 0.0520512\ttotal: 4m 59s\tremaining: 23m 45s\n",
      "1738:\tlearn: 0.0520512\ttotal: 4m 59s\tremaining: 23m 44s\n",
      "1739:\tlearn: 0.0520512\ttotal: 5m\tremaining: 23m 44s\n",
      "1740:\tlearn: 0.0520512\ttotal: 5m\tremaining: 23m 44s\n",
      "1741:\tlearn: 0.0520512\ttotal: 5m\tremaining: 23m 43s\n",
      "1742:\tlearn: 0.0520512\ttotal: 5m\tremaining: 23m 43s\n",
      "1743:\tlearn: 0.0520512\ttotal: 5m\tremaining: 23m 43s\n",
      "1744:\tlearn: 0.0520512\ttotal: 5m\tremaining: 23m 42s\n",
      "1745:\tlearn: 0.0520512\ttotal: 5m\tremaining: 23m 42s\n",
      "1746:\tlearn: 0.0520512\ttotal: 5m 1s\tremaining: 23m 42s\n",
      "1747:\tlearn: 0.0520512\ttotal: 5m 1s\tremaining: 23m 41s\n",
      "1748:\tlearn: 0.0520512\ttotal: 5m 1s\tremaining: 23m 41s\n",
      "1749:\tlearn: 0.0520512\ttotal: 5m 1s\tremaining: 23m 41s\n",
      "1750:\tlearn: 0.0520512\ttotal: 5m 1s\tremaining: 23m 41s\n",
      "1751:\tlearn: 0.0520512\ttotal: 5m 1s\tremaining: 23m 40s\n",
      "1752:\tlearn: 0.0520512\ttotal: 5m 1s\tremaining: 23m 40s\n",
      "1753:\tlearn: 0.0520512\ttotal: 5m 2s\tremaining: 23m 40s\n",
      "1754:\tlearn: 0.0520512\ttotal: 5m 2s\tremaining: 23m 39s\n",
      "1755:\tlearn: 0.0520512\ttotal: 5m 2s\tremaining: 23m 39s\n",
      "1756:\tlearn: 0.0520512\ttotal: 5m 2s\tremaining: 23m 39s\n",
      "1757:\tlearn: 0.0520512\ttotal: 5m 2s\tremaining: 23m 38s\n",
      "1758:\tlearn: 0.0520512\ttotal: 5m 2s\tremaining: 23m 38s\n",
      "1759:\tlearn: 0.0520512\ttotal: 5m 2s\tremaining: 23m 38s\n",
      "1760:\tlearn: 0.0520512\ttotal: 5m 3s\tremaining: 23m 37s\n",
      "1761:\tlearn: 0.0520512\ttotal: 5m 3s\tremaining: 23m 37s\n",
      "1762:\tlearn: 0.0520512\ttotal: 5m 3s\tremaining: 23m 37s\n",
      "1763:\tlearn: 0.0520512\ttotal: 5m 3s\tremaining: 23m 36s\n",
      "1764:\tlearn: 0.0520512\ttotal: 5m 3s\tremaining: 23m 36s\n",
      "1765:\tlearn: 0.0520512\ttotal: 5m 3s\tremaining: 23m 36s\n",
      "1766:\tlearn: 0.0520512\ttotal: 5m 3s\tremaining: 23m 35s\n",
      "1767:\tlearn: 0.0520512\ttotal: 5m 4s\tremaining: 23m 35s\n",
      "1768:\tlearn: 0.0520512\ttotal: 5m 4s\tremaining: 23m 35s\n",
      "1769:\tlearn: 0.0520512\ttotal: 5m 4s\tremaining: 23m 35s\n",
      "1770:\tlearn: 0.0520512\ttotal: 5m 4s\tremaining: 23m 34s\n",
      "1771:\tlearn: 0.0520512\ttotal: 5m 4s\tremaining: 23m 34s\n",
      "1772:\tlearn: 0.0520512\ttotal: 5m 4s\tremaining: 23m 34s\n",
      "1773:\tlearn: 0.0520512\ttotal: 5m 4s\tremaining: 23m 33s\n",
      "1774:\tlearn: 0.0520512\ttotal: 5m 5s\tremaining: 23m 33s\n",
      "1775:\tlearn: 0.0520512\ttotal: 5m 5s\tremaining: 23m 33s\n",
      "1776:\tlearn: 0.0520512\ttotal: 5m 5s\tremaining: 23m 32s\n",
      "1777:\tlearn: 0.0520512\ttotal: 5m 5s\tremaining: 23m 32s\n",
      "1778:\tlearn: 0.0520512\ttotal: 5m 5s\tremaining: 23m 32s\n",
      "1779:\tlearn: 0.0520512\ttotal: 5m 5s\tremaining: 23m 31s\n",
      "1780:\tlearn: 0.0520512\ttotal: 5m 5s\tremaining: 23m 31s\n",
      "1781:\tlearn: 0.0520512\ttotal: 5m 6s\tremaining: 23m 31s\n",
      "1782:\tlearn: 0.0520512\ttotal: 5m 6s\tremaining: 23m 30s\n",
      "1783:\tlearn: 0.0520512\ttotal: 5m 6s\tremaining: 23m 30s\n",
      "1784:\tlearn: 0.0520512\ttotal: 5m 6s\tremaining: 23m 30s\n",
      "1785:\tlearn: 0.0520512\ttotal: 5m 6s\tremaining: 23m 30s\n",
      "1786:\tlearn: 0.0520512\ttotal: 5m 6s\tremaining: 23m 29s\n",
      "1787:\tlearn: 0.0520512\ttotal: 5m 6s\tremaining: 23m 29s\n",
      "1788:\tlearn: 0.0520512\ttotal: 5m 7s\tremaining: 23m 29s\n",
      "1789:\tlearn: 0.0520512\ttotal: 5m 7s\tremaining: 23m 28s\n",
      "1790:\tlearn: 0.0520512\ttotal: 5m 7s\tremaining: 23m 28s\n",
      "1791:\tlearn: 0.0520512\ttotal: 5m 7s\tremaining: 23m 28s\n",
      "1792:\tlearn: 0.0520512\ttotal: 5m 7s\tremaining: 23m 27s\n",
      "1793:\tlearn: 0.0520512\ttotal: 5m 7s\tremaining: 23m 27s\n",
      "1794:\tlearn: 0.0520512\ttotal: 5m 7s\tremaining: 23m 27s\n",
      "1795:\tlearn: 0.0520512\ttotal: 5m 8s\tremaining: 23m 26s\n",
      "1796:\tlearn: 0.0520512\ttotal: 5m 8s\tremaining: 23m 26s\n",
      "1797:\tlearn: 0.0520512\ttotal: 5m 8s\tremaining: 23m 26s\n",
      "1798:\tlearn: 0.0520512\ttotal: 5m 8s\tremaining: 23m 26s\n",
      "1799:\tlearn: 0.0520512\ttotal: 5m 8s\tremaining: 23m 25s\n",
      "1800:\tlearn: 0.0520512\ttotal: 5m 8s\tremaining: 23m 25s\n",
      "1801:\tlearn: 0.0520512\ttotal: 5m 8s\tremaining: 23m 25s\n",
      "1802:\tlearn: 0.0520512\ttotal: 5m 9s\tremaining: 23m 24s\n",
      "1803:\tlearn: 0.0520512\ttotal: 5m 9s\tremaining: 23m 24s\n",
      "1804:\tlearn: 0.0520512\ttotal: 5m 9s\tremaining: 23m 24s\n",
      "1805:\tlearn: 0.0520512\ttotal: 5m 9s\tremaining: 23m 23s\n",
      "1806:\tlearn: 0.0520512\ttotal: 5m 9s\tremaining: 23m 23s\n",
      "1807:\tlearn: 0.0520512\ttotal: 5m 9s\tremaining: 23m 23s\n",
      "1808:\tlearn: 0.0520512\ttotal: 5m 9s\tremaining: 23m 23s\n",
      "1809:\tlearn: 0.0520512\ttotal: 5m 10s\tremaining: 23m 22s\n",
      "1810:\tlearn: 0.0520512\ttotal: 5m 10s\tremaining: 23m 22s\n",
      "1811:\tlearn: 0.0520512\ttotal: 5m 10s\tremaining: 23m 22s\n",
      "1812:\tlearn: 0.0520512\ttotal: 5m 10s\tremaining: 23m 21s\n",
      "1813:\tlearn: 0.0520512\ttotal: 5m 10s\tremaining: 23m 21s\n",
      "1814:\tlearn: 0.0520512\ttotal: 5m 10s\tremaining: 23m 21s\n",
      "1815:\tlearn: 0.0520512\ttotal: 5m 10s\tremaining: 23m 20s\n",
      "1816:\tlearn: 0.0520512\ttotal: 5m 11s\tremaining: 23m 20s\n",
      "1817:\tlearn: 0.0520512\ttotal: 5m 11s\tremaining: 23m 20s\n",
      "1818:\tlearn: 0.0520512\ttotal: 5m 11s\tremaining: 23m 20s\n",
      "1819:\tlearn: 0.0520512\ttotal: 5m 11s\tremaining: 23m 19s\n",
      "1820:\tlearn: 0.0520512\ttotal: 5m 11s\tremaining: 23m 19s\n",
      "1821:\tlearn: 0.0520512\ttotal: 5m 11s\tremaining: 23m 19s\n",
      "1822:\tlearn: 0.0520512\ttotal: 5m 11s\tremaining: 23m 18s\n",
      "1823:\tlearn: 0.0520512\ttotal: 5m 12s\tremaining: 23m 18s\n",
      "1824:\tlearn: 0.0520512\ttotal: 5m 12s\tremaining: 23m 18s\n",
      "1825:\tlearn: 0.0520512\ttotal: 5m 12s\tremaining: 23m 17s\n",
      "1826:\tlearn: 0.0520512\ttotal: 5m 12s\tremaining: 23m 17s\n",
      "1827:\tlearn: 0.0520512\ttotal: 5m 12s\tremaining: 23m 17s\n",
      "1828:\tlearn: 0.0520512\ttotal: 5m 12s\tremaining: 23m 17s\n",
      "1829:\tlearn: 0.0520512\ttotal: 5m 12s\tremaining: 23m 16s\n",
      "1830:\tlearn: 0.0520512\ttotal: 5m 13s\tremaining: 23m 16s\n",
      "1831:\tlearn: 0.0520512\ttotal: 5m 13s\tremaining: 23m 16s\n",
      "1832:\tlearn: 0.0520512\ttotal: 5m 13s\tremaining: 23m 15s\n",
      "1833:\tlearn: 0.0520512\ttotal: 5m 13s\tremaining: 23m 15s\n",
      "1834:\tlearn: 0.0520512\ttotal: 5m 13s\tremaining: 23m 15s\n",
      "1835:\tlearn: 0.0520512\ttotal: 5m 13s\tremaining: 23m 14s\n",
      "1836:\tlearn: 0.0520512\ttotal: 5m 13s\tremaining: 23m 14s\n",
      "1837:\tlearn: 0.0520512\ttotal: 5m 13s\tremaining: 23m 14s\n",
      "1838:\tlearn: 0.0520512\ttotal: 5m 14s\tremaining: 23m 14s\n",
      "1839:\tlearn: 0.0520512\ttotal: 5m 14s\tremaining: 23m 13s\n",
      "1840:\tlearn: 0.0520512\ttotal: 5m 14s\tremaining: 23m 13s\n",
      "1841:\tlearn: 0.0520512\ttotal: 5m 14s\tremaining: 23m 13s\n",
      "1842:\tlearn: 0.0520512\ttotal: 5m 14s\tremaining: 23m 12s\n",
      "1843:\tlearn: 0.0520512\ttotal: 5m 14s\tremaining: 23m 12s\n",
      "1844:\tlearn: 0.0520512\ttotal: 5m 14s\tremaining: 23m 12s\n",
      "1845:\tlearn: 0.0520512\ttotal: 5m 15s\tremaining: 23m 11s\n",
      "1846:\tlearn: 0.0520512\ttotal: 5m 15s\tremaining: 23m 11s\n",
      "1847:\tlearn: 0.0520512\ttotal: 5m 15s\tremaining: 23m 11s\n",
      "1848:\tlearn: 0.0520512\ttotal: 5m 15s\tremaining: 23m 11s\n",
      "1849:\tlearn: 0.0520512\ttotal: 5m 15s\tremaining: 23m 10s\n",
      "1850:\tlearn: 0.0520512\ttotal: 5m 15s\tremaining: 23m 10s\n",
      "1851:\tlearn: 0.0520512\ttotal: 5m 15s\tremaining: 23m 10s\n",
      "1852:\tlearn: 0.0520512\ttotal: 5m 16s\tremaining: 23m 9s\n",
      "1853:\tlearn: 0.0520512\ttotal: 5m 16s\tremaining: 23m 9s\n",
      "1854:\tlearn: 0.0520512\ttotal: 5m 16s\tremaining: 23m 9s\n",
      "1855:\tlearn: 0.0520512\ttotal: 5m 16s\tremaining: 23m 8s\n",
      "1856:\tlearn: 0.0520512\ttotal: 5m 16s\tremaining: 23m 8s\n",
      "1857:\tlearn: 0.0520512\ttotal: 5m 16s\tremaining: 23m 8s\n",
      "1858:\tlearn: 0.0520512\ttotal: 5m 16s\tremaining: 23m 8s\n",
      "1859:\tlearn: 0.0520512\ttotal: 5m 17s\tremaining: 23m 7s\n",
      "1860:\tlearn: 0.0520512\ttotal: 5m 17s\tremaining: 23m 7s\n",
      "1861:\tlearn: 0.0520512\ttotal: 5m 17s\tremaining: 23m 7s\n",
      "1862:\tlearn: 0.0520512\ttotal: 5m 17s\tremaining: 23m 6s\n",
      "1863:\tlearn: 0.0520512\ttotal: 5m 17s\tremaining: 23m 6s\n",
      "1864:\tlearn: 0.0520512\ttotal: 5m 17s\tremaining: 23m 6s\n",
      "1865:\tlearn: 0.0520512\ttotal: 5m 17s\tremaining: 23m 6s\n",
      "1866:\tlearn: 0.0520512\ttotal: 5m 18s\tremaining: 23m 5s\n",
      "1867:\tlearn: 0.0520512\ttotal: 5m 18s\tremaining: 23m 5s\n",
      "1868:\tlearn: 0.0520512\ttotal: 5m 18s\tremaining: 23m 5s\n",
      "1869:\tlearn: 0.0520512\ttotal: 5m 18s\tremaining: 23m 4s\n",
      "1870:\tlearn: 0.0520512\ttotal: 5m 18s\tremaining: 23m 4s\n",
      "1871:\tlearn: 0.0520512\ttotal: 5m 18s\tremaining: 23m 4s\n",
      "1872:\tlearn: 0.0520512\ttotal: 5m 18s\tremaining: 23m 3s\n",
      "1873:\tlearn: 0.0520512\ttotal: 5m 19s\tremaining: 23m 3s\n",
      "1874:\tlearn: 0.0520512\ttotal: 5m 19s\tremaining: 23m 3s\n",
      "1875:\tlearn: 0.0520512\ttotal: 5m 19s\tremaining: 23m 3s\n",
      "1876:\tlearn: 0.0520512\ttotal: 5m 19s\tremaining: 23m 2s\n",
      "1877:\tlearn: 0.0520512\ttotal: 5m 19s\tremaining: 23m 2s\n",
      "1878:\tlearn: 0.0520512\ttotal: 5m 19s\tremaining: 23m 2s\n",
      "1879:\tlearn: 0.0520512\ttotal: 5m 19s\tremaining: 23m 1s\n",
      "1880:\tlearn: 0.0520512\ttotal: 5m 20s\tremaining: 23m 1s\n",
      "1881:\tlearn: 0.0520512\ttotal: 5m 20s\tremaining: 23m 1s\n",
      "1882:\tlearn: 0.0520512\ttotal: 5m 20s\tremaining: 23m 1s\n",
      "1883:\tlearn: 0.0520512\ttotal: 5m 20s\tremaining: 23m\n",
      "1884:\tlearn: 0.0520512\ttotal: 5m 20s\tremaining: 23m\n",
      "1885:\tlearn: 0.0520512\ttotal: 5m 20s\tremaining: 23m\n",
      "1886:\tlearn: 0.0520512\ttotal: 5m 20s\tremaining: 22m 59s\n",
      "1887:\tlearn: 0.0520512\ttotal: 5m 21s\tremaining: 22m 59s\n",
      "1888:\tlearn: 0.0520512\ttotal: 5m 21s\tremaining: 22m 59s\n",
      "1889:\tlearn: 0.0520512\ttotal: 5m 21s\tremaining: 22m 59s\n",
      "1890:\tlearn: 0.0520512\ttotal: 5m 21s\tremaining: 22m 58s\n",
      "1891:\tlearn: 0.0520512\ttotal: 5m 21s\tremaining: 22m 58s\n",
      "1892:\tlearn: 0.0520512\ttotal: 5m 21s\tremaining: 22m 58s\n",
      "1893:\tlearn: 0.0520512\ttotal: 5m 21s\tremaining: 22m 57s\n",
      "1894:\tlearn: 0.0520512\ttotal: 5m 22s\tremaining: 22m 57s\n",
      "1895:\tlearn: 0.0520512\ttotal: 5m 22s\tremaining: 22m 57s\n",
      "1896:\tlearn: 0.0520512\ttotal: 5m 22s\tremaining: 22m 56s\n",
      "1897:\tlearn: 0.0520512\ttotal: 5m 22s\tremaining: 22m 56s\n",
      "1898:\tlearn: 0.0520512\ttotal: 5m 22s\tremaining: 22m 56s\n",
      "1899:\tlearn: 0.0520512\ttotal: 5m 22s\tremaining: 22m 56s\n",
      "1900:\tlearn: 0.0520512\ttotal: 5m 22s\tremaining: 22m 55s\n",
      "1901:\tlearn: 0.0520512\ttotal: 5m 23s\tremaining: 22m 55s\n",
      "1902:\tlearn: 0.0520512\ttotal: 5m 23s\tremaining: 22m 55s\n",
      "1903:\tlearn: 0.0520512\ttotal: 5m 23s\tremaining: 22m 54s\n",
      "1904:\tlearn: 0.0520512\ttotal: 5m 23s\tremaining: 22m 54s\n",
      "1905:\tlearn: 0.0520512\ttotal: 5m 23s\tremaining: 22m 54s\n",
      "1906:\tlearn: 0.0520512\ttotal: 5m 23s\tremaining: 22m 54s\n",
      "1907:\tlearn: 0.0520512\ttotal: 5m 23s\tremaining: 22m 53s\n",
      "1908:\tlearn: 0.0520512\ttotal: 5m 24s\tremaining: 22m 53s\n",
      "1909:\tlearn: 0.0520512\ttotal: 5m 24s\tremaining: 22m 53s\n",
      "1910:\tlearn: 0.0520512\ttotal: 5m 24s\tremaining: 22m 52s\n",
      "1911:\tlearn: 0.0520512\ttotal: 5m 24s\tremaining: 22m 52s\n",
      "1912:\tlearn: 0.0520512\ttotal: 5m 24s\tremaining: 22m 52s\n",
      "1913:\tlearn: 0.0520512\ttotal: 5m 24s\tremaining: 22m 52s\n",
      "1914:\tlearn: 0.0520512\ttotal: 5m 24s\tremaining: 22m 51s\n",
      "1915:\tlearn: 0.0520512\ttotal: 5m 25s\tremaining: 22m 51s\n",
      "1916:\tlearn: 0.0520512\ttotal: 5m 25s\tremaining: 22m 51s\n",
      "1917:\tlearn: 0.0520512\ttotal: 5m 25s\tremaining: 22m 50s\n",
      "1918:\tlearn: 0.0520512\ttotal: 5m 25s\tremaining: 22m 50s\n",
      "1919:\tlearn: 0.0520512\ttotal: 5m 25s\tremaining: 22m 50s\n",
      "1920:\tlearn: 0.0520512\ttotal: 5m 25s\tremaining: 22m 50s\n",
      "1921:\tlearn: 0.0520512\ttotal: 5m 25s\tremaining: 22m 49s\n",
      "1922:\tlearn: 0.0520512\ttotal: 5m 26s\tremaining: 22m 49s\n",
      "1923:\tlearn: 0.0520512\ttotal: 5m 26s\tremaining: 22m 49s\n",
      "1924:\tlearn: 0.0520512\ttotal: 5m 26s\tremaining: 22m 48s\n",
      "1925:\tlearn: 0.0520512\ttotal: 5m 26s\tremaining: 22m 48s\n",
      "1926:\tlearn: 0.0520512\ttotal: 5m 26s\tremaining: 22m 48s\n",
      "1927:\tlearn: 0.0520512\ttotal: 5m 26s\tremaining: 22m 48s\n",
      "1928:\tlearn: 0.0520512\ttotal: 5m 26s\tremaining: 22m 47s\n",
      "1929:\tlearn: 0.0520512\ttotal: 5m 27s\tremaining: 22m 47s\n",
      "1930:\tlearn: 0.0520512\ttotal: 5m 27s\tremaining: 22m 47s\n",
      "1931:\tlearn: 0.0520512\ttotal: 5m 27s\tremaining: 22m 46s\n",
      "1932:\tlearn: 0.0520512\ttotal: 5m 27s\tremaining: 22m 46s\n",
      "1933:\tlearn: 0.0520512\ttotal: 5m 27s\tremaining: 22m 46s\n",
      "1934:\tlearn: 0.0520512\ttotal: 5m 27s\tremaining: 22m 46s\n",
      "1935:\tlearn: 0.0520512\ttotal: 5m 27s\tremaining: 22m 45s\n",
      "1936:\tlearn: 0.0520512\ttotal: 5m 28s\tremaining: 22m 45s\n",
      "1937:\tlearn: 0.0520512\ttotal: 5m 28s\tremaining: 22m 45s\n",
      "1938:\tlearn: 0.0520512\ttotal: 5m 28s\tremaining: 22m 44s\n",
      "1939:\tlearn: 0.0520512\ttotal: 5m 28s\tremaining: 22m 44s\n",
      "1940:\tlearn: 0.0520512\ttotal: 5m 28s\tremaining: 22m 44s\n",
      "1941:\tlearn: 0.0520512\ttotal: 5m 28s\tremaining: 22m 44s\n",
      "1942:\tlearn: 0.0520512\ttotal: 5m 28s\tremaining: 22m 43s\n",
      "1943:\tlearn: 0.0520512\ttotal: 5m 29s\tremaining: 22m 43s\n",
      "1944:\tlearn: 0.0520512\ttotal: 5m 29s\tremaining: 22m 43s\n",
      "1945:\tlearn: 0.0520512\ttotal: 5m 29s\tremaining: 22m 43s\n",
      "1946:\tlearn: 0.0520512\ttotal: 5m 29s\tremaining: 22m 42s\n",
      "1947:\tlearn: 0.0520512\ttotal: 5m 29s\tremaining: 22m 42s\n",
      "1948:\tlearn: 0.0520512\ttotal: 5m 29s\tremaining: 22m 42s\n",
      "1949:\tlearn: 0.0520512\ttotal: 5m 29s\tremaining: 22m 41s\n",
      "1950:\tlearn: 0.0520512\ttotal: 5m 30s\tremaining: 22m 41s\n",
      "1951:\tlearn: 0.0520512\ttotal: 5m 30s\tremaining: 22m 41s\n",
      "1952:\tlearn: 0.0520512\ttotal: 5m 30s\tremaining: 22m 41s\n",
      "1953:\tlearn: 0.0520512\ttotal: 5m 30s\tremaining: 22m 40s\n",
      "1954:\tlearn: 0.0520512\ttotal: 5m 30s\tremaining: 22m 40s\n",
      "1955:\tlearn: 0.0520512\ttotal: 5m 30s\tremaining: 22m 40s\n",
      "1956:\tlearn: 0.0520512\ttotal: 5m 30s\tremaining: 22m 39s\n",
      "1957:\tlearn: 0.0520512\ttotal: 5m 31s\tremaining: 22m 39s\n",
      "1958:\tlearn: 0.0520512\ttotal: 5m 31s\tremaining: 22m 39s\n",
      "1959:\tlearn: 0.0520512\ttotal: 5m 31s\tremaining: 22m 39s\n",
      "1960:\tlearn: 0.0520512\ttotal: 5m 31s\tremaining: 22m 38s\n",
      "1961:\tlearn: 0.0520512\ttotal: 5m 31s\tremaining: 22m 38s\n",
      "1962:\tlearn: 0.0520512\ttotal: 5m 31s\tremaining: 22m 38s\n",
      "1963:\tlearn: 0.0520512\ttotal: 5m 31s\tremaining: 22m 37s\n",
      "1964:\tlearn: 0.0520512\ttotal: 5m 32s\tremaining: 22m 37s\n",
      "1965:\tlearn: 0.0520512\ttotal: 5m 32s\tremaining: 22m 37s\n",
      "1966:\tlearn: 0.0520512\ttotal: 5m 32s\tremaining: 22m 37s\n",
      "1967:\tlearn: 0.0520512\ttotal: 5m 32s\tremaining: 22m 36s\n",
      "1968:\tlearn: 0.0520512\ttotal: 5m 32s\tremaining: 22m 36s\n",
      "1969:\tlearn: 0.0520512\ttotal: 5m 32s\tremaining: 22m 36s\n",
      "1970:\tlearn: 0.0520512\ttotal: 5m 32s\tremaining: 22m 36s\n",
      "1971:\tlearn: 0.0520512\ttotal: 5m 33s\tremaining: 22m 35s\n",
      "1972:\tlearn: 0.0520512\ttotal: 5m 33s\tremaining: 22m 35s\n",
      "1973:\tlearn: 0.0520512\ttotal: 5m 33s\tremaining: 22m 35s\n",
      "1974:\tlearn: 0.0520512\ttotal: 5m 33s\tremaining: 22m 35s\n",
      "1975:\tlearn: 0.0520512\ttotal: 5m 33s\tremaining: 22m 34s\n",
      "1976:\tlearn: 0.0520512\ttotal: 5m 33s\tremaining: 22m 34s\n",
      "1977:\tlearn: 0.0520512\ttotal: 5m 33s\tremaining: 22m 34s\n",
      "1978:\tlearn: 0.0520512\ttotal: 5m 34s\tremaining: 22m 34s\n",
      "1979:\tlearn: 0.0520512\ttotal: 5m 34s\tremaining: 22m 33s\n",
      "1980:\tlearn: 0.0520512\ttotal: 5m 34s\tremaining: 22m 33s\n",
      "1981:\tlearn: 0.0520512\ttotal: 5m 34s\tremaining: 22m 33s\n",
      "1982:\tlearn: 0.0520512\ttotal: 5m 34s\tremaining: 22m 33s\n",
      "1983:\tlearn: 0.0520512\ttotal: 5m 34s\tremaining: 22m 32s\n",
      "1984:\tlearn: 0.0520512\ttotal: 5m 35s\tremaining: 22m 32s\n",
      "1985:\tlearn: 0.0520512\ttotal: 5m 35s\tremaining: 22m 32s\n",
      "1986:\tlearn: 0.0520512\ttotal: 5m 35s\tremaining: 22m 32s\n",
      "1987:\tlearn: 0.0520512\ttotal: 5m 35s\tremaining: 22m 32s\n",
      "1988:\tlearn: 0.0520512\ttotal: 5m 35s\tremaining: 22m 31s\n",
      "1989:\tlearn: 0.0520512\ttotal: 5m 35s\tremaining: 22m 31s\n",
      "1990:\tlearn: 0.0520512\ttotal: 5m 35s\tremaining: 22m 31s\n",
      "1991:\tlearn: 0.0520512\ttotal: 5m 36s\tremaining: 22m 31s\n",
      "1992:\tlearn: 0.0520512\ttotal: 5m 36s\tremaining: 22m 31s\n",
      "1993:\tlearn: 0.0520512\ttotal: 5m 36s\tremaining: 22m 30s\n",
      "1994:\tlearn: 0.0520512\ttotal: 5m 36s\tremaining: 22m 30s\n",
      "1995:\tlearn: 0.0520512\ttotal: 5m 36s\tremaining: 22m 30s\n",
      "1996:\tlearn: 0.0520512\ttotal: 5m 36s\tremaining: 22m 30s\n",
      "1997:\tlearn: 0.0520512\ttotal: 5m 37s\tremaining: 22m 29s\n",
      "1998:\tlearn: 0.0520512\ttotal: 5m 37s\tremaining: 22m 29s\n",
      "1999:\tlearn: 0.0520512\ttotal: 5m 37s\tremaining: 22m 29s\n",
      "2000:\tlearn: 0.0520512\ttotal: 5m 37s\tremaining: 22m 29s\n",
      "2001:\tlearn: 0.0520512\ttotal: 5m 37s\tremaining: 22m 28s\n",
      "2002:\tlearn: 0.0520512\ttotal: 5m 37s\tremaining: 22m 28s\n",
      "2003:\tlearn: 0.0520512\ttotal: 5m 37s\tremaining: 22m 28s\n",
      "2004:\tlearn: 0.0520512\ttotal: 5m 38s\tremaining: 22m 28s\n",
      "2005:\tlearn: 0.0520512\ttotal: 5m 38s\tremaining: 22m 27s\n",
      "2006:\tlearn: 0.0520512\ttotal: 5m 38s\tremaining: 22m 27s\n",
      "2007:\tlearn: 0.0520512\ttotal: 5m 38s\tremaining: 22m 27s\n",
      "2008:\tlearn: 0.0520512\ttotal: 5m 38s\tremaining: 22m 26s\n",
      "2009:\tlearn: 0.0520512\ttotal: 5m 38s\tremaining: 22m 26s\n",
      "2010:\tlearn: 0.0520512\ttotal: 5m 38s\tremaining: 22m 26s\n",
      "2011:\tlearn: 0.0520512\ttotal: 5m 39s\tremaining: 22m 26s\n",
      "2012:\tlearn: 0.0520512\ttotal: 5m 39s\tremaining: 22m 26s\n",
      "2013:\tlearn: 0.0520512\ttotal: 5m 39s\tremaining: 22m 25s\n",
      "2014:\tlearn: 0.0520512\ttotal: 5m 39s\tremaining: 22m 25s\n",
      "2015:\tlearn: 0.0520512\ttotal: 5m 39s\tremaining: 22m 25s\n",
      "2016:\tlearn: 0.0520512\ttotal: 5m 39s\tremaining: 22m 25s\n",
      "2017:\tlearn: 0.0520512\ttotal: 5m 40s\tremaining: 22m 25s\n",
      "2018:\tlearn: 0.0520512\ttotal: 5m 40s\tremaining: 22m 25s\n",
      "2019:\tlearn: 0.0520512\ttotal: 5m 40s\tremaining: 22m 24s\n",
      "2020:\tlearn: 0.0520512\ttotal: 5m 40s\tremaining: 22m 24s\n",
      "2021:\tlearn: 0.0520512\ttotal: 5m 40s\tremaining: 22m 24s\n",
      "2022:\tlearn: 0.0520512\ttotal: 5m 40s\tremaining: 22m 24s\n",
      "2023:\tlearn: 0.0520512\ttotal: 5m 40s\tremaining: 22m 23s\n",
      "2024:\tlearn: 0.0520512\ttotal: 5m 41s\tremaining: 22m 23s\n",
      "2025:\tlearn: 0.0520512\ttotal: 5m 41s\tremaining: 22m 23s\n",
      "2026:\tlearn: 0.0520512\ttotal: 5m 41s\tremaining: 22m 22s\n",
      "2027:\tlearn: 0.0520512\ttotal: 5m 41s\tremaining: 22m 22s\n",
      "2028:\tlearn: 0.0520512\ttotal: 5m 41s\tremaining: 22m 22s\n",
      "2029:\tlearn: 0.0520512\ttotal: 5m 41s\tremaining: 22m 22s\n",
      "2030:\tlearn: 0.0520512\ttotal: 5m 41s\tremaining: 22m 21s\n",
      "2031:\tlearn: 0.0520512\ttotal: 5m 42s\tremaining: 22m 21s\n",
      "2032:\tlearn: 0.0520512\ttotal: 5m 42s\tremaining: 22m 21s\n",
      "2033:\tlearn: 0.0520512\ttotal: 5m 42s\tremaining: 22m 21s\n",
      "2034:\tlearn: 0.0520512\ttotal: 5m 42s\tremaining: 22m 20s\n",
      "2035:\tlearn: 0.0520512\ttotal: 5m 42s\tremaining: 22m 20s\n",
      "2036:\tlearn: 0.0520512\ttotal: 5m 42s\tremaining: 22m 20s\n",
      "2037:\tlearn: 0.0520512\ttotal: 5m 42s\tremaining: 22m 19s\n",
      "2038:\tlearn: 0.0520512\ttotal: 5m 43s\tremaining: 22m 19s\n",
      "2039:\tlearn: 0.0520512\ttotal: 5m 43s\tremaining: 22m 19s\n",
      "2040:\tlearn: 0.0520512\ttotal: 5m 43s\tremaining: 22m 19s\n",
      "2041:\tlearn: 0.0520512\ttotal: 5m 43s\tremaining: 22m 19s\n",
      "2042:\tlearn: 0.0520512\ttotal: 5m 43s\tremaining: 22m 18s\n",
      "2043:\tlearn: 0.0520512\ttotal: 5m 43s\tremaining: 22m 18s\n",
      "2044:\tlearn: 0.0520512\ttotal: 5m 44s\tremaining: 22m 18s\n",
      "2045:\tlearn: 0.0520512\ttotal: 5m 44s\tremaining: 22m 17s\n",
      "2046:\tlearn: 0.0520512\ttotal: 5m 44s\tremaining: 22m 17s\n",
      "2047:\tlearn: 0.0520512\ttotal: 5m 44s\tremaining: 22m 17s\n",
      "2048:\tlearn: 0.0520512\ttotal: 5m 44s\tremaining: 22m 17s\n",
      "2049:\tlearn: 0.0520512\ttotal: 5m 44s\tremaining: 22m 17s\n",
      "2050:\tlearn: 0.0520512\ttotal: 5m 44s\tremaining: 22m 16s\n",
      "2051:\tlearn: 0.0520512\ttotal: 5m 45s\tremaining: 22m 16s\n",
      "2052:\tlearn: 0.0520512\ttotal: 5m 45s\tremaining: 22m 16s\n",
      "2053:\tlearn: 0.0520512\ttotal: 5m 45s\tremaining: 22m 16s\n",
      "2054:\tlearn: 0.0520512\ttotal: 5m 45s\tremaining: 22m 16s\n",
      "2055:\tlearn: 0.0520512\ttotal: 5m 45s\tremaining: 22m 15s\n",
      "2056:\tlearn: 0.0520512\ttotal: 5m 45s\tremaining: 22m 15s\n",
      "2057:\tlearn: 0.0520512\ttotal: 5m 46s\tremaining: 22m 15s\n",
      "2058:\tlearn: 0.0520512\ttotal: 5m 46s\tremaining: 22m 15s\n",
      "2059:\tlearn: 0.0520512\ttotal: 5m 46s\tremaining: 22m 15s\n",
      "2060:\tlearn: 0.0520512\ttotal: 5m 46s\tremaining: 22m 14s\n",
      "2061:\tlearn: 0.0520512\ttotal: 5m 46s\tremaining: 22m 14s\n",
      "2062:\tlearn: 0.0520512\ttotal: 5m 46s\tremaining: 22m 14s\n",
      "2063:\tlearn: 0.0520512\ttotal: 5m 46s\tremaining: 22m 14s\n",
      "2064:\tlearn: 0.0520512\ttotal: 5m 47s\tremaining: 22m 13s\n",
      "2065:\tlearn: 0.0520512\ttotal: 5m 47s\tremaining: 22m 13s\n",
      "2066:\tlearn: 0.0520512\ttotal: 5m 47s\tremaining: 22m 13s\n",
      "2067:\tlearn: 0.0520512\ttotal: 5m 47s\tremaining: 22m 13s\n",
      "2068:\tlearn: 0.0520512\ttotal: 5m 47s\tremaining: 22m 12s\n",
      "2069:\tlearn: 0.0520512\ttotal: 5m 47s\tremaining: 22m 12s\n",
      "2070:\tlearn: 0.0520512\ttotal: 5m 47s\tremaining: 22m 12s\n",
      "2071:\tlearn: 0.0520512\ttotal: 5m 48s\tremaining: 22m 12s\n",
      "2072:\tlearn: 0.0520512\ttotal: 5m 48s\tremaining: 22m 11s\n",
      "2073:\tlearn: 0.0520512\ttotal: 5m 48s\tremaining: 22m 11s\n",
      "2074:\tlearn: 0.0520512\ttotal: 5m 48s\tremaining: 22m 11s\n",
      "2075:\tlearn: 0.0520512\ttotal: 5m 48s\tremaining: 22m 11s\n",
      "2076:\tlearn: 0.0520512\ttotal: 5m 48s\tremaining: 22m 10s\n",
      "2077:\tlearn: 0.0520512\ttotal: 5m 49s\tremaining: 22m 10s\n",
      "2078:\tlearn: 0.0520512\ttotal: 5m 49s\tremaining: 22m 10s\n",
      "2079:\tlearn: 0.0520512\ttotal: 5m 49s\tremaining: 22m 10s\n",
      "2080:\tlearn: 0.0520512\ttotal: 5m 49s\tremaining: 22m 10s\n",
      "2081:\tlearn: 0.0520512\ttotal: 5m 49s\tremaining: 22m 9s\n",
      "2082:\tlearn: 0.0520512\ttotal: 5m 49s\tremaining: 22m 9s\n",
      "2083:\tlearn: 0.0520512\ttotal: 5m 49s\tremaining: 22m 9s\n",
      "2084:\tlearn: 0.0520512\ttotal: 5m 50s\tremaining: 22m 9s\n",
      "2085:\tlearn: 0.0520512\ttotal: 5m 50s\tremaining: 22m 8s\n",
      "2086:\tlearn: 0.0520512\ttotal: 5m 50s\tremaining: 22m 8s\n",
      "2087:\tlearn: 0.0520512\ttotal: 5m 50s\tremaining: 22m 8s\n",
      "2088:\tlearn: 0.0520512\ttotal: 5m 50s\tremaining: 22m 8s\n",
      "2089:\tlearn: 0.0520512\ttotal: 5m 50s\tremaining: 22m 7s\n",
      "2090:\tlearn: 0.0520512\ttotal: 5m 51s\tremaining: 22m 7s\n",
      "2091:\tlearn: 0.0520512\ttotal: 5m 51s\tremaining: 22m 7s\n",
      "2092:\tlearn: 0.0520512\ttotal: 5m 51s\tremaining: 22m 7s\n",
      "2093:\tlearn: 0.0520512\ttotal: 5m 51s\tremaining: 22m 7s\n",
      "2094:\tlearn: 0.0520512\ttotal: 5m 51s\tremaining: 22m 6s\n",
      "2095:\tlearn: 0.0520512\ttotal: 5m 51s\tremaining: 22m 6s\n",
      "2096:\tlearn: 0.0520512\ttotal: 5m 51s\tremaining: 22m 6s\n",
      "2097:\tlearn: 0.0520512\ttotal: 5m 52s\tremaining: 22m 6s\n",
      "2098:\tlearn: 0.0520512\ttotal: 5m 52s\tremaining: 22m 5s\n",
      "2099:\tlearn: 0.0520512\ttotal: 5m 52s\tremaining: 22m 5s\n",
      "2100:\tlearn: 0.0520512\ttotal: 5m 52s\tremaining: 22m 5s\n",
      "2101:\tlearn: 0.0520512\ttotal: 5m 52s\tremaining: 22m 5s\n",
      "2102:\tlearn: 0.0520512\ttotal: 5m 52s\tremaining: 22m 4s\n",
      "2103:\tlearn: 0.0520512\ttotal: 5m 52s\tremaining: 22m 4s\n",
      "2104:\tlearn: 0.0520512\ttotal: 5m 53s\tremaining: 22m 4s\n",
      "2105:\tlearn: 0.0520512\ttotal: 5m 53s\tremaining: 22m 4s\n",
      "2106:\tlearn: 0.0520512\ttotal: 5m 53s\tremaining: 22m 3s\n",
      "2107:\tlearn: 0.0520512\ttotal: 5m 53s\tremaining: 22m 3s\n",
      "2108:\tlearn: 0.0520512\ttotal: 5m 53s\tremaining: 22m 3s\n",
      "2109:\tlearn: 0.0520512\ttotal: 5m 53s\tremaining: 22m 3s\n",
      "2110:\tlearn: 0.0520512\ttotal: 5m 54s\tremaining: 22m 3s\n",
      "2111:\tlearn: 0.0520512\ttotal: 5m 54s\tremaining: 22m 3s\n",
      "2112:\tlearn: 0.0520512\ttotal: 5m 54s\tremaining: 22m 2s\n",
      "2113:\tlearn: 0.0520512\ttotal: 5m 54s\tremaining: 22m 2s\n",
      "2114:\tlearn: 0.0520512\ttotal: 5m 54s\tremaining: 22m 2s\n",
      "2115:\tlearn: 0.0520512\ttotal: 5m 54s\tremaining: 22m 2s\n",
      "2116:\tlearn: 0.0520512\ttotal: 5m 55s\tremaining: 22m 2s\n",
      "2117:\tlearn: 0.0520512\ttotal: 5m 55s\tremaining: 22m 1s\n",
      "2118:\tlearn: 0.0520512\ttotal: 5m 55s\tremaining: 22m 1s\n",
      "2119:\tlearn: 0.0520512\ttotal: 5m 55s\tremaining: 22m 1s\n",
      "2120:\tlearn: 0.0520512\ttotal: 5m 55s\tremaining: 22m\n",
      "2121:\tlearn: 0.0520512\ttotal: 5m 55s\tremaining: 22m\n",
      "2122:\tlearn: 0.0520512\ttotal: 5m 55s\tremaining: 22m\n",
      "2123:\tlearn: 0.0520512\ttotal: 5m 56s\tremaining: 22m\n",
      "2124:\tlearn: 0.0520512\ttotal: 5m 56s\tremaining: 21m 59s\n",
      "2125:\tlearn: 0.0520512\ttotal: 5m 56s\tremaining: 21m 59s\n",
      "2126:\tlearn: 0.0520512\ttotal: 5m 56s\tremaining: 21m 59s\n",
      "2127:\tlearn: 0.0520512\ttotal: 5m 56s\tremaining: 21m 59s\n",
      "2128:\tlearn: 0.0520512\ttotal: 5m 56s\tremaining: 21m 58s\n",
      "2129:\tlearn: 0.0520512\ttotal: 5m 56s\tremaining: 21m 58s\n",
      "2130:\tlearn: 0.0520512\ttotal: 5m 57s\tremaining: 21m 58s\n",
      "2131:\tlearn: 0.0520512\ttotal: 5m 57s\tremaining: 21m 58s\n",
      "2132:\tlearn: 0.0520512\ttotal: 5m 57s\tremaining: 21m 57s\n",
      "2133:\tlearn: 0.0520512\ttotal: 5m 57s\tremaining: 21m 57s\n",
      "2134:\tlearn: 0.0520512\ttotal: 5m 57s\tremaining: 21m 57s\n",
      "2135:\tlearn: 0.0520512\ttotal: 5m 57s\tremaining: 21m 57s\n",
      "2136:\tlearn: 0.0520512\ttotal: 5m 57s\tremaining: 21m 56s\n",
      "2137:\tlearn: 0.0520512\ttotal: 5m 58s\tremaining: 21m 56s\n",
      "2138:\tlearn: 0.0520512\ttotal: 5m 58s\tremaining: 21m 56s\n",
      "2139:\tlearn: 0.0520512\ttotal: 5m 58s\tremaining: 21m 56s\n",
      "2140:\tlearn: 0.0520512\ttotal: 5m 58s\tremaining: 21m 55s\n",
      "2141:\tlearn: 0.0520512\ttotal: 5m 58s\tremaining: 21m 55s\n",
      "2142:\tlearn: 0.0520512\ttotal: 5m 58s\tremaining: 21m 55s\n",
      "2143:\tlearn: 0.0520512\ttotal: 5m 58s\tremaining: 21m 55s\n",
      "2144:\tlearn: 0.0520512\ttotal: 5m 59s\tremaining: 21m 54s\n",
      "2145:\tlearn: 0.0520512\ttotal: 5m 59s\tremaining: 21m 54s\n",
      "2146:\tlearn: 0.0520512\ttotal: 5m 59s\tremaining: 21m 54s\n",
      "2147:\tlearn: 0.0520512\ttotal: 5m 59s\tremaining: 21m 54s\n",
      "2148:\tlearn: 0.0520512\ttotal: 5m 59s\tremaining: 21m 54s\n",
      "2149:\tlearn: 0.0520512\ttotal: 5m 59s\tremaining: 21m 53s\n",
      "2150:\tlearn: 0.0520512\ttotal: 5m 59s\tremaining: 21m 53s\n",
      "2151:\tlearn: 0.0520512\ttotal: 6m\tremaining: 21m 53s\n",
      "2152:\tlearn: 0.0520512\ttotal: 6m\tremaining: 21m 53s\n",
      "2153:\tlearn: 0.0520512\ttotal: 6m\tremaining: 21m 52s\n",
      "2154:\tlearn: 0.0520512\ttotal: 6m\tremaining: 21m 52s\n",
      "2155:\tlearn: 0.0520512\ttotal: 6m\tremaining: 21m 52s\n",
      "2156:\tlearn: 0.0520512\ttotal: 6m\tremaining: 21m 52s\n",
      "2157:\tlearn: 0.0520512\ttotal: 6m 1s\tremaining: 21m 51s\n",
      "2158:\tlearn: 0.0520512\ttotal: 6m 1s\tremaining: 21m 51s\n",
      "2159:\tlearn: 0.0520512\ttotal: 6m 1s\tremaining: 21m 51s\n",
      "2160:\tlearn: 0.0520512\ttotal: 6m 1s\tremaining: 21m 51s\n",
      "2161:\tlearn: 0.0520512\ttotal: 6m 1s\tremaining: 21m 50s\n",
      "2162:\tlearn: 0.0520512\ttotal: 6m 1s\tremaining: 21m 50s\n",
      "2163:\tlearn: 0.0520512\ttotal: 6m 1s\tremaining: 21m 50s\n",
      "2164:\tlearn: 0.0520512\ttotal: 6m 2s\tremaining: 21m 50s\n",
      "2165:\tlearn: 0.0520512\ttotal: 6m 2s\tremaining: 21m 50s\n",
      "2166:\tlearn: 0.0520512\ttotal: 6m 2s\tremaining: 21m 49s\n",
      "2167:\tlearn: 0.0520512\ttotal: 6m 2s\tremaining: 21m 49s\n",
      "2168:\tlearn: 0.0520512\ttotal: 6m 2s\tremaining: 21m 49s\n",
      "2169:\tlearn: 0.0520512\ttotal: 6m 2s\tremaining: 21m 49s\n",
      "2170:\tlearn: 0.0520512\ttotal: 6m 2s\tremaining: 21m 48s\n",
      "2171:\tlearn: 0.0520512\ttotal: 6m 3s\tremaining: 21m 48s\n",
      "2172:\tlearn: 0.0520512\ttotal: 6m 3s\tremaining: 21m 48s\n",
      "2173:\tlearn: 0.0520512\ttotal: 6m 3s\tremaining: 21m 48s\n",
      "2174:\tlearn: 0.0520512\ttotal: 6m 3s\tremaining: 21m 47s\n",
      "2175:\tlearn: 0.0520512\ttotal: 6m 3s\tremaining: 21m 47s\n",
      "2176:\tlearn: 0.0520512\ttotal: 6m 3s\tremaining: 21m 47s\n",
      "2177:\tlearn: 0.0520512\ttotal: 6m 4s\tremaining: 21m 47s\n",
      "2178:\tlearn: 0.0520512\ttotal: 6m 4s\tremaining: 21m 47s\n",
      "2179:\tlearn: 0.0520512\ttotal: 6m 4s\tremaining: 21m 46s\n",
      "2180:\tlearn: 0.0520512\ttotal: 6m 4s\tremaining: 21m 46s\n",
      "2181:\tlearn: 0.0520512\ttotal: 6m 4s\tremaining: 21m 46s\n",
      "2182:\tlearn: 0.0520512\ttotal: 6m 4s\tremaining: 21m 46s\n",
      "2183:\tlearn: 0.0520512\ttotal: 6m 4s\tremaining: 21m 46s\n",
      "2184:\tlearn: 0.0520512\ttotal: 6m 5s\tremaining: 21m 45s\n",
      "2185:\tlearn: 0.0520512\ttotal: 6m 5s\tremaining: 21m 45s\n",
      "2186:\tlearn: 0.0520512\ttotal: 6m 5s\tremaining: 21m 45s\n",
      "2187:\tlearn: 0.0520512\ttotal: 6m 5s\tremaining: 21m 45s\n",
      "2188:\tlearn: 0.0520512\ttotal: 6m 5s\tremaining: 21m 45s\n",
      "2189:\tlearn: 0.0520512\ttotal: 6m 5s\tremaining: 21m 44s\n",
      "2190:\tlearn: 0.0520512\ttotal: 6m 6s\tremaining: 21m 44s\n",
      "2191:\tlearn: 0.0520512\ttotal: 6m 6s\tremaining: 21m 44s\n",
      "2192:\tlearn: 0.0520512\ttotal: 6m 6s\tremaining: 21m 44s\n",
      "2193:\tlearn: 0.0520512\ttotal: 6m 6s\tremaining: 21m 43s\n",
      "2194:\tlearn: 0.0520512\ttotal: 6m 6s\tremaining: 21m 43s\n",
      "2195:\tlearn: 0.0520512\ttotal: 6m 6s\tremaining: 21m 43s\n",
      "2196:\tlearn: 0.0520512\ttotal: 6m 6s\tremaining: 21m 43s\n",
      "2197:\tlearn: 0.0520512\ttotal: 6m 7s\tremaining: 21m 42s\n",
      "2198:\tlearn: 0.0520512\ttotal: 6m 7s\tremaining: 21m 42s\n",
      "2199:\tlearn: 0.0520512\ttotal: 6m 7s\tremaining: 21m 42s\n",
      "2200:\tlearn: 0.0520512\ttotal: 6m 7s\tremaining: 21m 42s\n",
      "2201:\tlearn: 0.0520512\ttotal: 6m 7s\tremaining: 21m 41s\n",
      "2202:\tlearn: 0.0520512\ttotal: 6m 7s\tremaining: 21m 41s\n",
      "2203:\tlearn: 0.0520512\ttotal: 6m 7s\tremaining: 21m 41s\n",
      "2204:\tlearn: 0.0520512\ttotal: 6m 8s\tremaining: 21m 41s\n",
      "2205:\tlearn: 0.0520512\ttotal: 6m 8s\tremaining: 21m 40s\n",
      "2206:\tlearn: 0.0520512\ttotal: 6m 8s\tremaining: 21m 40s\n",
      "2207:\tlearn: 0.0520512\ttotal: 6m 8s\tremaining: 21m 40s\n",
      "2208:\tlearn: 0.0520512\ttotal: 6m 8s\tremaining: 21m 40s\n",
      "2209:\tlearn: 0.0520512\ttotal: 6m 8s\tremaining: 21m 39s\n",
      "2210:\tlearn: 0.0520512\ttotal: 6m 8s\tremaining: 21m 39s\n",
      "2211:\tlearn: 0.0520512\ttotal: 6m 9s\tremaining: 21m 39s\n",
      "2212:\tlearn: 0.0520512\ttotal: 6m 9s\tremaining: 21m 39s\n",
      "2213:\tlearn: 0.0520512\ttotal: 6m 9s\tremaining: 21m 38s\n",
      "2214:\tlearn: 0.0520512\ttotal: 6m 9s\tremaining: 21m 38s\n",
      "2215:\tlearn: 0.0520512\ttotal: 6m 9s\tremaining: 21m 38s\n",
      "2216:\tlearn: 0.0520512\ttotal: 6m 9s\tremaining: 21m 38s\n",
      "2217:\tlearn: 0.0520512\ttotal: 6m 9s\tremaining: 21m 38s\n",
      "2218:\tlearn: 0.0520512\ttotal: 6m 10s\tremaining: 21m 37s\n",
      "2219:\tlearn: 0.0520512\ttotal: 6m 10s\tremaining: 21m 37s\n",
      "2220:\tlearn: 0.0520512\ttotal: 6m 10s\tremaining: 21m 37s\n",
      "2221:\tlearn: 0.0520512\ttotal: 6m 10s\tremaining: 21m 37s\n",
      "2222:\tlearn: 0.0520512\ttotal: 6m 10s\tremaining: 21m 37s\n",
      "2223:\tlearn: 0.0520512\ttotal: 6m 10s\tremaining: 21m 36s\n",
      "2224:\tlearn: 0.0520512\ttotal: 6m 11s\tremaining: 21m 36s\n",
      "2225:\tlearn: 0.0520512\ttotal: 6m 11s\tremaining: 21m 36s\n",
      "2226:\tlearn: 0.0520512\ttotal: 6m 11s\tremaining: 21m 36s\n",
      "2227:\tlearn: 0.0520512\ttotal: 6m 11s\tremaining: 21m 36s\n",
      "2228:\tlearn: 0.0520512\ttotal: 6m 11s\tremaining: 21m 35s\n",
      "2229:\tlearn: 0.0520512\ttotal: 6m 11s\tremaining: 21m 35s\n",
      "2230:\tlearn: 0.0520512\ttotal: 6m 11s\tremaining: 21m 35s\n",
      "2231:\tlearn: 0.0520512\ttotal: 6m 12s\tremaining: 21m 35s\n",
      "2232:\tlearn: 0.0520512\ttotal: 6m 12s\tremaining: 21m 34s\n",
      "2233:\tlearn: 0.0520512\ttotal: 6m 12s\tremaining: 21m 34s\n",
      "2234:\tlearn: 0.0520512\ttotal: 6m 12s\tremaining: 21m 34s\n",
      "2235:\tlearn: 0.0520512\ttotal: 6m 12s\tremaining: 21m 34s\n",
      "2236:\tlearn: 0.0520512\ttotal: 6m 12s\tremaining: 21m 34s\n",
      "2237:\tlearn: 0.0520512\ttotal: 6m 13s\tremaining: 21m 33s\n",
      "2238:\tlearn: 0.0520512\ttotal: 6m 13s\tremaining: 21m 33s\n",
      "2239:\tlearn: 0.0520512\ttotal: 6m 13s\tremaining: 21m 33s\n",
      "2240:\tlearn: 0.0520512\ttotal: 6m 13s\tremaining: 21m 33s\n",
      "2241:\tlearn: 0.0520512\ttotal: 6m 13s\tremaining: 21m 32s\n",
      "2242:\tlearn: 0.0520512\ttotal: 6m 13s\tremaining: 21m 32s\n",
      "2243:\tlearn: 0.0520512\ttotal: 6m 13s\tremaining: 21m 32s\n",
      "2244:\tlearn: 0.0520512\ttotal: 6m 14s\tremaining: 21m 32s\n",
      "2245:\tlearn: 0.0520512\ttotal: 6m 14s\tremaining: 21m 32s\n",
      "2246:\tlearn: 0.0520512\ttotal: 6m 14s\tremaining: 21m 31s\n",
      "2247:\tlearn: 0.0520512\ttotal: 6m 14s\tremaining: 21m 31s\n",
      "2248:\tlearn: 0.0520512\ttotal: 6m 14s\tremaining: 21m 31s\n",
      "2249:\tlearn: 0.0520512\ttotal: 6m 14s\tremaining: 21m 31s\n",
      "2250:\tlearn: 0.0520512\ttotal: 6m 15s\tremaining: 21m 31s\n",
      "2251:\tlearn: 0.0520512\ttotal: 6m 15s\tremaining: 21m 30s\n",
      "2252:\tlearn: 0.0520512\ttotal: 6m 15s\tremaining: 21m 30s\n",
      "2253:\tlearn: 0.0520512\ttotal: 6m 15s\tremaining: 21m 30s\n",
      "2254:\tlearn: 0.0520512\ttotal: 6m 15s\tremaining: 21m 30s\n",
      "2255:\tlearn: 0.0520512\ttotal: 6m 15s\tremaining: 21m 29s\n",
      "2256:\tlearn: 0.0520512\ttotal: 6m 15s\tremaining: 21m 29s\n",
      "2257:\tlearn: 0.0520512\ttotal: 6m 16s\tremaining: 21m 29s\n",
      "2258:\tlearn: 0.0520512\ttotal: 6m 16s\tremaining: 21m 29s\n",
      "2259:\tlearn: 0.0520512\ttotal: 6m 16s\tremaining: 21m 29s\n",
      "2260:\tlearn: 0.0520512\ttotal: 6m 16s\tremaining: 21m 28s\n",
      "2261:\tlearn: 0.0520512\ttotal: 6m 16s\tremaining: 21m 28s\n",
      "2262:\tlearn: 0.0520512\ttotal: 6m 16s\tremaining: 21m 28s\n",
      "2263:\tlearn: 0.0520512\ttotal: 6m 17s\tremaining: 21m 28s\n",
      "2264:\tlearn: 0.0520512\ttotal: 6m 17s\tremaining: 21m 28s\n",
      "2265:\tlearn: 0.0520512\ttotal: 6m 17s\tremaining: 21m 28s\n",
      "2266:\tlearn: 0.0520512\ttotal: 6m 17s\tremaining: 21m 27s\n",
      "2267:\tlearn: 0.0520512\ttotal: 6m 17s\tremaining: 21m 27s\n",
      "2268:\tlearn: 0.0520512\ttotal: 6m 17s\tremaining: 21m 27s\n",
      "2269:\tlearn: 0.0520512\ttotal: 6m 17s\tremaining: 21m 27s\n",
      "2270:\tlearn: 0.0520512\ttotal: 6m 18s\tremaining: 21m 26s\n",
      "2271:\tlearn: 0.0520512\ttotal: 6m 18s\tremaining: 21m 26s\n",
      "2272:\tlearn: 0.0520512\ttotal: 6m 18s\tremaining: 21m 26s\n",
      "2273:\tlearn: 0.0520512\ttotal: 6m 18s\tremaining: 21m 26s\n",
      "2274:\tlearn: 0.0520512\ttotal: 6m 18s\tremaining: 21m 25s\n",
      "2275:\tlearn: 0.0520512\ttotal: 6m 18s\tremaining: 21m 25s\n",
      "2276:\tlearn: 0.0520512\ttotal: 6m 19s\tremaining: 21m 25s\n",
      "2277:\tlearn: 0.0520512\ttotal: 6m 19s\tremaining: 21m 25s\n",
      "2278:\tlearn: 0.0520512\ttotal: 6m 19s\tremaining: 21m 24s\n",
      "2279:\tlearn: 0.0520512\ttotal: 6m 19s\tremaining: 21m 24s\n",
      "2280:\tlearn: 0.0520512\ttotal: 6m 19s\tremaining: 21m 24s\n",
      "2281:\tlearn: 0.0520512\ttotal: 6m 19s\tremaining: 21m 24s\n",
      "2282:\tlearn: 0.0520512\ttotal: 6m 19s\tremaining: 21m 24s\n",
      "2283:\tlearn: 0.0520512\ttotal: 6m 20s\tremaining: 21m 23s\n",
      "2284:\tlearn: 0.0520512\ttotal: 6m 20s\tremaining: 21m 23s\n",
      "2285:\tlearn: 0.0520512\ttotal: 6m 20s\tremaining: 21m 23s\n",
      "2286:\tlearn: 0.0520512\ttotal: 6m 20s\tremaining: 21m 23s\n",
      "2287:\tlearn: 0.0520512\ttotal: 6m 20s\tremaining: 21m 22s\n",
      "2288:\tlearn: 0.0520512\ttotal: 6m 20s\tremaining: 21m 22s\n",
      "2289:\tlearn: 0.0520512\ttotal: 6m 20s\tremaining: 21m 22s\n",
      "2290:\tlearn: 0.0520512\ttotal: 6m 21s\tremaining: 21m 22s\n",
      "2291:\tlearn: 0.0520512\ttotal: 6m 21s\tremaining: 21m 21s\n",
      "2292:\tlearn: 0.0520512\ttotal: 6m 21s\tremaining: 21m 21s\n",
      "2293:\tlearn: 0.0520512\ttotal: 6m 21s\tremaining: 21m 21s\n",
      "2294:\tlearn: 0.0520512\ttotal: 6m 21s\tremaining: 21m 21s\n",
      "2295:\tlearn: 0.0520512\ttotal: 6m 21s\tremaining: 21m 21s\n",
      "2296:\tlearn: 0.0520512\ttotal: 6m 21s\tremaining: 21m 20s\n",
      "2297:\tlearn: 0.0520512\ttotal: 6m 22s\tremaining: 21m 20s\n",
      "2298:\tlearn: 0.0520512\ttotal: 6m 22s\tremaining: 21m 20s\n",
      "2299:\tlearn: 0.0520512\ttotal: 6m 22s\tremaining: 21m 20s\n",
      "2300:\tlearn: 0.0520512\ttotal: 6m 22s\tremaining: 21m 20s\n",
      "2301:\tlearn: 0.0520512\ttotal: 6m 22s\tremaining: 21m 19s\n",
      "2302:\tlearn: 0.0520512\ttotal: 6m 22s\tremaining: 21m 19s\n",
      "2303:\tlearn: 0.0520512\ttotal: 6m 23s\tremaining: 21m 19s\n",
      "2304:\tlearn: 0.0520512\ttotal: 6m 23s\tremaining: 21m 19s\n",
      "2305:\tlearn: 0.0520512\ttotal: 6m 23s\tremaining: 21m 19s\n",
      "2306:\tlearn: 0.0520512\ttotal: 6m 23s\tremaining: 21m 18s\n",
      "2307:\tlearn: 0.0520512\ttotal: 6m 23s\tremaining: 21m 18s\n",
      "2308:\tlearn: 0.0520512\ttotal: 6m 23s\tremaining: 21m 18s\n",
      "2309:\tlearn: 0.0520512\ttotal: 6m 23s\tremaining: 21m 18s\n",
      "2310:\tlearn: 0.0520512\ttotal: 6m 24s\tremaining: 21m 17s\n",
      "2311:\tlearn: 0.0520512\ttotal: 6m 24s\tremaining: 21m 17s\n",
      "2312:\tlearn: 0.0520512\ttotal: 6m 24s\tremaining: 21m 17s\n",
      "2313:\tlearn: 0.0520512\ttotal: 6m 24s\tremaining: 21m 17s\n",
      "2314:\tlearn: 0.0520512\ttotal: 6m 24s\tremaining: 21m 17s\n",
      "2315:\tlearn: 0.0520512\ttotal: 6m 24s\tremaining: 21m 16s\n",
      "2316:\tlearn: 0.0520512\ttotal: 6m 24s\tremaining: 21m 16s\n",
      "2317:\tlearn: 0.0520512\ttotal: 6m 25s\tremaining: 21m 16s\n",
      "2318:\tlearn: 0.0520512\ttotal: 6m 25s\tremaining: 21m 16s\n",
      "2319:\tlearn: 0.0520512\ttotal: 6m 25s\tremaining: 21m 15s\n",
      "2320:\tlearn: 0.0520512\ttotal: 6m 25s\tremaining: 21m 15s\n",
      "2321:\tlearn: 0.0520512\ttotal: 6m 25s\tremaining: 21m 15s\n",
      "2322:\tlearn: 0.0520512\ttotal: 6m 25s\tremaining: 21m 15s\n",
      "2323:\tlearn: 0.0520512\ttotal: 6m 26s\tremaining: 21m 15s\n",
      "2324:\tlearn: 0.0520512\ttotal: 6m 26s\tremaining: 21m 14s\n",
      "2325:\tlearn: 0.0520512\ttotal: 6m 26s\tremaining: 21m 14s\n",
      "2326:\tlearn: 0.0520512\ttotal: 6m 26s\tremaining: 21m 14s\n",
      "2327:\tlearn: 0.0520512\ttotal: 6m 26s\tremaining: 21m 14s\n",
      "2328:\tlearn: 0.0520512\ttotal: 6m 26s\tremaining: 21m 13s\n",
      "2329:\tlearn: 0.0520512\ttotal: 6m 26s\tremaining: 21m 13s\n",
      "2330:\tlearn: 0.0520512\ttotal: 6m 27s\tremaining: 21m 13s\n",
      "2331:\tlearn: 0.0520512\ttotal: 6m 27s\tremaining: 21m 13s\n",
      "2332:\tlearn: 0.0520512\ttotal: 6m 27s\tremaining: 21m 13s\n",
      "2333:\tlearn: 0.0520512\ttotal: 6m 27s\tremaining: 21m 12s\n",
      "2334:\tlearn: 0.0520512\ttotal: 6m 27s\tremaining: 21m 12s\n",
      "2335:\tlearn: 0.0520512\ttotal: 6m 27s\tremaining: 21m 12s\n",
      "2336:\tlearn: 0.0520512\ttotal: 6m 28s\tremaining: 21m 12s\n",
      "2337:\tlearn: 0.0520512\ttotal: 6m 28s\tremaining: 21m 12s\n",
      "2338:\tlearn: 0.0520512\ttotal: 6m 28s\tremaining: 21m 12s\n",
      "2339:\tlearn: 0.0520512\ttotal: 6m 28s\tremaining: 21m 11s\n",
      "2340:\tlearn: 0.0520512\ttotal: 6m 28s\tremaining: 21m 11s\n",
      "2341:\tlearn: 0.0520512\ttotal: 6m 28s\tremaining: 21m 11s\n",
      "2342:\tlearn: 0.0520512\ttotal: 6m 28s\tremaining: 21m 11s\n",
      "2343:\tlearn: 0.0520512\ttotal: 6m 29s\tremaining: 21m 10s\n",
      "2344:\tlearn: 0.0520512\ttotal: 6m 29s\tremaining: 21m 10s\n",
      "2345:\tlearn: 0.0520512\ttotal: 6m 29s\tremaining: 21m 10s\n",
      "2346:\tlearn: 0.0520512\ttotal: 6m 29s\tremaining: 21m 10s\n",
      "2347:\tlearn: 0.0520512\ttotal: 6m 29s\tremaining: 21m 10s\n",
      "2348:\tlearn: 0.0520512\ttotal: 6m 29s\tremaining: 21m 9s\n",
      "2349:\tlearn: 0.0520512\ttotal: 6m 30s\tremaining: 21m 9s\n",
      "2350:\tlearn: 0.0520512\ttotal: 6m 30s\tremaining: 21m 9s\n",
      "2351:\tlearn: 0.0520512\ttotal: 6m 30s\tremaining: 21m 9s\n",
      "2352:\tlearn: 0.0520512\ttotal: 6m 30s\tremaining: 21m 8s\n",
      "2353:\tlearn: 0.0520512\ttotal: 6m 30s\tremaining: 21m 8s\n",
      "2354:\tlearn: 0.0520512\ttotal: 6m 30s\tremaining: 21m 8s\n",
      "2355:\tlearn: 0.0520512\ttotal: 6m 30s\tremaining: 21m 8s\n",
      "2356:\tlearn: 0.0520512\ttotal: 6m 31s\tremaining: 21m 7s\n",
      "2357:\tlearn: 0.0520512\ttotal: 6m 31s\tremaining: 21m 7s\n",
      "2358:\tlearn: 0.0520512\ttotal: 6m 31s\tremaining: 21m 7s\n",
      "2359:\tlearn: 0.0520512\ttotal: 6m 31s\tremaining: 21m 7s\n",
      "2360:\tlearn: 0.0520512\ttotal: 6m 31s\tremaining: 21m 6s\n",
      "2361:\tlearn: 0.0520512\ttotal: 6m 31s\tremaining: 21m 6s\n",
      "2362:\tlearn: 0.0520512\ttotal: 6m 31s\tremaining: 21m 6s\n",
      "2363:\tlearn: 0.0520512\ttotal: 6m 32s\tremaining: 21m 6s\n",
      "2364:\tlearn: 0.0520512\ttotal: 6m 32s\tremaining: 21m 6s\n",
      "2365:\tlearn: 0.0520512\ttotal: 6m 32s\tremaining: 21m 5s\n",
      "2366:\tlearn: 0.0520512\ttotal: 6m 32s\tremaining: 21m 5s\n",
      "2367:\tlearn: 0.0520512\ttotal: 6m 32s\tremaining: 21m 5s\n",
      "2368:\tlearn: 0.0520512\ttotal: 6m 32s\tremaining: 21m 5s\n",
      "2369:\tlearn: 0.0520512\ttotal: 6m 32s\tremaining: 21m 4s\n",
      "2370:\tlearn: 0.0520512\ttotal: 6m 33s\tremaining: 21m 4s\n",
      "2371:\tlearn: 0.0520512\ttotal: 6m 33s\tremaining: 21m 4s\n",
      "2372:\tlearn: 0.0520512\ttotal: 6m 33s\tremaining: 21m 4s\n",
      "2373:\tlearn: 0.0520512\ttotal: 6m 33s\tremaining: 21m 3s\n",
      "2374:\tlearn: 0.0520512\ttotal: 6m 33s\tremaining: 21m 3s\n",
      "2375:\tlearn: 0.0520512\ttotal: 6m 33s\tremaining: 21m 3s\n",
      "2376:\tlearn: 0.0520512\ttotal: 6m 33s\tremaining: 21m 3s\n",
      "2377:\tlearn: 0.0520512\ttotal: 6m 34s\tremaining: 21m 2s\n",
      "2378:\tlearn: 0.0520512\ttotal: 6m 34s\tremaining: 21m 2s\n",
      "2379:\tlearn: 0.0520512\ttotal: 6m 34s\tremaining: 21m 2s\n",
      "2380:\tlearn: 0.0520512\ttotal: 6m 34s\tremaining: 21m 2s\n",
      "2381:\tlearn: 0.0520512\ttotal: 6m 34s\tremaining: 21m 1s\n",
      "2382:\tlearn: 0.0520512\ttotal: 6m 34s\tremaining: 21m 1s\n",
      "2383:\tlearn: 0.0520512\ttotal: 6m 34s\tremaining: 21m 1s\n",
      "2384:\tlearn: 0.0520512\ttotal: 6m 35s\tremaining: 21m 1s\n",
      "2385:\tlearn: 0.0520512\ttotal: 6m 35s\tremaining: 21m\n",
      "2386:\tlearn: 0.0520512\ttotal: 6m 35s\tremaining: 21m\n",
      "2387:\tlearn: 0.0520512\ttotal: 6m 35s\tremaining: 21m\n",
      "2388:\tlearn: 0.0520512\ttotal: 6m 35s\tremaining: 21m\n",
      "2389:\tlearn: 0.0520512\ttotal: 6m 35s\tremaining: 21m\n",
      "2390:\tlearn: 0.0520512\ttotal: 6m 35s\tremaining: 20m 59s\n",
      "2391:\tlearn: 0.0520512\ttotal: 6m 36s\tremaining: 20m 59s\n",
      "2392:\tlearn: 0.0520512\ttotal: 6m 36s\tremaining: 20m 59s\n",
      "2393:\tlearn: 0.0520512\ttotal: 6m 36s\tremaining: 20m 59s\n",
      "2394:\tlearn: 0.0520512\ttotal: 6m 36s\tremaining: 20m 58s\n",
      "2395:\tlearn: 0.0520512\ttotal: 6m 36s\tremaining: 20m 58s\n",
      "2396:\tlearn: 0.0520512\ttotal: 6m 36s\tremaining: 20m 58s\n",
      "2397:\tlearn: 0.0520512\ttotal: 6m 36s\tremaining: 20m 58s\n",
      "2398:\tlearn: 0.0520512\ttotal: 6m 37s\tremaining: 20m 57s\n",
      "2399:\tlearn: 0.0520512\ttotal: 6m 37s\tremaining: 20m 57s\n",
      "2400:\tlearn: 0.0520512\ttotal: 6m 37s\tremaining: 20m 57s\n",
      "2401:\tlearn: 0.0520512\ttotal: 6m 37s\tremaining: 20m 57s\n",
      "2402:\tlearn: 0.0520512\ttotal: 6m 37s\tremaining: 20m 56s\n",
      "2403:\tlearn: 0.0520512\ttotal: 6m 37s\tremaining: 20m 56s\n",
      "2404:\tlearn: 0.0520512\ttotal: 6m 37s\tremaining: 20m 56s\n",
      "2405:\tlearn: 0.0520512\ttotal: 6m 37s\tremaining: 20m 56s\n",
      "2406:\tlearn: 0.0520512\ttotal: 6m 38s\tremaining: 20m 55s\n",
      "2407:\tlearn: 0.0520512\ttotal: 6m 38s\tremaining: 20m 55s\n",
      "2408:\tlearn: 0.0520512\ttotal: 6m 38s\tremaining: 20m 55s\n",
      "2409:\tlearn: 0.0520512\ttotal: 6m 38s\tremaining: 20m 55s\n",
      "2410:\tlearn: 0.0520512\ttotal: 6m 38s\tremaining: 20m 54s\n",
      "2411:\tlearn: 0.0520512\ttotal: 6m 38s\tremaining: 20m 54s\n",
      "2412:\tlearn: 0.0520512\ttotal: 6m 38s\tremaining: 20m 54s\n",
      "2413:\tlearn: 0.0520512\ttotal: 6m 39s\tremaining: 20m 54s\n",
      "2414:\tlearn: 0.0520512\ttotal: 6m 39s\tremaining: 20m 54s\n",
      "2415:\tlearn: 0.0520512\ttotal: 6m 39s\tremaining: 20m 53s\n",
      "2416:\tlearn: 0.0520512\ttotal: 6m 39s\tremaining: 20m 53s\n",
      "2417:\tlearn: 0.0520512\ttotal: 6m 39s\tremaining: 20m 53s\n",
      "2418:\tlearn: 0.0520512\ttotal: 6m 39s\tremaining: 20m 53s\n",
      "2419:\tlearn: 0.0520512\ttotal: 6m 39s\tremaining: 20m 52s\n",
      "2420:\tlearn: 0.0520512\ttotal: 6m 40s\tremaining: 20m 52s\n",
      "2421:\tlearn: 0.0520512\ttotal: 6m 40s\tremaining: 20m 52s\n",
      "2422:\tlearn: 0.0520512\ttotal: 6m 40s\tremaining: 20m 52s\n",
      "2423:\tlearn: 0.0520512\ttotal: 6m 40s\tremaining: 20m 51s\n",
      "2424:\tlearn: 0.0520512\ttotal: 6m 40s\tremaining: 20m 51s\n",
      "2425:\tlearn: 0.0520512\ttotal: 6m 40s\tremaining: 20m 51s\n",
      "2426:\tlearn: 0.0520512\ttotal: 6m 40s\tremaining: 20m 51s\n",
      "2427:\tlearn: 0.0520512\ttotal: 6m 41s\tremaining: 20m 50s\n",
      "2428:\tlearn: 0.0520512\ttotal: 6m 41s\tremaining: 20m 50s\n",
      "2429:\tlearn: 0.0520512\ttotal: 6m 41s\tremaining: 20m 50s\n",
      "2430:\tlearn: 0.0520512\ttotal: 6m 41s\tremaining: 20m 50s\n",
      "2431:\tlearn: 0.0520512\ttotal: 6m 41s\tremaining: 20m 49s\n",
      "2432:\tlearn: 0.0520512\ttotal: 6m 41s\tremaining: 20m 49s\n",
      "2433:\tlearn: 0.0520512\ttotal: 6m 41s\tremaining: 20m 49s\n",
      "2434:\tlearn: 0.0520512\ttotal: 6m 42s\tremaining: 20m 49s\n",
      "2435:\tlearn: 0.0520512\ttotal: 6m 42s\tremaining: 20m 48s\n",
      "2436:\tlearn: 0.0520512\ttotal: 6m 42s\tremaining: 20m 48s\n",
      "2437:\tlearn: 0.0520512\ttotal: 6m 42s\tremaining: 20m 48s\n",
      "2438:\tlearn: 0.0520512\ttotal: 6m 42s\tremaining: 20m 48s\n",
      "2439:\tlearn: 0.0520512\ttotal: 6m 42s\tremaining: 20m 48s\n",
      "2440:\tlearn: 0.0520512\ttotal: 6m 42s\tremaining: 20m 47s\n",
      "2441:\tlearn: 0.0520512\ttotal: 6m 43s\tremaining: 20m 47s\n",
      "2442:\tlearn: 0.0520512\ttotal: 6m 43s\tremaining: 20m 47s\n",
      "2443:\tlearn: 0.0520512\ttotal: 6m 43s\tremaining: 20m 47s\n",
      "2444:\tlearn: 0.0520512\ttotal: 6m 43s\tremaining: 20m 46s\n",
      "2445:\tlearn: 0.0520512\ttotal: 6m 43s\tremaining: 20m 46s\n",
      "2446:\tlearn: 0.0520512\ttotal: 6m 43s\tremaining: 20m 46s\n",
      "2447:\tlearn: 0.0520512\ttotal: 6m 43s\tremaining: 20m 46s\n",
      "2448:\tlearn: 0.0520512\ttotal: 6m 44s\tremaining: 20m 45s\n",
      "2449:\tlearn: 0.0520512\ttotal: 6m 44s\tremaining: 20m 45s\n",
      "2450:\tlearn: 0.0520512\ttotal: 6m 44s\tremaining: 20m 45s\n",
      "2451:\tlearn: 0.0520512\ttotal: 6m 44s\tremaining: 20m 45s\n",
      "2452:\tlearn: 0.0520512\ttotal: 6m 44s\tremaining: 20m 44s\n",
      "2453:\tlearn: 0.0520512\ttotal: 6m 44s\tremaining: 20m 44s\n",
      "2454:\tlearn: 0.0520512\ttotal: 6m 44s\tremaining: 20m 44s\n",
      "2455:\tlearn: 0.0520512\ttotal: 6m 45s\tremaining: 20m 44s\n",
      "2456:\tlearn: 0.0520512\ttotal: 6m 45s\tremaining: 20m 44s\n",
      "2457:\tlearn: 0.0520512\ttotal: 6m 45s\tremaining: 20m 43s\n",
      "2458:\tlearn: 0.0520512\ttotal: 6m 45s\tremaining: 20m 43s\n",
      "2459:\tlearn: 0.0520512\ttotal: 6m 45s\tremaining: 20m 43s\n",
      "2460:\tlearn: 0.0520512\ttotal: 6m 45s\tremaining: 20m 43s\n",
      "2461:\tlearn: 0.0520512\ttotal: 6m 45s\tremaining: 20m 42s\n",
      "2462:\tlearn: 0.0520512\ttotal: 6m 46s\tremaining: 20m 42s\n",
      "2463:\tlearn: 0.0520512\ttotal: 6m 46s\tremaining: 20m 42s\n",
      "2464:\tlearn: 0.0520512\ttotal: 6m 46s\tremaining: 20m 42s\n",
      "2465:\tlearn: 0.0520512\ttotal: 6m 46s\tremaining: 20m 41s\n",
      "2466:\tlearn: 0.0520512\ttotal: 6m 46s\tremaining: 20m 41s\n",
      "2467:\tlearn: 0.0520512\ttotal: 6m 46s\tremaining: 20m 41s\n",
      "2468:\tlearn: 0.0520512\ttotal: 6m 46s\tremaining: 20m 41s\n",
      "2469:\tlearn: 0.0520512\ttotal: 6m 47s\tremaining: 20m 40s\n",
      "2470:\tlearn: 0.0520512\ttotal: 6m 47s\tremaining: 20m 40s\n",
      "2471:\tlearn: 0.0520512\ttotal: 6m 47s\tremaining: 20m 40s\n",
      "2472:\tlearn: 0.0520512\ttotal: 6m 47s\tremaining: 20m 40s\n",
      "2473:\tlearn: 0.0520512\ttotal: 6m 47s\tremaining: 20m 40s\n",
      "2474:\tlearn: 0.0520512\ttotal: 6m 47s\tremaining: 20m 39s\n",
      "2475:\tlearn: 0.0520512\ttotal: 6m 47s\tremaining: 20m 39s\n",
      "2476:\tlearn: 0.0520512\ttotal: 6m 48s\tremaining: 20m 39s\n",
      "2477:\tlearn: 0.0520512\ttotal: 6m 48s\tremaining: 20m 39s\n",
      "2478:\tlearn: 0.0520512\ttotal: 6m 48s\tremaining: 20m 38s\n",
      "2479:\tlearn: 0.0520512\ttotal: 6m 48s\tremaining: 20m 38s\n",
      "2480:\tlearn: 0.0520512\ttotal: 6m 48s\tremaining: 20m 38s\n",
      "2481:\tlearn: 0.0520512\ttotal: 6m 48s\tremaining: 20m 38s\n",
      "2482:\tlearn: 0.0520512\ttotal: 6m 48s\tremaining: 20m 37s\n",
      "2483:\tlearn: 0.0520512\ttotal: 6m 49s\tremaining: 20m 37s\n",
      "2484:\tlearn: 0.0520512\ttotal: 6m 49s\tremaining: 20m 37s\n",
      "2485:\tlearn: 0.0520512\ttotal: 6m 49s\tremaining: 20m 37s\n",
      "2486:\tlearn: 0.0520512\ttotal: 6m 49s\tremaining: 20m 37s\n",
      "2487:\tlearn: 0.0520512\ttotal: 6m 49s\tremaining: 20m 36s\n",
      "2488:\tlearn: 0.0520512\ttotal: 6m 49s\tremaining: 20m 36s\n",
      "2489:\tlearn: 0.0520512\ttotal: 6m 49s\tremaining: 20m 36s\n",
      "2490:\tlearn: 0.0520512\ttotal: 6m 50s\tremaining: 20m 36s\n",
      "2491:\tlearn: 0.0520512\ttotal: 6m 50s\tremaining: 20m 35s\n",
      "2492:\tlearn: 0.0520512\ttotal: 6m 50s\tremaining: 20m 35s\n",
      "2493:\tlearn: 0.0520512\ttotal: 6m 50s\tremaining: 20m 35s\n",
      "2494:\tlearn: 0.0520512\ttotal: 6m 50s\tremaining: 20m 35s\n",
      "2495:\tlearn: 0.0520512\ttotal: 6m 50s\tremaining: 20m 34s\n",
      "2496:\tlearn: 0.0520512\ttotal: 6m 50s\tremaining: 20m 34s\n",
      "2497:\tlearn: 0.0520512\ttotal: 6m 51s\tremaining: 20m 34s\n",
      "2498:\tlearn: 0.0520512\ttotal: 6m 51s\tremaining: 20m 34s\n",
      "2499:\tlearn: 0.0520512\ttotal: 6m 51s\tremaining: 20m 33s\n",
      "2500:\tlearn: 0.0520512\ttotal: 6m 51s\tremaining: 20m 33s\n",
      "2501:\tlearn: 0.0520512\ttotal: 6m 51s\tremaining: 20m 33s\n",
      "2502:\tlearn: 0.0520512\ttotal: 6m 51s\tremaining: 20m 33s\n",
      "2503:\tlearn: 0.0520512\ttotal: 6m 51s\tremaining: 20m 33s\n",
      "2504:\tlearn: 0.0520512\ttotal: 6m 52s\tremaining: 20m 32s\n",
      "2505:\tlearn: 0.0520512\ttotal: 6m 52s\tremaining: 20m 32s\n",
      "2506:\tlearn: 0.0520512\ttotal: 6m 52s\tremaining: 20m 32s\n",
      "2507:\tlearn: 0.0520512\ttotal: 6m 52s\tremaining: 20m 32s\n",
      "2508:\tlearn: 0.0520512\ttotal: 6m 52s\tremaining: 20m 31s\n",
      "2509:\tlearn: 0.0520512\ttotal: 6m 52s\tremaining: 20m 31s\n",
      "2510:\tlearn: 0.0520512\ttotal: 6m 52s\tremaining: 20m 31s\n",
      "2511:\tlearn: 0.0520512\ttotal: 6m 53s\tremaining: 20m 31s\n",
      "2512:\tlearn: 0.0520512\ttotal: 6m 53s\tremaining: 20m 30s\n",
      "2513:\tlearn: 0.0520512\ttotal: 6m 53s\tremaining: 20m 30s\n",
      "2514:\tlearn: 0.0520512\ttotal: 6m 53s\tremaining: 20m 30s\n",
      "2515:\tlearn: 0.0520512\ttotal: 6m 53s\tremaining: 20m 30s\n",
      "2516:\tlearn: 0.0520512\ttotal: 6m 53s\tremaining: 20m 30s\n",
      "2517:\tlearn: 0.0520512\ttotal: 6m 53s\tremaining: 20m 29s\n",
      "2518:\tlearn: 0.0520512\ttotal: 6m 54s\tremaining: 20m 29s\n",
      "2519:\tlearn: 0.0520512\ttotal: 6m 54s\tremaining: 20m 29s\n",
      "2520:\tlearn: 0.0520512\ttotal: 6m 54s\tremaining: 20m 29s\n",
      "2521:\tlearn: 0.0520512\ttotal: 6m 54s\tremaining: 20m 28s\n",
      "2522:\tlearn: 0.0520512\ttotal: 6m 54s\tremaining: 20m 28s\n",
      "2523:\tlearn: 0.0520512\ttotal: 6m 54s\tremaining: 20m 28s\n",
      "2524:\tlearn: 0.0520512\ttotal: 6m 54s\tremaining: 20m 28s\n",
      "2525:\tlearn: 0.0520512\ttotal: 6m 55s\tremaining: 20m 27s\n",
      "2526:\tlearn: 0.0520512\ttotal: 6m 55s\tremaining: 20m 27s\n",
      "2527:\tlearn: 0.0520512\ttotal: 6m 55s\tremaining: 20m 27s\n",
      "2528:\tlearn: 0.0520512\ttotal: 6m 55s\tremaining: 20m 27s\n",
      "2529:\tlearn: 0.0520512\ttotal: 6m 55s\tremaining: 20m 27s\n",
      "2530:\tlearn: 0.0520512\ttotal: 6m 55s\tremaining: 20m 26s\n",
      "2531:\tlearn: 0.0520512\ttotal: 6m 55s\tremaining: 20m 26s\n",
      "2532:\tlearn: 0.0520512\ttotal: 6m 56s\tremaining: 20m 26s\n",
      "2533:\tlearn: 0.0520512\ttotal: 6m 56s\tremaining: 20m 26s\n",
      "2534:\tlearn: 0.0520512\ttotal: 6m 56s\tremaining: 20m 25s\n",
      "2535:\tlearn: 0.0520512\ttotal: 6m 56s\tremaining: 20m 25s\n",
      "2536:\tlearn: 0.0520512\ttotal: 6m 56s\tremaining: 20m 25s\n",
      "2537:\tlearn: 0.0520512\ttotal: 6m 56s\tremaining: 20m 25s\n",
      "2538:\tlearn: 0.0520512\ttotal: 6m 56s\tremaining: 20m 24s\n",
      "2539:\tlearn: 0.0520512\ttotal: 6m 57s\tremaining: 20m 24s\n",
      "2540:\tlearn: 0.0520512\ttotal: 6m 57s\tremaining: 20m 24s\n",
      "2541:\tlearn: 0.0520512\ttotal: 6m 57s\tremaining: 20m 24s\n",
      "2542:\tlearn: 0.0520512\ttotal: 6m 57s\tremaining: 20m 24s\n",
      "2543:\tlearn: 0.0520512\ttotal: 6m 57s\tremaining: 20m 23s\n",
      "2544:\tlearn: 0.0520512\ttotal: 6m 57s\tremaining: 20m 23s\n",
      "2545:\tlearn: 0.0520512\ttotal: 6m 57s\tremaining: 20m 23s\n",
      "2546:\tlearn: 0.0520512\ttotal: 6m 58s\tremaining: 20m 23s\n",
      "2547:\tlearn: 0.0520512\ttotal: 6m 58s\tremaining: 20m 22s\n",
      "2548:\tlearn: 0.0520512\ttotal: 6m 58s\tremaining: 20m 22s\n",
      "2549:\tlearn: 0.0520512\ttotal: 6m 58s\tremaining: 20m 22s\n",
      "2550:\tlearn: 0.0520512\ttotal: 6m 58s\tremaining: 20m 22s\n",
      "2551:\tlearn: 0.0520512\ttotal: 6m 58s\tremaining: 20m 22s\n",
      "2552:\tlearn: 0.0520512\ttotal: 6m 58s\tremaining: 20m 21s\n",
      "2553:\tlearn: 0.0520512\ttotal: 6m 59s\tremaining: 20m 21s\n",
      "2554:\tlearn: 0.0520512\ttotal: 6m 59s\tremaining: 20m 21s\n",
      "2555:\tlearn: 0.0520512\ttotal: 6m 59s\tremaining: 20m 21s\n",
      "2556:\tlearn: 0.0520512\ttotal: 6m 59s\tremaining: 20m 20s\n",
      "2557:\tlearn: 0.0520512\ttotal: 6m 59s\tremaining: 20m 20s\n",
      "2558:\tlearn: 0.0520512\ttotal: 6m 59s\tremaining: 20m 20s\n",
      "2559:\tlearn: 0.0520512\ttotal: 6m 59s\tremaining: 20m 20s\n",
      "2560:\tlearn: 0.0520512\ttotal: 7m\tremaining: 20m 19s\n",
      "2561:\tlearn: 0.0520512\ttotal: 7m\tremaining: 20m 19s\n",
      "2562:\tlearn: 0.0520512\ttotal: 7m\tremaining: 20m 19s\n",
      "2563:\tlearn: 0.0520512\ttotal: 7m\tremaining: 20m 19s\n",
      "2564:\tlearn: 0.0520512\ttotal: 7m\tremaining: 20m 19s\n",
      "2565:\tlearn: 0.0520512\ttotal: 7m\tremaining: 20m 18s\n",
      "2566:\tlearn: 0.0520512\ttotal: 7m\tremaining: 20m 18s\n",
      "2567:\tlearn: 0.0520512\ttotal: 7m\tremaining: 20m 18s\n",
      "2568:\tlearn: 0.0520512\ttotal: 7m 1s\tremaining: 20m 18s\n",
      "2569:\tlearn: 0.0520512\ttotal: 7m 1s\tremaining: 20m 17s\n",
      "2570:\tlearn: 0.0520512\ttotal: 7m 1s\tremaining: 20m 17s\n",
      "2571:\tlearn: 0.0520512\ttotal: 7m 1s\tremaining: 20m 17s\n",
      "2572:\tlearn: 0.0520512\ttotal: 7m 1s\tremaining: 20m 17s\n",
      "2573:\tlearn: 0.0520512\ttotal: 7m 1s\tremaining: 20m 17s\n",
      "2574:\tlearn: 0.0520512\ttotal: 7m 1s\tremaining: 20m 16s\n",
      "2575:\tlearn: 0.0520512\ttotal: 7m 2s\tremaining: 20m 16s\n",
      "2576:\tlearn: 0.0520512\ttotal: 7m 2s\tremaining: 20m 16s\n",
      "2577:\tlearn: 0.0520512\ttotal: 7m 2s\tremaining: 20m 16s\n",
      "2578:\tlearn: 0.0520512\ttotal: 7m 2s\tremaining: 20m 15s\n",
      "2579:\tlearn: 0.0520512\ttotal: 7m 2s\tremaining: 20m 15s\n",
      "2580:\tlearn: 0.0520512\ttotal: 7m 2s\tremaining: 20m 15s\n",
      "2581:\tlearn: 0.0520512\ttotal: 7m 2s\tremaining: 20m 15s\n",
      "2582:\tlearn: 0.0520512\ttotal: 7m 3s\tremaining: 20m 14s\n",
      "2583:\tlearn: 0.0520512\ttotal: 7m 3s\tremaining: 20m 14s\n",
      "2584:\tlearn: 0.0520512\ttotal: 7m 3s\tremaining: 20m 14s\n",
      "2585:\tlearn: 0.0520512\ttotal: 7m 3s\tremaining: 20m 14s\n",
      "2586:\tlearn: 0.0520512\ttotal: 7m 3s\tremaining: 20m 14s\n",
      "2587:\tlearn: 0.0520512\ttotal: 7m 3s\tremaining: 20m 13s\n",
      "2588:\tlearn: 0.0520512\ttotal: 7m 3s\tremaining: 20m 13s\n",
      "2589:\tlearn: 0.0520512\ttotal: 7m 4s\tremaining: 20m 13s\n",
      "2590:\tlearn: 0.0520512\ttotal: 7m 4s\tremaining: 20m 13s\n",
      "2591:\tlearn: 0.0520512\ttotal: 7m 4s\tremaining: 20m 12s\n",
      "2592:\tlearn: 0.0520512\ttotal: 7m 4s\tremaining: 20m 12s\n",
      "2593:\tlearn: 0.0520512\ttotal: 7m 4s\tremaining: 20m 12s\n",
      "2594:\tlearn: 0.0520512\ttotal: 7m 4s\tremaining: 20m 12s\n",
      "2595:\tlearn: 0.0520512\ttotal: 7m 4s\tremaining: 20m 12s\n",
      "2596:\tlearn: 0.0520512\ttotal: 7m 5s\tremaining: 20m 11s\n",
      "2597:\tlearn: 0.0520512\ttotal: 7m 5s\tremaining: 20m 11s\n",
      "2598:\tlearn: 0.0520512\ttotal: 7m 5s\tremaining: 20m 11s\n",
      "2599:\tlearn: 0.0520512\ttotal: 7m 5s\tremaining: 20m 11s\n",
      "2600:\tlearn: 0.0520512\ttotal: 7m 5s\tremaining: 20m 10s\n",
      "2601:\tlearn: 0.0520512\ttotal: 7m 5s\tremaining: 20m 10s\n",
      "2602:\tlearn: 0.0520512\ttotal: 7m 5s\tremaining: 20m 10s\n",
      "2603:\tlearn: 0.0520512\ttotal: 7m 6s\tremaining: 20m 10s\n",
      "2604:\tlearn: 0.0520512\ttotal: 7m 6s\tremaining: 20m 10s\n",
      "2605:\tlearn: 0.0520512\ttotal: 7m 6s\tremaining: 20m 9s\n",
      "2606:\tlearn: 0.0520512\ttotal: 7m 6s\tremaining: 20m 9s\n",
      "2607:\tlearn: 0.0520512\ttotal: 7m 6s\tremaining: 20m 9s\n",
      "2608:\tlearn: 0.0520512\ttotal: 7m 6s\tremaining: 20m 9s\n",
      "2609:\tlearn: 0.0520512\ttotal: 7m 6s\tremaining: 20m 8s\n",
      "2610:\tlearn: 0.0520512\ttotal: 7m 7s\tremaining: 20m 8s\n",
      "2611:\tlearn: 0.0520512\ttotal: 7m 7s\tremaining: 20m 8s\n",
      "2612:\tlearn: 0.0520512\ttotal: 7m 7s\tremaining: 20m 8s\n",
      "2613:\tlearn: 0.0520512\ttotal: 7m 7s\tremaining: 20m 8s\n",
      "2614:\tlearn: 0.0520512\ttotal: 7m 7s\tremaining: 20m 7s\n",
      "2615:\tlearn: 0.0520512\ttotal: 7m 7s\tremaining: 20m 7s\n",
      "2616:\tlearn: 0.0520512\ttotal: 7m 7s\tremaining: 20m 7s\n",
      "2617:\tlearn: 0.0520512\ttotal: 7m 8s\tremaining: 20m 7s\n",
      "2618:\tlearn: 0.0520512\ttotal: 7m 8s\tremaining: 20m 6s\n",
      "2619:\tlearn: 0.0520512\ttotal: 7m 8s\tremaining: 20m 6s\n",
      "2620:\tlearn: 0.0520512\ttotal: 7m 8s\tremaining: 20m 6s\n",
      "2621:\tlearn: 0.0520512\ttotal: 7m 8s\tremaining: 20m 6s\n",
      "2622:\tlearn: 0.0520512\ttotal: 7m 8s\tremaining: 20m 6s\n",
      "2623:\tlearn: 0.0520512\ttotal: 7m 8s\tremaining: 20m 5s\n",
      "2624:\tlearn: 0.0520512\ttotal: 7m 9s\tremaining: 20m 5s\n",
      "2625:\tlearn: 0.0520512\ttotal: 7m 9s\tremaining: 20m 5s\n",
      "2626:\tlearn: 0.0520512\ttotal: 7m 9s\tremaining: 20m 5s\n",
      "2627:\tlearn: 0.0520512\ttotal: 7m 9s\tremaining: 20m 4s\n",
      "2628:\tlearn: 0.0520512\ttotal: 7m 9s\tremaining: 20m 4s\n",
      "2629:\tlearn: 0.0520512\ttotal: 7m 9s\tremaining: 20m 4s\n",
      "2630:\tlearn: 0.0520512\ttotal: 7m 9s\tremaining: 20m 4s\n",
      "2631:\tlearn: 0.0520512\ttotal: 7m 10s\tremaining: 20m 4s\n",
      "2632:\tlearn: 0.0520512\ttotal: 7m 10s\tremaining: 20m 3s\n",
      "2633:\tlearn: 0.0520512\ttotal: 7m 10s\tremaining: 20m 3s\n",
      "2634:\tlearn: 0.0520512\ttotal: 7m 10s\tremaining: 20m 3s\n",
      "2635:\tlearn: 0.0520512\ttotal: 7m 10s\tremaining: 20m 3s\n",
      "2636:\tlearn: 0.0520512\ttotal: 7m 10s\tremaining: 20m 2s\n",
      "2637:\tlearn: 0.0520512\ttotal: 7m 10s\tremaining: 20m 2s\n",
      "2638:\tlearn: 0.0520512\ttotal: 7m 11s\tremaining: 20m 2s\n",
      "2639:\tlearn: 0.0520512\ttotal: 7m 11s\tremaining: 20m 2s\n",
      "2640:\tlearn: 0.0520512\ttotal: 7m 11s\tremaining: 20m 2s\n",
      "2641:\tlearn: 0.0520512\ttotal: 7m 11s\tremaining: 20m 1s\n",
      "2642:\tlearn: 0.0520512\ttotal: 7m 11s\tremaining: 20m 1s\n",
      "2643:\tlearn: 0.0520512\ttotal: 7m 11s\tremaining: 20m 1s\n",
      "2644:\tlearn: 0.0520512\ttotal: 7m 11s\tremaining: 20m 1s\n",
      "2645:\tlearn: 0.0520512\ttotal: 7m 12s\tremaining: 20m\n",
      "2646:\tlearn: 0.0520512\ttotal: 7m 12s\tremaining: 20m\n",
      "2647:\tlearn: 0.0520512\ttotal: 7m 12s\tremaining: 20m\n",
      "2648:\tlearn: 0.0520512\ttotal: 7m 12s\tremaining: 20m\n",
      "2649:\tlearn: 0.0520512\ttotal: 7m 12s\tremaining: 20m\n",
      "2650:\tlearn: 0.0520512\ttotal: 7m 12s\tremaining: 19m 59s\n",
      "2651:\tlearn: 0.0520512\ttotal: 7m 12s\tremaining: 19m 59s\n",
      "2652:\tlearn: 0.0520512\ttotal: 7m 13s\tremaining: 19m 59s\n",
      "2653:\tlearn: 0.0520512\ttotal: 7m 13s\tremaining: 19m 59s\n",
      "2654:\tlearn: 0.0520512\ttotal: 7m 13s\tremaining: 19m 58s\n",
      "2655:\tlearn: 0.0520512\ttotal: 7m 13s\tremaining: 19m 58s\n",
      "2656:\tlearn: 0.0520512\ttotal: 7m 13s\tremaining: 19m 58s\n",
      "2657:\tlearn: 0.0520512\ttotal: 7m 13s\tremaining: 19m 58s\n",
      "2658:\tlearn: 0.0520512\ttotal: 7m 13s\tremaining: 19m 58s\n",
      "2659:\tlearn: 0.0520512\ttotal: 7m 14s\tremaining: 19m 57s\n",
      "2660:\tlearn: 0.0520512\ttotal: 7m 14s\tremaining: 19m 57s\n",
      "2661:\tlearn: 0.0520512\ttotal: 7m 14s\tremaining: 19m 57s\n",
      "2662:\tlearn: 0.0520512\ttotal: 7m 14s\tremaining: 19m 57s\n",
      "2663:\tlearn: 0.0520512\ttotal: 7m 14s\tremaining: 19m 56s\n",
      "2664:\tlearn: 0.0520512\ttotal: 7m 14s\tremaining: 19m 56s\n",
      "2665:\tlearn: 0.0520512\ttotal: 7m 14s\tremaining: 19m 56s\n",
      "2666:\tlearn: 0.0520512\ttotal: 7m 15s\tremaining: 19m 56s\n",
      "2667:\tlearn: 0.0520512\ttotal: 7m 15s\tremaining: 19m 56s\n",
      "2668:\tlearn: 0.0520512\ttotal: 7m 15s\tremaining: 19m 55s\n",
      "2669:\tlearn: 0.0520512\ttotal: 7m 15s\tremaining: 19m 55s\n",
      "2670:\tlearn: 0.0520512\ttotal: 7m 15s\tremaining: 19m 55s\n",
      "2671:\tlearn: 0.0520512\ttotal: 7m 15s\tremaining: 19m 55s\n",
      "2672:\tlearn: 0.0520512\ttotal: 7m 15s\tremaining: 19m 54s\n",
      "2673:\tlearn: 0.0520512\ttotal: 7m 16s\tremaining: 19m 54s\n",
      "2674:\tlearn: 0.0520512\ttotal: 7m 16s\tremaining: 19m 54s\n",
      "2675:\tlearn: 0.0520512\ttotal: 7m 16s\tremaining: 19m 54s\n",
      "2676:\tlearn: 0.0520512\ttotal: 7m 16s\tremaining: 19m 54s\n",
      "2677:\tlearn: 0.0520512\ttotal: 7m 16s\tremaining: 19m 53s\n",
      "2678:\tlearn: 0.0520512\ttotal: 7m 16s\tremaining: 19m 53s\n",
      "2679:\tlearn: 0.0520512\ttotal: 7m 16s\tremaining: 19m 53s\n",
      "2680:\tlearn: 0.0520512\ttotal: 7m 17s\tremaining: 19m 53s\n",
      "2681:\tlearn: 0.0520512\ttotal: 7m 17s\tremaining: 19m 53s\n",
      "2682:\tlearn: 0.0520512\ttotal: 7m 17s\tremaining: 19m 52s\n",
      "2683:\tlearn: 0.0520512\ttotal: 7m 17s\tremaining: 19m 52s\n",
      "2684:\tlearn: 0.0520512\ttotal: 7m 17s\tremaining: 19m 52s\n",
      "2685:\tlearn: 0.0520512\ttotal: 7m 17s\tremaining: 19m 52s\n",
      "2686:\tlearn: 0.0520512\ttotal: 7m 17s\tremaining: 19m 51s\n",
      "2687:\tlearn: 0.0520512\ttotal: 7m 18s\tremaining: 19m 51s\n",
      "2688:\tlearn: 0.0520512\ttotal: 7m 18s\tremaining: 19m 51s\n",
      "2689:\tlearn: 0.0520512\ttotal: 7m 18s\tremaining: 19m 51s\n",
      "2690:\tlearn: 0.0520512\ttotal: 7m 18s\tremaining: 19m 51s\n",
      "2691:\tlearn: 0.0520512\ttotal: 7m 18s\tremaining: 19m 50s\n",
      "2692:\tlearn: 0.0520512\ttotal: 7m 18s\tremaining: 19m 50s\n",
      "2693:\tlearn: 0.0520512\ttotal: 7m 18s\tremaining: 19m 50s\n",
      "2694:\tlearn: 0.0520512\ttotal: 7m 19s\tremaining: 19m 50s\n",
      "2695:\tlearn: 0.0520512\ttotal: 7m 19s\tremaining: 19m 49s\n",
      "2696:\tlearn: 0.0520512\ttotal: 7m 19s\tremaining: 19m 49s\n",
      "2697:\tlearn: 0.0520512\ttotal: 7m 19s\tremaining: 19m 49s\n",
      "2698:\tlearn: 0.0520512\ttotal: 7m 19s\tremaining: 19m 49s\n",
      "2699:\tlearn: 0.0520512\ttotal: 7m 19s\tremaining: 19m 49s\n",
      "2700:\tlearn: 0.0520512\ttotal: 7m 19s\tremaining: 19m 48s\n",
      "2701:\tlearn: 0.0520512\ttotal: 7m 20s\tremaining: 19m 48s\n",
      "2702:\tlearn: 0.0520512\ttotal: 7m 20s\tremaining: 19m 48s\n",
      "2703:\tlearn: 0.0520512\ttotal: 7m 20s\tremaining: 19m 48s\n",
      "2704:\tlearn: 0.0520512\ttotal: 7m 20s\tremaining: 19m 47s\n",
      "2705:\tlearn: 0.0520512\ttotal: 7m 20s\tremaining: 19m 47s\n",
      "2706:\tlearn: 0.0520512\ttotal: 7m 20s\tremaining: 19m 47s\n",
      "2707:\tlearn: 0.0520512\ttotal: 7m 20s\tremaining: 19m 47s\n",
      "2708:\tlearn: 0.0520512\ttotal: 7m 21s\tremaining: 19m 47s\n",
      "2709:\tlearn: 0.0520512\ttotal: 7m 21s\tremaining: 19m 46s\n",
      "2710:\tlearn: 0.0520512\ttotal: 7m 21s\tremaining: 19m 46s\n",
      "2711:\tlearn: 0.0520512\ttotal: 7m 21s\tremaining: 19m 46s\n",
      "2712:\tlearn: 0.0520512\ttotal: 7m 21s\tremaining: 19m 46s\n",
      "2713:\tlearn: 0.0520512\ttotal: 7m 21s\tremaining: 19m 46s\n",
      "2714:\tlearn: 0.0520512\ttotal: 7m 21s\tremaining: 19m 45s\n",
      "2715:\tlearn: 0.0520512\ttotal: 7m 22s\tremaining: 19m 45s\n",
      "2716:\tlearn: 0.0520512\ttotal: 7m 22s\tremaining: 19m 45s\n",
      "2717:\tlearn: 0.0520512\ttotal: 7m 22s\tremaining: 19m 45s\n",
      "2718:\tlearn: 0.0520512\ttotal: 7m 22s\tremaining: 19m 45s\n",
      "2719:\tlearn: 0.0520512\ttotal: 7m 22s\tremaining: 19m 44s\n",
      "2720:\tlearn: 0.0520512\ttotal: 7m 22s\tremaining: 19m 44s\n",
      "2721:\tlearn: 0.0520512\ttotal: 7m 22s\tremaining: 19m 44s\n",
      "2722:\tlearn: 0.0520512\ttotal: 7m 23s\tremaining: 19m 44s\n",
      "2723:\tlearn: 0.0520512\ttotal: 7m 23s\tremaining: 19m 43s\n",
      "2724:\tlearn: 0.0520512\ttotal: 7m 23s\tremaining: 19m 43s\n",
      "2725:\tlearn: 0.0520512\ttotal: 7m 23s\tremaining: 19m 43s\n",
      "2726:\tlearn: 0.0520512\ttotal: 7m 23s\tremaining: 19m 43s\n",
      "2727:\tlearn: 0.0520512\ttotal: 7m 23s\tremaining: 19m 43s\n",
      "2728:\tlearn: 0.0520512\ttotal: 7m 23s\tremaining: 19m 42s\n",
      "2729:\tlearn: 0.0520512\ttotal: 7m 24s\tremaining: 19m 42s\n",
      "2730:\tlearn: 0.0520512\ttotal: 7m 24s\tremaining: 19m 42s\n",
      "2731:\tlearn: 0.0520512\ttotal: 7m 24s\tremaining: 19m 42s\n",
      "2732:\tlearn: 0.0520512\ttotal: 7m 24s\tremaining: 19m 42s\n",
      "2733:\tlearn: 0.0520512\ttotal: 7m 24s\tremaining: 19m 41s\n",
      "2734:\tlearn: 0.0520512\ttotal: 7m 24s\tremaining: 19m 41s\n",
      "2735:\tlearn: 0.0520512\ttotal: 7m 24s\tremaining: 19m 41s\n",
      "2736:\tlearn: 0.0520512\ttotal: 7m 25s\tremaining: 19m 41s\n",
      "2737:\tlearn: 0.0520512\ttotal: 7m 25s\tremaining: 19m 40s\n",
      "2738:\tlearn: 0.0520512\ttotal: 7m 25s\tremaining: 19m 40s\n",
      "2739:\tlearn: 0.0520512\ttotal: 7m 25s\tremaining: 19m 40s\n",
      "2740:\tlearn: 0.0520512\ttotal: 7m 25s\tremaining: 19m 40s\n",
      "2741:\tlearn: 0.0520512\ttotal: 7m 25s\tremaining: 19m 40s\n",
      "2742:\tlearn: 0.0520512\ttotal: 7m 25s\tremaining: 19m 39s\n",
      "2743:\tlearn: 0.0520512\ttotal: 7m 26s\tremaining: 19m 39s\n",
      "2744:\tlearn: 0.0520512\ttotal: 7m 26s\tremaining: 19m 39s\n",
      "2745:\tlearn: 0.0520512\ttotal: 7m 26s\tremaining: 19m 39s\n",
      "2746:\tlearn: 0.0520512\ttotal: 7m 26s\tremaining: 19m 38s\n",
      "2747:\tlearn: 0.0520512\ttotal: 7m 26s\tremaining: 19m 38s\n",
      "2748:\tlearn: 0.0520512\ttotal: 7m 26s\tremaining: 19m 38s\n",
      "2749:\tlearn: 0.0520512\ttotal: 7m 26s\tremaining: 19m 38s\n",
      "2750:\tlearn: 0.0520512\ttotal: 7m 27s\tremaining: 19m 38s\n",
      "2751:\tlearn: 0.0520512\ttotal: 7m 27s\tremaining: 19m 37s\n",
      "2752:\tlearn: 0.0520512\ttotal: 7m 27s\tremaining: 19m 37s\n",
      "2753:\tlearn: 0.0520512\ttotal: 7m 27s\tremaining: 19m 37s\n",
      "2754:\tlearn: 0.0520512\ttotal: 7m 27s\tremaining: 19m 37s\n",
      "2755:\tlearn: 0.0520512\ttotal: 7m 27s\tremaining: 19m 37s\n",
      "2756:\tlearn: 0.0520512\ttotal: 7m 27s\tremaining: 19m 36s\n",
      "2757:\tlearn: 0.0520512\ttotal: 7m 28s\tremaining: 19m 36s\n",
      "2758:\tlearn: 0.0520512\ttotal: 7m 28s\tremaining: 19m 36s\n",
      "2759:\tlearn: 0.0520512\ttotal: 7m 28s\tremaining: 19m 36s\n",
      "2760:\tlearn: 0.0520512\ttotal: 7m 28s\tremaining: 19m 35s\n",
      "2761:\tlearn: 0.0520512\ttotal: 7m 28s\tremaining: 19m 35s\n",
      "2762:\tlearn: 0.0520512\ttotal: 7m 28s\tremaining: 19m 35s\n",
      "2763:\tlearn: 0.0520512\ttotal: 7m 28s\tremaining: 19m 35s\n",
      "2764:\tlearn: 0.0520512\ttotal: 7m 29s\tremaining: 19m 35s\n",
      "2765:\tlearn: 0.0520512\ttotal: 7m 29s\tremaining: 19m 34s\n",
      "2766:\tlearn: 0.0520512\ttotal: 7m 29s\tremaining: 19m 34s\n",
      "2767:\tlearn: 0.0520512\ttotal: 7m 29s\tremaining: 19m 34s\n",
      "2768:\tlearn: 0.0520512\ttotal: 7m 29s\tremaining: 19m 34s\n",
      "2769:\tlearn: 0.0520512\ttotal: 7m 29s\tremaining: 19m 34s\n",
      "2770:\tlearn: 0.0520512\ttotal: 7m 29s\tremaining: 19m 33s\n",
      "2771:\tlearn: 0.0520512\ttotal: 7m 30s\tremaining: 19m 33s\n",
      "2772:\tlearn: 0.0520512\ttotal: 7m 30s\tremaining: 19m 33s\n",
      "2773:\tlearn: 0.0520512\ttotal: 7m 30s\tremaining: 19m 33s\n",
      "2774:\tlearn: 0.0520512\ttotal: 7m 30s\tremaining: 19m 32s\n",
      "2775:\tlearn: 0.0520512\ttotal: 7m 30s\tremaining: 19m 32s\n",
      "2776:\tlearn: 0.0520512\ttotal: 7m 30s\tremaining: 19m 32s\n",
      "2777:\tlearn: 0.0520512\ttotal: 7m 30s\tremaining: 19m 32s\n",
      "2778:\tlearn: 0.0520512\ttotal: 7m 31s\tremaining: 19m 32s\n",
      "2779:\tlearn: 0.0520512\ttotal: 7m 31s\tremaining: 19m 31s\n",
      "2780:\tlearn: 0.0520512\ttotal: 7m 31s\tremaining: 19m 31s\n",
      "2781:\tlearn: 0.0520512\ttotal: 7m 31s\tremaining: 19m 31s\n",
      "2782:\tlearn: 0.0520512\ttotal: 7m 31s\tremaining: 19m 31s\n",
      "2783:\tlearn: 0.0520512\ttotal: 7m 31s\tremaining: 19m 31s\n",
      "2784:\tlearn: 0.0520512\ttotal: 7m 31s\tremaining: 19m 30s\n",
      "2785:\tlearn: 0.0520512\ttotal: 7m 32s\tremaining: 19m 30s\n",
      "2786:\tlearn: 0.0520512\ttotal: 7m 32s\tremaining: 19m 30s\n",
      "2787:\tlearn: 0.0520512\ttotal: 7m 32s\tremaining: 19m 30s\n",
      "2788:\tlearn: 0.0520512\ttotal: 7m 32s\tremaining: 19m 30s\n",
      "2789:\tlearn: 0.0520512\ttotal: 7m 32s\tremaining: 19m 29s\n",
      "2790:\tlearn: 0.0520512\ttotal: 7m 32s\tremaining: 19m 29s\n",
      "2791:\tlearn: 0.0520512\ttotal: 7m 32s\tremaining: 19m 29s\n",
      "2792:\tlearn: 0.0520512\ttotal: 7m 33s\tremaining: 19m 29s\n",
      "2793:\tlearn: 0.0520512\ttotal: 7m 33s\tremaining: 19m 28s\n",
      "2794:\tlearn: 0.0520512\ttotal: 7m 33s\tremaining: 19m 28s\n",
      "2795:\tlearn: 0.0520512\ttotal: 7m 33s\tremaining: 19m 28s\n",
      "2796:\tlearn: 0.0520512\ttotal: 7m 33s\tremaining: 19m 28s\n",
      "2797:\tlearn: 0.0520512\ttotal: 7m 33s\tremaining: 19m 28s\n",
      "2798:\tlearn: 0.0520512\ttotal: 7m 33s\tremaining: 19m 27s\n",
      "2799:\tlearn: 0.0520512\ttotal: 7m 34s\tremaining: 19m 27s\n",
      "2800:\tlearn: 0.0520512\ttotal: 7m 34s\tremaining: 19m 27s\n",
      "2801:\tlearn: 0.0520512\ttotal: 7m 34s\tremaining: 19m 27s\n",
      "2802:\tlearn: 0.0520512\ttotal: 7m 34s\tremaining: 19m 27s\n",
      "2803:\tlearn: 0.0520512\ttotal: 7m 34s\tremaining: 19m 26s\n",
      "2804:\tlearn: 0.0520512\ttotal: 7m 34s\tremaining: 19m 26s\n",
      "2805:\tlearn: 0.0520512\ttotal: 7m 34s\tremaining: 19m 26s\n",
      "2806:\tlearn: 0.0520512\ttotal: 7m 35s\tremaining: 19m 26s\n",
      "2807:\tlearn: 0.0520512\ttotal: 7m 35s\tremaining: 19m 25s\n",
      "2808:\tlearn: 0.0520512\ttotal: 7m 35s\tremaining: 19m 25s\n",
      "2809:\tlearn: 0.0520512\ttotal: 7m 35s\tremaining: 19m 25s\n",
      "2810:\tlearn: 0.0520512\ttotal: 7m 35s\tremaining: 19m 25s\n",
      "2811:\tlearn: 0.0520512\ttotal: 7m 35s\tremaining: 19m 25s\n",
      "2812:\tlearn: 0.0520512\ttotal: 7m 35s\tremaining: 19m 24s\n",
      "2813:\tlearn: 0.0520512\ttotal: 7m 36s\tremaining: 19m 24s\n",
      "2814:\tlearn: 0.0520512\ttotal: 7m 36s\tremaining: 19m 24s\n",
      "2815:\tlearn: 0.0520512\ttotal: 7m 36s\tremaining: 19m 24s\n",
      "2816:\tlearn: 0.0520512\ttotal: 7m 36s\tremaining: 19m 24s\n",
      "2817:\tlearn: 0.0520512\ttotal: 7m 36s\tremaining: 19m 23s\n",
      "2818:\tlearn: 0.0520512\ttotal: 7m 36s\tremaining: 19m 23s\n",
      "2819:\tlearn: 0.0520512\ttotal: 7m 36s\tremaining: 19m 23s\n",
      "2820:\tlearn: 0.0520512\ttotal: 7m 37s\tremaining: 19m 23s\n",
      "2821:\tlearn: 0.0520512\ttotal: 7m 37s\tremaining: 19m 23s\n",
      "2822:\tlearn: 0.0520512\ttotal: 7m 37s\tremaining: 19m 22s\n",
      "2823:\tlearn: 0.0520512\ttotal: 7m 37s\tremaining: 19m 22s\n",
      "2824:\tlearn: 0.0520512\ttotal: 7m 37s\tremaining: 19m 22s\n",
      "2825:\tlearn: 0.0520512\ttotal: 7m 37s\tremaining: 19m 22s\n",
      "2826:\tlearn: 0.0520512\ttotal: 7m 37s\tremaining: 19m 21s\n",
      "2827:\tlearn: 0.0520512\ttotal: 7m 38s\tremaining: 19m 21s\n",
      "2828:\tlearn: 0.0520512\ttotal: 7m 38s\tremaining: 19m 21s\n",
      "2829:\tlearn: 0.0520512\ttotal: 7m 38s\tremaining: 19m 21s\n",
      "2830:\tlearn: 0.0520512\ttotal: 7m 38s\tremaining: 19m 21s\n",
      "2831:\tlearn: 0.0520512\ttotal: 7m 38s\tremaining: 19m 20s\n",
      "2832:\tlearn: 0.0520512\ttotal: 7m 38s\tremaining: 19m 20s\n",
      "2833:\tlearn: 0.0520512\ttotal: 7m 38s\tremaining: 19m 20s\n",
      "2834:\tlearn: 0.0520512\ttotal: 7m 39s\tremaining: 19m 20s\n",
      "2835:\tlearn: 0.0520512\ttotal: 7m 39s\tremaining: 19m 20s\n",
      "2836:\tlearn: 0.0520512\ttotal: 7m 39s\tremaining: 19m 19s\n",
      "2837:\tlearn: 0.0520512\ttotal: 7m 39s\tremaining: 19m 19s\n",
      "2838:\tlearn: 0.0520512\ttotal: 7m 39s\tremaining: 19m 19s\n",
      "2839:\tlearn: 0.0520512\ttotal: 7m 39s\tremaining: 19m 19s\n",
      "2840:\tlearn: 0.0520512\ttotal: 7m 39s\tremaining: 19m 19s\n",
      "2841:\tlearn: 0.0520512\ttotal: 7m 40s\tremaining: 19m 18s\n",
      "2842:\tlearn: 0.0520512\ttotal: 7m 40s\tremaining: 19m 18s\n",
      "2843:\tlearn: 0.0520512\ttotal: 7m 40s\tremaining: 19m 18s\n",
      "2844:\tlearn: 0.0520512\ttotal: 7m 40s\tremaining: 19m 18s\n",
      "2845:\tlearn: 0.0520512\ttotal: 7m 40s\tremaining: 19m 17s\n",
      "2846:\tlearn: 0.0520512\ttotal: 7m 40s\tremaining: 19m 17s\n",
      "2847:\tlearn: 0.0520512\ttotal: 7m 40s\tremaining: 19m 17s\n",
      "2848:\tlearn: 0.0520512\ttotal: 7m 41s\tremaining: 19m 17s\n",
      "2849:\tlearn: 0.0520512\ttotal: 7m 41s\tremaining: 19m 17s\n",
      "2850:\tlearn: 0.0520512\ttotal: 7m 41s\tremaining: 19m 16s\n",
      "2851:\tlearn: 0.0520512\ttotal: 7m 41s\tremaining: 19m 16s\n",
      "2852:\tlearn: 0.0520512\ttotal: 7m 41s\tremaining: 19m 16s\n",
      "2853:\tlearn: 0.0520512\ttotal: 7m 41s\tremaining: 19m 16s\n",
      "2854:\tlearn: 0.0520512\ttotal: 7m 41s\tremaining: 19m 16s\n",
      "2855:\tlearn: 0.0520512\ttotal: 7m 42s\tremaining: 19m 15s\n",
      "2856:\tlearn: 0.0520512\ttotal: 7m 42s\tremaining: 19m 15s\n",
      "2857:\tlearn: 0.0520512\ttotal: 7m 42s\tremaining: 19m 15s\n",
      "2858:\tlearn: 0.0520512\ttotal: 7m 42s\tremaining: 19m 15s\n",
      "2859:\tlearn: 0.0520512\ttotal: 7m 42s\tremaining: 19m 15s\n",
      "2860:\tlearn: 0.0520512\ttotal: 7m 42s\tremaining: 19m 14s\n",
      "2861:\tlearn: 0.0520512\ttotal: 7m 42s\tremaining: 19m 14s\n",
      "2862:\tlearn: 0.0520512\ttotal: 7m 43s\tremaining: 19m 14s\n",
      "2863:\tlearn: 0.0520512\ttotal: 7m 43s\tremaining: 19m 14s\n",
      "2864:\tlearn: 0.0520512\ttotal: 7m 43s\tremaining: 19m 13s\n",
      "2865:\tlearn: 0.0520512\ttotal: 7m 43s\tremaining: 19m 13s\n",
      "2866:\tlearn: 0.0520512\ttotal: 7m 43s\tremaining: 19m 13s\n",
      "2867:\tlearn: 0.0520512\ttotal: 7m 43s\tremaining: 19m 13s\n",
      "2868:\tlearn: 0.0520512\ttotal: 7m 43s\tremaining: 19m 13s\n",
      "2869:\tlearn: 0.0520512\ttotal: 7m 44s\tremaining: 19m 12s\n",
      "2870:\tlearn: 0.0520512\ttotal: 7m 44s\tremaining: 19m 12s\n",
      "2871:\tlearn: 0.0520512\ttotal: 7m 44s\tremaining: 19m 12s\n",
      "2872:\tlearn: 0.0520512\ttotal: 7m 44s\tremaining: 19m 12s\n",
      "2873:\tlearn: 0.0520512\ttotal: 7m 44s\tremaining: 19m 12s\n",
      "2874:\tlearn: 0.0520512\ttotal: 7m 44s\tremaining: 19m 11s\n",
      "2875:\tlearn: 0.0520512\ttotal: 7m 44s\tremaining: 19m 11s\n",
      "2876:\tlearn: 0.0520512\ttotal: 7m 45s\tremaining: 19m 11s\n",
      "2877:\tlearn: 0.0520512\ttotal: 7m 45s\tremaining: 19m 11s\n",
      "2878:\tlearn: 0.0520512\ttotal: 7m 45s\tremaining: 19m 11s\n",
      "2879:\tlearn: 0.0520512\ttotal: 7m 45s\tremaining: 19m 10s\n",
      "2880:\tlearn: 0.0520512\ttotal: 7m 45s\tremaining: 19m 10s\n",
      "2881:\tlearn: 0.0520512\ttotal: 7m 45s\tremaining: 19m 10s\n",
      "2882:\tlearn: 0.0520512\ttotal: 7m 45s\tremaining: 19m 10s\n",
      "2883:\tlearn: 0.0520512\ttotal: 7m 46s\tremaining: 19m 10s\n",
      "2884:\tlearn: 0.0520512\ttotal: 7m 46s\tremaining: 19m 9s\n",
      "2885:\tlearn: 0.0520512\ttotal: 7m 46s\tremaining: 19m 9s\n",
      "2886:\tlearn: 0.0520512\ttotal: 7m 46s\tremaining: 19m 9s\n",
      "2887:\tlearn: 0.0520512\ttotal: 7m 46s\tremaining: 19m 9s\n",
      "2888:\tlearn: 0.0520512\ttotal: 7m 46s\tremaining: 19m 9s\n",
      "2889:\tlearn: 0.0520512\ttotal: 7m 46s\tremaining: 19m 8s\n",
      "2890:\tlearn: 0.0520512\ttotal: 7m 47s\tremaining: 19m 8s\n",
      "2891:\tlearn: 0.0520512\ttotal: 7m 47s\tremaining: 19m 8s\n",
      "2892:\tlearn: 0.0520512\ttotal: 7m 47s\tremaining: 19m 8s\n",
      "2893:\tlearn: 0.0520512\ttotal: 7m 47s\tremaining: 19m 7s\n",
      "2894:\tlearn: 0.0520512\ttotal: 7m 47s\tremaining: 19m 7s\n",
      "2895:\tlearn: 0.0520512\ttotal: 7m 47s\tremaining: 19m 7s\n",
      "2896:\tlearn: 0.0520512\ttotal: 7m 47s\tremaining: 19m 7s\n",
      "2897:\tlearn: 0.0520512\ttotal: 7m 48s\tremaining: 19m 7s\n",
      "2898:\tlearn: 0.0520512\ttotal: 7m 48s\tremaining: 19m 6s\n",
      "2899:\tlearn: 0.0520512\ttotal: 7m 48s\tremaining: 19m 6s\n",
      "2900:\tlearn: 0.0520512\ttotal: 7m 48s\tremaining: 19m 6s\n",
      "2901:\tlearn: 0.0520512\ttotal: 7m 48s\tremaining: 19m 6s\n",
      "2902:\tlearn: 0.0520512\ttotal: 7m 48s\tremaining: 19m 6s\n",
      "2903:\tlearn: 0.0520512\ttotal: 7m 48s\tremaining: 19m 5s\n",
      "2904:\tlearn: 0.0520512\ttotal: 7m 49s\tremaining: 19m 5s\n",
      "2905:\tlearn: 0.0520512\ttotal: 7m 49s\tremaining: 19m 5s\n",
      "2906:\tlearn: 0.0520512\ttotal: 7m 49s\tremaining: 19m 5s\n",
      "2907:\tlearn: 0.0520512\ttotal: 7m 49s\tremaining: 19m 5s\n",
      "2908:\tlearn: 0.0520512\ttotal: 7m 49s\tremaining: 19m 4s\n",
      "2909:\tlearn: 0.0520512\ttotal: 7m 49s\tremaining: 19m 4s\n",
      "2910:\tlearn: 0.0520512\ttotal: 7m 49s\tremaining: 19m 4s\n",
      "2911:\tlearn: 0.0520512\ttotal: 7m 50s\tremaining: 19m 4s\n",
      "2912:\tlearn: 0.0520512\ttotal: 7m 50s\tremaining: 19m 4s\n",
      "2913:\tlearn: 0.0520512\ttotal: 7m 50s\tremaining: 19m 3s\n",
      "2914:\tlearn: 0.0520512\ttotal: 7m 50s\tremaining: 19m 3s\n",
      "2915:\tlearn: 0.0520512\ttotal: 7m 50s\tremaining: 19m 3s\n",
      "2916:\tlearn: 0.0520512\ttotal: 7m 50s\tremaining: 19m 3s\n",
      "2917:\tlearn: 0.0520512\ttotal: 7m 50s\tremaining: 19m 2s\n",
      "2918:\tlearn: 0.0520512\ttotal: 7m 51s\tremaining: 19m 2s\n",
      "2919:\tlearn: 0.0520512\ttotal: 7m 51s\tremaining: 19m 2s\n",
      "2920:\tlearn: 0.0520512\ttotal: 7m 51s\tremaining: 19m 2s\n",
      "2921:\tlearn: 0.0520512\ttotal: 7m 51s\tremaining: 19m 2s\n",
      "2922:\tlearn: 0.0520512\ttotal: 7m 51s\tremaining: 19m 1s\n",
      "2923:\tlearn: 0.0520512\ttotal: 7m 51s\tremaining: 19m 1s\n",
      "2924:\tlearn: 0.0520512\ttotal: 7m 51s\tremaining: 19m 1s\n",
      "2925:\tlearn: 0.0520512\ttotal: 7m 52s\tremaining: 19m 1s\n",
      "2926:\tlearn: 0.0520512\ttotal: 7m 52s\tremaining: 19m 1s\n",
      "2927:\tlearn: 0.0520512\ttotal: 7m 52s\tremaining: 19m\n",
      "2928:\tlearn: 0.0520512\ttotal: 7m 52s\tremaining: 19m\n",
      "2929:\tlearn: 0.0520512\ttotal: 7m 52s\tremaining: 19m\n",
      "2930:\tlearn: 0.0520512\ttotal: 7m 52s\tremaining: 19m\n",
      "2931:\tlearn: 0.0520512\ttotal: 7m 52s\tremaining: 19m\n",
      "2932:\tlearn: 0.0520512\ttotal: 7m 53s\tremaining: 18m 59s\n",
      "2933:\tlearn: 0.0520512\ttotal: 7m 53s\tremaining: 18m 59s\n",
      "2934:\tlearn: 0.0520512\ttotal: 7m 53s\tremaining: 18m 59s\n",
      "2935:\tlearn: 0.0520512\ttotal: 7m 53s\tremaining: 18m 59s\n",
      "2936:\tlearn: 0.0520512\ttotal: 7m 53s\tremaining: 18m 59s\n",
      "2937:\tlearn: 0.0520512\ttotal: 7m 53s\tremaining: 18m 58s\n",
      "2938:\tlearn: 0.0520512\ttotal: 7m 53s\tremaining: 18m 58s\n",
      "2939:\tlearn: 0.0520512\ttotal: 7m 54s\tremaining: 18m 58s\n",
      "2940:\tlearn: 0.0520512\ttotal: 7m 54s\tremaining: 18m 58s\n",
      "2941:\tlearn: 0.0520512\ttotal: 7m 54s\tremaining: 18m 58s\n",
      "2942:\tlearn: 0.0520512\ttotal: 7m 54s\tremaining: 18m 57s\n",
      "2943:\tlearn: 0.0520512\ttotal: 7m 54s\tremaining: 18m 57s\n",
      "2944:\tlearn: 0.0520512\ttotal: 7m 54s\tremaining: 18m 57s\n",
      "2945:\tlearn: 0.0520512\ttotal: 7m 54s\tremaining: 18m 57s\n",
      "2946:\tlearn: 0.0520512\ttotal: 7m 55s\tremaining: 18m 56s\n",
      "2947:\tlearn: 0.0520512\ttotal: 7m 55s\tremaining: 18m 56s\n",
      "2948:\tlearn: 0.0520512\ttotal: 7m 55s\tremaining: 18m 56s\n",
      "2949:\tlearn: 0.0520512\ttotal: 7m 55s\tremaining: 18m 56s\n",
      "2950:\tlearn: 0.0520512\ttotal: 7m 55s\tremaining: 18m 56s\n",
      "2951:\tlearn: 0.0520512\ttotal: 7m 55s\tremaining: 18m 55s\n",
      "2952:\tlearn: 0.0520512\ttotal: 7m 55s\tremaining: 18m 55s\n",
      "2953:\tlearn: 0.0520512\ttotal: 7m 56s\tremaining: 18m 55s\n",
      "2954:\tlearn: 0.0520512\ttotal: 7m 56s\tremaining: 18m 55s\n",
      "2955:\tlearn: 0.0520512\ttotal: 7m 56s\tremaining: 18m 55s\n",
      "2956:\tlearn: 0.0520512\ttotal: 7m 56s\tremaining: 18m 54s\n",
      "2957:\tlearn: 0.0520512\ttotal: 7m 56s\tremaining: 18m 54s\n",
      "2958:\tlearn: 0.0520512\ttotal: 7m 56s\tremaining: 18m 54s\n",
      "2959:\tlearn: 0.0520512\ttotal: 7m 56s\tremaining: 18m 54s\n",
      "2960:\tlearn: 0.0520512\ttotal: 7m 57s\tremaining: 18m 54s\n",
      "2961:\tlearn: 0.0520512\ttotal: 7m 57s\tremaining: 18m 53s\n",
      "2962:\tlearn: 0.0520512\ttotal: 7m 57s\tremaining: 18m 53s\n",
      "2963:\tlearn: 0.0520512\ttotal: 7m 57s\tremaining: 18m 53s\n",
      "2964:\tlearn: 0.0520512\ttotal: 7m 57s\tremaining: 18m 53s\n",
      "2965:\tlearn: 0.0520512\ttotal: 7m 57s\tremaining: 18m 53s\n",
      "2966:\tlearn: 0.0520512\ttotal: 7m 57s\tremaining: 18m 52s\n",
      "2967:\tlearn: 0.0520512\ttotal: 7m 58s\tremaining: 18m 52s\n",
      "2968:\tlearn: 0.0520512\ttotal: 7m 58s\tremaining: 18m 52s\n",
      "2969:\tlearn: 0.0520512\ttotal: 7m 58s\tremaining: 18m 52s\n",
      "2970:\tlearn: 0.0520512\ttotal: 7m 58s\tremaining: 18m 52s\n",
      "2971:\tlearn: 0.0520512\ttotal: 7m 58s\tremaining: 18m 51s\n",
      "2972:\tlearn: 0.0520512\ttotal: 7m 58s\tremaining: 18m 51s\n",
      "2973:\tlearn: 0.0520512\ttotal: 7m 58s\tremaining: 18m 51s\n",
      "2974:\tlearn: 0.0520512\ttotal: 7m 59s\tremaining: 18m 51s\n",
      "2975:\tlearn: 0.0520512\ttotal: 7m 59s\tremaining: 18m 51s\n",
      "2976:\tlearn: 0.0520512\ttotal: 7m 59s\tremaining: 18m 50s\n",
      "2977:\tlearn: 0.0520512\ttotal: 7m 59s\tremaining: 18m 50s\n",
      "2978:\tlearn: 0.0520512\ttotal: 7m 59s\tremaining: 18m 50s\n",
      "2979:\tlearn: 0.0520512\ttotal: 7m 59s\tremaining: 18m 50s\n",
      "2980:\tlearn: 0.0520512\ttotal: 7m 59s\tremaining: 18m 50s\n",
      "2981:\tlearn: 0.0520512\ttotal: 8m\tremaining: 18m 49s\n",
      "2982:\tlearn: 0.0520512\ttotal: 8m\tremaining: 18m 49s\n",
      "2983:\tlearn: 0.0520512\ttotal: 8m\tremaining: 18m 49s\n",
      "2984:\tlearn: 0.0520512\ttotal: 8m\tremaining: 18m 49s\n",
      "2985:\tlearn: 0.0520512\ttotal: 8m\tremaining: 18m 48s\n",
      "2986:\tlearn: 0.0520512\ttotal: 8m\tremaining: 18m 48s\n",
      "2987:\tlearn: 0.0520512\ttotal: 8m\tremaining: 18m 48s\n",
      "2988:\tlearn: 0.0520512\ttotal: 8m 1s\tremaining: 18m 48s\n",
      "2989:\tlearn: 0.0520512\ttotal: 8m 1s\tremaining: 18m 48s\n",
      "2990:\tlearn: 0.0520512\ttotal: 8m 1s\tremaining: 18m 47s\n",
      "2991:\tlearn: 0.0520512\ttotal: 8m 1s\tremaining: 18m 47s\n",
      "2992:\tlearn: 0.0520512\ttotal: 8m 1s\tremaining: 18m 47s\n",
      "2993:\tlearn: 0.0520512\ttotal: 8m 1s\tremaining: 18m 47s\n",
      "2994:\tlearn: 0.0520512\ttotal: 8m 1s\tremaining: 18m 47s\n",
      "2995:\tlearn: 0.0520512\ttotal: 8m 2s\tremaining: 18m 46s\n",
      "2996:\tlearn: 0.0520512\ttotal: 8m 2s\tremaining: 18m 46s\n",
      "2997:\tlearn: 0.0520512\ttotal: 8m 2s\tremaining: 18m 46s\n",
      "2998:\tlearn: 0.0520512\ttotal: 8m 2s\tremaining: 18m 46s\n",
      "2999:\tlearn: 0.0520512\ttotal: 8m 2s\tremaining: 18m 46s\n",
      "3000:\tlearn: 0.0520512\ttotal: 8m 2s\tremaining: 18m 46s\n",
      "3001:\tlearn: 0.0520512\ttotal: 8m 2s\tremaining: 18m 45s\n",
      "3002:\tlearn: 0.0520512\ttotal: 8m 3s\tremaining: 18m 45s\n",
      "3003:\tlearn: 0.0520512\ttotal: 8m 3s\tremaining: 18m 45s\n",
      "3004:\tlearn: 0.0520512\ttotal: 8m 3s\tremaining: 18m 45s\n",
      "3005:\tlearn: 0.0520512\ttotal: 8m 3s\tremaining: 18m 45s\n",
      "3006:\tlearn: 0.0520512\ttotal: 8m 3s\tremaining: 18m 44s\n",
      "3007:\tlearn: 0.0520512\ttotal: 8m 3s\tremaining: 18m 44s\n",
      "3008:\tlearn: 0.0520512\ttotal: 8m 4s\tremaining: 18m 44s\n",
      "3009:\tlearn: 0.0520512\ttotal: 8m 4s\tremaining: 18m 44s\n",
      "3010:\tlearn: 0.0520512\ttotal: 8m 4s\tremaining: 18m 44s\n",
      "3011:\tlearn: 0.0520512\ttotal: 8m 4s\tremaining: 18m 44s\n",
      "3012:\tlearn: 0.0520512\ttotal: 8m 4s\tremaining: 18m 43s\n",
      "3013:\tlearn: 0.0520512\ttotal: 8m 4s\tremaining: 18m 43s\n",
      "3014:\tlearn: 0.0520512\ttotal: 8m 4s\tremaining: 18m 43s\n",
      "3015:\tlearn: 0.0520512\ttotal: 8m 5s\tremaining: 18m 43s\n",
      "3016:\tlearn: 0.0520512\ttotal: 8m 5s\tremaining: 18m 43s\n",
      "3017:\tlearn: 0.0520512\ttotal: 8m 5s\tremaining: 18m 42s\n",
      "3018:\tlearn: 0.0520512\ttotal: 8m 5s\tremaining: 18m 42s\n",
      "3019:\tlearn: 0.0520512\ttotal: 8m 5s\tremaining: 18m 42s\n",
      "3020:\tlearn: 0.0520512\ttotal: 8m 5s\tremaining: 18m 42s\n",
      "3021:\tlearn: 0.0520512\ttotal: 8m 5s\tremaining: 18m 42s\n",
      "3022:\tlearn: 0.0520512\ttotal: 8m 6s\tremaining: 18m 41s\n",
      "3023:\tlearn: 0.0520512\ttotal: 8m 6s\tremaining: 18m 41s\n",
      "3024:\tlearn: 0.0520512\ttotal: 8m 6s\tremaining: 18m 41s\n",
      "3025:\tlearn: 0.0520512\ttotal: 8m 6s\tremaining: 18m 41s\n",
      "3026:\tlearn: 0.0520512\ttotal: 8m 6s\tremaining: 18m 41s\n",
      "3027:\tlearn: 0.0520512\ttotal: 8m 6s\tremaining: 18m 40s\n",
      "3028:\tlearn: 0.0520512\ttotal: 8m 6s\tremaining: 18m 40s\n",
      "3029:\tlearn: 0.0520512\ttotal: 8m 7s\tremaining: 18m 40s\n",
      "3030:\tlearn: 0.0520512\ttotal: 8m 7s\tremaining: 18m 40s\n",
      "3031:\tlearn: 0.0520512\ttotal: 8m 7s\tremaining: 18m 40s\n",
      "3032:\tlearn: 0.0520512\ttotal: 8m 7s\tremaining: 18m 40s\n",
      "3033:\tlearn: 0.0520512\ttotal: 8m 7s\tremaining: 18m 39s\n",
      "3034:\tlearn: 0.0520512\ttotal: 8m 7s\tremaining: 18m 39s\n",
      "3035:\tlearn: 0.0520512\ttotal: 8m 8s\tremaining: 18m 39s\n",
      "3036:\tlearn: 0.0520512\ttotal: 8m 8s\tremaining: 18m 39s\n",
      "3037:\tlearn: 0.0520512\ttotal: 8m 8s\tremaining: 18m 39s\n",
      "3038:\tlearn: 0.0520512\ttotal: 8m 8s\tremaining: 18m 39s\n",
      "3039:\tlearn: 0.0520512\ttotal: 8m 8s\tremaining: 18m 39s\n",
      "3040:\tlearn: 0.0520512\ttotal: 8m 8s\tremaining: 18m 38s\n",
      "3041:\tlearn: 0.0520512\ttotal: 8m 9s\tremaining: 18m 38s\n",
      "3042:\tlearn: 0.0520512\ttotal: 8m 9s\tremaining: 18m 38s\n",
      "3043:\tlearn: 0.0520512\ttotal: 8m 9s\tremaining: 18m 38s\n",
      "3044:\tlearn: 0.0520512\ttotal: 8m 9s\tremaining: 18m 38s\n",
      "3045:\tlearn: 0.0520512\ttotal: 8m 9s\tremaining: 18m 38s\n",
      "3046:\tlearn: 0.0520512\ttotal: 8m 9s\tremaining: 18m 37s\n",
      "3047:\tlearn: 0.0520512\ttotal: 8m 10s\tremaining: 18m 37s\n",
      "3048:\tlearn: 0.0520512\ttotal: 8m 10s\tremaining: 18m 37s\n",
      "3049:\tlearn: 0.0520512\ttotal: 8m 10s\tremaining: 18m 37s\n",
      "3050:\tlearn: 0.0520512\ttotal: 8m 10s\tremaining: 18m 37s\n",
      "3051:\tlearn: 0.0520512\ttotal: 8m 10s\tremaining: 18m 36s\n",
      "3052:\tlearn: 0.0520512\ttotal: 8m 10s\tremaining: 18m 36s\n",
      "3053:\tlearn: 0.0520512\ttotal: 8m 10s\tremaining: 18m 36s\n",
      "3054:\tlearn: 0.0520512\ttotal: 8m 11s\tremaining: 18m 36s\n",
      "3055:\tlearn: 0.0520512\ttotal: 8m 11s\tremaining: 18m 36s\n",
      "3056:\tlearn: 0.0520512\ttotal: 8m 11s\tremaining: 18m 36s\n",
      "3057:\tlearn: 0.0520512\ttotal: 8m 11s\tremaining: 18m 35s\n",
      "3058:\tlearn: 0.0520512\ttotal: 8m 11s\tremaining: 18m 35s\n",
      "3059:\tlearn: 0.0520512\ttotal: 8m 11s\tremaining: 18m 35s\n",
      "3060:\tlearn: 0.0520512\ttotal: 8m 11s\tremaining: 18m 35s\n",
      "3061:\tlearn: 0.0520512\ttotal: 8m 12s\tremaining: 18m 35s\n",
      "3062:\tlearn: 0.0520512\ttotal: 8m 12s\tremaining: 18m 34s\n",
      "3063:\tlearn: 0.0520512\ttotal: 8m 12s\tremaining: 18m 34s\n",
      "3064:\tlearn: 0.0520512\ttotal: 8m 12s\tremaining: 18m 34s\n",
      "3065:\tlearn: 0.0520512\ttotal: 8m 12s\tremaining: 18m 34s\n",
      "3066:\tlearn: 0.0520512\ttotal: 8m 12s\tremaining: 18m 34s\n",
      "3067:\tlearn: 0.0520512\ttotal: 8m 13s\tremaining: 18m 34s\n",
      "3068:\tlearn: 0.0520512\ttotal: 8m 13s\tremaining: 18m 33s\n",
      "3069:\tlearn: 0.0520512\ttotal: 8m 13s\tremaining: 18m 33s\n",
      "3070:\tlearn: 0.0520512\ttotal: 8m 13s\tremaining: 18m 33s\n",
      "3071:\tlearn: 0.0520512\ttotal: 8m 13s\tremaining: 18m 33s\n",
      "3072:\tlearn: 0.0520512\ttotal: 8m 13s\tremaining: 18m 33s\n",
      "3073:\tlearn: 0.0520512\ttotal: 8m 13s\tremaining: 18m 32s\n",
      "3074:\tlearn: 0.0520512\ttotal: 8m 14s\tremaining: 18m 32s\n",
      "3075:\tlearn: 0.0520512\ttotal: 8m 14s\tremaining: 18m 32s\n",
      "3076:\tlearn: 0.0520512\ttotal: 8m 14s\tremaining: 18m 32s\n",
      "3077:\tlearn: 0.0520512\ttotal: 8m 14s\tremaining: 18m 32s\n",
      "3078:\tlearn: 0.0520512\ttotal: 8m 14s\tremaining: 18m 31s\n",
      "3079:\tlearn: 0.0520512\ttotal: 8m 14s\tremaining: 18m 31s\n",
      "3080:\tlearn: 0.0520512\ttotal: 8m 15s\tremaining: 18m 31s\n",
      "3081:\tlearn: 0.0520512\ttotal: 8m 15s\tremaining: 18m 31s\n",
      "3082:\tlearn: 0.0520512\ttotal: 8m 15s\tremaining: 18m 31s\n",
      "3083:\tlearn: 0.0520512\ttotal: 8m 15s\tremaining: 18m 31s\n",
      "3084:\tlearn: 0.0520512\ttotal: 8m 15s\tremaining: 18m 30s\n",
      "3085:\tlearn: 0.0520512\ttotal: 8m 15s\tremaining: 18m 30s\n",
      "3086:\tlearn: 0.0520512\ttotal: 8m 15s\tremaining: 18m 30s\n",
      "3087:\tlearn: 0.0520512\ttotal: 8m 16s\tremaining: 18m 30s\n",
      "3088:\tlearn: 0.0520512\ttotal: 8m 16s\tremaining: 18m 30s\n",
      "3089:\tlearn: 0.0520512\ttotal: 8m 16s\tremaining: 18m 29s\n",
      "3090:\tlearn: 0.0520512\ttotal: 8m 16s\tremaining: 18m 29s\n",
      "3091:\tlearn: 0.0520512\ttotal: 8m 16s\tremaining: 18m 29s\n",
      "3092:\tlearn: 0.0520512\ttotal: 8m 16s\tremaining: 18m 29s\n",
      "3093:\tlearn: 0.0520512\ttotal: 8m 16s\tremaining: 18m 29s\n",
      "3094:\tlearn: 0.0520512\ttotal: 8m 17s\tremaining: 18m 29s\n",
      "3095:\tlearn: 0.0520512\ttotal: 8m 17s\tremaining: 18m 28s\n",
      "3096:\tlearn: 0.0520512\ttotal: 8m 17s\tremaining: 18m 28s\n",
      "3097:\tlearn: 0.0520512\ttotal: 8m 17s\tremaining: 18m 28s\n",
      "3098:\tlearn: 0.0520512\ttotal: 8m 17s\tremaining: 18m 28s\n",
      "3099:\tlearn: 0.0520512\ttotal: 8m 17s\tremaining: 18m 28s\n",
      "3100:\tlearn: 0.0520512\ttotal: 8m 17s\tremaining: 18m 27s\n",
      "3101:\tlearn: 0.0520512\ttotal: 8m 18s\tremaining: 18m 27s\n",
      "3102:\tlearn: 0.0520512\ttotal: 8m 18s\tremaining: 18m 27s\n",
      "3103:\tlearn: 0.0520512\ttotal: 8m 18s\tremaining: 18m 27s\n",
      "3104:\tlearn: 0.0520512\ttotal: 8m 18s\tremaining: 18m 27s\n",
      "3105:\tlearn: 0.0520512\ttotal: 8m 18s\tremaining: 18m 26s\n",
      "3106:\tlearn: 0.0520512\ttotal: 8m 18s\tremaining: 18m 26s\n",
      "3107:\tlearn: 0.0520512\ttotal: 8m 19s\tremaining: 18m 26s\n",
      "3108:\tlearn: 0.0520512\ttotal: 8m 19s\tremaining: 18m 26s\n",
      "3109:\tlearn: 0.0520512\ttotal: 8m 19s\tremaining: 18m 26s\n",
      "3110:\tlearn: 0.0520512\ttotal: 8m 19s\tremaining: 18m 26s\n",
      "3111:\tlearn: 0.0520512\ttotal: 8m 19s\tremaining: 18m 25s\n",
      "3112:\tlearn: 0.0520512\ttotal: 8m 19s\tremaining: 18m 25s\n",
      "3113:\tlearn: 0.0520512\ttotal: 8m 19s\tremaining: 18m 25s\n",
      "3114:\tlearn: 0.0520512\ttotal: 8m 20s\tremaining: 18m 25s\n",
      "3115:\tlearn: 0.0520512\ttotal: 8m 20s\tremaining: 18m 25s\n",
      "3116:\tlearn: 0.0520512\ttotal: 8m 20s\tremaining: 18m 24s\n",
      "3117:\tlearn: 0.0520512\ttotal: 8m 20s\tremaining: 18m 24s\n",
      "3118:\tlearn: 0.0520512\ttotal: 8m 20s\tremaining: 18m 24s\n",
      "3119:\tlearn: 0.0520512\ttotal: 8m 20s\tremaining: 18m 24s\n",
      "3120:\tlearn: 0.0520512\ttotal: 8m 20s\tremaining: 18m 24s\n",
      "3121:\tlearn: 0.0520512\ttotal: 8m 21s\tremaining: 18m 24s\n",
      "3122:\tlearn: 0.0520512\ttotal: 8m 21s\tremaining: 18m 23s\n",
      "3123:\tlearn: 0.0520512\ttotal: 8m 21s\tremaining: 18m 23s\n",
      "3124:\tlearn: 0.0520512\ttotal: 8m 21s\tremaining: 18m 23s\n",
      "3125:\tlearn: 0.0520512\ttotal: 8m 21s\tremaining: 18m 23s\n",
      "3126:\tlearn: 0.0520512\ttotal: 8m 21s\tremaining: 18m 23s\n",
      "3127:\tlearn: 0.0520512\ttotal: 8m 22s\tremaining: 18m 22s\n",
      "3128:\tlearn: 0.0520512\ttotal: 8m 22s\tremaining: 18m 22s\n",
      "3129:\tlearn: 0.0520512\ttotal: 8m 22s\tremaining: 18m 22s\n",
      "3130:\tlearn: 0.0520512\ttotal: 8m 22s\tremaining: 18m 22s\n",
      "3131:\tlearn: 0.0520512\ttotal: 8m 22s\tremaining: 18m 22s\n",
      "3132:\tlearn: 0.0520512\ttotal: 8m 22s\tremaining: 18m 22s\n",
      "3133:\tlearn: 0.0520512\ttotal: 8m 22s\tremaining: 18m 21s\n",
      "3134:\tlearn: 0.0520512\ttotal: 8m 23s\tremaining: 18m 21s\n",
      "3135:\tlearn: 0.0520512\ttotal: 8m 23s\tremaining: 18m 21s\n",
      "3136:\tlearn: 0.0520512\ttotal: 8m 23s\tremaining: 18m 21s\n",
      "3137:\tlearn: 0.0520512\ttotal: 8m 23s\tremaining: 18m 21s\n",
      "3138:\tlearn: 0.0520512\ttotal: 8m 23s\tremaining: 18m 20s\n",
      "3139:\tlearn: 0.0520512\ttotal: 8m 23s\tremaining: 18m 20s\n",
      "3140:\tlearn: 0.0520512\ttotal: 8m 23s\tremaining: 18m 20s\n",
      "3141:\tlearn: 0.0520512\ttotal: 8m 24s\tremaining: 18m 20s\n",
      "3142:\tlearn: 0.0520512\ttotal: 8m 24s\tremaining: 18m 20s\n",
      "3143:\tlearn: 0.0520512\ttotal: 8m 24s\tremaining: 18m 20s\n",
      "3144:\tlearn: 0.0520512\ttotal: 8m 24s\tremaining: 18m 19s\n",
      "3145:\tlearn: 0.0520512\ttotal: 8m 24s\tremaining: 18m 19s\n",
      "3146:\tlearn: 0.0520512\ttotal: 8m 24s\tremaining: 18m 19s\n",
      "3147:\tlearn: 0.0520512\ttotal: 8m 25s\tremaining: 18m 19s\n",
      "3148:\tlearn: 0.0520512\ttotal: 8m 25s\tremaining: 18m 19s\n",
      "3149:\tlearn: 0.0520512\ttotal: 8m 25s\tremaining: 18m 18s\n",
      "3150:\tlearn: 0.0520512\ttotal: 8m 25s\tremaining: 18m 18s\n",
      "3151:\tlearn: 0.0520512\ttotal: 8m 25s\tremaining: 18m 18s\n",
      "3152:\tlearn: 0.0520512\ttotal: 8m 25s\tremaining: 18m 18s\n",
      "3153:\tlearn: 0.0520512\ttotal: 8m 26s\tremaining: 18m 18s\n",
      "3154:\tlearn: 0.0520512\ttotal: 8m 26s\tremaining: 18m 18s\n",
      "3155:\tlearn: 0.0520512\ttotal: 8m 26s\tremaining: 18m 18s\n",
      "3156:\tlearn: 0.0520512\ttotal: 8m 26s\tremaining: 18m 17s\n",
      "3157:\tlearn: 0.0520512\ttotal: 8m 26s\tremaining: 18m 17s\n",
      "3158:\tlearn: 0.0520512\ttotal: 8m 26s\tremaining: 18m 17s\n",
      "3159:\tlearn: 0.0520512\ttotal: 8m 26s\tremaining: 18m 17s\n",
      "3160:\tlearn: 0.0520512\ttotal: 8m 27s\tremaining: 18m 17s\n",
      "3161:\tlearn: 0.0520512\ttotal: 8m 27s\tremaining: 18m 17s\n",
      "3162:\tlearn: 0.0520512\ttotal: 8m 27s\tremaining: 18m 16s\n",
      "3163:\tlearn: 0.0520512\ttotal: 8m 27s\tremaining: 18m 16s\n",
      "3164:\tlearn: 0.0520512\ttotal: 8m 27s\tremaining: 18m 16s\n",
      "3165:\tlearn: 0.0520512\ttotal: 8m 27s\tremaining: 18m 16s\n",
      "3166:\tlearn: 0.0520512\ttotal: 8m 28s\tremaining: 18m 16s\n",
      "3167:\tlearn: 0.0520512\ttotal: 8m 28s\tremaining: 18m 16s\n",
      "3168:\tlearn: 0.0520512\ttotal: 8m 28s\tremaining: 18m 16s\n",
      "3169:\tlearn: 0.0520512\ttotal: 8m 28s\tremaining: 18m 15s\n",
      "3170:\tlearn: 0.0520512\ttotal: 8m 28s\tremaining: 18m 15s\n",
      "3171:\tlearn: 0.0520512\ttotal: 8m 28s\tremaining: 18m 15s\n",
      "3172:\tlearn: 0.0520512\ttotal: 8m 29s\tremaining: 18m 15s\n",
      "3173:\tlearn: 0.0520512\ttotal: 8m 29s\tremaining: 18m 15s\n",
      "3174:\tlearn: 0.0520512\ttotal: 8m 29s\tremaining: 18m 15s\n",
      "3175:\tlearn: 0.0520512\ttotal: 8m 29s\tremaining: 18m 15s\n",
      "3176:\tlearn: 0.0520512\ttotal: 8m 29s\tremaining: 18m 14s\n",
      "3177:\tlearn: 0.0520512\ttotal: 8m 29s\tremaining: 18m 14s\n",
      "3178:\tlearn: 0.0520512\ttotal: 8m 30s\tremaining: 18m 14s\n",
      "3179:\tlearn: 0.0520512\ttotal: 8m 30s\tremaining: 18m 14s\n",
      "3180:\tlearn: 0.0520512\ttotal: 8m 30s\tremaining: 18m 14s\n",
      "3181:\tlearn: 0.0520512\ttotal: 8m 30s\tremaining: 18m 14s\n",
      "3182:\tlearn: 0.0520512\ttotal: 8m 30s\tremaining: 18m 13s\n",
      "3183:\tlearn: 0.0520512\ttotal: 8m 30s\tremaining: 18m 13s\n",
      "3184:\tlearn: 0.0520512\ttotal: 8m 31s\tremaining: 18m 13s\n",
      "3185:\tlearn: 0.0520512\ttotal: 8m 31s\tremaining: 18m 13s\n",
      "3186:\tlearn: 0.0520512\ttotal: 8m 31s\tremaining: 18m 13s\n",
      "3187:\tlearn: 0.0520512\ttotal: 8m 31s\tremaining: 18m 13s\n",
      "3188:\tlearn: 0.0520512\ttotal: 8m 31s\tremaining: 18m 12s\n",
      "3189:\tlearn: 0.0520512\ttotal: 8m 31s\tremaining: 18m 12s\n",
      "3190:\tlearn: 0.0520512\ttotal: 8m 32s\tremaining: 18m 12s\n",
      "3191:\tlearn: 0.0520512\ttotal: 8m 32s\tremaining: 18m 12s\n",
      "3192:\tlearn: 0.0520512\ttotal: 8m 32s\tremaining: 18m 12s\n",
      "3193:\tlearn: 0.0520512\ttotal: 8m 32s\tremaining: 18m 12s\n",
      "3194:\tlearn: 0.0520512\ttotal: 8m 32s\tremaining: 18m 11s\n",
      "3195:\tlearn: 0.0520512\ttotal: 8m 32s\tremaining: 18m 11s\n",
      "3196:\tlearn: 0.0520512\ttotal: 8m 32s\tremaining: 18m 11s\n",
      "3197:\tlearn: 0.0520512\ttotal: 8m 33s\tremaining: 18m 11s\n",
      "3198:\tlearn: 0.0520512\ttotal: 8m 33s\tremaining: 18m 11s\n",
      "3199:\tlearn: 0.0520512\ttotal: 8m 33s\tremaining: 18m 11s\n",
      "3200:\tlearn: 0.0520512\ttotal: 8m 33s\tremaining: 18m 10s\n",
      "3201:\tlearn: 0.0520512\ttotal: 8m 33s\tremaining: 18m 10s\n",
      "3202:\tlearn: 0.0520512\ttotal: 8m 33s\tremaining: 18m 10s\n",
      "3203:\tlearn: 0.0520512\ttotal: 8m 34s\tremaining: 18m 10s\n",
      "3204:\tlearn: 0.0520512\ttotal: 8m 34s\tremaining: 18m 10s\n",
      "3205:\tlearn: 0.0520512\ttotal: 8m 34s\tremaining: 18m 10s\n",
      "3206:\tlearn: 0.0520512\ttotal: 8m 34s\tremaining: 18m 9s\n",
      "3207:\tlearn: 0.0520512\ttotal: 8m 34s\tremaining: 18m 9s\n",
      "3208:\tlearn: 0.0520512\ttotal: 8m 34s\tremaining: 18m 9s\n",
      "3209:\tlearn: 0.0520512\ttotal: 8m 34s\tremaining: 18m 9s\n",
      "3210:\tlearn: 0.0520512\ttotal: 8m 35s\tremaining: 18m 9s\n",
      "3211:\tlearn: 0.0520512\ttotal: 8m 35s\tremaining: 18m 8s\n",
      "3212:\tlearn: 0.0520512\ttotal: 8m 35s\tremaining: 18m 8s\n",
      "3213:\tlearn: 0.0520512\ttotal: 8m 35s\tremaining: 18m 8s\n",
      "3214:\tlearn: 0.0520512\ttotal: 8m 35s\tremaining: 18m 8s\n",
      "3215:\tlearn: 0.0520512\ttotal: 8m 35s\tremaining: 18m 8s\n",
      "3216:\tlearn: 0.0520512\ttotal: 8m 36s\tremaining: 18m 8s\n",
      "3217:\tlearn: 0.0520512\ttotal: 8m 36s\tremaining: 18m 7s\n",
      "3218:\tlearn: 0.0520512\ttotal: 8m 36s\tremaining: 18m 7s\n",
      "3219:\tlearn: 0.0520512\ttotal: 8m 36s\tremaining: 18m 7s\n",
      "3220:\tlearn: 0.0520512\ttotal: 8m 36s\tremaining: 18m 7s\n",
      "3221:\tlearn: 0.0520512\ttotal: 8m 36s\tremaining: 18m 7s\n",
      "3222:\tlearn: 0.0520512\ttotal: 8m 36s\tremaining: 18m 7s\n",
      "3223:\tlearn: 0.0520512\ttotal: 8m 37s\tremaining: 18m 6s\n",
      "3224:\tlearn: 0.0520512\ttotal: 8m 37s\tremaining: 18m 6s\n",
      "3225:\tlearn: 0.0520512\ttotal: 8m 37s\tremaining: 18m 6s\n",
      "3226:\tlearn: 0.0520512\ttotal: 8m 37s\tremaining: 18m 6s\n",
      "3227:\tlearn: 0.0520512\ttotal: 8m 37s\tremaining: 18m 6s\n",
      "3228:\tlearn: 0.0520512\ttotal: 8m 37s\tremaining: 18m 5s\n",
      "3229:\tlearn: 0.0520512\ttotal: 8m 38s\tremaining: 18m 5s\n",
      "3230:\tlearn: 0.0520512\ttotal: 8m 38s\tremaining: 18m 5s\n",
      "3231:\tlearn: 0.0520512\ttotal: 8m 38s\tremaining: 18m 5s\n",
      "3232:\tlearn: 0.0520512\ttotal: 8m 38s\tremaining: 18m 5s\n",
      "3233:\tlearn: 0.0520512\ttotal: 8m 38s\tremaining: 18m 4s\n",
      "3234:\tlearn: 0.0520512\ttotal: 8m 38s\tremaining: 18m 4s\n",
      "3235:\tlearn: 0.0520512\ttotal: 8m 38s\tremaining: 18m 4s\n",
      "3236:\tlearn: 0.0520512\ttotal: 8m 39s\tremaining: 18m 4s\n",
      "3237:\tlearn: 0.0520512\ttotal: 8m 39s\tremaining: 18m 4s\n",
      "3238:\tlearn: 0.0520512\ttotal: 8m 39s\tremaining: 18m 4s\n",
      "3239:\tlearn: 0.0520512\ttotal: 8m 39s\tremaining: 18m 3s\n",
      "3240:\tlearn: 0.0520512\ttotal: 8m 39s\tremaining: 18m 3s\n",
      "3241:\tlearn: 0.0520512\ttotal: 8m 39s\tremaining: 18m 3s\n",
      "3242:\tlearn: 0.0520512\ttotal: 8m 39s\tremaining: 18m 3s\n",
      "3243:\tlearn: 0.0520512\ttotal: 8m 40s\tremaining: 18m 3s\n",
      "3244:\tlearn: 0.0520512\ttotal: 8m 40s\tremaining: 18m 2s\n",
      "3245:\tlearn: 0.0520512\ttotal: 8m 40s\tremaining: 18m 2s\n",
      "3246:\tlearn: 0.0520512\ttotal: 8m 40s\tremaining: 18m 2s\n",
      "3247:\tlearn: 0.0520512\ttotal: 8m 40s\tremaining: 18m 2s\n",
      "3248:\tlearn: 0.0520512\ttotal: 8m 40s\tremaining: 18m 2s\n",
      "3249:\tlearn: 0.0520512\ttotal: 8m 40s\tremaining: 18m 1s\n",
      "3250:\tlearn: 0.0520512\ttotal: 8m 41s\tremaining: 18m 1s\n",
      "3251:\tlearn: 0.0520512\ttotal: 8m 41s\tremaining: 18m 1s\n",
      "3252:\tlearn: 0.0520512\ttotal: 8m 41s\tremaining: 18m 1s\n",
      "3253:\tlearn: 0.0520512\ttotal: 8m 41s\tremaining: 18m 1s\n",
      "3254:\tlearn: 0.0520512\ttotal: 8m 41s\tremaining: 18m 1s\n",
      "3255:\tlearn: 0.0520512\ttotal: 8m 41s\tremaining: 18m\n",
      "3256:\tlearn: 0.0520512\ttotal: 8m 42s\tremaining: 18m\n",
      "3257:\tlearn: 0.0520512\ttotal: 8m 42s\tremaining: 18m\n",
      "3258:\tlearn: 0.0520512\ttotal: 8m 42s\tremaining: 18m\n",
      "3259:\tlearn: 0.0520512\ttotal: 8m 42s\tremaining: 18m\n",
      "3260:\tlearn: 0.0520512\ttotal: 8m 42s\tremaining: 17m 59s\n",
      "3261:\tlearn: 0.0520512\ttotal: 8m 42s\tremaining: 17m 59s\n",
      "3262:\tlearn: 0.0520512\ttotal: 8m 42s\tremaining: 17m 59s\n",
      "3263:\tlearn: 0.0520512\ttotal: 8m 43s\tremaining: 17m 59s\n",
      "3264:\tlearn: 0.0520512\ttotal: 8m 43s\tremaining: 17m 59s\n",
      "3265:\tlearn: 0.0520512\ttotal: 8m 43s\tremaining: 17m 59s\n",
      "3266:\tlearn: 0.0520512\ttotal: 8m 43s\tremaining: 17m 58s\n",
      "3267:\tlearn: 0.0520512\ttotal: 8m 43s\tremaining: 17m 58s\n",
      "3268:\tlearn: 0.0520512\ttotal: 8m 43s\tremaining: 17m 58s\n",
      "3269:\tlearn: 0.0520512\ttotal: 8m 43s\tremaining: 17m 58s\n",
      "3270:\tlearn: 0.0520512\ttotal: 8m 44s\tremaining: 17m 58s\n",
      "3271:\tlearn: 0.0520512\ttotal: 8m 44s\tremaining: 17m 58s\n",
      "3272:\tlearn: 0.0520512\ttotal: 8m 44s\tremaining: 17m 57s\n",
      "3273:\tlearn: 0.0520512\ttotal: 8m 44s\tremaining: 17m 57s\n",
      "3274:\tlearn: 0.0520512\ttotal: 8m 44s\tremaining: 17m 57s\n",
      "3275:\tlearn: 0.0520512\ttotal: 8m 44s\tremaining: 17m 57s\n",
      "3276:\tlearn: 0.0520512\ttotal: 8m 45s\tremaining: 17m 57s\n",
      "3277:\tlearn: 0.0520512\ttotal: 8m 45s\tremaining: 17m 56s\n",
      "3278:\tlearn: 0.0520512\ttotal: 8m 45s\tremaining: 17m 56s\n",
      "3279:\tlearn: 0.0520512\ttotal: 8m 45s\tremaining: 17m 56s\n",
      "3280:\tlearn: 0.0520512\ttotal: 8m 45s\tremaining: 17m 56s\n",
      "3281:\tlearn: 0.0520512\ttotal: 8m 45s\tremaining: 17m 56s\n",
      "3282:\tlearn: 0.0520512\ttotal: 8m 45s\tremaining: 17m 56s\n",
      "3283:\tlearn: 0.0520512\ttotal: 8m 46s\tremaining: 17m 55s\n",
      "3284:\tlearn: 0.0520512\ttotal: 8m 46s\tremaining: 17m 55s\n",
      "3285:\tlearn: 0.0520512\ttotal: 8m 46s\tremaining: 17m 55s\n",
      "3286:\tlearn: 0.0520512\ttotal: 8m 46s\tremaining: 17m 55s\n",
      "3287:\tlearn: 0.0520512\ttotal: 8m 46s\tremaining: 17m 55s\n",
      "3288:\tlearn: 0.0520512\ttotal: 8m 46s\tremaining: 17m 54s\n",
      "3289:\tlearn: 0.0520512\ttotal: 8m 46s\tremaining: 17m 54s\n",
      "3290:\tlearn: 0.0520512\ttotal: 8m 47s\tremaining: 17m 54s\n",
      "3291:\tlearn: 0.0520512\ttotal: 8m 47s\tremaining: 17m 54s\n",
      "3292:\tlearn: 0.0520512\ttotal: 8m 47s\tremaining: 17m 54s\n",
      "3293:\tlearn: 0.0520512\ttotal: 8m 47s\tremaining: 17m 54s\n",
      "3294:\tlearn: 0.0520512\ttotal: 8m 47s\tremaining: 17m 53s\n",
      "3295:\tlearn: 0.0520512\ttotal: 8m 47s\tremaining: 17m 53s\n",
      "3296:\tlearn: 0.0520512\ttotal: 8m 48s\tremaining: 17m 53s\n",
      "3297:\tlearn: 0.0520512\ttotal: 8m 48s\tremaining: 17m 53s\n",
      "3298:\tlearn: 0.0520512\ttotal: 8m 48s\tremaining: 17m 53s\n",
      "3299:\tlearn: 0.0520512\ttotal: 8m 48s\tremaining: 17m 52s\n",
      "3300:\tlearn: 0.0520512\ttotal: 8m 48s\tremaining: 17m 52s\n",
      "3301:\tlearn: 0.0520512\ttotal: 8m 48s\tremaining: 17m 52s\n",
      "3302:\tlearn: 0.0520512\ttotal: 8m 48s\tremaining: 17m 52s\n",
      "3303:\tlearn: 0.0520512\ttotal: 8m 49s\tremaining: 17m 52s\n",
      "3304:\tlearn: 0.0520512\ttotal: 8m 49s\tremaining: 17m 52s\n",
      "3305:\tlearn: 0.0520512\ttotal: 8m 49s\tremaining: 17m 51s\n",
      "3306:\tlearn: 0.0520512\ttotal: 8m 49s\tremaining: 17m 51s\n",
      "3307:\tlearn: 0.0520512\ttotal: 8m 49s\tremaining: 17m 51s\n",
      "3308:\tlearn: 0.0520512\ttotal: 8m 49s\tremaining: 17m 51s\n",
      "3309:\tlearn: 0.0520512\ttotal: 8m 50s\tremaining: 17m 51s\n",
      "3310:\tlearn: 0.0520512\ttotal: 8m 50s\tremaining: 17m 51s\n",
      "3311:\tlearn: 0.0520512\ttotal: 8m 50s\tremaining: 17m 50s\n",
      "3312:\tlearn: 0.0520512\ttotal: 8m 50s\tremaining: 17m 50s\n",
      "3313:\tlearn: 0.0520512\ttotal: 8m 50s\tremaining: 17m 50s\n",
      "3314:\tlearn: 0.0520512\ttotal: 8m 50s\tremaining: 17m 50s\n",
      "3315:\tlearn: 0.0520512\ttotal: 8m 50s\tremaining: 17m 50s\n",
      "3316:\tlearn: 0.0520512\ttotal: 8m 51s\tremaining: 17m 50s\n",
      "3317:\tlearn: 0.0520512\ttotal: 8m 51s\tremaining: 17m 49s\n",
      "3318:\tlearn: 0.0520512\ttotal: 8m 51s\tremaining: 17m 49s\n",
      "3319:\tlearn: 0.0520512\ttotal: 8m 51s\tremaining: 17m 49s\n",
      "3320:\tlearn: 0.0520512\ttotal: 8m 51s\tremaining: 17m 49s\n",
      "3321:\tlearn: 0.0520512\ttotal: 8m 51s\tremaining: 17m 49s\n",
      "3322:\tlearn: 0.0520512\ttotal: 8m 52s\tremaining: 17m 49s\n",
      "3323:\tlearn: 0.0520512\ttotal: 8m 52s\tremaining: 17m 48s\n",
      "3324:\tlearn: 0.0520512\ttotal: 8m 52s\tremaining: 17m 48s\n",
      "3325:\tlearn: 0.0520512\ttotal: 8m 52s\tremaining: 17m 48s\n",
      "3326:\tlearn: 0.0520512\ttotal: 8m 52s\tremaining: 17m 48s\n",
      "3327:\tlearn: 0.0520512\ttotal: 8m 52s\tremaining: 17m 48s\n",
      "3328:\tlearn: 0.0520512\ttotal: 8m 53s\tremaining: 17m 48s\n",
      "3329:\tlearn: 0.0520512\ttotal: 8m 53s\tremaining: 17m 48s\n",
      "3330:\tlearn: 0.0520512\ttotal: 8m 53s\tremaining: 17m 47s\n",
      "3331:\tlearn: 0.0520512\ttotal: 8m 53s\tremaining: 17m 47s\n",
      "3332:\tlearn: 0.0520512\ttotal: 8m 53s\tremaining: 17m 47s\n",
      "3333:\tlearn: 0.0520512\ttotal: 8m 53s\tremaining: 17m 47s\n",
      "3334:\tlearn: 0.0520512\ttotal: 8m 54s\tremaining: 17m 47s\n",
      "3335:\tlearn: 0.0520512\ttotal: 8m 54s\tremaining: 17m 47s\n",
      "3336:\tlearn: 0.0520512\ttotal: 8m 54s\tremaining: 17m 46s\n",
      "3337:\tlearn: 0.0520512\ttotal: 8m 54s\tremaining: 17m 46s\n",
      "3338:\tlearn: 0.0520512\ttotal: 8m 54s\tremaining: 17m 46s\n",
      "3339:\tlearn: 0.0520512\ttotal: 8m 54s\tremaining: 17m 46s\n",
      "3340:\tlearn: 0.0520512\ttotal: 8m 55s\tremaining: 17m 46s\n",
      "3341:\tlearn: 0.0520512\ttotal: 8m 55s\tremaining: 17m 46s\n",
      "3342:\tlearn: 0.0520512\ttotal: 8m 55s\tremaining: 17m 46s\n",
      "3343:\tlearn: 0.0520512\ttotal: 8m 55s\tremaining: 17m 45s\n",
      "3344:\tlearn: 0.0520512\ttotal: 8m 55s\tremaining: 17m 45s\n",
      "3345:\tlearn: 0.0520512\ttotal: 8m 55s\tremaining: 17m 45s\n",
      "3346:\tlearn: 0.0520512\ttotal: 8m 56s\tremaining: 17m 45s\n",
      "3347:\tlearn: 0.0520512\ttotal: 8m 56s\tremaining: 17m 45s\n",
      "3348:\tlearn: 0.0520512\ttotal: 8m 56s\tremaining: 17m 45s\n",
      "3349:\tlearn: 0.0520512\ttotal: 8m 56s\tremaining: 17m 45s\n",
      "3350:\tlearn: 0.0520512\ttotal: 8m 56s\tremaining: 17m 44s\n",
      "3351:\tlearn: 0.0520512\ttotal: 8m 56s\tremaining: 17m 44s\n",
      "3352:\tlearn: 0.0520512\ttotal: 8m 57s\tremaining: 17m 44s\n",
      "3353:\tlearn: 0.0520512\ttotal: 8m 57s\tremaining: 17m 44s\n",
      "3354:\tlearn: 0.0520512\ttotal: 8m 57s\tremaining: 17m 44s\n",
      "3355:\tlearn: 0.0520512\ttotal: 8m 57s\tremaining: 17m 44s\n",
      "3356:\tlearn: 0.0520512\ttotal: 8m 57s\tremaining: 17m 43s\n",
      "3357:\tlearn: 0.0520512\ttotal: 8m 57s\tremaining: 17m 43s\n",
      "3358:\tlearn: 0.0520512\ttotal: 8m 58s\tremaining: 17m 43s\n",
      "3359:\tlearn: 0.0520512\ttotal: 8m 58s\tremaining: 17m 43s\n",
      "3360:\tlearn: 0.0520512\ttotal: 8m 58s\tremaining: 17m 43s\n",
      "3361:\tlearn: 0.0520512\ttotal: 8m 58s\tremaining: 17m 43s\n",
      "3362:\tlearn: 0.0520512\ttotal: 8m 58s\tremaining: 17m 43s\n",
      "3363:\tlearn: 0.0520512\ttotal: 8m 58s\tremaining: 17m 42s\n",
      "3364:\tlearn: 0.0520512\ttotal: 8m 58s\tremaining: 17m 42s\n",
      "3365:\tlearn: 0.0520512\ttotal: 8m 59s\tremaining: 17m 42s\n",
      "3366:\tlearn: 0.0520512\ttotal: 8m 59s\tremaining: 17m 42s\n",
      "3367:\tlearn: 0.0520512\ttotal: 8m 59s\tremaining: 17m 42s\n",
      "3368:\tlearn: 0.0520512\ttotal: 8m 59s\tremaining: 17m 42s\n",
      "3369:\tlearn: 0.0520512\ttotal: 8m 59s\tremaining: 17m 42s\n",
      "3370:\tlearn: 0.0520512\ttotal: 8m 59s\tremaining: 17m 41s\n",
      "3371:\tlearn: 0.0520512\ttotal: 9m\tremaining: 17m 41s\n",
      "3372:\tlearn: 0.0520512\ttotal: 9m\tremaining: 17m 41s\n",
      "3373:\tlearn: 0.0520512\ttotal: 9m\tremaining: 17m 41s\n",
      "3374:\tlearn: 0.0520512\ttotal: 9m\tremaining: 17m 41s\n",
      "3375:\tlearn: 0.0520512\ttotal: 9m\tremaining: 17m 40s\n",
      "3376:\tlearn: 0.0520512\ttotal: 9m\tremaining: 17m 40s\n",
      "3377:\tlearn: 0.0520512\ttotal: 9m 1s\tremaining: 17m 40s\n",
      "3378:\tlearn: 0.0520512\ttotal: 9m 1s\tremaining: 17m 40s\n",
      "3379:\tlearn: 0.0520512\ttotal: 9m 1s\tremaining: 17m 40s\n",
      "3380:\tlearn: 0.0520512\ttotal: 9m 1s\tremaining: 17m 39s\n",
      "3381:\tlearn: 0.0520512\ttotal: 9m 1s\tremaining: 17m 39s\n",
      "3382:\tlearn: 0.0520512\ttotal: 9m 1s\tremaining: 17m 39s\n",
      "3383:\tlearn: 0.0520512\ttotal: 9m 1s\tremaining: 17m 39s\n",
      "3384:\tlearn: 0.0520512\ttotal: 9m 2s\tremaining: 17m 39s\n",
      "3385:\tlearn: 0.0520512\ttotal: 9m 2s\tremaining: 17m 39s\n",
      "3386:\tlearn: 0.0520512\ttotal: 9m 2s\tremaining: 17m 38s\n",
      "3387:\tlearn: 0.0520512\ttotal: 9m 2s\tremaining: 17m 38s\n",
      "3388:\tlearn: 0.0520512\ttotal: 9m 2s\tremaining: 17m 38s\n",
      "3389:\tlearn: 0.0520512\ttotal: 9m 2s\tremaining: 17m 38s\n",
      "3390:\tlearn: 0.0520512\ttotal: 9m 2s\tremaining: 17m 38s\n",
      "3391:\tlearn: 0.0520512\ttotal: 9m 3s\tremaining: 17m 37s\n",
      "3392:\tlearn: 0.0520512\ttotal: 9m 3s\tremaining: 17m 37s\n",
      "3393:\tlearn: 0.0520512\ttotal: 9m 3s\tremaining: 17m 37s\n",
      "3394:\tlearn: 0.0520512\ttotal: 9m 3s\tremaining: 17m 37s\n",
      "3395:\tlearn: 0.0520512\ttotal: 9m 3s\tremaining: 17m 37s\n",
      "3396:\tlearn: 0.0520512\ttotal: 9m 3s\tremaining: 17m 37s\n",
      "3397:\tlearn: 0.0520512\ttotal: 9m 3s\tremaining: 17m 36s\n",
      "3398:\tlearn: 0.0520512\ttotal: 9m 4s\tremaining: 17m 36s\n",
      "3399:\tlearn: 0.0520512\ttotal: 9m 4s\tremaining: 17m 36s\n",
      "3400:\tlearn: 0.0520512\ttotal: 9m 4s\tremaining: 17m 36s\n",
      "3401:\tlearn: 0.0520512\ttotal: 9m 4s\tremaining: 17m 36s\n",
      "3402:\tlearn: 0.0520512\ttotal: 9m 4s\tremaining: 17m 35s\n",
      "3403:\tlearn: 0.0520512\ttotal: 9m 4s\tremaining: 17m 35s\n",
      "3404:\tlearn: 0.0520512\ttotal: 9m 4s\tremaining: 17m 35s\n",
      "3405:\tlearn: 0.0520512\ttotal: 9m 5s\tremaining: 17m 35s\n",
      "3406:\tlearn: 0.0520512\ttotal: 9m 5s\tremaining: 17m 35s\n",
      "3407:\tlearn: 0.0520512\ttotal: 9m 5s\tremaining: 17m 35s\n",
      "3408:\tlearn: 0.0520512\ttotal: 9m 5s\tremaining: 17m 34s\n",
      "3409:\tlearn: 0.0520512\ttotal: 9m 5s\tremaining: 17m 34s\n",
      "3410:\tlearn: 0.0520512\ttotal: 9m 5s\tremaining: 17m 34s\n",
      "3411:\tlearn: 0.0520512\ttotal: 9m 6s\tremaining: 17m 34s\n",
      "3412:\tlearn: 0.0520512\ttotal: 9m 6s\tremaining: 17m 34s\n",
      "3413:\tlearn: 0.0520512\ttotal: 9m 6s\tremaining: 17m 33s\n",
      "3414:\tlearn: 0.0520512\ttotal: 9m 6s\tremaining: 17m 33s\n",
      "3415:\tlearn: 0.0520512\ttotal: 9m 6s\tremaining: 17m 33s\n",
      "3416:\tlearn: 0.0520512\ttotal: 9m 6s\tremaining: 17m 33s\n",
      "3417:\tlearn: 0.0520512\ttotal: 9m 6s\tremaining: 17m 33s\n",
      "3418:\tlearn: 0.0520512\ttotal: 9m 7s\tremaining: 17m 33s\n",
      "3419:\tlearn: 0.0520512\ttotal: 9m 7s\tremaining: 17m 32s\n",
      "3420:\tlearn: 0.0520512\ttotal: 9m 7s\tremaining: 17m 32s\n",
      "3421:\tlearn: 0.0520512\ttotal: 9m 7s\tremaining: 17m 32s\n",
      "3422:\tlearn: 0.0520512\ttotal: 9m 7s\tremaining: 17m 32s\n",
      "3423:\tlearn: 0.0520512\ttotal: 9m 7s\tremaining: 17m 32s\n",
      "3424:\tlearn: 0.0520512\ttotal: 9m 7s\tremaining: 17m 31s\n",
      "3425:\tlearn: 0.0520512\ttotal: 9m 8s\tremaining: 17m 31s\n",
      "3426:\tlearn: 0.0520512\ttotal: 9m 8s\tremaining: 17m 31s\n",
      "3427:\tlearn: 0.0520512\ttotal: 9m 8s\tremaining: 17m 31s\n",
      "3428:\tlearn: 0.0520512\ttotal: 9m 8s\tremaining: 17m 31s\n",
      "3429:\tlearn: 0.0520512\ttotal: 9m 8s\tremaining: 17m 31s\n",
      "3430:\tlearn: 0.0520512\ttotal: 9m 8s\tremaining: 17m 30s\n",
      "3431:\tlearn: 0.0520512\ttotal: 9m 9s\tremaining: 17m 30s\n",
      "3432:\tlearn: 0.0520512\ttotal: 9m 9s\tremaining: 17m 30s\n",
      "3433:\tlearn: 0.0520512\ttotal: 9m 9s\tremaining: 17m 30s\n",
      "3434:\tlearn: 0.0520512\ttotal: 9m 9s\tremaining: 17m 30s\n",
      "3435:\tlearn: 0.0520512\ttotal: 9m 9s\tremaining: 17m 29s\n",
      "3436:\tlearn: 0.0520512\ttotal: 9m 9s\tremaining: 17m 29s\n",
      "3437:\tlearn: 0.0520512\ttotal: 9m 9s\tremaining: 17m 29s\n",
      "3438:\tlearn: 0.0520512\ttotal: 9m 10s\tremaining: 17m 29s\n",
      "3439:\tlearn: 0.0520512\ttotal: 9m 10s\tremaining: 17m 29s\n",
      "3440:\tlearn: 0.0520512\ttotal: 9m 10s\tremaining: 17m 29s\n",
      "3441:\tlearn: 0.0520512\ttotal: 9m 10s\tremaining: 17m 28s\n",
      "3442:\tlearn: 0.0520512\ttotal: 9m 10s\tremaining: 17m 28s\n",
      "3443:\tlearn: 0.0520512\ttotal: 9m 10s\tremaining: 17m 28s\n",
      "3444:\tlearn: 0.0520512\ttotal: 9m 10s\tremaining: 17m 28s\n",
      "3445:\tlearn: 0.0520512\ttotal: 9m 11s\tremaining: 17m 28s\n",
      "3446:\tlearn: 0.0520512\ttotal: 9m 11s\tremaining: 17m 28s\n",
      "3447:\tlearn: 0.0520512\ttotal: 9m 11s\tremaining: 17m 27s\n",
      "3448:\tlearn: 0.0520512\ttotal: 9m 11s\tremaining: 17m 27s\n",
      "3449:\tlearn: 0.0520512\ttotal: 9m 11s\tremaining: 17m 27s\n",
      "3450:\tlearn: 0.0520512\ttotal: 9m 11s\tremaining: 17m 27s\n",
      "3451:\tlearn: 0.0520512\ttotal: 9m 12s\tremaining: 17m 27s\n",
      "3452:\tlearn: 0.0520512\ttotal: 9m 12s\tremaining: 17m 26s\n",
      "3453:\tlearn: 0.0520512\ttotal: 9m 12s\tremaining: 17m 26s\n",
      "3454:\tlearn: 0.0520512\ttotal: 9m 12s\tremaining: 17m 26s\n",
      "3455:\tlearn: 0.0520512\ttotal: 9m 12s\tremaining: 17m 26s\n",
      "3456:\tlearn: 0.0520512\ttotal: 9m 12s\tremaining: 17m 26s\n",
      "3457:\tlearn: 0.0520512\ttotal: 9m 12s\tremaining: 17m 26s\n",
      "3458:\tlearn: 0.0520512\ttotal: 9m 13s\tremaining: 17m 25s\n",
      "3459:\tlearn: 0.0520512\ttotal: 9m 13s\tremaining: 17m 25s\n",
      "3460:\tlearn: 0.0520512\ttotal: 9m 13s\tremaining: 17m 25s\n",
      "3461:\tlearn: 0.0520512\ttotal: 9m 13s\tremaining: 17m 25s\n",
      "3462:\tlearn: 0.0520512\ttotal: 9m 13s\tremaining: 17m 25s\n",
      "3463:\tlearn: 0.0520512\ttotal: 9m 13s\tremaining: 17m 24s\n",
      "3464:\tlearn: 0.0520512\ttotal: 9m 13s\tremaining: 17m 24s\n",
      "3465:\tlearn: 0.0520512\ttotal: 9m 14s\tremaining: 17m 24s\n",
      "3466:\tlearn: 0.0520512\ttotal: 9m 14s\tremaining: 17m 24s\n",
      "3467:\tlearn: 0.0520512\ttotal: 9m 14s\tremaining: 17m 24s\n",
      "3468:\tlearn: 0.0520512\ttotal: 9m 14s\tremaining: 17m 24s\n",
      "3469:\tlearn: 0.0520512\ttotal: 9m 14s\tremaining: 17m 23s\n",
      "3470:\tlearn: 0.0520512\ttotal: 9m 14s\tremaining: 17m 23s\n",
      "3471:\tlearn: 0.0520512\ttotal: 9m 15s\tremaining: 17m 23s\n",
      "3472:\tlearn: 0.0520512\ttotal: 9m 15s\tremaining: 17m 23s\n",
      "3473:\tlearn: 0.0520512\ttotal: 9m 15s\tremaining: 17m 23s\n",
      "3474:\tlearn: 0.0520512\ttotal: 9m 15s\tremaining: 17m 22s\n",
      "3475:\tlearn: 0.0520512\ttotal: 9m 15s\tremaining: 17m 22s\n",
      "3476:\tlearn: 0.0520512\ttotal: 9m 15s\tremaining: 17m 22s\n",
      "3477:\tlearn: 0.0520512\ttotal: 9m 15s\tremaining: 17m 22s\n",
      "3478:\tlearn: 0.0520512\ttotal: 9m 16s\tremaining: 17m 22s\n",
      "3479:\tlearn: 0.0520512\ttotal: 9m 16s\tremaining: 17m 22s\n",
      "3480:\tlearn: 0.0520512\ttotal: 9m 16s\tremaining: 17m 21s\n",
      "3481:\tlearn: 0.0520512\ttotal: 9m 16s\tremaining: 17m 21s\n",
      "3482:\tlearn: 0.0520512\ttotal: 9m 16s\tremaining: 17m 21s\n",
      "3483:\tlearn: 0.0520512\ttotal: 9m 16s\tremaining: 17m 21s\n",
      "3484:\tlearn: 0.0520512\ttotal: 9m 16s\tremaining: 17m 21s\n",
      "3485:\tlearn: 0.0520512\ttotal: 9m 17s\tremaining: 17m 20s\n",
      "3486:\tlearn: 0.0520512\ttotal: 9m 17s\tremaining: 17m 20s\n",
      "3487:\tlearn: 0.0520512\ttotal: 9m 17s\tremaining: 17m 20s\n",
      "3488:\tlearn: 0.0520512\ttotal: 9m 17s\tremaining: 17m 20s\n",
      "3489:\tlearn: 0.0520512\ttotal: 9m 17s\tremaining: 17m 20s\n",
      "3490:\tlearn: 0.0520512\ttotal: 9m 17s\tremaining: 17m 20s\n",
      "3491:\tlearn: 0.0520512\ttotal: 9m 17s\tremaining: 17m 19s\n",
      "3492:\tlearn: 0.0520512\ttotal: 9m 18s\tremaining: 17m 19s\n",
      "3493:\tlearn: 0.0520512\ttotal: 9m 18s\tremaining: 17m 19s\n",
      "3494:\tlearn: 0.0520512\ttotal: 9m 18s\tremaining: 17m 19s\n",
      "3495:\tlearn: 0.0520512\ttotal: 9m 18s\tremaining: 17m 19s\n",
      "3496:\tlearn: 0.0520512\ttotal: 9m 18s\tremaining: 17m 18s\n",
      "3497:\tlearn: 0.0520512\ttotal: 9m 18s\tremaining: 17m 18s\n",
      "3498:\tlearn: 0.0520512\ttotal: 9m 19s\tremaining: 17m 18s\n",
      "3499:\tlearn: 0.0520512\ttotal: 9m 19s\tremaining: 17m 18s\n",
      "3500:\tlearn: 0.0520512\ttotal: 9m 19s\tremaining: 17m 18s\n",
      "3501:\tlearn: 0.0520512\ttotal: 9m 19s\tremaining: 17m 18s\n",
      "3502:\tlearn: 0.0520512\ttotal: 9m 19s\tremaining: 17m 17s\n",
      "3503:\tlearn: 0.0520512\ttotal: 9m 19s\tremaining: 17m 17s\n",
      "3504:\tlearn: 0.0520512\ttotal: 9m 19s\tremaining: 17m 17s\n",
      "3505:\tlearn: 0.0520512\ttotal: 9m 20s\tremaining: 17m 17s\n",
      "3506:\tlearn: 0.0520512\ttotal: 9m 20s\tremaining: 17m 17s\n",
      "3507:\tlearn: 0.0520512\ttotal: 9m 20s\tremaining: 17m 17s\n",
      "3508:\tlearn: 0.0520512\ttotal: 9m 20s\tremaining: 17m 16s\n",
      "3509:\tlearn: 0.0520512\ttotal: 9m 20s\tremaining: 17m 16s\n",
      "3510:\tlearn: 0.0520512\ttotal: 9m 20s\tremaining: 17m 16s\n",
      "3511:\tlearn: 0.0520512\ttotal: 9m 20s\tremaining: 17m 16s\n",
      "3512:\tlearn: 0.0520512\ttotal: 9m 21s\tremaining: 17m 16s\n",
      "3513:\tlearn: 0.0520512\ttotal: 9m 21s\tremaining: 17m 15s\n",
      "3514:\tlearn: 0.0520512\ttotal: 9m 21s\tremaining: 17m 15s\n",
      "3515:\tlearn: 0.0520512\ttotal: 9m 21s\tremaining: 17m 15s\n",
      "3516:\tlearn: 0.0520512\ttotal: 9m 21s\tremaining: 17m 15s\n",
      "3517:\tlearn: 0.0520512\ttotal: 9m 21s\tremaining: 17m 15s\n",
      "3518:\tlearn: 0.0520512\ttotal: 9m 22s\tremaining: 17m 15s\n",
      "3519:\tlearn: 0.0520512\ttotal: 9m 22s\tremaining: 17m 14s\n",
      "3520:\tlearn: 0.0520512\ttotal: 9m 22s\tremaining: 17m 14s\n",
      "3521:\tlearn: 0.0520512\ttotal: 9m 22s\tremaining: 17m 14s\n",
      "3522:\tlearn: 0.0520512\ttotal: 9m 22s\tremaining: 17m 14s\n",
      "3523:\tlearn: 0.0520512\ttotal: 9m 22s\tremaining: 17m 14s\n",
      "3524:\tlearn: 0.0520512\ttotal: 9m 22s\tremaining: 17m 14s\n",
      "3525:\tlearn: 0.0520512\ttotal: 9m 23s\tremaining: 17m 13s\n",
      "3526:\tlearn: 0.0520512\ttotal: 9m 23s\tremaining: 17m 13s\n",
      "3527:\tlearn: 0.0520512\ttotal: 9m 23s\tremaining: 17m 13s\n",
      "3528:\tlearn: 0.0520512\ttotal: 9m 23s\tremaining: 17m 13s\n",
      "3529:\tlearn: 0.0520512\ttotal: 9m 23s\tremaining: 17m 13s\n",
      "3530:\tlearn: 0.0520512\ttotal: 9m 23s\tremaining: 17m 13s\n",
      "3531:\tlearn: 0.0520512\ttotal: 9m 24s\tremaining: 17m 12s\n",
      "3532:\tlearn: 0.0520512\ttotal: 9m 24s\tremaining: 17m 12s\n",
      "3533:\tlearn: 0.0520512\ttotal: 9m 24s\tremaining: 17m 12s\n",
      "3534:\tlearn: 0.0520512\ttotal: 9m 24s\tremaining: 17m 12s\n",
      "3535:\tlearn: 0.0520512\ttotal: 9m 24s\tremaining: 17m 12s\n",
      "3536:\tlearn: 0.0520512\ttotal: 9m 24s\tremaining: 17m 11s\n",
      "3537:\tlearn: 0.0520512\ttotal: 9m 24s\tremaining: 17m 11s\n",
      "3538:\tlearn: 0.0520512\ttotal: 9m 25s\tremaining: 17m 11s\n",
      "3539:\tlearn: 0.0520512\ttotal: 9m 25s\tremaining: 17m 11s\n",
      "3540:\tlearn: 0.0520512\ttotal: 9m 25s\tremaining: 17m 11s\n",
      "3541:\tlearn: 0.0520512\ttotal: 9m 25s\tremaining: 17m 11s\n",
      "3542:\tlearn: 0.0520512\ttotal: 9m 25s\tremaining: 17m 10s\n",
      "3543:\tlearn: 0.0520512\ttotal: 9m 25s\tremaining: 17m 10s\n",
      "3544:\tlearn: 0.0520512\ttotal: 9m 25s\tremaining: 17m 10s\n",
      "3545:\tlearn: 0.0520512\ttotal: 9m 26s\tremaining: 17m 10s\n",
      "3546:\tlearn: 0.0520512\ttotal: 9m 26s\tremaining: 17m 10s\n",
      "3547:\tlearn: 0.0520512\ttotal: 9m 26s\tremaining: 17m 9s\n",
      "3548:\tlearn: 0.0520512\ttotal: 9m 26s\tremaining: 17m 9s\n",
      "3549:\tlearn: 0.0520512\ttotal: 9m 26s\tremaining: 17m 9s\n",
      "3550:\tlearn: 0.0520512\ttotal: 9m 26s\tremaining: 17m 9s\n",
      "3551:\tlearn: 0.0520512\ttotal: 9m 26s\tremaining: 17m 9s\n",
      "3552:\tlearn: 0.0520512\ttotal: 9m 27s\tremaining: 17m 9s\n",
      "3553:\tlearn: 0.0520512\ttotal: 9m 27s\tremaining: 17m 8s\n",
      "3554:\tlearn: 0.0520512\ttotal: 9m 27s\tremaining: 17m 8s\n",
      "3555:\tlearn: 0.0520512\ttotal: 9m 27s\tremaining: 17m 8s\n",
      "3556:\tlearn: 0.0520512\ttotal: 9m 27s\tremaining: 17m 8s\n",
      "3557:\tlearn: 0.0520512\ttotal: 9m 27s\tremaining: 17m 8s\n",
      "3558:\tlearn: 0.0520512\ttotal: 9m 28s\tremaining: 17m 8s\n",
      "3559:\tlearn: 0.0520512\ttotal: 9m 28s\tremaining: 17m 7s\n",
      "3560:\tlearn: 0.0520512\ttotal: 9m 28s\tremaining: 17m 7s\n",
      "3561:\tlearn: 0.0520512\ttotal: 9m 28s\tremaining: 17m 7s\n",
      "3562:\tlearn: 0.0520512\ttotal: 9m 28s\tremaining: 17m 7s\n",
      "3563:\tlearn: 0.0520512\ttotal: 9m 28s\tremaining: 17m 7s\n",
      "3564:\tlearn: 0.0520512\ttotal: 9m 28s\tremaining: 17m 6s\n",
      "3565:\tlearn: 0.0520512\ttotal: 9m 29s\tremaining: 17m 6s\n",
      "3566:\tlearn: 0.0520512\ttotal: 9m 29s\tremaining: 17m 6s\n",
      "3567:\tlearn: 0.0520512\ttotal: 9m 29s\tremaining: 17m 6s\n",
      "3568:\tlearn: 0.0520512\ttotal: 9m 29s\tremaining: 17m 6s\n",
      "3569:\tlearn: 0.0520512\ttotal: 9m 29s\tremaining: 17m 6s\n",
      "3570:\tlearn: 0.0520512\ttotal: 9m 29s\tremaining: 17m 5s\n",
      "3571:\tlearn: 0.0520512\ttotal: 9m 29s\tremaining: 17m 5s\n",
      "3572:\tlearn: 0.0520512\ttotal: 9m 30s\tremaining: 17m 5s\n",
      "3573:\tlearn: 0.0520512\ttotal: 9m 30s\tremaining: 17m 5s\n",
      "3574:\tlearn: 0.0520512\ttotal: 9m 30s\tremaining: 17m 5s\n",
      "3575:\tlearn: 0.0520512\ttotal: 9m 30s\tremaining: 17m 5s\n",
      "3576:\tlearn: 0.0520512\ttotal: 9m 30s\tremaining: 17m 4s\n",
      "3577:\tlearn: 0.0520512\ttotal: 9m 30s\tremaining: 17m 4s\n",
      "3578:\tlearn: 0.0520512\ttotal: 9m 31s\tremaining: 17m 4s\n",
      "3579:\tlearn: 0.0520512\ttotal: 9m 31s\tremaining: 17m 4s\n",
      "3580:\tlearn: 0.0520512\ttotal: 9m 31s\tremaining: 17m 4s\n",
      "3581:\tlearn: 0.0520512\ttotal: 9m 31s\tremaining: 17m 3s\n",
      "3582:\tlearn: 0.0520512\ttotal: 9m 31s\tremaining: 17m 3s\n",
      "3583:\tlearn: 0.0520512\ttotal: 9m 31s\tremaining: 17m 3s\n",
      "3584:\tlearn: 0.0520512\ttotal: 9m 31s\tremaining: 17m 3s\n",
      "3585:\tlearn: 0.0520512\ttotal: 9m 32s\tremaining: 17m 3s\n",
      "3586:\tlearn: 0.0520512\ttotal: 9m 32s\tremaining: 17m 3s\n",
      "3587:\tlearn: 0.0520512\ttotal: 9m 32s\tremaining: 17m 2s\n",
      "3588:\tlearn: 0.0520512\ttotal: 9m 32s\tremaining: 17m 2s\n",
      "3589:\tlearn: 0.0520512\ttotal: 9m 32s\tremaining: 17m 2s\n",
      "3590:\tlearn: 0.0520512\ttotal: 9m 32s\tremaining: 17m 2s\n",
      "3591:\tlearn: 0.0520512\ttotal: 9m 32s\tremaining: 17m 2s\n",
      "3592:\tlearn: 0.0520512\ttotal: 9m 33s\tremaining: 17m 2s\n",
      "3593:\tlearn: 0.0520512\ttotal: 9m 33s\tremaining: 17m 1s\n",
      "3594:\tlearn: 0.0520512\ttotal: 9m 33s\tremaining: 17m 1s\n",
      "3595:\tlearn: 0.0520512\ttotal: 9m 33s\tremaining: 17m 1s\n",
      "3596:\tlearn: 0.0520512\ttotal: 9m 33s\tremaining: 17m 1s\n",
      "3597:\tlearn: 0.0520512\ttotal: 9m 33s\tremaining: 17m 1s\n",
      "3598:\tlearn: 0.0520512\ttotal: 9m 34s\tremaining: 17m\n",
      "3599:\tlearn: 0.0520512\ttotal: 9m 34s\tremaining: 17m\n",
      "3600:\tlearn: 0.0520512\ttotal: 9m 34s\tremaining: 17m\n",
      "3601:\tlearn: 0.0520512\ttotal: 9m 34s\tremaining: 17m\n",
      "3602:\tlearn: 0.0520512\ttotal: 9m 34s\tremaining: 17m\n",
      "3603:\tlearn: 0.0520512\ttotal: 9m 34s\tremaining: 17m\n",
      "3604:\tlearn: 0.0520512\ttotal: 9m 34s\tremaining: 16m 59s\n",
      "3605:\tlearn: 0.0520512\ttotal: 9m 35s\tremaining: 16m 59s\n",
      "3606:\tlearn: 0.0520512\ttotal: 9m 35s\tremaining: 16m 59s\n",
      "3607:\tlearn: 0.0520512\ttotal: 9m 35s\tremaining: 16m 59s\n",
      "3608:\tlearn: 0.0520512\ttotal: 9m 35s\tremaining: 16m 59s\n",
      "3609:\tlearn: 0.0520512\ttotal: 9m 35s\tremaining: 16m 59s\n",
      "3610:\tlearn: 0.0520512\ttotal: 9m 35s\tremaining: 16m 58s\n",
      "3611:\tlearn: 0.0520512\ttotal: 9m 35s\tremaining: 16m 58s\n",
      "3612:\tlearn: 0.0520512\ttotal: 9m 36s\tremaining: 16m 58s\n",
      "3613:\tlearn: 0.0520512\ttotal: 9m 36s\tremaining: 16m 58s\n",
      "3614:\tlearn: 0.0520512\ttotal: 9m 36s\tremaining: 16m 58s\n",
      "3615:\tlearn: 0.0520512\ttotal: 9m 36s\tremaining: 16m 57s\n",
      "3616:\tlearn: 0.0520512\ttotal: 9m 36s\tremaining: 16m 57s\n",
      "3617:\tlearn: 0.0520512\ttotal: 9m 36s\tremaining: 16m 57s\n",
      "3618:\tlearn: 0.0520512\ttotal: 9m 37s\tremaining: 16m 57s\n",
      "3619:\tlearn: 0.0520512\ttotal: 9m 37s\tremaining: 16m 57s\n",
      "3620:\tlearn: 0.0520512\ttotal: 9m 37s\tremaining: 16m 57s\n",
      "3621:\tlearn: 0.0520512\ttotal: 9m 37s\tremaining: 16m 56s\n",
      "3622:\tlearn: 0.0520512\ttotal: 9m 37s\tremaining: 16m 56s\n",
      "3623:\tlearn: 0.0520512\ttotal: 9m 37s\tremaining: 16m 56s\n",
      "3624:\tlearn: 0.0520512\ttotal: 9m 37s\tremaining: 16m 56s\n",
      "3625:\tlearn: 0.0520512\ttotal: 9m 38s\tremaining: 16m 56s\n",
      "3626:\tlearn: 0.0520512\ttotal: 9m 38s\tremaining: 16m 56s\n",
      "3627:\tlearn: 0.0520512\ttotal: 9m 38s\tremaining: 16m 55s\n",
      "3628:\tlearn: 0.0520512\ttotal: 9m 38s\tremaining: 16m 55s\n",
      "3629:\tlearn: 0.0520512\ttotal: 9m 38s\tremaining: 16m 55s\n",
      "3630:\tlearn: 0.0520512\ttotal: 9m 38s\tremaining: 16m 55s\n",
      "3631:\tlearn: 0.0520512\ttotal: 9m 38s\tremaining: 16m 55s\n",
      "3632:\tlearn: 0.0520512\ttotal: 9m 39s\tremaining: 16m 54s\n",
      "3633:\tlearn: 0.0520512\ttotal: 9m 39s\tremaining: 16m 54s\n",
      "3634:\tlearn: 0.0520512\ttotal: 9m 39s\tremaining: 16m 54s\n",
      "3635:\tlearn: 0.0520512\ttotal: 9m 39s\tremaining: 16m 54s\n",
      "3636:\tlearn: 0.0520512\ttotal: 9m 39s\tremaining: 16m 54s\n",
      "3637:\tlearn: 0.0520512\ttotal: 9m 39s\tremaining: 16m 54s\n",
      "3638:\tlearn: 0.0520512\ttotal: 9m 40s\tremaining: 16m 53s\n",
      "3639:\tlearn: 0.0520512\ttotal: 9m 40s\tremaining: 16m 53s\n",
      "3640:\tlearn: 0.0520512\ttotal: 9m 40s\tremaining: 16m 53s\n",
      "3641:\tlearn: 0.0520512\ttotal: 9m 40s\tremaining: 16m 53s\n",
      "3642:\tlearn: 0.0520512\ttotal: 9m 40s\tremaining: 16m 53s\n",
      "3643:\tlearn: 0.0520512\ttotal: 9m 40s\tremaining: 16m 53s\n",
      "3644:\tlearn: 0.0520512\ttotal: 9m 40s\tremaining: 16m 52s\n",
      "3645:\tlearn: 0.0520512\ttotal: 9m 41s\tremaining: 16m 52s\n",
      "3646:\tlearn: 0.0520512\ttotal: 9m 41s\tremaining: 16m 52s\n",
      "3647:\tlearn: 0.0520512\ttotal: 9m 41s\tremaining: 16m 52s\n",
      "3648:\tlearn: 0.0520512\ttotal: 9m 41s\tremaining: 16m 52s\n",
      "3649:\tlearn: 0.0520512\ttotal: 9m 41s\tremaining: 16m 51s\n",
      "3650:\tlearn: 0.0520512\ttotal: 9m 41s\tremaining: 16m 51s\n",
      "3651:\tlearn: 0.0520512\ttotal: 9m 41s\tremaining: 16m 51s\n",
      "3652:\tlearn: 0.0520512\ttotal: 9m 42s\tremaining: 16m 51s\n",
      "3653:\tlearn: 0.0520512\ttotal: 9m 42s\tremaining: 16m 51s\n",
      "3654:\tlearn: 0.0520512\ttotal: 9m 42s\tremaining: 16m 51s\n",
      "3655:\tlearn: 0.0520512\ttotal: 9m 42s\tremaining: 16m 50s\n",
      "3656:\tlearn: 0.0520512\ttotal: 9m 42s\tremaining: 16m 50s\n",
      "3657:\tlearn: 0.0520512\ttotal: 9m 42s\tremaining: 16m 50s\n",
      "3658:\tlearn: 0.0520512\ttotal: 9m 43s\tremaining: 16m 50s\n",
      "3659:\tlearn: 0.0520512\ttotal: 9m 43s\tremaining: 16m 50s\n",
      "3660:\tlearn: 0.0520512\ttotal: 9m 43s\tremaining: 16m 50s\n",
      "3661:\tlearn: 0.0520512\ttotal: 9m 43s\tremaining: 16m 49s\n",
      "3662:\tlearn: 0.0520512\ttotal: 9m 43s\tremaining: 16m 49s\n",
      "3663:\tlearn: 0.0520512\ttotal: 9m 43s\tremaining: 16m 49s\n",
      "3664:\tlearn: 0.0520512\ttotal: 9m 43s\tremaining: 16m 49s\n",
      "3665:\tlearn: 0.0520512\ttotal: 9m 44s\tremaining: 16m 49s\n",
      "3666:\tlearn: 0.0520512\ttotal: 9m 44s\tremaining: 16m 49s\n",
      "3667:\tlearn: 0.0520512\ttotal: 9m 44s\tremaining: 16m 48s\n",
      "3668:\tlearn: 0.0520512\ttotal: 9m 44s\tremaining: 16m 48s\n",
      "3669:\tlearn: 0.0520512\ttotal: 9m 44s\tremaining: 16m 48s\n",
      "3670:\tlearn: 0.0520512\ttotal: 9m 44s\tremaining: 16m 48s\n",
      "3671:\tlearn: 0.0520512\ttotal: 9m 44s\tremaining: 16m 48s\n",
      "3672:\tlearn: 0.0520512\ttotal: 9m 45s\tremaining: 16m 47s\n",
      "3673:\tlearn: 0.0520512\ttotal: 9m 45s\tremaining: 16m 47s\n",
      "3674:\tlearn: 0.0520512\ttotal: 9m 45s\tremaining: 16m 47s\n",
      "3675:\tlearn: 0.0520512\ttotal: 9m 45s\tremaining: 16m 47s\n",
      "3676:\tlearn: 0.0520512\ttotal: 9m 45s\tremaining: 16m 47s\n",
      "3677:\tlearn: 0.0520512\ttotal: 9m 45s\tremaining: 16m 47s\n",
      "3678:\tlearn: 0.0520512\ttotal: 9m 46s\tremaining: 16m 46s\n",
      "3679:\tlearn: 0.0520512\ttotal: 9m 46s\tremaining: 16m 46s\n",
      "3680:\tlearn: 0.0520512\ttotal: 9m 46s\tremaining: 16m 46s\n",
      "3681:\tlearn: 0.0520512\ttotal: 9m 46s\tremaining: 16m 46s\n",
      "3682:\tlearn: 0.0520512\ttotal: 9m 46s\tremaining: 16m 46s\n",
      "3683:\tlearn: 0.0520512\ttotal: 9m 46s\tremaining: 16m 45s\n",
      "3684:\tlearn: 0.0520512\ttotal: 9m 46s\tremaining: 16m 45s\n",
      "3685:\tlearn: 0.0520512\ttotal: 9m 47s\tremaining: 16m 45s\n",
      "3686:\tlearn: 0.0520512\ttotal: 9m 47s\tremaining: 16m 45s\n",
      "3687:\tlearn: 0.0520512\ttotal: 9m 47s\tremaining: 16m 45s\n",
      "3688:\tlearn: 0.0520512\ttotal: 9m 47s\tremaining: 16m 45s\n",
      "3689:\tlearn: 0.0520512\ttotal: 9m 47s\tremaining: 16m 44s\n",
      "3690:\tlearn: 0.0520512\ttotal: 9m 47s\tremaining: 16m 44s\n",
      "3691:\tlearn: 0.0520512\ttotal: 9m 47s\tremaining: 16m 44s\n",
      "3692:\tlearn: 0.0520512\ttotal: 9m 48s\tremaining: 16m 44s\n",
      "3693:\tlearn: 0.0520512\ttotal: 9m 48s\tremaining: 16m 44s\n",
      "3694:\tlearn: 0.0520512\ttotal: 9m 48s\tremaining: 16m 43s\n",
      "3695:\tlearn: 0.0520512\ttotal: 9m 48s\tremaining: 16m 43s\n",
      "3696:\tlearn: 0.0520512\ttotal: 9m 48s\tremaining: 16m 43s\n",
      "3697:\tlearn: 0.0520512\ttotal: 9m 48s\tremaining: 16m 43s\n",
      "3698:\tlearn: 0.0520512\ttotal: 9m 48s\tremaining: 16m 43s\n",
      "3699:\tlearn: 0.0520512\ttotal: 9m 49s\tremaining: 16m 43s\n",
      "3700:\tlearn: 0.0520512\ttotal: 9m 49s\tremaining: 16m 42s\n",
      "3701:\tlearn: 0.0520512\ttotal: 9m 49s\tremaining: 16m 42s\n",
      "3702:\tlearn: 0.0520512\ttotal: 9m 49s\tremaining: 16m 42s\n",
      "3703:\tlearn: 0.0520512\ttotal: 9m 49s\tremaining: 16m 42s\n",
      "3704:\tlearn: 0.0520512\ttotal: 9m 49s\tremaining: 16m 42s\n",
      "3705:\tlearn: 0.0520512\ttotal: 9m 50s\tremaining: 16m 42s\n",
      "3706:\tlearn: 0.0520512\ttotal: 9m 50s\tremaining: 16m 41s\n",
      "3707:\tlearn: 0.0520512\ttotal: 9m 50s\tremaining: 16m 41s\n",
      "3708:\tlearn: 0.0520512\ttotal: 9m 50s\tremaining: 16m 41s\n",
      "3709:\tlearn: 0.0520512\ttotal: 9m 50s\tremaining: 16m 41s\n",
      "3710:\tlearn: 0.0520512\ttotal: 9m 50s\tremaining: 16m 41s\n",
      "3711:\tlearn: 0.0520512\ttotal: 9m 50s\tremaining: 16m 41s\n",
      "3712:\tlearn: 0.0520512\ttotal: 9m 51s\tremaining: 16m 40s\n",
      "3713:\tlearn: 0.0520512\ttotal: 9m 51s\tremaining: 16m 40s\n",
      "3714:\tlearn: 0.0520512\ttotal: 9m 51s\tremaining: 16m 40s\n",
      "3715:\tlearn: 0.0520512\ttotal: 9m 51s\tremaining: 16m 40s\n",
      "3716:\tlearn: 0.0520512\ttotal: 9m 51s\tremaining: 16m 40s\n",
      "3717:\tlearn: 0.0520512\ttotal: 9m 51s\tremaining: 16m 39s\n",
      "3718:\tlearn: 0.0520512\ttotal: 9m 51s\tremaining: 16m 39s\n",
      "3719:\tlearn: 0.0520512\ttotal: 9m 52s\tremaining: 16m 39s\n",
      "3720:\tlearn: 0.0520512\ttotal: 9m 52s\tremaining: 16m 39s\n",
      "3721:\tlearn: 0.0520512\ttotal: 9m 52s\tremaining: 16m 39s\n",
      "3722:\tlearn: 0.0520512\ttotal: 9m 52s\tremaining: 16m 39s\n",
      "3723:\tlearn: 0.0520512\ttotal: 9m 52s\tremaining: 16m 38s\n",
      "3724:\tlearn: 0.0520512\ttotal: 9m 52s\tremaining: 16m 38s\n",
      "3725:\tlearn: 0.0520512\ttotal: 9m 53s\tremaining: 16m 38s\n",
      "3726:\tlearn: 0.0520512\ttotal: 9m 53s\tremaining: 16m 38s\n",
      "3727:\tlearn: 0.0520512\ttotal: 9m 53s\tremaining: 16m 38s\n",
      "3728:\tlearn: 0.0520512\ttotal: 9m 53s\tremaining: 16m 38s\n",
      "3729:\tlearn: 0.0520512\ttotal: 9m 53s\tremaining: 16m 37s\n",
      "3730:\tlearn: 0.0520512\ttotal: 9m 53s\tremaining: 16m 37s\n",
      "3731:\tlearn: 0.0520512\ttotal: 9m 53s\tremaining: 16m 37s\n",
      "3732:\tlearn: 0.0520512\ttotal: 9m 54s\tremaining: 16m 37s\n",
      "3733:\tlearn: 0.0520512\ttotal: 9m 54s\tremaining: 16m 37s\n",
      "3734:\tlearn: 0.0520512\ttotal: 9m 54s\tremaining: 16m 36s\n",
      "3735:\tlearn: 0.0520512\ttotal: 9m 54s\tremaining: 16m 36s\n",
      "3736:\tlearn: 0.0520512\ttotal: 9m 54s\tremaining: 16m 36s\n",
      "3737:\tlearn: 0.0520512\ttotal: 9m 54s\tremaining: 16m 36s\n",
      "3738:\tlearn: 0.0520512\ttotal: 9m 54s\tremaining: 16m 36s\n",
      "3739:\tlearn: 0.0520512\ttotal: 9m 55s\tremaining: 16m 36s\n",
      "3740:\tlearn: 0.0520512\ttotal: 9m 55s\tremaining: 16m 35s\n",
      "3741:\tlearn: 0.0520512\ttotal: 9m 55s\tremaining: 16m 35s\n",
      "3742:\tlearn: 0.0520512\ttotal: 9m 55s\tremaining: 16m 35s\n",
      "3743:\tlearn: 0.0520512\ttotal: 9m 55s\tremaining: 16m 35s\n",
      "3744:\tlearn: 0.0520512\ttotal: 9m 55s\tremaining: 16m 35s\n",
      "3745:\tlearn: 0.0520512\ttotal: 9m 55s\tremaining: 16m 34s\n",
      "3746:\tlearn: 0.0520512\ttotal: 9m 56s\tremaining: 16m 34s\n",
      "3747:\tlearn: 0.0520512\ttotal: 9m 56s\tremaining: 16m 34s\n",
      "3748:\tlearn: 0.0520512\ttotal: 9m 56s\tremaining: 16m 34s\n",
      "3749:\tlearn: 0.0520512\ttotal: 9m 56s\tremaining: 16m 34s\n",
      "3750:\tlearn: 0.0520512\ttotal: 9m 56s\tremaining: 16m 34s\n",
      "3751:\tlearn: 0.0520512\ttotal: 9m 56s\tremaining: 16m 33s\n",
      "3752:\tlearn: 0.0520512\ttotal: 9m 57s\tremaining: 16m 33s\n",
      "3753:\tlearn: 0.0520512\ttotal: 9m 57s\tremaining: 16m 33s\n",
      "3754:\tlearn: 0.0520512\ttotal: 9m 57s\tremaining: 16m 33s\n",
      "3755:\tlearn: 0.0520512\ttotal: 9m 57s\tremaining: 16m 33s\n",
      "3756:\tlearn: 0.0520512\ttotal: 9m 57s\tremaining: 16m 33s\n",
      "3757:\tlearn: 0.0520512\ttotal: 9m 57s\tremaining: 16m 32s\n",
      "3758:\tlearn: 0.0520512\ttotal: 9m 57s\tremaining: 16m 32s\n",
      "3759:\tlearn: 0.0520512\ttotal: 9m 58s\tremaining: 16m 32s\n",
      "3760:\tlearn: 0.0520512\ttotal: 9m 58s\tremaining: 16m 32s\n",
      "3761:\tlearn: 0.0520512\ttotal: 9m 58s\tremaining: 16m 32s\n",
      "3762:\tlearn: 0.0520512\ttotal: 9m 58s\tremaining: 16m 31s\n",
      "3763:\tlearn: 0.0520512\ttotal: 9m 58s\tremaining: 16m 31s\n",
      "3764:\tlearn: 0.0520512\ttotal: 9m 58s\tremaining: 16m 31s\n",
      "3765:\tlearn: 0.0520512\ttotal: 9m 58s\tremaining: 16m 31s\n",
      "3766:\tlearn: 0.0520512\ttotal: 9m 59s\tremaining: 16m 31s\n",
      "3767:\tlearn: 0.0520512\ttotal: 9m 59s\tremaining: 16m 31s\n",
      "3768:\tlearn: 0.0520512\ttotal: 9m 59s\tremaining: 16m 30s\n",
      "3769:\tlearn: 0.0520512\ttotal: 9m 59s\tremaining: 16m 30s\n",
      "3770:\tlearn: 0.0520512\ttotal: 9m 59s\tremaining: 16m 30s\n",
      "3771:\tlearn: 0.0520512\ttotal: 9m 59s\tremaining: 16m 30s\n",
      "3772:\tlearn: 0.0520512\ttotal: 9m 59s\tremaining: 16m 30s\n",
      "3773:\tlearn: 0.0520512\ttotal: 10m\tremaining: 16m 30s\n",
      "3774:\tlearn: 0.0520512\ttotal: 10m\tremaining: 16m 29s\n",
      "3775:\tlearn: 0.0520512\ttotal: 10m\tremaining: 16m 29s\n",
      "3776:\tlearn: 0.0520512\ttotal: 10m\tremaining: 16m 29s\n",
      "3777:\tlearn: 0.0520512\ttotal: 10m\tremaining: 16m 29s\n",
      "3778:\tlearn: 0.0520512\ttotal: 10m\tremaining: 16m 29s\n",
      "3779:\tlearn: 0.0520512\ttotal: 10m 1s\tremaining: 16m 28s\n",
      "3780:\tlearn: 0.0520512\ttotal: 10m 1s\tremaining: 16m 28s\n",
      "3781:\tlearn: 0.0520512\ttotal: 10m 1s\tremaining: 16m 28s\n",
      "3782:\tlearn: 0.0520512\ttotal: 10m 1s\tremaining: 16m 28s\n",
      "3783:\tlearn: 0.0520512\ttotal: 10m 1s\tremaining: 16m 28s\n",
      "3784:\tlearn: 0.0520512\ttotal: 10m 1s\tremaining: 16m 28s\n",
      "3785:\tlearn: 0.0520512\ttotal: 10m 1s\tremaining: 16m 27s\n",
      "3786:\tlearn: 0.0520512\ttotal: 10m 2s\tremaining: 16m 27s\n",
      "3787:\tlearn: 0.0520512\ttotal: 10m 2s\tremaining: 16m 27s\n",
      "3788:\tlearn: 0.0520512\ttotal: 10m 2s\tremaining: 16m 27s\n",
      "3789:\tlearn: 0.0520512\ttotal: 10m 2s\tremaining: 16m 27s\n",
      "3790:\tlearn: 0.0520512\ttotal: 10m 2s\tremaining: 16m 27s\n",
      "3791:\tlearn: 0.0520512\ttotal: 10m 2s\tremaining: 16m 26s\n",
      "3792:\tlearn: 0.0520512\ttotal: 10m 2s\tremaining: 16m 26s\n",
      "3793:\tlearn: 0.0520512\ttotal: 10m 3s\tremaining: 16m 26s\n",
      "3794:\tlearn: 0.0520512\ttotal: 10m 3s\tremaining: 16m 26s\n",
      "3795:\tlearn: 0.0520512\ttotal: 10m 3s\tremaining: 16m 26s\n",
      "3796:\tlearn: 0.0520512\ttotal: 10m 3s\tremaining: 16m 26s\n",
      "3797:\tlearn: 0.0520512\ttotal: 10m 3s\tremaining: 16m 26s\n",
      "3798:\tlearn: 0.0520512\ttotal: 10m 3s\tremaining: 16m 25s\n",
      "3799:\tlearn: 0.0520512\ttotal: 10m 4s\tremaining: 16m 25s\n",
      "3800:\tlearn: 0.0520512\ttotal: 10m 4s\tremaining: 16m 25s\n",
      "3801:\tlearn: 0.0520512\ttotal: 10m 4s\tremaining: 16m 25s\n",
      "3802:\tlearn: 0.0520512\ttotal: 10m 4s\tremaining: 16m 25s\n",
      "3803:\tlearn: 0.0520512\ttotal: 10m 4s\tremaining: 16m 25s\n",
      "3804:\tlearn: 0.0520512\ttotal: 10m 4s\tremaining: 16m 24s\n",
      "3805:\tlearn: 0.0520512\ttotal: 10m 5s\tremaining: 16m 24s\n",
      "3806:\tlearn: 0.0520512\ttotal: 10m 5s\tremaining: 16m 24s\n",
      "3807:\tlearn: 0.0520512\ttotal: 10m 5s\tremaining: 16m 24s\n",
      "3808:\tlearn: 0.0520512\ttotal: 10m 5s\tremaining: 16m 24s\n",
      "3809:\tlearn: 0.0520512\ttotal: 10m 5s\tremaining: 16m 23s\n",
      "3810:\tlearn: 0.0520512\ttotal: 10m 5s\tremaining: 16m 23s\n",
      "3811:\tlearn: 0.0520512\ttotal: 10m 5s\tremaining: 16m 23s\n",
      "3812:\tlearn: 0.0520512\ttotal: 10m 6s\tremaining: 16m 23s\n",
      "3813:\tlearn: 0.0520512\ttotal: 10m 6s\tremaining: 16m 23s\n",
      "3814:\tlearn: 0.0520512\ttotal: 10m 6s\tremaining: 16m 23s\n",
      "3815:\tlearn: 0.0520512\ttotal: 10m 6s\tremaining: 16m 22s\n",
      "3816:\tlearn: 0.0520512\ttotal: 10m 6s\tremaining: 16m 22s\n",
      "3817:\tlearn: 0.0520512\ttotal: 10m 6s\tremaining: 16m 22s\n",
      "3818:\tlearn: 0.0520512\ttotal: 10m 7s\tremaining: 16m 22s\n",
      "3819:\tlearn: 0.0520512\ttotal: 10m 7s\tremaining: 16m 22s\n",
      "3820:\tlearn: 0.0520512\ttotal: 10m 7s\tremaining: 16m 22s\n",
      "3821:\tlearn: 0.0520512\ttotal: 10m 7s\tremaining: 16m 21s\n",
      "3822:\tlearn: 0.0520512\ttotal: 10m 7s\tremaining: 16m 21s\n",
      "3823:\tlearn: 0.0520512\ttotal: 10m 7s\tremaining: 16m 21s\n",
      "3824:\tlearn: 0.0520512\ttotal: 10m 7s\tremaining: 16m 21s\n",
      "3825:\tlearn: 0.0520512\ttotal: 10m 8s\tremaining: 16m 21s\n",
      "3826:\tlearn: 0.0520512\ttotal: 10m 8s\tremaining: 16m 21s\n",
      "3827:\tlearn: 0.0520512\ttotal: 10m 8s\tremaining: 16m 20s\n",
      "3828:\tlearn: 0.0520512\ttotal: 10m 8s\tremaining: 16m 20s\n",
      "3829:\tlearn: 0.0520512\ttotal: 10m 8s\tremaining: 16m 20s\n",
      "3830:\tlearn: 0.0520512\ttotal: 10m 8s\tremaining: 16m 20s\n",
      "3831:\tlearn: 0.0520512\ttotal: 10m 9s\tremaining: 16m 20s\n",
      "3832:\tlearn: 0.0520512\ttotal: 10m 9s\tremaining: 16m 20s\n",
      "3833:\tlearn: 0.0520512\ttotal: 10m 9s\tremaining: 16m 19s\n",
      "3834:\tlearn: 0.0520512\ttotal: 10m 9s\tremaining: 16m 19s\n",
      "3835:\tlearn: 0.0520512\ttotal: 10m 9s\tremaining: 16m 19s\n",
      "3836:\tlearn: 0.0520512\ttotal: 10m 9s\tremaining: 16m 19s\n",
      "3837:\tlearn: 0.0520512\ttotal: 10m 9s\tremaining: 16m 19s\n",
      "3838:\tlearn: 0.0520512\ttotal: 10m 10s\tremaining: 16m 19s\n",
      "3839:\tlearn: 0.0520512\ttotal: 10m 10s\tremaining: 16m 18s\n",
      "3840:\tlearn: 0.0520512\ttotal: 10m 10s\tremaining: 16m 18s\n",
      "3841:\tlearn: 0.0520512\ttotal: 10m 10s\tremaining: 16m 18s\n",
      "3842:\tlearn: 0.0520512\ttotal: 10m 10s\tremaining: 16m 18s\n",
      "3843:\tlearn: 0.0520512\ttotal: 10m 10s\tremaining: 16m 18s\n",
      "3844:\tlearn: 0.0520512\ttotal: 10m 11s\tremaining: 16m 18s\n",
      "3845:\tlearn: 0.0520512\ttotal: 10m 11s\tremaining: 16m 17s\n",
      "3846:\tlearn: 0.0520512\ttotal: 10m 11s\tremaining: 16m 17s\n",
      "3847:\tlearn: 0.0520512\ttotal: 10m 11s\tremaining: 16m 17s\n",
      "3848:\tlearn: 0.0520512\ttotal: 10m 11s\tremaining: 16m 17s\n",
      "3849:\tlearn: 0.0520512\ttotal: 10m 11s\tremaining: 16m 17s\n",
      "3850:\tlearn: 0.0520512\ttotal: 10m 11s\tremaining: 16m 17s\n",
      "3851:\tlearn: 0.0520512\ttotal: 10m 12s\tremaining: 16m 16s\n",
      "3852:\tlearn: 0.0520512\ttotal: 10m 12s\tremaining: 16m 16s\n",
      "3853:\tlearn: 0.0520512\ttotal: 10m 12s\tremaining: 16m 16s\n",
      "3854:\tlearn: 0.0520512\ttotal: 10m 12s\tremaining: 16m 16s\n",
      "3855:\tlearn: 0.0520512\ttotal: 10m 12s\tremaining: 16m 16s\n",
      "3856:\tlearn: 0.0520512\ttotal: 10m 12s\tremaining: 16m 16s\n",
      "3857:\tlearn: 0.0520512\ttotal: 10m 13s\tremaining: 16m 15s\n",
      "3858:\tlearn: 0.0520512\ttotal: 10m 13s\tremaining: 16m 15s\n",
      "3859:\tlearn: 0.0520512\ttotal: 10m 13s\tremaining: 16m 15s\n",
      "3860:\tlearn: 0.0520512\ttotal: 10m 13s\tremaining: 16m 15s\n",
      "3861:\tlearn: 0.0520512\ttotal: 10m 13s\tremaining: 16m 15s\n",
      "3862:\tlearn: 0.0520512\ttotal: 10m 13s\tremaining: 16m 15s\n",
      "3863:\tlearn: 0.0520512\ttotal: 10m 13s\tremaining: 16m 14s\n",
      "3864:\tlearn: 0.0520512\ttotal: 10m 14s\tremaining: 16m 14s\n",
      "3865:\tlearn: 0.0520512\ttotal: 10m 14s\tremaining: 16m 14s\n",
      "3866:\tlearn: 0.0520512\ttotal: 10m 14s\tremaining: 16m 14s\n",
      "3867:\tlearn: 0.0520512\ttotal: 10m 14s\tremaining: 16m 14s\n",
      "3868:\tlearn: 0.0520512\ttotal: 10m 14s\tremaining: 16m 14s\n",
      "3869:\tlearn: 0.0520512\ttotal: 10m 14s\tremaining: 16m 13s\n",
      "3870:\tlearn: 0.0520512\ttotal: 10m 15s\tremaining: 16m 13s\n",
      "3871:\tlearn: 0.0520512\ttotal: 10m 15s\tremaining: 16m 13s\n",
      "3872:\tlearn: 0.0520512\ttotal: 10m 15s\tremaining: 16m 13s\n",
      "3873:\tlearn: 0.0520512\ttotal: 10m 15s\tremaining: 16m 13s\n",
      "3874:\tlearn: 0.0520512\ttotal: 10m 15s\tremaining: 16m 13s\n",
      "3875:\tlearn: 0.0520512\ttotal: 10m 15s\tremaining: 16m 12s\n",
      "3876:\tlearn: 0.0520512\ttotal: 10m 15s\tremaining: 16m 12s\n",
      "3877:\tlearn: 0.0520512\ttotal: 10m 16s\tremaining: 16m 12s\n",
      "3878:\tlearn: 0.0520512\ttotal: 10m 16s\tremaining: 16m 12s\n",
      "3879:\tlearn: 0.0520512\ttotal: 10m 16s\tremaining: 16m 12s\n",
      "3880:\tlearn: 0.0520512\ttotal: 10m 16s\tremaining: 16m 12s\n",
      "3881:\tlearn: 0.0520512\ttotal: 10m 16s\tremaining: 16m 12s\n",
      "3882:\tlearn: 0.0520512\ttotal: 10m 16s\tremaining: 16m 11s\n",
      "3883:\tlearn: 0.0520512\ttotal: 10m 17s\tremaining: 16m 11s\n",
      "3884:\tlearn: 0.0520512\ttotal: 10m 17s\tremaining: 16m 11s\n",
      "3885:\tlearn: 0.0520512\ttotal: 10m 17s\tremaining: 16m 11s\n",
      "3886:\tlearn: 0.0520512\ttotal: 10m 17s\tremaining: 16m 11s\n",
      "3887:\tlearn: 0.0520512\ttotal: 10m 17s\tremaining: 16m 11s\n",
      "3888:\tlearn: 0.0520512\ttotal: 10m 17s\tremaining: 16m 10s\n",
      "3889:\tlearn: 0.0520512\ttotal: 10m 18s\tremaining: 16m 10s\n",
      "3890:\tlearn: 0.0520512\ttotal: 10m 18s\tremaining: 16m 10s\n",
      "3891:\tlearn: 0.0520512\ttotal: 10m 18s\tremaining: 16m 10s\n",
      "3892:\tlearn: 0.0520512\ttotal: 10m 18s\tremaining: 16m 10s\n",
      "3893:\tlearn: 0.0520512\ttotal: 10m 18s\tremaining: 16m 10s\n",
      "3894:\tlearn: 0.0520512\ttotal: 10m 18s\tremaining: 16m 9s\n",
      "3895:\tlearn: 0.0520512\ttotal: 10m 18s\tremaining: 16m 9s\n",
      "3896:\tlearn: 0.0520512\ttotal: 10m 19s\tremaining: 16m 9s\n",
      "3897:\tlearn: 0.0520512\ttotal: 10m 19s\tremaining: 16m 9s\n",
      "3898:\tlearn: 0.0520512\ttotal: 10m 19s\tremaining: 16m 9s\n",
      "3899:\tlearn: 0.0520512\ttotal: 10m 19s\tremaining: 16m 9s\n",
      "3900:\tlearn: 0.0520512\ttotal: 10m 19s\tremaining: 16m 8s\n",
      "3901:\tlearn: 0.0520512\ttotal: 10m 19s\tremaining: 16m 8s\n",
      "3902:\tlearn: 0.0520512\ttotal: 10m 20s\tremaining: 16m 8s\n",
      "3903:\tlearn: 0.0520512\ttotal: 10m 20s\tremaining: 16m 8s\n",
      "3904:\tlearn: 0.0520512\ttotal: 10m 20s\tremaining: 16m 8s\n",
      "3905:\tlearn: 0.0520512\ttotal: 10m 20s\tremaining: 16m 8s\n",
      "3906:\tlearn: 0.0520512\ttotal: 10m 20s\tremaining: 16m 7s\n",
      "3907:\tlearn: 0.0520512\ttotal: 10m 20s\tremaining: 16m 7s\n",
      "3908:\tlearn: 0.0520512\ttotal: 10m 20s\tremaining: 16m 7s\n",
      "3909:\tlearn: 0.0520512\ttotal: 10m 21s\tremaining: 16m 7s\n",
      "3910:\tlearn: 0.0520512\ttotal: 10m 21s\tremaining: 16m 7s\n",
      "3911:\tlearn: 0.0520512\ttotal: 10m 21s\tremaining: 16m 7s\n",
      "3912:\tlearn: 0.0520512\ttotal: 10m 21s\tremaining: 16m 6s\n",
      "3913:\tlearn: 0.0520512\ttotal: 10m 21s\tremaining: 16m 6s\n",
      "3914:\tlearn: 0.0520512\ttotal: 10m 21s\tremaining: 16m 6s\n",
      "3915:\tlearn: 0.0520512\ttotal: 10m 22s\tremaining: 16m 6s\n",
      "3916:\tlearn: 0.0520512\ttotal: 10m 22s\tremaining: 16m 6s\n",
      "3917:\tlearn: 0.0520512\ttotal: 10m 22s\tremaining: 16m 6s\n",
      "3918:\tlearn: 0.0520512\ttotal: 10m 22s\tremaining: 16m 5s\n",
      "3919:\tlearn: 0.0520512\ttotal: 10m 22s\tremaining: 16m 5s\n",
      "3920:\tlearn: 0.0520512\ttotal: 10m 22s\tremaining: 16m 5s\n",
      "3921:\tlearn: 0.0520512\ttotal: 10m 22s\tremaining: 16m 5s\n",
      "3922:\tlearn: 0.0520512\ttotal: 10m 23s\tremaining: 16m 5s\n",
      "3923:\tlearn: 0.0520512\ttotal: 10m 23s\tremaining: 16m 5s\n",
      "3924:\tlearn: 0.0520512\ttotal: 10m 23s\tremaining: 16m 4s\n",
      "3925:\tlearn: 0.0520512\ttotal: 10m 23s\tremaining: 16m 4s\n",
      "3926:\tlearn: 0.0520512\ttotal: 10m 23s\tremaining: 16m 4s\n",
      "3927:\tlearn: 0.0520512\ttotal: 10m 23s\tremaining: 16m 4s\n",
      "3928:\tlearn: 0.0520512\ttotal: 10m 24s\tremaining: 16m 4s\n",
      "3929:\tlearn: 0.0520512\ttotal: 10m 24s\tremaining: 16m 4s\n",
      "3930:\tlearn: 0.0520512\ttotal: 10m 24s\tremaining: 16m 3s\n",
      "3931:\tlearn: 0.0520512\ttotal: 10m 24s\tremaining: 16m 3s\n",
      "3932:\tlearn: 0.0520512\ttotal: 10m 24s\tremaining: 16m 3s\n",
      "3933:\tlearn: 0.0520512\ttotal: 10m 24s\tremaining: 16m 3s\n",
      "3934:\tlearn: 0.0520512\ttotal: 10m 24s\tremaining: 16m 3s\n",
      "3935:\tlearn: 0.0520512\ttotal: 10m 25s\tremaining: 16m 3s\n",
      "3936:\tlearn: 0.0520512\ttotal: 10m 25s\tremaining: 16m 2s\n",
      "3937:\tlearn: 0.0520512\ttotal: 10m 25s\tremaining: 16m 2s\n",
      "3938:\tlearn: 0.0520512\ttotal: 10m 25s\tremaining: 16m 2s\n",
      "3939:\tlearn: 0.0520512\ttotal: 10m 25s\tremaining: 16m 2s\n",
      "3940:\tlearn: 0.0520512\ttotal: 10m 25s\tremaining: 16m 2s\n",
      "3941:\tlearn: 0.0520512\ttotal: 10m 25s\tremaining: 16m 2s\n",
      "3942:\tlearn: 0.0520512\ttotal: 10m 26s\tremaining: 16m 1s\n",
      "3943:\tlearn: 0.0520512\ttotal: 10m 26s\tremaining: 16m 1s\n",
      "3944:\tlearn: 0.0520512\ttotal: 10m 26s\tremaining: 16m 1s\n",
      "3945:\tlearn: 0.0520512\ttotal: 10m 26s\tremaining: 16m 1s\n",
      "3946:\tlearn: 0.0520512\ttotal: 10m 26s\tremaining: 16m 1s\n",
      "3947:\tlearn: 0.0520512\ttotal: 10m 26s\tremaining: 16m 1s\n",
      "3948:\tlearn: 0.0520512\ttotal: 10m 27s\tremaining: 16m\n",
      "3949:\tlearn: 0.0520512\ttotal: 10m 27s\tremaining: 16m\n",
      "3950:\tlearn: 0.0520512\ttotal: 10m 27s\tremaining: 16m\n",
      "3951:\tlearn: 0.0520512\ttotal: 10m 27s\tremaining: 16m\n",
      "3952:\tlearn: 0.0520512\ttotal: 10m 27s\tremaining: 16m\n",
      "3953:\tlearn: 0.0520512\ttotal: 10m 27s\tremaining: 16m\n",
      "3954:\tlearn: 0.0520512\ttotal: 10m 28s\tremaining: 15m 59s\n",
      "3955:\tlearn: 0.0520512\ttotal: 10m 28s\tremaining: 15m 59s\n",
      "3956:\tlearn: 0.0520512\ttotal: 10m 28s\tremaining: 15m 59s\n",
      "3957:\tlearn: 0.0520512\ttotal: 10m 28s\tremaining: 15m 59s\n",
      "3958:\tlearn: 0.0520512\ttotal: 10m 28s\tremaining: 15m 59s\n",
      "3959:\tlearn: 0.0520512\ttotal: 10m 28s\tremaining: 15m 59s\n",
      "3960:\tlearn: 0.0520512\ttotal: 10m 28s\tremaining: 15m 58s\n",
      "3961:\tlearn: 0.0520512\ttotal: 10m 29s\tremaining: 15m 58s\n",
      "3962:\tlearn: 0.0520512\ttotal: 10m 29s\tremaining: 15m 58s\n",
      "3963:\tlearn: 0.0520512\ttotal: 10m 29s\tremaining: 15m 58s\n",
      "3964:\tlearn: 0.0520512\ttotal: 10m 29s\tremaining: 15m 58s\n",
      "3965:\tlearn: 0.0520512\ttotal: 10m 29s\tremaining: 15m 58s\n",
      "3966:\tlearn: 0.0520512\ttotal: 10m 29s\tremaining: 15m 57s\n",
      "3967:\tlearn: 0.0520512\ttotal: 10m 30s\tremaining: 15m 57s\n",
      "3968:\tlearn: 0.0520512\ttotal: 10m 30s\tremaining: 15m 57s\n",
      "3969:\tlearn: 0.0520512\ttotal: 10m 30s\tremaining: 15m 57s\n",
      "3970:\tlearn: 0.0520512\ttotal: 10m 30s\tremaining: 15m 57s\n",
      "3971:\tlearn: 0.0520512\ttotal: 10m 30s\tremaining: 15m 57s\n",
      "3972:\tlearn: 0.0520512\ttotal: 10m 30s\tremaining: 15m 56s\n",
      "3973:\tlearn: 0.0520512\ttotal: 10m 30s\tremaining: 15m 56s\n",
      "3974:\tlearn: 0.0520512\ttotal: 10m 31s\tremaining: 15m 56s\n",
      "3975:\tlearn: 0.0520512\ttotal: 10m 31s\tremaining: 15m 56s\n",
      "3976:\tlearn: 0.0520512\ttotal: 10m 31s\tremaining: 15m 56s\n",
      "3977:\tlearn: 0.0520512\ttotal: 10m 31s\tremaining: 15m 56s\n",
      "3978:\tlearn: 0.0520512\ttotal: 10m 31s\tremaining: 15m 55s\n",
      "3979:\tlearn: 0.0520512\ttotal: 10m 31s\tremaining: 15m 55s\n",
      "3980:\tlearn: 0.0520512\ttotal: 10m 32s\tremaining: 15m 55s\n",
      "3981:\tlearn: 0.0520512\ttotal: 10m 32s\tremaining: 15m 55s\n",
      "3982:\tlearn: 0.0520512\ttotal: 10m 32s\tremaining: 15m 55s\n",
      "3983:\tlearn: 0.0520512\ttotal: 10m 32s\tremaining: 15m 55s\n",
      "3984:\tlearn: 0.0520512\ttotal: 10m 32s\tremaining: 15m 55s\n",
      "3985:\tlearn: 0.0520512\ttotal: 10m 32s\tremaining: 15m 54s\n",
      "3986:\tlearn: 0.0520512\ttotal: 10m 33s\tremaining: 15m 54s\n",
      "3987:\tlearn: 0.0520512\ttotal: 10m 33s\tremaining: 15m 54s\n",
      "3988:\tlearn: 0.0520512\ttotal: 10m 33s\tremaining: 15m 54s\n",
      "3989:\tlearn: 0.0520512\ttotal: 10m 33s\tremaining: 15m 54s\n",
      "3990:\tlearn: 0.0520512\ttotal: 10m 33s\tremaining: 15m 54s\n",
      "3991:\tlearn: 0.0520512\ttotal: 10m 33s\tremaining: 15m 53s\n",
      "3992:\tlearn: 0.0520512\ttotal: 10m 33s\tremaining: 15m 53s\n",
      "3993:\tlearn: 0.0520512\ttotal: 10m 34s\tremaining: 15m 53s\n",
      "3994:\tlearn: 0.0520512\ttotal: 10m 34s\tremaining: 15m 53s\n",
      "3995:\tlearn: 0.0520512\ttotal: 10m 34s\tremaining: 15m 53s\n",
      "3996:\tlearn: 0.0520512\ttotal: 10m 34s\tremaining: 15m 53s\n",
      "3997:\tlearn: 0.0520512\ttotal: 10m 34s\tremaining: 15m 52s\n",
      "3998:\tlearn: 0.0520512\ttotal: 10m 34s\tremaining: 15m 52s\n",
      "3999:\tlearn: 0.0520512\ttotal: 10m 35s\tremaining: 15m 52s\n",
      "4000:\tlearn: 0.0520512\ttotal: 10m 35s\tremaining: 15m 52s\n",
      "4001:\tlearn: 0.0520512\ttotal: 10m 35s\tremaining: 15m 52s\n",
      "4002:\tlearn: 0.0520512\ttotal: 10m 35s\tremaining: 15m 52s\n",
      "4003:\tlearn: 0.0520512\ttotal: 10m 35s\tremaining: 15m 51s\n",
      "4004:\tlearn: 0.0520512\ttotal: 10m 35s\tremaining: 15m 51s\n",
      "4005:\tlearn: 0.0520512\ttotal: 10m 35s\tremaining: 15m 51s\n",
      "4006:\tlearn: 0.0520512\ttotal: 10m 36s\tremaining: 15m 51s\n",
      "4007:\tlearn: 0.0520512\ttotal: 10m 36s\tremaining: 15m 51s\n",
      "4008:\tlearn: 0.0520512\ttotal: 10m 36s\tremaining: 15m 51s\n",
      "4009:\tlearn: 0.0520512\ttotal: 10m 36s\tremaining: 15m 50s\n",
      "4010:\tlearn: 0.0520512\ttotal: 10m 36s\tremaining: 15m 50s\n",
      "4011:\tlearn: 0.0520512\ttotal: 10m 36s\tremaining: 15m 50s\n",
      "4012:\tlearn: 0.0520512\ttotal: 10m 37s\tremaining: 15m 50s\n",
      "4013:\tlearn: 0.0520512\ttotal: 10m 37s\tremaining: 15m 50s\n",
      "4014:\tlearn: 0.0520512\ttotal: 10m 37s\tremaining: 15m 50s\n",
      "4015:\tlearn: 0.0520512\ttotal: 10m 37s\tremaining: 15m 49s\n",
      "4016:\tlearn: 0.0520512\ttotal: 10m 37s\tremaining: 15m 49s\n",
      "4017:\tlearn: 0.0520512\ttotal: 10m 37s\tremaining: 15m 49s\n",
      "4018:\tlearn: 0.0520512\ttotal: 10m 38s\tremaining: 15m 49s\n",
      "4019:\tlearn: 0.0520512\ttotal: 10m 38s\tremaining: 15m 49s\n",
      "4020:\tlearn: 0.0520512\ttotal: 10m 38s\tremaining: 15m 49s\n",
      "4021:\tlearn: 0.0520512\ttotal: 10m 38s\tremaining: 15m 48s\n",
      "4022:\tlearn: 0.0520512\ttotal: 10m 38s\tremaining: 15m 48s\n",
      "4023:\tlearn: 0.0520512\ttotal: 10m 38s\tremaining: 15m 48s\n",
      "4024:\tlearn: 0.0520512\ttotal: 10m 38s\tremaining: 15m 48s\n",
      "4025:\tlearn: 0.0520512\ttotal: 10m 39s\tremaining: 15m 48s\n",
      "4026:\tlearn: 0.0520512\ttotal: 10m 39s\tremaining: 15m 48s\n",
      "4027:\tlearn: 0.0520512\ttotal: 10m 39s\tremaining: 15m 47s\n",
      "4028:\tlearn: 0.0520512\ttotal: 10m 39s\tremaining: 15m 47s\n",
      "4029:\tlearn: 0.0520512\ttotal: 10m 39s\tremaining: 15m 47s\n",
      "4030:\tlearn: 0.0520512\ttotal: 10m 39s\tremaining: 15m 47s\n",
      "4031:\tlearn: 0.0520512\ttotal: 10m 40s\tremaining: 15m 47s\n",
      "4032:\tlearn: 0.0520512\ttotal: 10m 40s\tremaining: 15m 47s\n",
      "4033:\tlearn: 0.0520512\ttotal: 10m 40s\tremaining: 15m 46s\n",
      "4034:\tlearn: 0.0520512\ttotal: 10m 40s\tremaining: 15m 46s\n",
      "4035:\tlearn: 0.0520512\ttotal: 10m 40s\tremaining: 15m 46s\n",
      "4036:\tlearn: 0.0520512\ttotal: 10m 40s\tremaining: 15m 46s\n",
      "4037:\tlearn: 0.0520512\ttotal: 10m 40s\tremaining: 15m 46s\n",
      "4038:\tlearn: 0.0520512\ttotal: 10m 41s\tremaining: 15m 46s\n",
      "4039:\tlearn: 0.0520512\ttotal: 10m 41s\tremaining: 15m 46s\n",
      "4040:\tlearn: 0.0520512\ttotal: 10m 41s\tremaining: 15m 45s\n",
      "4041:\tlearn: 0.0520512\ttotal: 10m 41s\tremaining: 15m 45s\n",
      "4042:\tlearn: 0.0520512\ttotal: 10m 41s\tremaining: 15m 45s\n",
      "4043:\tlearn: 0.0520512\ttotal: 10m 41s\tremaining: 15m 45s\n",
      "4044:\tlearn: 0.0520512\ttotal: 10m 42s\tremaining: 15m 45s\n",
      "4045:\tlearn: 0.0520512\ttotal: 10m 42s\tremaining: 15m 45s\n",
      "4046:\tlearn: 0.0520512\ttotal: 10m 42s\tremaining: 15m 44s\n",
      "4047:\tlearn: 0.0520512\ttotal: 10m 42s\tremaining: 15m 44s\n",
      "4048:\tlearn: 0.0520512\ttotal: 10m 42s\tremaining: 15m 44s\n",
      "4049:\tlearn: 0.0520512\ttotal: 10m 42s\tremaining: 15m 44s\n",
      "4050:\tlearn: 0.0520512\ttotal: 10m 42s\tremaining: 15m 44s\n",
      "4051:\tlearn: 0.0520512\ttotal: 10m 43s\tremaining: 15m 44s\n",
      "4052:\tlearn: 0.0520512\ttotal: 10m 43s\tremaining: 15m 43s\n",
      "4053:\tlearn: 0.0520512\ttotal: 10m 43s\tremaining: 15m 43s\n",
      "4054:\tlearn: 0.0520512\ttotal: 10m 43s\tremaining: 15m 43s\n",
      "4055:\tlearn: 0.0520512\ttotal: 10m 43s\tremaining: 15m 43s\n",
      "4056:\tlearn: 0.0520512\ttotal: 10m 43s\tremaining: 15m 43s\n",
      "4057:\tlearn: 0.0520512\ttotal: 10m 44s\tremaining: 15m 43s\n",
      "4058:\tlearn: 0.0520512\ttotal: 10m 44s\tremaining: 15m 42s\n",
      "4059:\tlearn: 0.0520512\ttotal: 10m 44s\tremaining: 15m 42s\n",
      "4060:\tlearn: 0.0520512\ttotal: 10m 44s\tremaining: 15m 42s\n",
      "4061:\tlearn: 0.0520512\ttotal: 10m 44s\tremaining: 15m 42s\n",
      "4062:\tlearn: 0.0520512\ttotal: 10m 44s\tremaining: 15m 42s\n",
      "4063:\tlearn: 0.0520512\ttotal: 10m 44s\tremaining: 15m 42s\n",
      "4064:\tlearn: 0.0520512\ttotal: 10m 45s\tremaining: 15m 41s\n",
      "4065:\tlearn: 0.0520512\ttotal: 10m 45s\tremaining: 15m 41s\n",
      "4066:\tlearn: 0.0520512\ttotal: 10m 45s\tremaining: 15m 41s\n",
      "4067:\tlearn: 0.0520512\ttotal: 10m 45s\tremaining: 15m 41s\n",
      "4068:\tlearn: 0.0520512\ttotal: 10m 45s\tremaining: 15m 41s\n",
      "4069:\tlearn: 0.0520512\ttotal: 10m 45s\tremaining: 15m 41s\n",
      "4070:\tlearn: 0.0520512\ttotal: 10m 46s\tremaining: 15m 40s\n",
      "4071:\tlearn: 0.0520512\ttotal: 10m 46s\tremaining: 15m 40s\n",
      "4072:\tlearn: 0.0520512\ttotal: 10m 46s\tremaining: 15m 40s\n",
      "4073:\tlearn: 0.0520512\ttotal: 10m 46s\tremaining: 15m 40s\n",
      "4074:\tlearn: 0.0520512\ttotal: 10m 46s\tremaining: 15m 40s\n",
      "4075:\tlearn: 0.0520512\ttotal: 10m 46s\tremaining: 15m 40s\n",
      "4076:\tlearn: 0.0520512\ttotal: 10m 46s\tremaining: 15m 39s\n",
      "4077:\tlearn: 0.0520512\ttotal: 10m 47s\tremaining: 15m 39s\n",
      "4078:\tlearn: 0.0520512\ttotal: 10m 47s\tremaining: 15m 39s\n",
      "4079:\tlearn: 0.0520512\ttotal: 10m 47s\tremaining: 15m 39s\n",
      "4080:\tlearn: 0.0520512\ttotal: 10m 47s\tremaining: 15m 39s\n",
      "4081:\tlearn: 0.0520512\ttotal: 10m 47s\tremaining: 15m 39s\n",
      "4082:\tlearn: 0.0520512\ttotal: 10m 47s\tremaining: 15m 38s\n",
      "4083:\tlearn: 0.0520512\ttotal: 10m 48s\tremaining: 15m 38s\n",
      "4084:\tlearn: 0.0520512\ttotal: 10m 48s\tremaining: 15m 38s\n",
      "4085:\tlearn: 0.0520512\ttotal: 10m 48s\tremaining: 15m 38s\n",
      "4086:\tlearn: 0.0520512\ttotal: 10m 48s\tremaining: 15m 38s\n",
      "4087:\tlearn: 0.0520512\ttotal: 10m 48s\tremaining: 15m 38s\n",
      "4088:\tlearn: 0.0520512\ttotal: 10m 48s\tremaining: 15m 37s\n",
      "4089:\tlearn: 0.0520512\ttotal: 10m 49s\tremaining: 15m 37s\n",
      "4090:\tlearn: 0.0520512\ttotal: 10m 49s\tremaining: 15m 37s\n",
      "4091:\tlearn: 0.0520512\ttotal: 10m 49s\tremaining: 15m 37s\n",
      "4092:\tlearn: 0.0520512\ttotal: 10m 49s\tremaining: 15m 37s\n",
      "4093:\tlearn: 0.0520512\ttotal: 10m 49s\tremaining: 15m 37s\n",
      "4094:\tlearn: 0.0520512\ttotal: 10m 49s\tremaining: 15m 37s\n",
      "4095:\tlearn: 0.0520512\ttotal: 10m 49s\tremaining: 15m 36s\n",
      "4096:\tlearn: 0.0520512\ttotal: 10m 50s\tremaining: 15m 36s\n",
      "4097:\tlearn: 0.0520512\ttotal: 10m 50s\tremaining: 15m 36s\n",
      "4098:\tlearn: 0.0520512\ttotal: 10m 50s\tremaining: 15m 36s\n",
      "4099:\tlearn: 0.0520512\ttotal: 10m 50s\tremaining: 15m 36s\n",
      "4100:\tlearn: 0.0520512\ttotal: 10m 50s\tremaining: 15m 36s\n",
      "4101:\tlearn: 0.0520512\ttotal: 10m 50s\tremaining: 15m 35s\n",
      "4102:\tlearn: 0.0520512\ttotal: 10m 51s\tremaining: 15m 35s\n",
      "4103:\tlearn: 0.0520512\ttotal: 10m 51s\tremaining: 15m 35s\n",
      "4104:\tlearn: 0.0520512\ttotal: 10m 51s\tremaining: 15m 35s\n",
      "4105:\tlearn: 0.0520512\ttotal: 10m 51s\tremaining: 15m 35s\n",
      "4106:\tlearn: 0.0520512\ttotal: 10m 51s\tremaining: 15m 35s\n",
      "4107:\tlearn: 0.0520512\ttotal: 10m 51s\tremaining: 15m 34s\n",
      "4108:\tlearn: 0.0520512\ttotal: 10m 51s\tremaining: 15m 34s\n",
      "4109:\tlearn: 0.0520512\ttotal: 10m 52s\tremaining: 15m 34s\n",
      "4110:\tlearn: 0.0520512\ttotal: 10m 52s\tremaining: 15m 34s\n",
      "4111:\tlearn: 0.0520512\ttotal: 10m 52s\tremaining: 15m 34s\n",
      "4112:\tlearn: 0.0520512\ttotal: 10m 52s\tremaining: 15m 34s\n",
      "4113:\tlearn: 0.0520512\ttotal: 10m 52s\tremaining: 15m 33s\n",
      "4114:\tlearn: 0.0520512\ttotal: 10m 52s\tremaining: 15m 33s\n",
      "4115:\tlearn: 0.0520512\ttotal: 10m 53s\tremaining: 15m 33s\n",
      "4116:\tlearn: 0.0520512\ttotal: 10m 53s\tremaining: 15m 33s\n",
      "4117:\tlearn: 0.0520512\ttotal: 10m 53s\tremaining: 15m 33s\n",
      "4118:\tlearn: 0.0520512\ttotal: 10m 53s\tremaining: 15m 33s\n",
      "4119:\tlearn: 0.0520512\ttotal: 10m 53s\tremaining: 15m 32s\n",
      "4120:\tlearn: 0.0520512\ttotal: 10m 53s\tremaining: 15m 32s\n",
      "4121:\tlearn: 0.0520512\ttotal: 10m 53s\tremaining: 15m 32s\n",
      "4122:\tlearn: 0.0520512\ttotal: 10m 54s\tremaining: 15m 32s\n",
      "4123:\tlearn: 0.0520512\ttotal: 10m 54s\tremaining: 15m 32s\n",
      "4124:\tlearn: 0.0520512\ttotal: 10m 54s\tremaining: 15m 32s\n",
      "4125:\tlearn: 0.0520512\ttotal: 10m 54s\tremaining: 15m 31s\n",
      "4126:\tlearn: 0.0520512\ttotal: 10m 54s\tremaining: 15m 31s\n",
      "4127:\tlearn: 0.0520512\ttotal: 10m 54s\tremaining: 15m 31s\n",
      "4128:\tlearn: 0.0520512\ttotal: 10m 55s\tremaining: 15m 31s\n",
      "4129:\tlearn: 0.0520512\ttotal: 10m 55s\tremaining: 15m 31s\n",
      "4130:\tlearn: 0.0520512\ttotal: 10m 55s\tremaining: 15m 31s\n",
      "4131:\tlearn: 0.0520512\ttotal: 10m 55s\tremaining: 15m 30s\n",
      "4132:\tlearn: 0.0520512\ttotal: 10m 55s\tremaining: 15m 30s\n",
      "4133:\tlearn: 0.0520512\ttotal: 10m 55s\tremaining: 15m 30s\n",
      "4134:\tlearn: 0.0520512\ttotal: 10m 56s\tremaining: 15m 30s\n",
      "4135:\tlearn: 0.0520512\ttotal: 10m 56s\tremaining: 15m 30s\n",
      "4136:\tlearn: 0.0520512\ttotal: 10m 56s\tremaining: 15m 30s\n",
      "4137:\tlearn: 0.0520512\ttotal: 10m 56s\tremaining: 15m 29s\n",
      "4138:\tlearn: 0.0520512\ttotal: 10m 56s\tremaining: 15m 29s\n",
      "4139:\tlearn: 0.0520512\ttotal: 10m 56s\tremaining: 15m 29s\n",
      "4140:\tlearn: 0.0520512\ttotal: 10m 56s\tremaining: 15m 29s\n",
      "4141:\tlearn: 0.0520512\ttotal: 10m 57s\tremaining: 15m 29s\n",
      "4142:\tlearn: 0.0520512\ttotal: 10m 57s\tremaining: 15m 29s\n",
      "4143:\tlearn: 0.0520512\ttotal: 10m 57s\tremaining: 15m 28s\n",
      "4144:\tlearn: 0.0520512\ttotal: 10m 57s\tremaining: 15m 28s\n",
      "4145:\tlearn: 0.0520512\ttotal: 10m 57s\tremaining: 15m 28s\n",
      "4146:\tlearn: 0.0520512\ttotal: 10m 57s\tremaining: 15m 28s\n",
      "4147:\tlearn: 0.0520512\ttotal: 10m 57s\tremaining: 15m 28s\n",
      "4148:\tlearn: 0.0520512\ttotal: 10m 58s\tremaining: 15m 28s\n",
      "4149:\tlearn: 0.0520512\ttotal: 10m 58s\tremaining: 15m 27s\n",
      "4150:\tlearn: 0.0520512\ttotal: 10m 58s\tremaining: 15m 27s\n",
      "4151:\tlearn: 0.0520512\ttotal: 10m 58s\tremaining: 15m 27s\n",
      "4152:\tlearn: 0.0520512\ttotal: 10m 58s\tremaining: 15m 27s\n",
      "4153:\tlearn: 0.0520512\ttotal: 10m 58s\tremaining: 15m 27s\n",
      "4154:\tlearn: 0.0520512\ttotal: 10m 59s\tremaining: 15m 27s\n",
      "4155:\tlearn: 0.0520512\ttotal: 10m 59s\tremaining: 15m 26s\n",
      "4156:\tlearn: 0.0520512\ttotal: 10m 59s\tremaining: 15m 26s\n",
      "4157:\tlearn: 0.0520512\ttotal: 10m 59s\tremaining: 15m 26s\n",
      "4158:\tlearn: 0.0520512\ttotal: 10m 59s\tremaining: 15m 26s\n",
      "4159:\tlearn: 0.0520512\ttotal: 10m 59s\tremaining: 15m 26s\n",
      "4160:\tlearn: 0.0520512\ttotal: 11m\tremaining: 15m 26s\n",
      "4161:\tlearn: 0.0520512\ttotal: 11m\tremaining: 15m 26s\n",
      "4162:\tlearn: 0.0520512\ttotal: 11m\tremaining: 15m 25s\n",
      "4163:\tlearn: 0.0520512\ttotal: 11m\tremaining: 15m 25s\n",
      "4164:\tlearn: 0.0520512\ttotal: 11m\tremaining: 15m 25s\n",
      "4165:\tlearn: 0.0520512\ttotal: 11m\tremaining: 15m 25s\n",
      "4166:\tlearn: 0.0520512\ttotal: 11m\tremaining: 15m 25s\n",
      "4167:\tlearn: 0.0520512\ttotal: 11m 1s\tremaining: 15m 25s\n",
      "4168:\tlearn: 0.0520512\ttotal: 11m 1s\tremaining: 15m 24s\n",
      "4169:\tlearn: 0.0520512\ttotal: 11m 1s\tremaining: 15m 24s\n",
      "4170:\tlearn: 0.0520512\ttotal: 11m 1s\tremaining: 15m 24s\n",
      "4171:\tlearn: 0.0520512\ttotal: 11m 1s\tremaining: 15m 24s\n",
      "4172:\tlearn: 0.0520512\ttotal: 11m 1s\tremaining: 15m 24s\n",
      "4173:\tlearn: 0.0520512\ttotal: 11m 2s\tremaining: 15m 24s\n",
      "4174:\tlearn: 0.0520512\ttotal: 11m 2s\tremaining: 15m 23s\n",
      "4175:\tlearn: 0.0520512\ttotal: 11m 2s\tremaining: 15m 23s\n",
      "4176:\tlearn: 0.0520512\ttotal: 11m 2s\tremaining: 15m 23s\n",
      "4177:\tlearn: 0.0520512\ttotal: 11m 2s\tremaining: 15m 23s\n",
      "4178:\tlearn: 0.0520512\ttotal: 11m 2s\tremaining: 15m 23s\n",
      "4179:\tlearn: 0.0520512\ttotal: 11m 2s\tremaining: 15m 23s\n",
      "4180:\tlearn: 0.0520512\ttotal: 11m 3s\tremaining: 15m 22s\n",
      "4181:\tlearn: 0.0520512\ttotal: 11m 3s\tremaining: 15m 22s\n",
      "4182:\tlearn: 0.0520512\ttotal: 11m 3s\tremaining: 15m 22s\n",
      "4183:\tlearn: 0.0520512\ttotal: 11m 3s\tremaining: 15m 22s\n",
      "4184:\tlearn: 0.0520512\ttotal: 11m 3s\tremaining: 15m 22s\n",
      "4185:\tlearn: 0.0520512\ttotal: 11m 3s\tremaining: 15m 22s\n",
      "4186:\tlearn: 0.0520512\ttotal: 11m 3s\tremaining: 15m 21s\n",
      "4187:\tlearn: 0.0520512\ttotal: 11m 4s\tremaining: 15m 21s\n",
      "4188:\tlearn: 0.0520512\ttotal: 11m 4s\tremaining: 15m 21s\n",
      "4189:\tlearn: 0.0520512\ttotal: 11m 4s\tremaining: 15m 21s\n",
      "4190:\tlearn: 0.0520512\ttotal: 11m 4s\tremaining: 15m 21s\n",
      "4191:\tlearn: 0.0520512\ttotal: 11m 4s\tremaining: 15m 21s\n",
      "4192:\tlearn: 0.0520512\ttotal: 11m 4s\tremaining: 15m 20s\n",
      "4193:\tlearn: 0.0520512\ttotal: 11m 5s\tremaining: 15m 20s\n",
      "4194:\tlearn: 0.0520512\ttotal: 11m 5s\tremaining: 15m 20s\n",
      "4195:\tlearn: 0.0520512\ttotal: 11m 5s\tremaining: 15m 20s\n",
      "4196:\tlearn: 0.0520512\ttotal: 11m 5s\tremaining: 15m 20s\n",
      "4197:\tlearn: 0.0520512\ttotal: 11m 5s\tremaining: 15m 20s\n",
      "4198:\tlearn: 0.0520512\ttotal: 11m 5s\tremaining: 15m 19s\n",
      "4199:\tlearn: 0.0520512\ttotal: 11m 6s\tremaining: 15m 19s\n",
      "4200:\tlearn: 0.0520512\ttotal: 11m 6s\tremaining: 15m 19s\n",
      "4201:\tlearn: 0.0520512\ttotal: 11m 6s\tremaining: 15m 19s\n",
      "4202:\tlearn: 0.0520512\ttotal: 11m 6s\tremaining: 15m 19s\n",
      "4203:\tlearn: 0.0520512\ttotal: 11m 6s\tremaining: 15m 19s\n",
      "4204:\tlearn: 0.0520512\ttotal: 11m 6s\tremaining: 15m 18s\n",
      "4205:\tlearn: 0.0520512\ttotal: 11m 6s\tremaining: 15m 18s\n",
      "4206:\tlearn: 0.0520512\ttotal: 11m 7s\tremaining: 15m 18s\n",
      "4207:\tlearn: 0.0520512\ttotal: 11m 7s\tremaining: 15m 18s\n",
      "4208:\tlearn: 0.0520512\ttotal: 11m 7s\tremaining: 15m 18s\n",
      "4209:\tlearn: 0.0520512\ttotal: 11m 7s\tremaining: 15m 18s\n",
      "4210:\tlearn: 0.0520512\ttotal: 11m 7s\tremaining: 15m 17s\n",
      "4211:\tlearn: 0.0520512\ttotal: 11m 7s\tremaining: 15m 17s\n",
      "4212:\tlearn: 0.0520512\ttotal: 11m 8s\tremaining: 15m 17s\n",
      "4213:\tlearn: 0.0520512\ttotal: 11m 8s\tremaining: 15m 17s\n",
      "4214:\tlearn: 0.0520512\ttotal: 11m 8s\tremaining: 15m 17s\n",
      "4215:\tlearn: 0.0520512\ttotal: 11m 8s\tremaining: 15m 17s\n",
      "4216:\tlearn: 0.0520512\ttotal: 11m 8s\tremaining: 15m 16s\n",
      "4217:\tlearn: 0.0520512\ttotal: 11m 8s\tremaining: 15m 16s\n",
      "4218:\tlearn: 0.0520512\ttotal: 11m 8s\tremaining: 15m 16s\n",
      "4219:\tlearn: 0.0520512\ttotal: 11m 9s\tremaining: 15m 16s\n",
      "4220:\tlearn: 0.0520512\ttotal: 11m 9s\tremaining: 15m 16s\n",
      "4221:\tlearn: 0.0520512\ttotal: 11m 9s\tremaining: 15m 16s\n",
      "4222:\tlearn: 0.0520512\ttotal: 11m 9s\tremaining: 15m 15s\n",
      "4223:\tlearn: 0.0520512\ttotal: 11m 9s\tremaining: 15m 15s\n",
      "4224:\tlearn: 0.0520512\ttotal: 11m 9s\tremaining: 15m 15s\n",
      "4225:\tlearn: 0.0520512\ttotal: 11m 10s\tremaining: 15m 15s\n",
      "4226:\tlearn: 0.0520512\ttotal: 11m 10s\tremaining: 15m 15s\n",
      "4227:\tlearn: 0.0520512\ttotal: 11m 10s\tremaining: 15m 15s\n",
      "4228:\tlearn: 0.0520512\ttotal: 11m 10s\tremaining: 15m 15s\n",
      "4229:\tlearn: 0.0520512\ttotal: 11m 10s\tremaining: 15m 14s\n",
      "4230:\tlearn: 0.0520512\ttotal: 11m 10s\tremaining: 15m 14s\n",
      "4231:\tlearn: 0.0520512\ttotal: 11m 11s\tremaining: 15m 14s\n",
      "4232:\tlearn: 0.0520512\ttotal: 11m 11s\tremaining: 15m 14s\n",
      "4233:\tlearn: 0.0520512\ttotal: 11m 11s\tremaining: 15m 14s\n",
      "4234:\tlearn: 0.0520512\ttotal: 11m 11s\tremaining: 15m 14s\n",
      "4235:\tlearn: 0.0520512\ttotal: 11m 11s\tremaining: 15m 13s\n",
      "4236:\tlearn: 0.0520512\ttotal: 11m 11s\tremaining: 15m 13s\n",
      "4237:\tlearn: 0.0520512\ttotal: 11m 12s\tremaining: 15m 13s\n",
      "4238:\tlearn: 0.0520512\ttotal: 11m 12s\tremaining: 15m 13s\n",
      "4239:\tlearn: 0.0520512\ttotal: 11m 12s\tremaining: 15m 13s\n",
      "4240:\tlearn: 0.0520512\ttotal: 11m 12s\tremaining: 15m 13s\n",
      "4241:\tlearn: 0.0520512\ttotal: 11m 12s\tremaining: 15m 12s\n",
      "4242:\tlearn: 0.0520512\ttotal: 11m 12s\tremaining: 15m 12s\n",
      "4243:\tlearn: 0.0520512\ttotal: 11m 12s\tremaining: 15m 12s\n",
      "4244:\tlearn: 0.0520512\ttotal: 11m 13s\tremaining: 15m 12s\n",
      "4245:\tlearn: 0.0520512\ttotal: 11m 13s\tremaining: 15m 12s\n",
      "4246:\tlearn: 0.0520512\ttotal: 11m 13s\tremaining: 15m 12s\n",
      "4247:\tlearn: 0.0520512\ttotal: 11m 13s\tremaining: 15m 12s\n",
      "4248:\tlearn: 0.0520512\ttotal: 11m 13s\tremaining: 15m 11s\n",
      "4249:\tlearn: 0.0520512\ttotal: 11m 13s\tremaining: 15m 11s\n",
      "4250:\tlearn: 0.0520512\ttotal: 11m 14s\tremaining: 15m 11s\n",
      "4251:\tlearn: 0.0520512\ttotal: 11m 14s\tremaining: 15m 11s\n",
      "4252:\tlearn: 0.0520512\ttotal: 11m 14s\tremaining: 15m 11s\n",
      "4253:\tlearn: 0.0520512\ttotal: 11m 14s\tremaining: 15m 11s\n",
      "4254:\tlearn: 0.0520512\ttotal: 11m 14s\tremaining: 15m 10s\n",
      "4255:\tlearn: 0.0520512\ttotal: 11m 14s\tremaining: 15m 10s\n",
      "4256:\tlearn: 0.0520512\ttotal: 11m 15s\tremaining: 15m 10s\n",
      "4257:\tlearn: 0.0520512\ttotal: 11m 15s\tremaining: 15m 10s\n",
      "4258:\tlearn: 0.0520512\ttotal: 11m 15s\tremaining: 15m 10s\n",
      "4259:\tlearn: 0.0520512\ttotal: 11m 15s\tremaining: 15m 10s\n",
      "4260:\tlearn: 0.0520512\ttotal: 11m 15s\tremaining: 15m 10s\n",
      "4261:\tlearn: 0.0520512\ttotal: 11m 15s\tremaining: 15m 9s\n",
      "4262:\tlearn: 0.0520512\ttotal: 11m 15s\tremaining: 15m 9s\n",
      "4263:\tlearn: 0.0520512\ttotal: 11m 16s\tremaining: 15m 9s\n",
      "4264:\tlearn: 0.0520512\ttotal: 11m 16s\tremaining: 15m 9s\n",
      "4265:\tlearn: 0.0520512\ttotal: 11m 16s\tremaining: 15m 9s\n",
      "4266:\tlearn: 0.0520512\ttotal: 11m 16s\tremaining: 15m 9s\n",
      "4267:\tlearn: 0.0520512\ttotal: 11m 16s\tremaining: 15m 8s\n",
      "4268:\tlearn: 0.0520512\ttotal: 11m 16s\tremaining: 15m 8s\n",
      "4269:\tlearn: 0.0520512\ttotal: 11m 17s\tremaining: 15m 8s\n",
      "4270:\tlearn: 0.0520512\ttotal: 11m 17s\tremaining: 15m 8s\n",
      "4271:\tlearn: 0.0520512\ttotal: 11m 17s\tremaining: 15m 8s\n",
      "4272:\tlearn: 0.0520512\ttotal: 11m 17s\tremaining: 15m 8s\n",
      "4273:\tlearn: 0.0520512\ttotal: 11m 17s\tremaining: 15m 7s\n",
      "4274:\tlearn: 0.0520512\ttotal: 11m 17s\tremaining: 15m 7s\n",
      "4275:\tlearn: 0.0520512\ttotal: 11m 18s\tremaining: 15m 7s\n",
      "4276:\tlearn: 0.0520512\ttotal: 11m 18s\tremaining: 15m 7s\n",
      "4277:\tlearn: 0.0520512\ttotal: 11m 18s\tremaining: 15m 7s\n",
      "4278:\tlearn: 0.0520512\ttotal: 11m 18s\tremaining: 15m 7s\n",
      "4279:\tlearn: 0.0520512\ttotal: 11m 18s\tremaining: 15m 6s\n",
      "4280:\tlearn: 0.0520512\ttotal: 11m 18s\tremaining: 15m 6s\n",
      "4281:\tlearn: 0.0520512\ttotal: 11m 18s\tremaining: 15m 6s\n",
      "4282:\tlearn: 0.0520512\ttotal: 11m 19s\tremaining: 15m 6s\n",
      "4283:\tlearn: 0.0520512\ttotal: 11m 19s\tremaining: 15m 6s\n",
      "4284:\tlearn: 0.0520512\ttotal: 11m 19s\tremaining: 15m 6s\n",
      "4285:\tlearn: 0.0520512\ttotal: 11m 19s\tremaining: 15m 5s\n",
      "4286:\tlearn: 0.0520512\ttotal: 11m 19s\tremaining: 15m 5s\n",
      "4287:\tlearn: 0.0520512\ttotal: 11m 19s\tremaining: 15m 5s\n",
      "4288:\tlearn: 0.0520512\ttotal: 11m 19s\tremaining: 15m 5s\n",
      "4289:\tlearn: 0.0520512\ttotal: 11m 20s\tremaining: 15m 5s\n",
      "4290:\tlearn: 0.0520512\ttotal: 11m 20s\tremaining: 15m 5s\n",
      "4291:\tlearn: 0.0520512\ttotal: 11m 20s\tremaining: 15m 4s\n",
      "4292:\tlearn: 0.0520512\ttotal: 11m 20s\tremaining: 15m 4s\n",
      "4293:\tlearn: 0.0520512\ttotal: 11m 20s\tremaining: 15m 4s\n",
      "4294:\tlearn: 0.0520512\ttotal: 11m 20s\tremaining: 15m 4s\n",
      "4295:\tlearn: 0.0520512\ttotal: 11m 21s\tremaining: 15m 4s\n",
      "4296:\tlearn: 0.0520512\ttotal: 11m 21s\tremaining: 15m 4s\n",
      "4297:\tlearn: 0.0520512\ttotal: 11m 21s\tremaining: 15m 3s\n",
      "4298:\tlearn: 0.0520512\ttotal: 11m 21s\tremaining: 15m 3s\n",
      "4299:\tlearn: 0.0520512\ttotal: 11m 21s\tremaining: 15m 3s\n",
      "4300:\tlearn: 0.0520512\ttotal: 11m 21s\tremaining: 15m 3s\n",
      "4301:\tlearn: 0.0520512\ttotal: 11m 21s\tremaining: 15m 3s\n",
      "4302:\tlearn: 0.0520512\ttotal: 11m 22s\tremaining: 15m 3s\n",
      "4303:\tlearn: 0.0520512\ttotal: 11m 22s\tremaining: 15m 2s\n",
      "4304:\tlearn: 0.0520512\ttotal: 11m 22s\tremaining: 15m 2s\n",
      "4305:\tlearn: 0.0520512\ttotal: 11m 22s\tremaining: 15m 2s\n",
      "4306:\tlearn: 0.0520512\ttotal: 11m 22s\tremaining: 15m 2s\n",
      "4307:\tlearn: 0.0520512\ttotal: 11m 22s\tremaining: 15m 2s\n",
      "4308:\tlearn: 0.0520512\ttotal: 11m 22s\tremaining: 15m 2s\n",
      "4309:\tlearn: 0.0520512\ttotal: 11m 23s\tremaining: 15m 1s\n",
      "4310:\tlearn: 0.0520512\ttotal: 11m 23s\tremaining: 15m 1s\n",
      "4311:\tlearn: 0.0520512\ttotal: 11m 23s\tremaining: 15m 1s\n",
      "4312:\tlearn: 0.0520512\ttotal: 11m 23s\tremaining: 15m 1s\n",
      "4313:\tlearn: 0.0520512\ttotal: 11m 23s\tremaining: 15m 1s\n",
      "4314:\tlearn: 0.0520512\ttotal: 11m 23s\tremaining: 15m 1s\n",
      "4315:\tlearn: 0.0520512\ttotal: 11m 24s\tremaining: 15m\n",
      "4316:\tlearn: 0.0520512\ttotal: 11m 24s\tremaining: 15m\n",
      "4317:\tlearn: 0.0520512\ttotal: 11m 24s\tremaining: 15m\n",
      "4318:\tlearn: 0.0520512\ttotal: 11m 24s\tremaining: 15m\n",
      "4319:\tlearn: 0.0520512\ttotal: 11m 24s\tremaining: 15m\n",
      "4320:\tlearn: 0.0520512\ttotal: 11m 24s\tremaining: 14m 59s\n",
      "4321:\tlearn: 0.0520512\ttotal: 11m 24s\tremaining: 14m 59s\n",
      "4322:\tlearn: 0.0520512\ttotal: 11m 25s\tremaining: 14m 59s\n",
      "4323:\tlearn: 0.0520512\ttotal: 11m 25s\tremaining: 14m 59s\n",
      "4324:\tlearn: 0.0520512\ttotal: 11m 25s\tremaining: 14m 59s\n",
      "4325:\tlearn: 0.0520512\ttotal: 11m 25s\tremaining: 14m 59s\n",
      "4326:\tlearn: 0.0520512\ttotal: 11m 25s\tremaining: 14m 58s\n",
      "4327:\tlearn: 0.0520512\ttotal: 11m 25s\tremaining: 14m 58s\n",
      "4328:\tlearn: 0.0520512\ttotal: 11m 25s\tremaining: 14m 58s\n",
      "4329:\tlearn: 0.0520512\ttotal: 11m 26s\tremaining: 14m 58s\n",
      "4330:\tlearn: 0.0520512\ttotal: 11m 26s\tremaining: 14m 58s\n",
      "4331:\tlearn: 0.0520512\ttotal: 11m 26s\tremaining: 14m 58s\n",
      "4332:\tlearn: 0.0520512\ttotal: 11m 26s\tremaining: 14m 58s\n",
      "4333:\tlearn: 0.0520512\ttotal: 11m 26s\tremaining: 14m 57s\n",
      "4334:\tlearn: 0.0520512\ttotal: 11m 26s\tremaining: 14m 57s\n",
      "4335:\tlearn: 0.0520512\ttotal: 11m 27s\tremaining: 14m 57s\n",
      "4336:\tlearn: 0.0520512\ttotal: 11m 27s\tremaining: 14m 57s\n",
      "4337:\tlearn: 0.0520512\ttotal: 11m 27s\tremaining: 14m 57s\n",
      "4338:\tlearn: 0.0520512\ttotal: 11m 27s\tremaining: 14m 57s\n",
      "4339:\tlearn: 0.0520512\ttotal: 11m 27s\tremaining: 14m 56s\n",
      "4340:\tlearn: 0.0520512\ttotal: 11m 27s\tremaining: 14m 56s\n",
      "4341:\tlearn: 0.0520512\ttotal: 11m 27s\tremaining: 14m 56s\n",
      "4342:\tlearn: 0.0520512\ttotal: 11m 28s\tremaining: 14m 56s\n",
      "4343:\tlearn: 0.0520512\ttotal: 11m 28s\tremaining: 14m 56s\n",
      "4344:\tlearn: 0.0520512\ttotal: 11m 28s\tremaining: 14m 56s\n",
      "4345:\tlearn: 0.0520512\ttotal: 11m 28s\tremaining: 14m 55s\n",
      "4346:\tlearn: 0.0520512\ttotal: 11m 28s\tremaining: 14m 55s\n",
      "4347:\tlearn: 0.0520512\ttotal: 11m 28s\tremaining: 14m 55s\n",
      "4348:\tlearn: 0.0520512\ttotal: 11m 29s\tremaining: 14m 55s\n",
      "4349:\tlearn: 0.0520512\ttotal: 11m 29s\tremaining: 14m 55s\n",
      "4350:\tlearn: 0.0520512\ttotal: 11m 29s\tremaining: 14m 55s\n",
      "4351:\tlearn: 0.0520512\ttotal: 11m 29s\tremaining: 14m 54s\n",
      "4352:\tlearn: 0.0520512\ttotal: 11m 29s\tremaining: 14m 54s\n",
      "4353:\tlearn: 0.0520512\ttotal: 11m 29s\tremaining: 14m 54s\n",
      "4354:\tlearn: 0.0520512\ttotal: 11m 29s\tremaining: 14m 54s\n",
      "4355:\tlearn: 0.0520512\ttotal: 11m 30s\tremaining: 14m 54s\n",
      "4356:\tlearn: 0.0520512\ttotal: 11m 30s\tremaining: 14m 54s\n",
      "4357:\tlearn: 0.0520512\ttotal: 11m 30s\tremaining: 14m 53s\n",
      "4358:\tlearn: 0.0520512\ttotal: 11m 30s\tremaining: 14m 53s\n",
      "4359:\tlearn: 0.0520512\ttotal: 11m 30s\tremaining: 14m 53s\n",
      "4360:\tlearn: 0.0520512\ttotal: 11m 30s\tremaining: 14m 53s\n",
      "4361:\tlearn: 0.0520512\ttotal: 11m 31s\tremaining: 14m 53s\n",
      "4362:\tlearn: 0.0520512\ttotal: 11m 31s\tremaining: 14m 53s\n",
      "4363:\tlearn: 0.0520512\ttotal: 11m 31s\tremaining: 14m 52s\n",
      "4364:\tlearn: 0.0520512\ttotal: 11m 31s\tremaining: 14m 52s\n",
      "4365:\tlearn: 0.0520512\ttotal: 11m 31s\tremaining: 14m 52s\n",
      "4366:\tlearn: 0.0520512\ttotal: 11m 31s\tremaining: 14m 52s\n",
      "4367:\tlearn: 0.0520512\ttotal: 11m 31s\tremaining: 14m 52s\n",
      "4368:\tlearn: 0.0520512\ttotal: 11m 32s\tremaining: 14m 51s\n",
      "4369:\tlearn: 0.0520512\ttotal: 11m 32s\tremaining: 14m 51s\n",
      "4370:\tlearn: 0.0520512\ttotal: 11m 32s\tremaining: 14m 51s\n",
      "4371:\tlearn: 0.0520512\ttotal: 11m 32s\tremaining: 14m 51s\n",
      "4372:\tlearn: 0.0520512\ttotal: 11m 32s\tremaining: 14m 51s\n",
      "4373:\tlearn: 0.0520512\ttotal: 11m 32s\tremaining: 14m 51s\n",
      "4374:\tlearn: 0.0520512\ttotal: 11m 32s\tremaining: 14m 50s\n",
      "4375:\tlearn: 0.0520512\ttotal: 11m 33s\tremaining: 14m 50s\n",
      "4376:\tlearn: 0.0520512\ttotal: 11m 33s\tremaining: 14m 50s\n",
      "4377:\tlearn: 0.0520512\ttotal: 11m 33s\tremaining: 14m 50s\n",
      "4378:\tlearn: 0.0520512\ttotal: 11m 33s\tremaining: 14m 50s\n",
      "4379:\tlearn: 0.0520512\ttotal: 11m 33s\tremaining: 14m 50s\n",
      "4380:\tlearn: 0.0520512\ttotal: 11m 33s\tremaining: 14m 50s\n",
      "4381:\tlearn: 0.0520512\ttotal: 11m 34s\tremaining: 14m 49s\n",
      "4382:\tlearn: 0.0520512\ttotal: 11m 34s\tremaining: 14m 49s\n",
      "4383:\tlearn: 0.0520512\ttotal: 11m 34s\tremaining: 14m 49s\n",
      "4384:\tlearn: 0.0520512\ttotal: 11m 34s\tremaining: 14m 49s\n",
      "4385:\tlearn: 0.0520512\ttotal: 11m 34s\tremaining: 14m 49s\n",
      "4386:\tlearn: 0.0520512\ttotal: 11m 34s\tremaining: 14m 49s\n",
      "4387:\tlearn: 0.0520512\ttotal: 11m 34s\tremaining: 14m 48s\n",
      "4388:\tlearn: 0.0520512\ttotal: 11m 35s\tremaining: 14m 48s\n",
      "4389:\tlearn: 0.0520512\ttotal: 11m 35s\tremaining: 14m 48s\n",
      "4390:\tlearn: 0.0520512\ttotal: 11m 35s\tremaining: 14m 48s\n",
      "4391:\tlearn: 0.0520512\ttotal: 11m 35s\tremaining: 14m 48s\n",
      "4392:\tlearn: 0.0520512\ttotal: 11m 35s\tremaining: 14m 47s\n",
      "4393:\tlearn: 0.0520512\ttotal: 11m 35s\tremaining: 14m 47s\n",
      "4394:\tlearn: 0.0520512\ttotal: 11m 36s\tremaining: 14m 47s\n",
      "4395:\tlearn: 0.0520512\ttotal: 11m 36s\tremaining: 14m 47s\n",
      "4396:\tlearn: 0.0520512\ttotal: 11m 36s\tremaining: 14m 47s\n",
      "4397:\tlearn: 0.0520512\ttotal: 11m 36s\tremaining: 14m 47s\n",
      "4398:\tlearn: 0.0520512\ttotal: 11m 36s\tremaining: 14m 47s\n",
      "4399:\tlearn: 0.0520512\ttotal: 11m 36s\tremaining: 14m 46s\n",
      "4400:\tlearn: 0.0520512\ttotal: 11m 36s\tremaining: 14m 46s\n",
      "4401:\tlearn: 0.0520512\ttotal: 11m 37s\tremaining: 14m 46s\n",
      "4402:\tlearn: 0.0520512\ttotal: 11m 37s\tremaining: 14m 46s\n",
      "4403:\tlearn: 0.0520512\ttotal: 11m 37s\tremaining: 14m 46s\n",
      "4404:\tlearn: 0.0520512\ttotal: 11m 37s\tremaining: 14m 46s\n",
      "4405:\tlearn: 0.0520512\ttotal: 11m 37s\tremaining: 14m 45s\n",
      "4406:\tlearn: 0.0520512\ttotal: 11m 37s\tremaining: 14m 45s\n",
      "4407:\tlearn: 0.0520512\ttotal: 11m 38s\tremaining: 14m 45s\n",
      "4408:\tlearn: 0.0520512\ttotal: 11m 38s\tremaining: 14m 45s\n",
      "4409:\tlearn: 0.0520512\ttotal: 11m 38s\tremaining: 14m 45s\n",
      "4410:\tlearn: 0.0520512\ttotal: 11m 38s\tremaining: 14m 45s\n",
      "4411:\tlearn: 0.0520512\ttotal: 11m 38s\tremaining: 14m 44s\n",
      "4412:\tlearn: 0.0520512\ttotal: 11m 38s\tremaining: 14m 44s\n",
      "4413:\tlearn: 0.0520512\ttotal: 11m 38s\tremaining: 14m 44s\n",
      "4414:\tlearn: 0.0520512\ttotal: 11m 39s\tremaining: 14m 44s\n",
      "4415:\tlearn: 0.0520512\ttotal: 11m 39s\tremaining: 14m 44s\n",
      "4416:\tlearn: 0.0520512\ttotal: 11m 39s\tremaining: 14m 44s\n",
      "4417:\tlearn: 0.0520512\ttotal: 11m 39s\tremaining: 14m 43s\n",
      "4418:\tlearn: 0.0520512\ttotal: 11m 39s\tremaining: 14m 43s\n",
      "4419:\tlearn: 0.0520512\ttotal: 11m 39s\tremaining: 14m 43s\n",
      "4420:\tlearn: 0.0520512\ttotal: 11m 40s\tremaining: 14m 43s\n",
      "4421:\tlearn: 0.0520512\ttotal: 11m 40s\tremaining: 14m 43s\n",
      "4422:\tlearn: 0.0520512\ttotal: 11m 40s\tremaining: 14m 43s\n",
      "4423:\tlearn: 0.0520512\ttotal: 11m 40s\tremaining: 14m 42s\n",
      "4424:\tlearn: 0.0520512\ttotal: 11m 40s\tremaining: 14m 42s\n",
      "4425:\tlearn: 0.0520512\ttotal: 11m 40s\tremaining: 14m 42s\n",
      "4426:\tlearn: 0.0520512\ttotal: 11m 40s\tremaining: 14m 42s\n",
      "4427:\tlearn: 0.0520512\ttotal: 11m 41s\tremaining: 14m 42s\n",
      "4428:\tlearn: 0.0520512\ttotal: 11m 41s\tremaining: 14m 42s\n",
      "4429:\tlearn: 0.0520512\ttotal: 11m 41s\tremaining: 14m 41s\n",
      "4430:\tlearn: 0.0520512\ttotal: 11m 41s\tremaining: 14m 41s\n",
      "4431:\tlearn: 0.0520512\ttotal: 11m 41s\tremaining: 14m 41s\n",
      "4432:\tlearn: 0.0520512\ttotal: 11m 41s\tremaining: 14m 41s\n",
      "4433:\tlearn: 0.0520512\ttotal: 11m 41s\tremaining: 14m 41s\n",
      "4434:\tlearn: 0.0520512\ttotal: 11m 42s\tremaining: 14m 41s\n",
      "4435:\tlearn: 0.0520512\ttotal: 11m 42s\tremaining: 14m 40s\n",
      "4436:\tlearn: 0.0520512\ttotal: 11m 42s\tremaining: 14m 40s\n",
      "4437:\tlearn: 0.0520512\ttotal: 11m 42s\tremaining: 14m 40s\n",
      "4438:\tlearn: 0.0520512\ttotal: 11m 42s\tremaining: 14m 40s\n",
      "4439:\tlearn: 0.0520512\ttotal: 11m 42s\tremaining: 14m 40s\n",
      "4440:\tlearn: 0.0520512\ttotal: 11m 43s\tremaining: 14m 40s\n",
      "4441:\tlearn: 0.0520512\ttotal: 11m 43s\tremaining: 14m 39s\n",
      "4442:\tlearn: 0.0520512\ttotal: 11m 43s\tremaining: 14m 39s\n",
      "4443:\tlearn: 0.0520512\ttotal: 11m 43s\tremaining: 14m 39s\n",
      "4444:\tlearn: 0.0520512\ttotal: 11m 43s\tremaining: 14m 39s\n",
      "4445:\tlearn: 0.0520512\ttotal: 11m 43s\tremaining: 14m 39s\n",
      "4446:\tlearn: 0.0520512\ttotal: 11m 43s\tremaining: 14m 39s\n",
      "4447:\tlearn: 0.0520512\ttotal: 11m 44s\tremaining: 14m 38s\n",
      "4448:\tlearn: 0.0520512\ttotal: 11m 44s\tremaining: 14m 38s\n",
      "4449:\tlearn: 0.0520512\ttotal: 11m 44s\tremaining: 14m 38s\n",
      "4450:\tlearn: 0.0520512\ttotal: 11m 44s\tremaining: 14m 38s\n",
      "4451:\tlearn: 0.0520512\ttotal: 11m 44s\tremaining: 14m 38s\n",
      "4452:\tlearn: 0.0520512\ttotal: 11m 44s\tremaining: 14m 38s\n",
      "4453:\tlearn: 0.0520512\ttotal: 11m 45s\tremaining: 14m 37s\n",
      "4454:\tlearn: 0.0520512\ttotal: 11m 45s\tremaining: 14m 37s\n",
      "4455:\tlearn: 0.0520512\ttotal: 11m 45s\tremaining: 14m 37s\n",
      "4456:\tlearn: 0.0520512\ttotal: 11m 45s\tremaining: 14m 37s\n",
      "4457:\tlearn: 0.0520512\ttotal: 11m 45s\tremaining: 14m 37s\n",
      "4458:\tlearn: 0.0520512\ttotal: 11m 45s\tremaining: 14m 37s\n",
      "4459:\tlearn: 0.0520512\ttotal: 11m 46s\tremaining: 14m 37s\n",
      "4460:\tlearn: 0.0520512\ttotal: 11m 46s\tremaining: 14m 36s\n",
      "4461:\tlearn: 0.0520512\ttotal: 11m 46s\tremaining: 14m 36s\n",
      "4462:\tlearn: 0.0520512\ttotal: 11m 46s\tremaining: 14m 36s\n",
      "4463:\tlearn: 0.0520512\ttotal: 11m 46s\tremaining: 14m 36s\n",
      "4464:\tlearn: 0.0520512\ttotal: 11m 46s\tremaining: 14m 36s\n",
      "4465:\tlearn: 0.0520512\ttotal: 11m 46s\tremaining: 14m 36s\n",
      "4466:\tlearn: 0.0520512\ttotal: 11m 47s\tremaining: 14m 35s\n",
      "4467:\tlearn: 0.0520512\ttotal: 11m 47s\tremaining: 14m 35s\n",
      "4468:\tlearn: 0.0520512\ttotal: 11m 47s\tremaining: 14m 35s\n",
      "4469:\tlearn: 0.0520512\ttotal: 11m 47s\tremaining: 14m 35s\n",
      "4470:\tlearn: 0.0520512\ttotal: 11m 47s\tremaining: 14m 35s\n",
      "4471:\tlearn: 0.0520512\ttotal: 11m 47s\tremaining: 14m 35s\n",
      "4472:\tlearn: 0.0520512\ttotal: 11m 48s\tremaining: 14m 34s\n",
      "4473:\tlearn: 0.0520512\ttotal: 11m 48s\tremaining: 14m 34s\n",
      "4474:\tlearn: 0.0520512\ttotal: 11m 48s\tremaining: 14m 34s\n",
      "4475:\tlearn: 0.0520512\ttotal: 11m 48s\tremaining: 14m 34s\n",
      "4476:\tlearn: 0.0520512\ttotal: 11m 48s\tremaining: 14m 34s\n",
      "4477:\tlearn: 0.0520512\ttotal: 11m 48s\tremaining: 14m 34s\n",
      "4478:\tlearn: 0.0520512\ttotal: 11m 48s\tremaining: 14m 33s\n",
      "4479:\tlearn: 0.0520512\ttotal: 11m 49s\tremaining: 14m 33s\n",
      "4480:\tlearn: 0.0520512\ttotal: 11m 49s\tremaining: 14m 33s\n",
      "4481:\tlearn: 0.0520512\ttotal: 11m 49s\tremaining: 14m 33s\n",
      "4482:\tlearn: 0.0520512\ttotal: 11m 49s\tremaining: 14m 33s\n",
      "4483:\tlearn: 0.0520512\ttotal: 11m 49s\tremaining: 14m 33s\n",
      "4484:\tlearn: 0.0520512\ttotal: 11m 49s\tremaining: 14m 32s\n",
      "4485:\tlearn: 0.0520512\ttotal: 11m 50s\tremaining: 14m 32s\n",
      "4486:\tlearn: 0.0520512\ttotal: 11m 50s\tremaining: 14m 32s\n",
      "4487:\tlearn: 0.0520512\ttotal: 11m 50s\tremaining: 14m 32s\n",
      "4488:\tlearn: 0.0520512\ttotal: 11m 50s\tremaining: 14m 32s\n",
      "4489:\tlearn: 0.0520512\ttotal: 11m 50s\tremaining: 14m 32s\n",
      "4490:\tlearn: 0.0520512\ttotal: 11m 50s\tremaining: 14m 31s\n",
      "4491:\tlearn: 0.0520512\ttotal: 11m 50s\tremaining: 14m 31s\n",
      "4492:\tlearn: 0.0520512\ttotal: 11m 51s\tremaining: 14m 31s\n",
      "4493:\tlearn: 0.0520512\ttotal: 11m 51s\tremaining: 14m 31s\n",
      "4494:\tlearn: 0.0520512\ttotal: 11m 51s\tremaining: 14m 31s\n",
      "4495:\tlearn: 0.0520512\ttotal: 11m 51s\tremaining: 14m 31s\n",
      "4496:\tlearn: 0.0520512\ttotal: 11m 51s\tremaining: 14m 30s\n",
      "4497:\tlearn: 0.0520512\ttotal: 11m 51s\tremaining: 14m 30s\n",
      "4498:\tlearn: 0.0520512\ttotal: 11m 52s\tremaining: 14m 30s\n",
      "4499:\tlearn: 0.0520512\ttotal: 11m 52s\tremaining: 14m 30s\n",
      "4500:\tlearn: 0.0520512\ttotal: 11m 52s\tremaining: 14m 30s\n",
      "4501:\tlearn: 0.0520512\ttotal: 11m 52s\tremaining: 14m 30s\n",
      "4502:\tlearn: 0.0520512\ttotal: 11m 52s\tremaining: 14m 29s\n",
      "4503:\tlearn: 0.0520512\ttotal: 11m 52s\tremaining: 14m 29s\n",
      "4504:\tlearn: 0.0520512\ttotal: 11m 52s\tremaining: 14m 29s\n",
      "4505:\tlearn: 0.0520512\ttotal: 11m 53s\tremaining: 14m 29s\n",
      "4506:\tlearn: 0.0520512\ttotal: 11m 53s\tremaining: 14m 29s\n",
      "4507:\tlearn: 0.0520512\ttotal: 11m 53s\tremaining: 14m 29s\n",
      "4508:\tlearn: 0.0520512\ttotal: 11m 53s\tremaining: 14m 28s\n",
      "4509:\tlearn: 0.0520512\ttotal: 11m 53s\tremaining: 14m 28s\n",
      "4510:\tlearn: 0.0520512\ttotal: 11m 53s\tremaining: 14m 28s\n",
      "4511:\tlearn: 0.0520512\ttotal: 11m 54s\tremaining: 14m 28s\n",
      "4512:\tlearn: 0.0520512\ttotal: 11m 54s\tremaining: 14m 28s\n",
      "4513:\tlearn: 0.0520512\ttotal: 11m 54s\tremaining: 14m 28s\n",
      "4514:\tlearn: 0.0520512\ttotal: 11m 54s\tremaining: 14m 27s\n",
      "4515:\tlearn: 0.0520512\ttotal: 11m 54s\tremaining: 14m 27s\n",
      "4516:\tlearn: 0.0520512\ttotal: 11m 54s\tremaining: 14m 27s\n",
      "4517:\tlearn: 0.0520512\ttotal: 11m 54s\tremaining: 14m 27s\n",
      "4518:\tlearn: 0.0520512\ttotal: 11m 55s\tremaining: 14m 27s\n",
      "4519:\tlearn: 0.0520512\ttotal: 11m 55s\tremaining: 14m 27s\n",
      "4520:\tlearn: 0.0520512\ttotal: 11m 55s\tremaining: 14m 27s\n",
      "4521:\tlearn: 0.0520512\ttotal: 11m 55s\tremaining: 14m 26s\n",
      "4522:\tlearn: 0.0520512\ttotal: 11m 55s\tremaining: 14m 26s\n",
      "4523:\tlearn: 0.0520512\ttotal: 11m 55s\tremaining: 14m 26s\n",
      "4524:\tlearn: 0.0520512\ttotal: 11m 56s\tremaining: 14m 26s\n",
      "4525:\tlearn: 0.0520512\ttotal: 11m 56s\tremaining: 14m 26s\n",
      "4526:\tlearn: 0.0520512\ttotal: 11m 56s\tremaining: 14m 26s\n",
      "4527:\tlearn: 0.0520512\ttotal: 11m 56s\tremaining: 14m 25s\n",
      "4528:\tlearn: 0.0520512\ttotal: 11m 56s\tremaining: 14m 25s\n",
      "4529:\tlearn: 0.0520512\ttotal: 11m 56s\tremaining: 14m 25s\n",
      "4530:\tlearn: 0.0520512\ttotal: 11m 56s\tremaining: 14m 25s\n",
      "4531:\tlearn: 0.0520512\ttotal: 11m 57s\tremaining: 14m 25s\n",
      "4532:\tlearn: 0.0520512\ttotal: 11m 57s\tremaining: 14m 25s\n",
      "4533:\tlearn: 0.0520512\ttotal: 11m 57s\tremaining: 14m 24s\n",
      "4534:\tlearn: 0.0520512\ttotal: 11m 57s\tremaining: 14m 24s\n",
      "4535:\tlearn: 0.0520512\ttotal: 11m 57s\tremaining: 14m 24s\n",
      "4536:\tlearn: 0.0520512\ttotal: 11m 57s\tremaining: 14m 24s\n",
      "4537:\tlearn: 0.0520512\ttotal: 11m 58s\tremaining: 14m 24s\n",
      "4538:\tlearn: 0.0520512\ttotal: 11m 58s\tremaining: 14m 24s\n",
      "4539:\tlearn: 0.0520512\ttotal: 11m 58s\tremaining: 14m 23s\n",
      "4540:\tlearn: 0.0520512\ttotal: 11m 58s\tremaining: 14m 23s\n",
      "4541:\tlearn: 0.0520512\ttotal: 11m 58s\tremaining: 14m 23s\n",
      "4542:\tlearn: 0.0520512\ttotal: 11m 58s\tremaining: 14m 23s\n",
      "4543:\tlearn: 0.0520512\ttotal: 11m 58s\tremaining: 14m 23s\n",
      "4544:\tlearn: 0.0520512\ttotal: 11m 59s\tremaining: 14m 23s\n",
      "4545:\tlearn: 0.0520512\ttotal: 11m 59s\tremaining: 14m 22s\n",
      "4546:\tlearn: 0.0520512\ttotal: 11m 59s\tremaining: 14m 22s\n",
      "4547:\tlearn: 0.0520512\ttotal: 11m 59s\tremaining: 14m 22s\n",
      "4548:\tlearn: 0.0520512\ttotal: 11m 59s\tremaining: 14m 22s\n",
      "4549:\tlearn: 0.0520512\ttotal: 11m 59s\tremaining: 14m 22s\n",
      "4550:\tlearn: 0.0520512\ttotal: 12m\tremaining: 14m 22s\n",
      "4551:\tlearn: 0.0520512\ttotal: 12m\tremaining: 14m 21s\n",
      "4552:\tlearn: 0.0520512\ttotal: 12m\tremaining: 14m 21s\n",
      "4553:\tlearn: 0.0520512\ttotal: 12m\tremaining: 14m 21s\n",
      "4554:\tlearn: 0.0520512\ttotal: 12m\tremaining: 14m 21s\n",
      "4555:\tlearn: 0.0520512\ttotal: 12m\tremaining: 14m 21s\n",
      "4556:\tlearn: 0.0520512\ttotal: 12m\tremaining: 14m 21s\n",
      "4557:\tlearn: 0.0520512\ttotal: 12m 1s\tremaining: 14m 20s\n",
      "4558:\tlearn: 0.0520512\ttotal: 12m 1s\tremaining: 14m 20s\n",
      "4559:\tlearn: 0.0520512\ttotal: 12m 1s\tremaining: 14m 20s\n",
      "4560:\tlearn: 0.0520512\ttotal: 12m 1s\tremaining: 14m 20s\n",
      "4561:\tlearn: 0.0520512\ttotal: 12m 1s\tremaining: 14m 20s\n",
      "4562:\tlearn: 0.0520512\ttotal: 12m 1s\tremaining: 14m 20s\n",
      "4563:\tlearn: 0.0520512\ttotal: 12m 2s\tremaining: 14m 19s\n",
      "4564:\tlearn: 0.0520512\ttotal: 12m 2s\tremaining: 14m 19s\n",
      "4565:\tlearn: 0.0520512\ttotal: 12m 2s\tremaining: 14m 19s\n",
      "4566:\tlearn: 0.0520512\ttotal: 12m 2s\tremaining: 14m 19s\n",
      "4567:\tlearn: 0.0520512\ttotal: 12m 2s\tremaining: 14m 19s\n",
      "4568:\tlearn: 0.0520512\ttotal: 12m 2s\tremaining: 14m 19s\n",
      "4569:\tlearn: 0.0520512\ttotal: 12m 2s\tremaining: 14m 18s\n",
      "4570:\tlearn: 0.0520512\ttotal: 12m 3s\tremaining: 14m 18s\n",
      "4571:\tlearn: 0.0520512\ttotal: 12m 3s\tremaining: 14m 18s\n",
      "4572:\tlearn: 0.0520512\ttotal: 12m 3s\tremaining: 14m 18s\n",
      "4573:\tlearn: 0.0520512\ttotal: 12m 3s\tremaining: 14m 18s\n",
      "4574:\tlearn: 0.0520512\ttotal: 12m 3s\tremaining: 14m 18s\n",
      "4575:\tlearn: 0.0520512\ttotal: 12m 3s\tremaining: 14m 17s\n",
      "4576:\tlearn: 0.0520512\ttotal: 12m 3s\tremaining: 14m 17s\n",
      "4577:\tlearn: 0.0520512\ttotal: 12m 4s\tremaining: 14m 17s\n",
      "4578:\tlearn: 0.0520512\ttotal: 12m 4s\tremaining: 14m 17s\n",
      "4579:\tlearn: 0.0520512\ttotal: 12m 4s\tremaining: 14m 17s\n",
      "4580:\tlearn: 0.0520512\ttotal: 12m 4s\tremaining: 14m 17s\n",
      "4581:\tlearn: 0.0520512\ttotal: 12m 4s\tremaining: 14m 16s\n",
      "4582:\tlearn: 0.0520512\ttotal: 12m 4s\tremaining: 14m 16s\n",
      "4583:\tlearn: 0.0520512\ttotal: 12m 5s\tremaining: 14m 16s\n",
      "4584:\tlearn: 0.0520512\ttotal: 12m 5s\tremaining: 14m 16s\n",
      "4585:\tlearn: 0.0520512\ttotal: 12m 5s\tremaining: 14m 16s\n",
      "4586:\tlearn: 0.0520512\ttotal: 12m 5s\tremaining: 14m 16s\n",
      "4587:\tlearn: 0.0520512\ttotal: 12m 5s\tremaining: 14m 15s\n",
      "4588:\tlearn: 0.0520512\ttotal: 12m 5s\tremaining: 14m 15s\n",
      "4589:\tlearn: 0.0520512\ttotal: 12m 5s\tremaining: 14m 15s\n",
      "4590:\tlearn: 0.0520512\ttotal: 12m 6s\tremaining: 14m 15s\n",
      "4591:\tlearn: 0.0520512\ttotal: 12m 6s\tremaining: 14m 15s\n",
      "4592:\tlearn: 0.0520512\ttotal: 12m 6s\tremaining: 14m 15s\n",
      "4593:\tlearn: 0.0520512\ttotal: 12m 6s\tremaining: 14m 14s\n",
      "4594:\tlearn: 0.0520512\ttotal: 12m 6s\tremaining: 14m 14s\n",
      "4595:\tlearn: 0.0520512\ttotal: 12m 6s\tremaining: 14m 14s\n",
      "4596:\tlearn: 0.0520512\ttotal: 12m 7s\tremaining: 14m 14s\n",
      "4597:\tlearn: 0.0520512\ttotal: 12m 7s\tremaining: 14m 14s\n",
      "4598:\tlearn: 0.0520512\ttotal: 12m 7s\tremaining: 14m 14s\n",
      "4599:\tlearn: 0.0520512\ttotal: 12m 7s\tremaining: 14m 13s\n",
      "4600:\tlearn: 0.0520512\ttotal: 12m 7s\tremaining: 14m 13s\n",
      "4601:\tlearn: 0.0520512\ttotal: 12m 7s\tremaining: 14m 13s\n",
      "4602:\tlearn: 0.0520512\ttotal: 12m 7s\tremaining: 14m 13s\n",
      "4603:\tlearn: 0.0520512\ttotal: 12m 8s\tremaining: 14m 13s\n",
      "4604:\tlearn: 0.0520512\ttotal: 12m 8s\tremaining: 14m 13s\n",
      "4605:\tlearn: 0.0520512\ttotal: 12m 8s\tremaining: 14m 13s\n",
      "4606:\tlearn: 0.0520512\ttotal: 12m 8s\tremaining: 14m 12s\n",
      "4607:\tlearn: 0.0520512\ttotal: 12m 8s\tremaining: 14m 12s\n",
      "4608:\tlearn: 0.0520512\ttotal: 12m 8s\tremaining: 14m 12s\n",
      "4609:\tlearn: 0.0520512\ttotal: 12m 9s\tremaining: 14m 12s\n",
      "4610:\tlearn: 0.0520512\ttotal: 12m 9s\tremaining: 14m 12s\n",
      "4611:\tlearn: 0.0520512\ttotal: 12m 9s\tremaining: 14m 12s\n",
      "4612:\tlearn: 0.0520512\ttotal: 12m 9s\tremaining: 14m 11s\n",
      "4613:\tlearn: 0.0520512\ttotal: 12m 9s\tremaining: 14m 11s\n",
      "4614:\tlearn: 0.0520512\ttotal: 12m 9s\tremaining: 14m 11s\n",
      "4615:\tlearn: 0.0520512\ttotal: 12m 9s\tremaining: 14m 11s\n",
      "4616:\tlearn: 0.0520512\ttotal: 12m 10s\tremaining: 14m 11s\n",
      "4617:\tlearn: 0.0520512\ttotal: 12m 10s\tremaining: 14m 11s\n",
      "4618:\tlearn: 0.0520512\ttotal: 12m 10s\tremaining: 14m 10s\n",
      "4619:\tlearn: 0.0520512\ttotal: 12m 10s\tremaining: 14m 10s\n",
      "4620:\tlearn: 0.0520512\ttotal: 12m 10s\tremaining: 14m 10s\n",
      "4621:\tlearn: 0.0520512\ttotal: 12m 10s\tremaining: 14m 10s\n",
      "4622:\tlearn: 0.0520512\ttotal: 12m 11s\tremaining: 14m 10s\n",
      "4623:\tlearn: 0.0520512\ttotal: 12m 11s\tremaining: 14m 10s\n",
      "4624:\tlearn: 0.0520512\ttotal: 12m 11s\tremaining: 14m 9s\n",
      "4625:\tlearn: 0.0520512\ttotal: 12m 11s\tremaining: 14m 9s\n",
      "4626:\tlearn: 0.0520512\ttotal: 12m 11s\tremaining: 14m 9s\n",
      "4627:\tlearn: 0.0520512\ttotal: 12m 11s\tremaining: 14m 9s\n",
      "4628:\tlearn: 0.0520512\ttotal: 12m 11s\tremaining: 14m 9s\n",
      "4629:\tlearn: 0.0520512\ttotal: 12m 12s\tremaining: 14m 9s\n",
      "4630:\tlearn: 0.0520512\ttotal: 12m 12s\tremaining: 14m 8s\n",
      "4631:\tlearn: 0.0520512\ttotal: 12m 12s\tremaining: 14m 8s\n",
      "4632:\tlearn: 0.0520512\ttotal: 12m 12s\tremaining: 14m 8s\n",
      "4633:\tlearn: 0.0520512\ttotal: 12m 12s\tremaining: 14m 8s\n",
      "4634:\tlearn: 0.0520512\ttotal: 12m 12s\tremaining: 14m 8s\n",
      "4635:\tlearn: 0.0520512\ttotal: 12m 13s\tremaining: 14m 8s\n",
      "4636:\tlearn: 0.0520512\ttotal: 12m 13s\tremaining: 14m 8s\n",
      "4637:\tlearn: 0.0520512\ttotal: 12m 13s\tremaining: 14m 7s\n",
      "4638:\tlearn: 0.0520512\ttotal: 12m 13s\tremaining: 14m 7s\n",
      "4639:\tlearn: 0.0520512\ttotal: 12m 13s\tremaining: 14m 7s\n",
      "4640:\tlearn: 0.0520512\ttotal: 12m 13s\tremaining: 14m 7s\n",
      "4641:\tlearn: 0.0520512\ttotal: 12m 13s\tremaining: 14m 7s\n",
      "4642:\tlearn: 0.0520512\ttotal: 12m 14s\tremaining: 14m 7s\n",
      "4643:\tlearn: 0.0520512\ttotal: 12m 14s\tremaining: 14m 6s\n",
      "4644:\tlearn: 0.0520512\ttotal: 12m 14s\tremaining: 14m 6s\n",
      "4645:\tlearn: 0.0520512\ttotal: 12m 14s\tremaining: 14m 6s\n",
      "4646:\tlearn: 0.0520512\ttotal: 12m 14s\tremaining: 14m 6s\n",
      "4647:\tlearn: 0.0520512\ttotal: 12m 14s\tremaining: 14m 6s\n",
      "4648:\tlearn: 0.0520512\ttotal: 12m 15s\tremaining: 14m 6s\n",
      "4649:\tlearn: 0.0520512\ttotal: 12m 15s\tremaining: 14m 5s\n",
      "4650:\tlearn: 0.0520512\ttotal: 12m 15s\tremaining: 14m 5s\n",
      "4651:\tlearn: 0.0520512\ttotal: 12m 15s\tremaining: 14m 5s\n",
      "4652:\tlearn: 0.0520512\ttotal: 12m 15s\tremaining: 14m 5s\n",
      "4653:\tlearn: 0.0520512\ttotal: 12m 15s\tremaining: 14m 5s\n",
      "4654:\tlearn: 0.0520512\ttotal: 12m 16s\tremaining: 14m 5s\n",
      "4655:\tlearn: 0.0520512\ttotal: 12m 16s\tremaining: 14m 4s\n",
      "4656:\tlearn: 0.0520512\ttotal: 12m 16s\tremaining: 14m 4s\n",
      "4657:\tlearn: 0.0520512\ttotal: 12m 16s\tremaining: 14m 4s\n",
      "4658:\tlearn: 0.0520512\ttotal: 12m 16s\tremaining: 14m 4s\n",
      "4659:\tlearn: 0.0520512\ttotal: 12m 16s\tremaining: 14m 4s\n",
      "4660:\tlearn: 0.0520512\ttotal: 12m 16s\tremaining: 14m 4s\n",
      "4661:\tlearn: 0.0520512\ttotal: 12m 17s\tremaining: 14m 3s\n",
      "4662:\tlearn: 0.0520512\ttotal: 12m 17s\tremaining: 14m 3s\n",
      "4663:\tlearn: 0.0520512\ttotal: 12m 17s\tremaining: 14m 3s\n",
      "4664:\tlearn: 0.0520512\ttotal: 12m 17s\tremaining: 14m 3s\n",
      "4665:\tlearn: 0.0520512\ttotal: 12m 17s\tremaining: 14m 3s\n",
      "4666:\tlearn: 0.0520512\ttotal: 12m 17s\tremaining: 14m 3s\n",
      "4667:\tlearn: 0.0520512\ttotal: 12m 17s\tremaining: 14m 2s\n",
      "4668:\tlearn: 0.0520512\ttotal: 12m 18s\tremaining: 14m 2s\n",
      "4669:\tlearn: 0.0520512\ttotal: 12m 18s\tremaining: 14m 2s\n",
      "4670:\tlearn: 0.0520512\ttotal: 12m 18s\tremaining: 14m 2s\n",
      "4671:\tlearn: 0.0520512\ttotal: 12m 18s\tremaining: 14m 2s\n",
      "4672:\tlearn: 0.0520512\ttotal: 12m 18s\tremaining: 14m 2s\n",
      "4673:\tlearn: 0.0520512\ttotal: 12m 18s\tremaining: 14m 1s\n",
      "4674:\tlearn: 0.0520512\ttotal: 12m 19s\tremaining: 14m 1s\n",
      "4675:\tlearn: 0.0520512\ttotal: 12m 19s\tremaining: 14m 1s\n",
      "4676:\tlearn: 0.0520512\ttotal: 12m 19s\tremaining: 14m 1s\n",
      "4677:\tlearn: 0.0520512\ttotal: 12m 19s\tremaining: 14m 1s\n",
      "4678:\tlearn: 0.0520512\ttotal: 12m 19s\tremaining: 14m 1s\n",
      "4679:\tlearn: 0.0520512\ttotal: 12m 19s\tremaining: 14m 1s\n",
      "4680:\tlearn: 0.0520512\ttotal: 12m 20s\tremaining: 14m\n",
      "4681:\tlearn: 0.0520512\ttotal: 12m 20s\tremaining: 14m\n",
      "4682:\tlearn: 0.0520512\ttotal: 12m 20s\tremaining: 14m\n",
      "4683:\tlearn: 0.0520512\ttotal: 12m 20s\tremaining: 14m\n",
      "4684:\tlearn: 0.0520512\ttotal: 12m 20s\tremaining: 14m\n",
      "4685:\tlearn: 0.0520512\ttotal: 12m 20s\tremaining: 14m\n",
      "4686:\tlearn: 0.0520512\ttotal: 12m 20s\tremaining: 13m 59s\n",
      "4687:\tlearn: 0.0520512\ttotal: 12m 21s\tremaining: 13m 59s\n",
      "4688:\tlearn: 0.0520512\ttotal: 12m 21s\tremaining: 13m 59s\n",
      "4689:\tlearn: 0.0520512\ttotal: 12m 21s\tremaining: 13m 59s\n",
      "4690:\tlearn: 0.0520512\ttotal: 12m 21s\tremaining: 13m 59s\n",
      "4691:\tlearn: 0.0520512\ttotal: 12m 21s\tremaining: 13m 59s\n",
      "4692:\tlearn: 0.0520512\ttotal: 12m 21s\tremaining: 13m 59s\n",
      "4693:\tlearn: 0.0520512\ttotal: 12m 22s\tremaining: 13m 58s\n",
      "4694:\tlearn: 0.0520512\ttotal: 12m 22s\tremaining: 13m 58s\n",
      "4695:\tlearn: 0.0520512\ttotal: 12m 22s\tremaining: 13m 58s\n",
      "4696:\tlearn: 0.0520512\ttotal: 12m 22s\tremaining: 13m 58s\n",
      "4697:\tlearn: 0.0520512\ttotal: 12m 22s\tremaining: 13m 58s\n",
      "4698:\tlearn: 0.0520512\ttotal: 12m 22s\tremaining: 13m 58s\n",
      "4699:\tlearn: 0.0520512\ttotal: 12m 23s\tremaining: 13m 57s\n",
      "4700:\tlearn: 0.0520512\ttotal: 12m 23s\tremaining: 13m 57s\n",
      "4701:\tlearn: 0.0520512\ttotal: 12m 23s\tremaining: 13m 57s\n",
      "4702:\tlearn: 0.0520512\ttotal: 12m 23s\tremaining: 13m 57s\n",
      "4703:\tlearn: 0.0520512\ttotal: 12m 23s\tremaining: 13m 57s\n",
      "4704:\tlearn: 0.0520512\ttotal: 12m 23s\tremaining: 13m 57s\n",
      "4705:\tlearn: 0.0520512\ttotal: 12m 23s\tremaining: 13m 56s\n",
      "4706:\tlearn: 0.0520512\ttotal: 12m 24s\tremaining: 13m 56s\n",
      "4707:\tlearn: 0.0520512\ttotal: 12m 24s\tremaining: 13m 56s\n",
      "4708:\tlearn: 0.0520512\ttotal: 12m 24s\tremaining: 13m 56s\n",
      "4709:\tlearn: 0.0520512\ttotal: 12m 24s\tremaining: 13m 56s\n",
      "4710:\tlearn: 0.0520512\ttotal: 12m 24s\tremaining: 13m 56s\n",
      "4711:\tlearn: 0.0520512\ttotal: 12m 24s\tremaining: 13m 55s\n",
      "4712:\tlearn: 0.0520512\ttotal: 12m 25s\tremaining: 13m 55s\n",
      "4713:\tlearn: 0.0520512\ttotal: 12m 25s\tremaining: 13m 55s\n",
      "4714:\tlearn: 0.0520512\ttotal: 12m 25s\tremaining: 13m 55s\n",
      "4715:\tlearn: 0.0520512\ttotal: 12m 25s\tremaining: 13m 55s\n",
      "4716:\tlearn: 0.0520512\ttotal: 12m 25s\tremaining: 13m 55s\n",
      "4717:\tlearn: 0.0520512\ttotal: 12m 25s\tremaining: 13m 55s\n",
      "4718:\tlearn: 0.0520512\ttotal: 12m 26s\tremaining: 13m 54s\n",
      "4719:\tlearn: 0.0520512\ttotal: 12m 26s\tremaining: 13m 54s\n",
      "4720:\tlearn: 0.0520512\ttotal: 12m 26s\tremaining: 13m 54s\n",
      "4721:\tlearn: 0.0520512\ttotal: 12m 26s\tremaining: 13m 54s\n",
      "4722:\tlearn: 0.0520512\ttotal: 12m 26s\tremaining: 13m 54s\n",
      "4723:\tlearn: 0.0520512\ttotal: 12m 26s\tremaining: 13m 54s\n",
      "4724:\tlearn: 0.0520512\ttotal: 12m 26s\tremaining: 13m 53s\n",
      "4725:\tlearn: 0.0520512\ttotal: 12m 27s\tremaining: 13m 53s\n",
      "4726:\tlearn: 0.0520512\ttotal: 12m 27s\tremaining: 13m 53s\n",
      "4727:\tlearn: 0.0520512\ttotal: 12m 27s\tremaining: 13m 53s\n",
      "4728:\tlearn: 0.0520512\ttotal: 12m 27s\tremaining: 13m 53s\n",
      "4729:\tlearn: 0.0520512\ttotal: 12m 27s\tremaining: 13m 53s\n",
      "4730:\tlearn: 0.0520512\ttotal: 12m 27s\tremaining: 13m 52s\n",
      "4731:\tlearn: 0.0520512\ttotal: 12m 28s\tremaining: 13m 52s\n",
      "4732:\tlearn: 0.0520512\ttotal: 12m 28s\tremaining: 13m 52s\n",
      "4733:\tlearn: 0.0520512\ttotal: 12m 28s\tremaining: 13m 52s\n",
      "4734:\tlearn: 0.0520512\ttotal: 12m 28s\tremaining: 13m 52s\n",
      "4735:\tlearn: 0.0520512\ttotal: 12m 28s\tremaining: 13m 52s\n",
      "4736:\tlearn: 0.0520512\ttotal: 12m 28s\tremaining: 13m 51s\n",
      "4737:\tlearn: 0.0520512\ttotal: 12m 28s\tremaining: 13m 51s\n",
      "4738:\tlearn: 0.0520512\ttotal: 12m 29s\tremaining: 13m 51s\n",
      "4739:\tlearn: 0.0520512\ttotal: 12m 29s\tremaining: 13m 51s\n",
      "4740:\tlearn: 0.0520512\ttotal: 12m 29s\tremaining: 13m 51s\n",
      "4741:\tlearn: 0.0520512\ttotal: 12m 29s\tremaining: 13m 51s\n",
      "4742:\tlearn: 0.0520512\ttotal: 12m 29s\tremaining: 13m 51s\n",
      "4743:\tlearn: 0.0520512\ttotal: 12m 29s\tremaining: 13m 50s\n",
      "4744:\tlearn: 0.0520512\ttotal: 12m 30s\tremaining: 13m 50s\n",
      "4745:\tlearn: 0.0520512\ttotal: 12m 30s\tremaining: 13m 50s\n",
      "4746:\tlearn: 0.0520512\ttotal: 12m 30s\tremaining: 13m 50s\n",
      "4747:\tlearn: 0.0520512\ttotal: 12m 30s\tremaining: 13m 50s\n",
      "4748:\tlearn: 0.0520512\ttotal: 12m 30s\tremaining: 13m 50s\n",
      "4749:\tlearn: 0.0520512\ttotal: 12m 30s\tremaining: 13m 49s\n",
      "4750:\tlearn: 0.0520512\ttotal: 12m 31s\tremaining: 13m 49s\n",
      "4751:\tlearn: 0.0520512\ttotal: 12m 31s\tremaining: 13m 49s\n",
      "4752:\tlearn: 0.0520512\ttotal: 12m 31s\tremaining: 13m 49s\n",
      "4753:\tlearn: 0.0520512\ttotal: 12m 31s\tremaining: 13m 49s\n",
      "4754:\tlearn: 0.0520512\ttotal: 12m 31s\tremaining: 13m 49s\n",
      "4755:\tlearn: 0.0520512\ttotal: 12m 31s\tremaining: 13m 48s\n",
      "4756:\tlearn: 0.0520512\ttotal: 12m 31s\tremaining: 13m 48s\n",
      "4757:\tlearn: 0.0520512\ttotal: 12m 32s\tremaining: 13m 48s\n",
      "4758:\tlearn: 0.0520512\ttotal: 12m 32s\tremaining: 13m 48s\n",
      "4759:\tlearn: 0.0520512\ttotal: 12m 32s\tremaining: 13m 48s\n",
      "4760:\tlearn: 0.0520512\ttotal: 12m 32s\tremaining: 13m 48s\n",
      "4761:\tlearn: 0.0520512\ttotal: 12m 32s\tremaining: 13m 47s\n",
      "4762:\tlearn: 0.0520512\ttotal: 12m 32s\tremaining: 13m 47s\n",
      "4763:\tlearn: 0.0520512\ttotal: 12m 33s\tremaining: 13m 47s\n",
      "4764:\tlearn: 0.0520512\ttotal: 12m 33s\tremaining: 13m 47s\n",
      "4765:\tlearn: 0.0520512\ttotal: 12m 33s\tremaining: 13m 47s\n",
      "4766:\tlearn: 0.0520512\ttotal: 12m 33s\tremaining: 13m 47s\n",
      "4767:\tlearn: 0.0520512\ttotal: 12m 33s\tremaining: 13m 47s\n",
      "4768:\tlearn: 0.0520512\ttotal: 12m 33s\tremaining: 13m 46s\n",
      "4769:\tlearn: 0.0520512\ttotal: 12m 33s\tremaining: 13m 46s\n",
      "4770:\tlearn: 0.0520512\ttotal: 12m 34s\tremaining: 13m 46s\n",
      "4771:\tlearn: 0.0520512\ttotal: 12m 34s\tremaining: 13m 46s\n",
      "4772:\tlearn: 0.0520512\ttotal: 12m 34s\tremaining: 13m 46s\n",
      "4773:\tlearn: 0.0520512\ttotal: 12m 34s\tremaining: 13m 46s\n",
      "4774:\tlearn: 0.0520512\ttotal: 12m 34s\tremaining: 13m 45s\n",
      "4775:\tlearn: 0.0520512\ttotal: 12m 34s\tremaining: 13m 45s\n",
      "4776:\tlearn: 0.0520512\ttotal: 12m 35s\tremaining: 13m 45s\n",
      "4777:\tlearn: 0.0520512\ttotal: 12m 35s\tremaining: 13m 45s\n",
      "4778:\tlearn: 0.0520512\ttotal: 12m 35s\tremaining: 13m 45s\n",
      "4779:\tlearn: 0.0520512\ttotal: 12m 35s\tremaining: 13m 45s\n",
      "4780:\tlearn: 0.0520512\ttotal: 12m 35s\tremaining: 13m 44s\n",
      "4781:\tlearn: 0.0520512\ttotal: 12m 35s\tremaining: 13m 44s\n",
      "4782:\tlearn: 0.0520512\ttotal: 12m 36s\tremaining: 13m 44s\n",
      "4783:\tlearn: 0.0520512\ttotal: 12m 36s\tremaining: 13m 44s\n",
      "4784:\tlearn: 0.0520512\ttotal: 12m 36s\tremaining: 13m 44s\n",
      "4785:\tlearn: 0.0520512\ttotal: 12m 36s\tremaining: 13m 44s\n",
      "4786:\tlearn: 0.0520512\ttotal: 12m 36s\tremaining: 13m 43s\n",
      "4787:\tlearn: 0.0520512\ttotal: 12m 36s\tremaining: 13m 43s\n",
      "4788:\tlearn: 0.0520512\ttotal: 12m 36s\tremaining: 13m 43s\n",
      "4789:\tlearn: 0.0520512\ttotal: 12m 37s\tremaining: 13m 43s\n",
      "4790:\tlearn: 0.0520512\ttotal: 12m 37s\tremaining: 13m 43s\n",
      "4791:\tlearn: 0.0520512\ttotal: 12m 37s\tremaining: 13m 43s\n",
      "4792:\tlearn: 0.0520512\ttotal: 12m 37s\tremaining: 13m 42s\n",
      "4793:\tlearn: 0.0520512\ttotal: 12m 37s\tremaining: 13m 42s\n",
      "4794:\tlearn: 0.0520512\ttotal: 12m 37s\tremaining: 13m 42s\n",
      "4795:\tlearn: 0.0520512\ttotal: 12m 38s\tremaining: 13m 42s\n",
      "4796:\tlearn: 0.0520512\ttotal: 12m 38s\tremaining: 13m 42s\n",
      "4797:\tlearn: 0.0520512\ttotal: 12m 38s\tremaining: 13m 42s\n",
      "4798:\tlearn: 0.0520512\ttotal: 12m 38s\tremaining: 13m 42s\n",
      "4799:\tlearn: 0.0520512\ttotal: 12m 38s\tremaining: 13m 41s\n",
      "4800:\tlearn: 0.0520512\ttotal: 12m 38s\tremaining: 13m 41s\n",
      "4801:\tlearn: 0.0520512\ttotal: 12m 38s\tremaining: 13m 41s\n",
      "4802:\tlearn: 0.0520512\ttotal: 12m 39s\tremaining: 13m 41s\n",
      "4803:\tlearn: 0.0520512\ttotal: 12m 39s\tremaining: 13m 41s\n",
      "4804:\tlearn: 0.0520512\ttotal: 12m 39s\tremaining: 13m 41s\n",
      "4805:\tlearn: 0.0520512\ttotal: 12m 39s\tremaining: 13m 40s\n",
      "4806:\tlearn: 0.0520512\ttotal: 12m 39s\tremaining: 13m 40s\n",
      "4807:\tlearn: 0.0520512\ttotal: 12m 39s\tremaining: 13m 40s\n",
      "4808:\tlearn: 0.0520512\ttotal: 12m 40s\tremaining: 13m 40s\n",
      "4809:\tlearn: 0.0520512\ttotal: 12m 40s\tremaining: 13m 40s\n",
      "4810:\tlearn: 0.0520512\ttotal: 12m 40s\tremaining: 13m 40s\n",
      "4811:\tlearn: 0.0520512\ttotal: 12m 40s\tremaining: 13m 39s\n",
      "4812:\tlearn: 0.0520512\ttotal: 12m 40s\tremaining: 13m 39s\n",
      "4813:\tlearn: 0.0520512\ttotal: 12m 40s\tremaining: 13m 39s\n",
      "4814:\tlearn: 0.0520512\ttotal: 12m 41s\tremaining: 13m 39s\n",
      "4815:\tlearn: 0.0520512\ttotal: 12m 41s\tremaining: 13m 39s\n",
      "4816:\tlearn: 0.0520512\ttotal: 12m 41s\tremaining: 13m 39s\n",
      "4817:\tlearn: 0.0520512\ttotal: 12m 41s\tremaining: 13m 39s\n",
      "4818:\tlearn: 0.0520512\ttotal: 12m 41s\tremaining: 13m 38s\n",
      "4819:\tlearn: 0.0520512\ttotal: 12m 41s\tremaining: 13m 38s\n",
      "4820:\tlearn: 0.0520512\ttotal: 12m 41s\tremaining: 13m 38s\n",
      "4821:\tlearn: 0.0520512\ttotal: 12m 42s\tremaining: 13m 38s\n",
      "4822:\tlearn: 0.0520512\ttotal: 12m 42s\tremaining: 13m 38s\n",
      "4823:\tlearn: 0.0520512\ttotal: 12m 42s\tremaining: 13m 38s\n",
      "4824:\tlearn: 0.0520512\ttotal: 12m 42s\tremaining: 13m 37s\n",
      "4825:\tlearn: 0.0520512\ttotal: 12m 42s\tremaining: 13m 37s\n",
      "4826:\tlearn: 0.0520512\ttotal: 12m 42s\tremaining: 13m 37s\n",
      "4827:\tlearn: 0.0520512\ttotal: 12m 43s\tremaining: 13m 37s\n",
      "4828:\tlearn: 0.0520512\ttotal: 12m 43s\tremaining: 13m 37s\n",
      "4829:\tlearn: 0.0520512\ttotal: 12m 43s\tremaining: 13m 37s\n",
      "4830:\tlearn: 0.0520512\ttotal: 12m 43s\tremaining: 13m 36s\n",
      "4831:\tlearn: 0.0520512\ttotal: 12m 43s\tremaining: 13m 36s\n",
      "4832:\tlearn: 0.0520512\ttotal: 12m 43s\tremaining: 13m 36s\n",
      "4833:\tlearn: 0.0520512\ttotal: 12m 44s\tremaining: 13m 36s\n",
      "4834:\tlearn: 0.0520512\ttotal: 12m 44s\tremaining: 13m 36s\n",
      "4835:\tlearn: 0.0520512\ttotal: 12m 44s\tremaining: 13m 36s\n",
      "4836:\tlearn: 0.0520512\ttotal: 12m 44s\tremaining: 13m 36s\n",
      "4837:\tlearn: 0.0520512\ttotal: 12m 44s\tremaining: 13m 35s\n",
      "4838:\tlearn: 0.0520512\ttotal: 12m 44s\tremaining: 13m 35s\n",
      "4839:\tlearn: 0.0520512\ttotal: 12m 44s\tremaining: 13m 35s\n",
      "4840:\tlearn: 0.0520512\ttotal: 12m 45s\tremaining: 13m 35s\n",
      "4841:\tlearn: 0.0520512\ttotal: 12m 45s\tremaining: 13m 35s\n",
      "4842:\tlearn: 0.0520512\ttotal: 12m 45s\tremaining: 13m 35s\n",
      "4843:\tlearn: 0.0520512\ttotal: 12m 45s\tremaining: 13m 34s\n",
      "4844:\tlearn: 0.0520512\ttotal: 12m 45s\tremaining: 13m 34s\n",
      "4845:\tlearn: 0.0520512\ttotal: 12m 45s\tremaining: 13m 34s\n",
      "4846:\tlearn: 0.0520512\ttotal: 12m 46s\tremaining: 13m 34s\n",
      "4847:\tlearn: 0.0520512\ttotal: 12m 46s\tremaining: 13m 34s\n",
      "4848:\tlearn: 0.0520512\ttotal: 12m 46s\tremaining: 13m 34s\n",
      "4849:\tlearn: 0.0520512\ttotal: 12m 46s\tremaining: 13m 33s\n",
      "4850:\tlearn: 0.0520512\ttotal: 12m 46s\tremaining: 13m 33s\n",
      "4851:\tlearn: 0.0520512\ttotal: 12m 46s\tremaining: 13m 33s\n",
      "4852:\tlearn: 0.0520512\ttotal: 12m 47s\tremaining: 13m 33s\n",
      "4853:\tlearn: 0.0520512\ttotal: 12m 47s\tremaining: 13m 33s\n",
      "4854:\tlearn: 0.0520512\ttotal: 12m 47s\tremaining: 13m 33s\n",
      "4855:\tlearn: 0.0520512\ttotal: 12m 47s\tremaining: 13m 33s\n",
      "4856:\tlearn: 0.0520512\ttotal: 12m 47s\tremaining: 13m 32s\n",
      "4857:\tlearn: 0.0520512\ttotal: 12m 47s\tremaining: 13m 32s\n",
      "4858:\tlearn: 0.0520512\ttotal: 12m 47s\tremaining: 13m 32s\n",
      "4859:\tlearn: 0.0520512\ttotal: 12m 48s\tremaining: 13m 32s\n",
      "4860:\tlearn: 0.0520512\ttotal: 12m 48s\tremaining: 13m 32s\n",
      "4861:\tlearn: 0.0520512\ttotal: 12m 48s\tremaining: 13m 32s\n",
      "4862:\tlearn: 0.0520512\ttotal: 12m 48s\tremaining: 13m 31s\n",
      "4863:\tlearn: 0.0520512\ttotal: 12m 48s\tremaining: 13m 31s\n",
      "4864:\tlearn: 0.0520512\ttotal: 12m 48s\tremaining: 13m 31s\n",
      "4865:\tlearn: 0.0520512\ttotal: 12m 49s\tremaining: 13m 31s\n",
      "4866:\tlearn: 0.0520512\ttotal: 12m 49s\tremaining: 13m 31s\n",
      "4867:\tlearn: 0.0520512\ttotal: 12m 49s\tremaining: 13m 31s\n",
      "4868:\tlearn: 0.0520512\ttotal: 12m 49s\tremaining: 13m 30s\n",
      "4869:\tlearn: 0.0520512\ttotal: 12m 49s\tremaining: 13m 30s\n",
      "4870:\tlearn: 0.0520512\ttotal: 12m 49s\tremaining: 13m 30s\n",
      "4871:\tlearn: 0.0520512\ttotal: 12m 50s\tremaining: 13m 30s\n",
      "4872:\tlearn: 0.0520512\ttotal: 12m 50s\tremaining: 13m 30s\n",
      "4873:\tlearn: 0.0520512\ttotal: 12m 50s\tremaining: 13m 30s\n",
      "4874:\tlearn: 0.0520512\ttotal: 12m 50s\tremaining: 13m 29s\n",
      "4875:\tlearn: 0.0520512\ttotal: 12m 50s\tremaining: 13m 29s\n",
      "4876:\tlearn: 0.0520512\ttotal: 12m 50s\tremaining: 13m 29s\n",
      "4877:\tlearn: 0.0520512\ttotal: 12m 50s\tremaining: 13m 29s\n",
      "4878:\tlearn: 0.0520512\ttotal: 12m 51s\tremaining: 13m 29s\n",
      "4879:\tlearn: 0.0520512\ttotal: 12m 51s\tremaining: 13m 29s\n",
      "4880:\tlearn: 0.0520512\ttotal: 12m 51s\tremaining: 13m 29s\n",
      "4881:\tlearn: 0.0520512\ttotal: 12m 51s\tremaining: 13m 28s\n",
      "4882:\tlearn: 0.0520512\ttotal: 12m 51s\tremaining: 13m 28s\n",
      "4883:\tlearn: 0.0520512\ttotal: 12m 51s\tremaining: 13m 28s\n",
      "4884:\tlearn: 0.0520512\ttotal: 12m 52s\tremaining: 13m 28s\n",
      "4885:\tlearn: 0.0520512\ttotal: 12m 52s\tremaining: 13m 28s\n",
      "4886:\tlearn: 0.0520512\ttotal: 12m 52s\tremaining: 13m 28s\n",
      "4887:\tlearn: 0.0520512\ttotal: 12m 52s\tremaining: 13m 27s\n",
      "4888:\tlearn: 0.0520512\ttotal: 12m 52s\tremaining: 13m 27s\n",
      "4889:\tlearn: 0.0520512\ttotal: 12m 52s\tremaining: 13m 27s\n",
      "4890:\tlearn: 0.0520512\ttotal: 12m 52s\tremaining: 13m 27s\n",
      "4891:\tlearn: 0.0520512\ttotal: 12m 53s\tremaining: 13m 27s\n",
      "4892:\tlearn: 0.0520512\ttotal: 12m 53s\tremaining: 13m 27s\n",
      "4893:\tlearn: 0.0520512\ttotal: 12m 53s\tremaining: 13m 26s\n",
      "4894:\tlearn: 0.0520512\ttotal: 12m 53s\tremaining: 13m 26s\n",
      "4895:\tlearn: 0.0520512\ttotal: 12m 53s\tremaining: 13m 26s\n",
      "4896:\tlearn: 0.0520512\ttotal: 12m 53s\tremaining: 13m 26s\n",
      "4897:\tlearn: 0.0520512\ttotal: 12m 54s\tremaining: 13m 26s\n",
      "4898:\tlearn: 0.0520512\ttotal: 12m 54s\tremaining: 13m 26s\n",
      "4899:\tlearn: 0.0520512\ttotal: 12m 54s\tremaining: 13m 25s\n",
      "4900:\tlearn: 0.0520512\ttotal: 12m 54s\tremaining: 13m 25s\n",
      "4901:\tlearn: 0.0520512\ttotal: 12m 54s\tremaining: 13m 25s\n",
      "4902:\tlearn: 0.0520512\ttotal: 12m 54s\tremaining: 13m 25s\n",
      "4903:\tlearn: 0.0520512\ttotal: 12m 54s\tremaining: 13m 25s\n",
      "4904:\tlearn: 0.0520512\ttotal: 12m 55s\tremaining: 13m 25s\n",
      "4905:\tlearn: 0.0520512\ttotal: 12m 55s\tremaining: 13m 24s\n",
      "4906:\tlearn: 0.0520512\ttotal: 12m 55s\tremaining: 13m 24s\n",
      "4907:\tlearn: 0.0520512\ttotal: 12m 55s\tremaining: 13m 24s\n",
      "4908:\tlearn: 0.0520512\ttotal: 12m 55s\tremaining: 13m 24s\n",
      "4909:\tlearn: 0.0520512\ttotal: 12m 55s\tremaining: 13m 24s\n",
      "4910:\tlearn: 0.0520512\ttotal: 12m 56s\tremaining: 13m 24s\n",
      "4911:\tlearn: 0.0520512\ttotal: 12m 56s\tremaining: 13m 24s\n",
      "4912:\tlearn: 0.0520512\ttotal: 12m 56s\tremaining: 13m 23s\n",
      "4913:\tlearn: 0.0520512\ttotal: 12m 56s\tremaining: 13m 23s\n",
      "4914:\tlearn: 0.0520512\ttotal: 12m 56s\tremaining: 13m 23s\n",
      "4915:\tlearn: 0.0520512\ttotal: 12m 56s\tremaining: 13m 23s\n",
      "4916:\tlearn: 0.0520512\ttotal: 12m 57s\tremaining: 13m 23s\n",
      "4917:\tlearn: 0.0520512\ttotal: 12m 57s\tremaining: 13m 23s\n",
      "4918:\tlearn: 0.0520512\ttotal: 12m 57s\tremaining: 13m 22s\n",
      "4919:\tlearn: 0.0520512\ttotal: 12m 57s\tremaining: 13m 22s\n",
      "4920:\tlearn: 0.0520512\ttotal: 12m 57s\tremaining: 13m 22s\n",
      "4921:\tlearn: 0.0520512\ttotal: 12m 57s\tremaining: 13m 22s\n",
      "4922:\tlearn: 0.0520512\ttotal: 12m 57s\tremaining: 13m 22s\n",
      "4923:\tlearn: 0.0520512\ttotal: 12m 58s\tremaining: 13m 22s\n",
      "4924:\tlearn: 0.0520512\ttotal: 12m 58s\tremaining: 13m 21s\n",
      "4925:\tlearn: 0.0520512\ttotal: 12m 58s\tremaining: 13m 21s\n",
      "4926:\tlearn: 0.0520512\ttotal: 12m 58s\tremaining: 13m 21s\n",
      "4927:\tlearn: 0.0520512\ttotal: 12m 58s\tremaining: 13m 21s\n",
      "4928:\tlearn: 0.0520512\ttotal: 12m 58s\tremaining: 13m 21s\n",
      "4929:\tlearn: 0.0520512\ttotal: 12m 59s\tremaining: 13m 21s\n",
      "4930:\tlearn: 0.0520512\ttotal: 12m 59s\tremaining: 13m 21s\n",
      "4931:\tlearn: 0.0520512\ttotal: 12m 59s\tremaining: 13m 20s\n",
      "4932:\tlearn: 0.0520512\ttotal: 12m 59s\tremaining: 13m 20s\n",
      "4933:\tlearn: 0.0520512\ttotal: 12m 59s\tremaining: 13m 20s\n",
      "4934:\tlearn: 0.0520512\ttotal: 12m 59s\tremaining: 13m 20s\n",
      "4935:\tlearn: 0.0520512\ttotal: 12m 59s\tremaining: 13m 20s\n",
      "4936:\tlearn: 0.0520512\ttotal: 13m\tremaining: 13m 20s\n",
      "4937:\tlearn: 0.0520512\ttotal: 13m\tremaining: 13m 19s\n",
      "4938:\tlearn: 0.0520512\ttotal: 13m\tremaining: 13m 19s\n",
      "4939:\tlearn: 0.0520512\ttotal: 13m\tremaining: 13m 19s\n",
      "4940:\tlearn: 0.0520512\ttotal: 13m\tremaining: 13m 19s\n",
      "4941:\tlearn: 0.0520512\ttotal: 13m\tremaining: 13m 19s\n",
      "4942:\tlearn: 0.0520512\ttotal: 13m 1s\tremaining: 13m 19s\n",
      "4943:\tlearn: 0.0520512\ttotal: 13m 1s\tremaining: 13m 18s\n",
      "4944:\tlearn: 0.0520512\ttotal: 13m 1s\tremaining: 13m 18s\n",
      "4945:\tlearn: 0.0520512\ttotal: 13m 1s\tremaining: 13m 18s\n",
      "4946:\tlearn: 0.0520512\ttotal: 13m 1s\tremaining: 13m 18s\n",
      "4947:\tlearn: 0.0520512\ttotal: 13m 1s\tremaining: 13m 18s\n",
      "4948:\tlearn: 0.0520512\ttotal: 13m 2s\tremaining: 13m 18s\n",
      "4949:\tlearn: 0.0520512\ttotal: 13m 2s\tremaining: 13m 17s\n",
      "4950:\tlearn: 0.0520512\ttotal: 13m 2s\tremaining: 13m 17s\n",
      "4951:\tlearn: 0.0520512\ttotal: 13m 2s\tremaining: 13m 17s\n",
      "4952:\tlearn: 0.0520512\ttotal: 13m 2s\tremaining: 13m 17s\n",
      "4953:\tlearn: 0.0520512\ttotal: 13m 2s\tremaining: 13m 17s\n",
      "4954:\tlearn: 0.0520512\ttotal: 13m 2s\tremaining: 13m 17s\n",
      "4955:\tlearn: 0.0520512\ttotal: 13m 3s\tremaining: 13m 16s\n",
      "4956:\tlearn: 0.0520512\ttotal: 13m 3s\tremaining: 13m 16s\n",
      "4957:\tlearn: 0.0520512\ttotal: 13m 3s\tremaining: 13m 16s\n",
      "4958:\tlearn: 0.0520512\ttotal: 13m 3s\tremaining: 13m 16s\n",
      "4959:\tlearn: 0.0520512\ttotal: 13m 3s\tremaining: 13m 16s\n",
      "4960:\tlearn: 0.0520512\ttotal: 13m 3s\tremaining: 13m 16s\n",
      "4961:\tlearn: 0.0520512\ttotal: 13m 4s\tremaining: 13m 16s\n",
      "4962:\tlearn: 0.0520512\ttotal: 13m 4s\tremaining: 13m 15s\n",
      "4963:\tlearn: 0.0520512\ttotal: 13m 4s\tremaining: 13m 15s\n",
      "4964:\tlearn: 0.0520512\ttotal: 13m 4s\tremaining: 13m 15s\n",
      "4965:\tlearn: 0.0520512\ttotal: 13m 4s\tremaining: 13m 15s\n",
      "4966:\tlearn: 0.0520512\ttotal: 13m 4s\tremaining: 13m 15s\n",
      "4967:\tlearn: 0.0520512\ttotal: 13m 4s\tremaining: 13m 15s\n",
      "4968:\tlearn: 0.0520512\ttotal: 13m 5s\tremaining: 13m 14s\n",
      "4969:\tlearn: 0.0520512\ttotal: 13m 5s\tremaining: 13m 14s\n",
      "4970:\tlearn: 0.0520512\ttotal: 13m 5s\tremaining: 13m 14s\n",
      "4971:\tlearn: 0.0520512\ttotal: 13m 5s\tremaining: 13m 14s\n",
      "4972:\tlearn: 0.0520512\ttotal: 13m 5s\tremaining: 13m 14s\n",
      "4973:\tlearn: 0.0520512\ttotal: 13m 5s\tremaining: 13m 14s\n",
      "4974:\tlearn: 0.0520512\ttotal: 13m 6s\tremaining: 13m 13s\n",
      "4975:\tlearn: 0.0520512\ttotal: 13m 6s\tremaining: 13m 13s\n",
      "4976:\tlearn: 0.0520512\ttotal: 13m 6s\tremaining: 13m 13s\n",
      "4977:\tlearn: 0.0520512\ttotal: 13m 6s\tremaining: 13m 13s\n",
      "4978:\tlearn: 0.0520512\ttotal: 13m 6s\tremaining: 13m 13s\n",
      "4979:\tlearn: 0.0520512\ttotal: 13m 6s\tremaining: 13m 13s\n",
      "4980:\tlearn: 0.0520512\ttotal: 13m 7s\tremaining: 13m 13s\n",
      "4981:\tlearn: 0.0520512\ttotal: 13m 7s\tremaining: 13m 12s\n",
      "4982:\tlearn: 0.0520512\ttotal: 13m 7s\tremaining: 13m 12s\n",
      "4983:\tlearn: 0.0520512\ttotal: 13m 7s\tremaining: 13m 12s\n",
      "4984:\tlearn: 0.0520512\ttotal: 13m 7s\tremaining: 13m 12s\n",
      "4985:\tlearn: 0.0520512\ttotal: 13m 7s\tremaining: 13m 12s\n",
      "4986:\tlearn: 0.0520512\ttotal: 13m 7s\tremaining: 13m 12s\n",
      "4987:\tlearn: 0.0520512\ttotal: 13m 8s\tremaining: 13m 11s\n",
      "4988:\tlearn: 0.0520512\ttotal: 13m 8s\tremaining: 13m 11s\n",
      "4989:\tlearn: 0.0520512\ttotal: 13m 8s\tremaining: 13m 11s\n",
      "4990:\tlearn: 0.0520512\ttotal: 13m 8s\tremaining: 13m 11s\n",
      "4991:\tlearn: 0.0520512\ttotal: 13m 8s\tremaining: 13m 11s\n",
      "4992:\tlearn: 0.0520512\ttotal: 13m 8s\tremaining: 13m 11s\n",
      "4993:\tlearn: 0.0520512\ttotal: 13m 9s\tremaining: 13m 10s\n",
      "4994:\tlearn: 0.0520512\ttotal: 13m 9s\tremaining: 13m 10s\n",
      "4995:\tlearn: 0.0520512\ttotal: 13m 9s\tremaining: 13m 10s\n",
      "4996:\tlearn: 0.0520512\ttotal: 13m 9s\tremaining: 13m 10s\n",
      "4997:\tlearn: 0.0520512\ttotal: 13m 9s\tremaining: 13m 10s\n",
      "4998:\tlearn: 0.0520512\ttotal: 13m 9s\tremaining: 13m 10s\n",
      "4999:\tlearn: 0.0520512\ttotal: 13m 9s\tremaining: 13m 9s\n",
      "5000:\tlearn: 0.0520512\ttotal: 13m 10s\tremaining: 13m 9s\n",
      "5001:\tlearn: 0.0520512\ttotal: 13m 10s\tremaining: 13m 9s\n",
      "5002:\tlearn: 0.0520512\ttotal: 13m 10s\tremaining: 13m 9s\n",
      "5003:\tlearn: 0.0520512\ttotal: 13m 10s\tremaining: 13m 9s\n",
      "5004:\tlearn: 0.0520512\ttotal: 13m 10s\tremaining: 13m 9s\n",
      "5005:\tlearn: 0.0520512\ttotal: 13m 10s\tremaining: 13m 9s\n",
      "5006:\tlearn: 0.0520512\ttotal: 13m 11s\tremaining: 13m 8s\n",
      "5007:\tlearn: 0.0520512\ttotal: 13m 11s\tremaining: 13m 8s\n",
      "5008:\tlearn: 0.0520512\ttotal: 13m 11s\tremaining: 13m 8s\n",
      "5009:\tlearn: 0.0520512\ttotal: 13m 11s\tremaining: 13m 8s\n",
      "5010:\tlearn: 0.0520512\ttotal: 13m 11s\tremaining: 13m 8s\n",
      "5011:\tlearn: 0.0520512\ttotal: 13m 11s\tremaining: 13m 8s\n",
      "5012:\tlearn: 0.0520512\ttotal: 13m 12s\tremaining: 13m 7s\n",
      "5013:\tlearn: 0.0520512\ttotal: 13m 12s\tremaining: 13m 7s\n",
      "5014:\tlearn: 0.0520512\ttotal: 13m 12s\tremaining: 13m 7s\n",
      "5015:\tlearn: 0.0520512\ttotal: 13m 12s\tremaining: 13m 7s\n",
      "5016:\tlearn: 0.0520512\ttotal: 13m 12s\tremaining: 13m 7s\n",
      "5017:\tlearn: 0.0520512\ttotal: 13m 12s\tremaining: 13m 7s\n",
      "5018:\tlearn: 0.0520512\ttotal: 13m 12s\tremaining: 13m 6s\n",
      "5019:\tlearn: 0.0520512\ttotal: 13m 13s\tremaining: 13m 6s\n",
      "5020:\tlearn: 0.0520512\ttotal: 13m 13s\tremaining: 13m 6s\n",
      "5021:\tlearn: 0.0520512\ttotal: 13m 13s\tremaining: 13m 6s\n",
      "5022:\tlearn: 0.0520512\ttotal: 13m 13s\tremaining: 13m 6s\n",
      "5023:\tlearn: 0.0520512\ttotal: 13m 13s\tremaining: 13m 6s\n",
      "5024:\tlearn: 0.0520512\ttotal: 13m 13s\tremaining: 13m 6s\n",
      "5025:\tlearn: 0.0520512\ttotal: 13m 14s\tremaining: 13m 5s\n",
      "5026:\tlearn: 0.0520512\ttotal: 13m 14s\tremaining: 13m 5s\n",
      "5027:\tlearn: 0.0520512\ttotal: 13m 14s\tremaining: 13m 5s\n",
      "5028:\tlearn: 0.0520512\ttotal: 13m 14s\tremaining: 13m 5s\n",
      "5029:\tlearn: 0.0520512\ttotal: 13m 14s\tremaining: 13m 5s\n",
      "5030:\tlearn: 0.0520512\ttotal: 13m 14s\tremaining: 13m 5s\n",
      "5031:\tlearn: 0.0520512\ttotal: 13m 15s\tremaining: 13m 4s\n",
      "5032:\tlearn: 0.0520512\ttotal: 13m 15s\tremaining: 13m 4s\n",
      "5033:\tlearn: 0.0520512\ttotal: 13m 15s\tremaining: 13m 4s\n",
      "5034:\tlearn: 0.0520512\ttotal: 13m 15s\tremaining: 13m 4s\n",
      "5035:\tlearn: 0.0520512\ttotal: 13m 15s\tremaining: 13m 4s\n",
      "5036:\tlearn: 0.0520512\ttotal: 13m 15s\tremaining: 13m 4s\n",
      "5037:\tlearn: 0.0520512\ttotal: 13m 15s\tremaining: 13m 3s\n",
      "5038:\tlearn: 0.0520512\ttotal: 13m 16s\tremaining: 13m 3s\n",
      "5039:\tlearn: 0.0520512\ttotal: 13m 16s\tremaining: 13m 3s\n",
      "5040:\tlearn: 0.0520512\ttotal: 13m 16s\tremaining: 13m 3s\n",
      "5041:\tlearn: 0.0520512\ttotal: 13m 16s\tremaining: 13m 3s\n",
      "5042:\tlearn: 0.0520512\ttotal: 13m 16s\tremaining: 13m 3s\n",
      "5043:\tlearn: 0.0520512\ttotal: 13m 16s\tremaining: 13m 2s\n",
      "5044:\tlearn: 0.0520512\ttotal: 13m 17s\tremaining: 13m 2s\n",
      "5045:\tlearn: 0.0520512\ttotal: 13m 17s\tremaining: 13m 2s\n",
      "5046:\tlearn: 0.0520512\ttotal: 13m 17s\tremaining: 13m 2s\n",
      "5047:\tlearn: 0.0520512\ttotal: 13m 17s\tremaining: 13m 2s\n",
      "5048:\tlearn: 0.0520512\ttotal: 13m 17s\tremaining: 13m 2s\n",
      "5049:\tlearn: 0.0520512\ttotal: 13m 17s\tremaining: 13m 1s\n",
      "5050:\tlearn: 0.0520512\ttotal: 13m 17s\tremaining: 13m 1s\n",
      "5051:\tlearn: 0.0520512\ttotal: 13m 18s\tremaining: 13m 1s\n",
      "5052:\tlearn: 0.0520512\ttotal: 13m 18s\tremaining: 13m 1s\n",
      "5053:\tlearn: 0.0520512\ttotal: 13m 18s\tremaining: 13m 1s\n",
      "5054:\tlearn: 0.0520512\ttotal: 13m 18s\tremaining: 13m 1s\n",
      "5055:\tlearn: 0.0520512\ttotal: 13m 18s\tremaining: 13m 1s\n",
      "5056:\tlearn: 0.0520512\ttotal: 13m 18s\tremaining: 13m\n",
      "5057:\tlearn: 0.0520512\ttotal: 13m 19s\tremaining: 13m\n",
      "5058:\tlearn: 0.0520512\ttotal: 13m 19s\tremaining: 13m\n",
      "5059:\tlearn: 0.0520512\ttotal: 13m 19s\tremaining: 13m\n",
      "5060:\tlearn: 0.0520512\ttotal: 13m 19s\tremaining: 13m\n",
      "5061:\tlearn: 0.0520512\ttotal: 13m 19s\tremaining: 13m\n",
      "5062:\tlearn: 0.0520512\ttotal: 13m 19s\tremaining: 12m 59s\n",
      "5063:\tlearn: 0.0520512\ttotal: 13m 19s\tremaining: 12m 59s\n",
      "5064:\tlearn: 0.0520512\ttotal: 13m 20s\tremaining: 12m 59s\n",
      "5065:\tlearn: 0.0520512\ttotal: 13m 20s\tremaining: 12m 59s\n",
      "5066:\tlearn: 0.0520512\ttotal: 13m 20s\tremaining: 12m 59s\n",
      "5067:\tlearn: 0.0520512\ttotal: 13m 20s\tremaining: 12m 59s\n",
      "5068:\tlearn: 0.0520512\ttotal: 13m 20s\tremaining: 12m 58s\n",
      "5069:\tlearn: 0.0520512\ttotal: 13m 20s\tremaining: 12m 58s\n",
      "5070:\tlearn: 0.0520512\ttotal: 13m 21s\tremaining: 12m 58s\n",
      "5071:\tlearn: 0.0520512\ttotal: 13m 21s\tremaining: 12m 58s\n",
      "5072:\tlearn: 0.0520512\ttotal: 13m 21s\tremaining: 12m 58s\n",
      "5073:\tlearn: 0.0520512\ttotal: 13m 21s\tremaining: 12m 58s\n",
      "5074:\tlearn: 0.0520512\ttotal: 13m 21s\tremaining: 12m 58s\n",
      "5075:\tlearn: 0.0520512\ttotal: 13m 21s\tremaining: 12m 57s\n",
      "5076:\tlearn: 0.0520512\ttotal: 13m 22s\tremaining: 12m 57s\n",
      "5077:\tlearn: 0.0520512\ttotal: 13m 22s\tremaining: 12m 57s\n",
      "5078:\tlearn: 0.0520512\ttotal: 13m 22s\tremaining: 12m 57s\n",
      "5079:\tlearn: 0.0520512\ttotal: 13m 22s\tremaining: 12m 57s\n",
      "5080:\tlearn: 0.0520512\ttotal: 13m 22s\tremaining: 12m 57s\n",
      "5081:\tlearn: 0.0520512\ttotal: 13m 22s\tremaining: 12m 56s\n",
      "5082:\tlearn: 0.0520512\ttotal: 13m 22s\tremaining: 12m 56s\n",
      "5083:\tlearn: 0.0520512\ttotal: 13m 23s\tremaining: 12m 56s\n",
      "5084:\tlearn: 0.0520512\ttotal: 13m 23s\tremaining: 12m 56s\n",
      "5085:\tlearn: 0.0520512\ttotal: 13m 23s\tremaining: 12m 56s\n",
      "5086:\tlearn: 0.0520512\ttotal: 13m 23s\tremaining: 12m 56s\n",
      "5087:\tlearn: 0.0520512\ttotal: 13m 23s\tremaining: 12m 55s\n",
      "5088:\tlearn: 0.0520512\ttotal: 13m 23s\tremaining: 12m 55s\n",
      "5089:\tlearn: 0.0520512\ttotal: 13m 24s\tremaining: 12m 55s\n",
      "5090:\tlearn: 0.0520512\ttotal: 13m 24s\tremaining: 12m 55s\n",
      "5091:\tlearn: 0.0520512\ttotal: 13m 24s\tremaining: 12m 55s\n",
      "5092:\tlearn: 0.0520512\ttotal: 13m 24s\tremaining: 12m 55s\n",
      "5093:\tlearn: 0.0520512\ttotal: 13m 24s\tremaining: 12m 54s\n",
      "5094:\tlearn: 0.0520512\ttotal: 13m 24s\tremaining: 12m 54s\n",
      "5095:\tlearn: 0.0520512\ttotal: 13m 24s\tremaining: 12m 54s\n",
      "5096:\tlearn: 0.0520512\ttotal: 13m 25s\tremaining: 12m 54s\n",
      "5097:\tlearn: 0.0520512\ttotal: 13m 25s\tremaining: 12m 54s\n",
      "5098:\tlearn: 0.0520512\ttotal: 13m 25s\tremaining: 12m 54s\n",
      "5099:\tlearn: 0.0520512\ttotal: 13m 25s\tremaining: 12m 53s\n",
      "5100:\tlearn: 0.0520512\ttotal: 13m 25s\tremaining: 12m 53s\n",
      "5101:\tlearn: 0.0520512\ttotal: 13m 25s\tremaining: 12m 53s\n",
      "5102:\tlearn: 0.0520512\ttotal: 13m 26s\tremaining: 12m 53s\n",
      "5103:\tlearn: 0.0520512\ttotal: 13m 26s\tremaining: 12m 53s\n",
      "5104:\tlearn: 0.0520512\ttotal: 13m 26s\tremaining: 12m 53s\n",
      "5105:\tlearn: 0.0520512\ttotal: 13m 26s\tremaining: 12m 53s\n",
      "5106:\tlearn: 0.0520512\ttotal: 13m 26s\tremaining: 12m 52s\n",
      "5107:\tlearn: 0.0520512\ttotal: 13m 26s\tremaining: 12m 52s\n",
      "5108:\tlearn: 0.0520512\ttotal: 13m 26s\tremaining: 12m 52s\n",
      "5109:\tlearn: 0.0520512\ttotal: 13m 27s\tremaining: 12m 52s\n",
      "5110:\tlearn: 0.0520512\ttotal: 13m 27s\tremaining: 12m 52s\n",
      "5111:\tlearn: 0.0520512\ttotal: 13m 27s\tremaining: 12m 52s\n",
      "5112:\tlearn: 0.0520512\ttotal: 13m 27s\tremaining: 12m 51s\n",
      "5113:\tlearn: 0.0520512\ttotal: 13m 27s\tremaining: 12m 51s\n",
      "5114:\tlearn: 0.0520512\ttotal: 13m 27s\tremaining: 12m 51s\n",
      "5115:\tlearn: 0.0520512\ttotal: 13m 28s\tremaining: 12m 51s\n",
      "5116:\tlearn: 0.0520512\ttotal: 13m 28s\tremaining: 12m 51s\n",
      "5117:\tlearn: 0.0520512\ttotal: 13m 28s\tremaining: 12m 51s\n",
      "5118:\tlearn: 0.0520512\ttotal: 13m 28s\tremaining: 12m 50s\n",
      "5119:\tlearn: 0.0520512\ttotal: 13m 28s\tremaining: 12m 50s\n",
      "5120:\tlearn: 0.0520512\ttotal: 13m 28s\tremaining: 12m 50s\n",
      "5121:\tlearn: 0.0520512\ttotal: 13m 28s\tremaining: 12m 50s\n",
      "5122:\tlearn: 0.0520512\ttotal: 13m 29s\tremaining: 12m 50s\n",
      "5123:\tlearn: 0.0520512\ttotal: 13m 29s\tremaining: 12m 50s\n",
      "5124:\tlearn: 0.0520512\ttotal: 13m 29s\tremaining: 12m 49s\n",
      "5125:\tlearn: 0.0520512\ttotal: 13m 29s\tremaining: 12m 49s\n",
      "5126:\tlearn: 0.0520512\ttotal: 13m 29s\tremaining: 12m 49s\n",
      "5127:\tlearn: 0.0520512\ttotal: 13m 29s\tremaining: 12m 49s\n",
      "5128:\tlearn: 0.0520512\ttotal: 13m 30s\tremaining: 12m 49s\n",
      "5129:\tlearn: 0.0520512\ttotal: 13m 30s\tremaining: 12m 49s\n",
      "5130:\tlearn: 0.0520512\ttotal: 13m 30s\tremaining: 12m 49s\n",
      "5131:\tlearn: 0.0520512\ttotal: 13m 30s\tremaining: 12m 48s\n",
      "5132:\tlearn: 0.0520512\ttotal: 13m 30s\tremaining: 12m 48s\n",
      "5133:\tlearn: 0.0520512\ttotal: 13m 30s\tremaining: 12m 48s\n",
      "5134:\tlearn: 0.0520512\ttotal: 13m 31s\tremaining: 12m 48s\n",
      "5135:\tlearn: 0.0520512\ttotal: 13m 31s\tremaining: 12m 48s\n",
      "5136:\tlearn: 0.0520512\ttotal: 13m 31s\tremaining: 12m 48s\n",
      "5137:\tlearn: 0.0520512\ttotal: 13m 31s\tremaining: 12m 47s\n",
      "5138:\tlearn: 0.0520512\ttotal: 13m 31s\tremaining: 12m 47s\n",
      "5139:\tlearn: 0.0520512\ttotal: 13m 31s\tremaining: 12m 47s\n",
      "5140:\tlearn: 0.0520512\ttotal: 13m 31s\tremaining: 12m 47s\n",
      "5141:\tlearn: 0.0520512\ttotal: 13m 32s\tremaining: 12m 47s\n",
      "5142:\tlearn: 0.0520512\ttotal: 13m 32s\tremaining: 12m 47s\n",
      "5143:\tlearn: 0.0520512\ttotal: 13m 32s\tremaining: 12m 46s\n",
      "5144:\tlearn: 0.0520512\ttotal: 13m 32s\tremaining: 12m 46s\n",
      "5145:\tlearn: 0.0520512\ttotal: 13m 32s\tremaining: 12m 46s\n",
      "5146:\tlearn: 0.0520512\ttotal: 13m 32s\tremaining: 12m 46s\n",
      "5147:\tlearn: 0.0520512\ttotal: 13m 33s\tremaining: 12m 46s\n",
      "5148:\tlearn: 0.0520512\ttotal: 13m 33s\tremaining: 12m 46s\n",
      "5149:\tlearn: 0.0520512\ttotal: 13m 33s\tremaining: 12m 45s\n",
      "5150:\tlearn: 0.0520512\ttotal: 13m 33s\tremaining: 12m 45s\n",
      "5151:\tlearn: 0.0520512\ttotal: 13m 33s\tremaining: 12m 45s\n",
      "5152:\tlearn: 0.0520512\ttotal: 13m 33s\tremaining: 12m 45s\n",
      "5153:\tlearn: 0.0520512\ttotal: 13m 33s\tremaining: 12m 45s\n",
      "5154:\tlearn: 0.0520512\ttotal: 13m 34s\tremaining: 12m 45s\n",
      "5155:\tlearn: 0.0520512\ttotal: 13m 34s\tremaining: 12m 44s\n",
      "5156:\tlearn: 0.0520512\ttotal: 13m 34s\tremaining: 12m 44s\n",
      "5157:\tlearn: 0.0520512\ttotal: 13m 34s\tremaining: 12m 44s\n",
      "5158:\tlearn: 0.0520512\ttotal: 13m 34s\tremaining: 12m 44s\n",
      "5159:\tlearn: 0.0520512\ttotal: 13m 34s\tremaining: 12m 44s\n",
      "5160:\tlearn: 0.0520512\ttotal: 13m 35s\tremaining: 12m 44s\n",
      "5161:\tlearn: 0.0520512\ttotal: 13m 35s\tremaining: 12m 44s\n",
      "5162:\tlearn: 0.0520512\ttotal: 13m 35s\tremaining: 12m 43s\n",
      "5163:\tlearn: 0.0520512\ttotal: 13m 35s\tremaining: 12m 43s\n",
      "5164:\tlearn: 0.0520512\ttotal: 13m 35s\tremaining: 12m 43s\n",
      "5165:\tlearn: 0.0520512\ttotal: 13m 35s\tremaining: 12m 43s\n",
      "5166:\tlearn: 0.0520512\ttotal: 13m 35s\tremaining: 12m 43s\n",
      "5167:\tlearn: 0.0520512\ttotal: 13m 36s\tremaining: 12m 43s\n",
      "5168:\tlearn: 0.0520512\ttotal: 13m 36s\tremaining: 12m 42s\n",
      "5169:\tlearn: 0.0520512\ttotal: 13m 36s\tremaining: 12m 42s\n",
      "5170:\tlearn: 0.0520512\ttotal: 13m 36s\tremaining: 12m 42s\n",
      "5171:\tlearn: 0.0520512\ttotal: 13m 36s\tremaining: 12m 42s\n",
      "5172:\tlearn: 0.0520512\ttotal: 13m 36s\tremaining: 12m 42s\n",
      "5173:\tlearn: 0.0520512\ttotal: 13m 37s\tremaining: 12m 42s\n",
      "5174:\tlearn: 0.0520512\ttotal: 13m 37s\tremaining: 12m 41s\n",
      "5175:\tlearn: 0.0520512\ttotal: 13m 37s\tremaining: 12m 41s\n",
      "5176:\tlearn: 0.0520512\ttotal: 13m 37s\tremaining: 12m 41s\n",
      "5177:\tlearn: 0.0520512\ttotal: 13m 37s\tremaining: 12m 41s\n",
      "5178:\tlearn: 0.0520512\ttotal: 13m 37s\tremaining: 12m 41s\n",
      "5179:\tlearn: 0.0520512\ttotal: 13m 38s\tremaining: 12m 41s\n",
      "5180:\tlearn: 0.0520512\ttotal: 13m 38s\tremaining: 12m 41s\n",
      "5181:\tlearn: 0.0520512\ttotal: 13m 38s\tremaining: 12m 40s\n",
      "5182:\tlearn: 0.0520512\ttotal: 13m 38s\tremaining: 12m 40s\n",
      "5183:\tlearn: 0.0520512\ttotal: 13m 38s\tremaining: 12m 40s\n",
      "5184:\tlearn: 0.0520512\ttotal: 13m 38s\tremaining: 12m 40s\n",
      "5185:\tlearn: 0.0520512\ttotal: 13m 38s\tremaining: 12m 40s\n",
      "5186:\tlearn: 0.0520512\ttotal: 13m 39s\tremaining: 12m 40s\n",
      "5187:\tlearn: 0.0520512\ttotal: 13m 39s\tremaining: 12m 39s\n",
      "5188:\tlearn: 0.0520512\ttotal: 13m 39s\tremaining: 12m 39s\n",
      "5189:\tlearn: 0.0520512\ttotal: 13m 39s\tremaining: 12m 39s\n",
      "5190:\tlearn: 0.0520512\ttotal: 13m 39s\tremaining: 12m 39s\n",
      "5191:\tlearn: 0.0520512\ttotal: 13m 39s\tremaining: 12m 39s\n",
      "5192:\tlearn: 0.0520512\ttotal: 13m 40s\tremaining: 12m 39s\n",
      "5193:\tlearn: 0.0520512\ttotal: 13m 40s\tremaining: 12m 38s\n",
      "5194:\tlearn: 0.0520512\ttotal: 13m 40s\tremaining: 12m 38s\n",
      "5195:\tlearn: 0.0520512\ttotal: 13m 40s\tremaining: 12m 38s\n",
      "5196:\tlearn: 0.0520512\ttotal: 13m 40s\tremaining: 12m 38s\n",
      "5197:\tlearn: 0.0520512\ttotal: 13m 40s\tremaining: 12m 38s\n",
      "5198:\tlearn: 0.0520512\ttotal: 13m 40s\tremaining: 12m 38s\n",
      "5199:\tlearn: 0.0520512\ttotal: 13m 41s\tremaining: 12m 37s\n",
      "5200:\tlearn: 0.0520512\ttotal: 13m 41s\tremaining: 12m 37s\n",
      "5201:\tlearn: 0.0520512\ttotal: 13m 41s\tremaining: 12m 37s\n",
      "5202:\tlearn: 0.0520512\ttotal: 13m 41s\tremaining: 12m 37s\n",
      "5203:\tlearn: 0.0520512\ttotal: 13m 41s\tremaining: 12m 37s\n",
      "5204:\tlearn: 0.0520512\ttotal: 13m 41s\tremaining: 12m 37s\n",
      "5205:\tlearn: 0.0520512\ttotal: 13m 42s\tremaining: 12m 37s\n",
      "5206:\tlearn: 0.0520512\ttotal: 13m 42s\tremaining: 12m 36s\n",
      "5207:\tlearn: 0.0520512\ttotal: 13m 42s\tremaining: 12m 36s\n",
      "5208:\tlearn: 0.0520512\ttotal: 13m 42s\tremaining: 12m 36s\n",
      "5209:\tlearn: 0.0520512\ttotal: 13m 42s\tremaining: 12m 36s\n",
      "5210:\tlearn: 0.0520512\ttotal: 13m 42s\tremaining: 12m 36s\n",
      "5211:\tlearn: 0.0520512\ttotal: 13m 43s\tremaining: 12m 36s\n",
      "5212:\tlearn: 0.0520512\ttotal: 13m 43s\tremaining: 12m 35s\n",
      "5213:\tlearn: 0.0520512\ttotal: 13m 43s\tremaining: 12m 35s\n",
      "5214:\tlearn: 0.0520512\ttotal: 13m 43s\tremaining: 12m 35s\n",
      "5215:\tlearn: 0.0520512\ttotal: 13m 43s\tremaining: 12m 35s\n",
      "5216:\tlearn: 0.0520512\ttotal: 13m 43s\tremaining: 12m 35s\n",
      "5217:\tlearn: 0.0520512\ttotal: 13m 43s\tremaining: 12m 35s\n",
      "5218:\tlearn: 0.0520512\ttotal: 13m 44s\tremaining: 12m 34s\n",
      "5219:\tlearn: 0.0520512\ttotal: 13m 44s\tremaining: 12m 34s\n",
      "5220:\tlearn: 0.0520512\ttotal: 13m 44s\tremaining: 12m 34s\n",
      "5221:\tlearn: 0.0520512\ttotal: 13m 44s\tremaining: 12m 34s\n",
      "5222:\tlearn: 0.0520512\ttotal: 13m 44s\tremaining: 12m 34s\n",
      "5223:\tlearn: 0.0520512\ttotal: 13m 44s\tremaining: 12m 34s\n",
      "5224:\tlearn: 0.0520512\ttotal: 13m 45s\tremaining: 12m 34s\n",
      "5225:\tlearn: 0.0520512\ttotal: 13m 45s\tremaining: 12m 33s\n",
      "5226:\tlearn: 0.0520512\ttotal: 13m 45s\tremaining: 12m 33s\n",
      "5227:\tlearn: 0.0520512\ttotal: 13m 45s\tremaining: 12m 33s\n",
      "5228:\tlearn: 0.0520512\ttotal: 13m 45s\tremaining: 12m 33s\n",
      "5229:\tlearn: 0.0520512\ttotal: 13m 45s\tremaining: 12m 33s\n",
      "5230:\tlearn: 0.0520512\ttotal: 13m 46s\tremaining: 12m 33s\n",
      "5231:\tlearn: 0.0520512\ttotal: 13m 46s\tremaining: 12m 32s\n",
      "5232:\tlearn: 0.0520512\ttotal: 13m 46s\tremaining: 12m 32s\n",
      "5233:\tlearn: 0.0520512\ttotal: 13m 46s\tremaining: 12m 32s\n",
      "5234:\tlearn: 0.0520512\ttotal: 13m 46s\tremaining: 12m 32s\n",
      "5235:\tlearn: 0.0520512\ttotal: 13m 46s\tremaining: 12m 32s\n",
      "5236:\tlearn: 0.0520512\ttotal: 13m 46s\tremaining: 12m 32s\n",
      "5237:\tlearn: 0.0520512\ttotal: 13m 47s\tremaining: 12m 31s\n",
      "5238:\tlearn: 0.0520512\ttotal: 13m 47s\tremaining: 12m 31s\n",
      "5239:\tlearn: 0.0520512\ttotal: 13m 47s\tremaining: 12m 31s\n",
      "5240:\tlearn: 0.0520512\ttotal: 13m 47s\tremaining: 12m 31s\n",
      "5241:\tlearn: 0.0520512\ttotal: 13m 47s\tremaining: 12m 31s\n",
      "5242:\tlearn: 0.0520512\ttotal: 13m 47s\tremaining: 12m 31s\n",
      "5243:\tlearn: 0.0520512\ttotal: 13m 48s\tremaining: 12m 30s\n",
      "5244:\tlearn: 0.0520512\ttotal: 13m 48s\tremaining: 12m 30s\n",
      "5245:\tlearn: 0.0520512\ttotal: 13m 48s\tremaining: 12m 30s\n",
      "5246:\tlearn: 0.0520512\ttotal: 13m 48s\tremaining: 12m 30s\n",
      "5247:\tlearn: 0.0520512\ttotal: 13m 48s\tremaining: 12m 30s\n",
      "5248:\tlearn: 0.0520512\ttotal: 13m 48s\tremaining: 12m 30s\n",
      "5249:\tlearn: 0.0520512\ttotal: 13m 48s\tremaining: 12m 30s\n",
      "5250:\tlearn: 0.0520512\ttotal: 13m 49s\tremaining: 12m 29s\n",
      "5251:\tlearn: 0.0520512\ttotal: 13m 49s\tremaining: 12m 29s\n",
      "5252:\tlearn: 0.0520512\ttotal: 13m 49s\tremaining: 12m 29s\n",
      "5253:\tlearn: 0.0520512\ttotal: 13m 49s\tremaining: 12m 29s\n",
      "5254:\tlearn: 0.0520512\ttotal: 13m 49s\tremaining: 12m 29s\n",
      "5255:\tlearn: 0.0520512\ttotal: 13m 49s\tremaining: 12m 29s\n",
      "5256:\tlearn: 0.0520512\ttotal: 13m 50s\tremaining: 12m 28s\n",
      "5257:\tlearn: 0.0520512\ttotal: 13m 50s\tremaining: 12m 28s\n",
      "5258:\tlearn: 0.0520512\ttotal: 13m 50s\tremaining: 12m 28s\n",
      "5259:\tlearn: 0.0520512\ttotal: 13m 50s\tremaining: 12m 28s\n",
      "5260:\tlearn: 0.0520512\ttotal: 13m 50s\tremaining: 12m 28s\n",
      "5261:\tlearn: 0.0520512\ttotal: 13m 50s\tremaining: 12m 28s\n",
      "5262:\tlearn: 0.0520512\ttotal: 13m 51s\tremaining: 12m 27s\n",
      "5263:\tlearn: 0.0520512\ttotal: 13m 51s\tremaining: 12m 27s\n",
      "5264:\tlearn: 0.0520512\ttotal: 13m 51s\tremaining: 12m 27s\n",
      "5265:\tlearn: 0.0520512\ttotal: 13m 51s\tremaining: 12m 27s\n",
      "5266:\tlearn: 0.0520512\ttotal: 13m 51s\tremaining: 12m 27s\n",
      "5267:\tlearn: 0.0520512\ttotal: 13m 51s\tremaining: 12m 27s\n",
      "5268:\tlearn: 0.0520512\ttotal: 13m 51s\tremaining: 12m 26s\n",
      "5269:\tlearn: 0.0520512\ttotal: 13m 52s\tremaining: 12m 26s\n",
      "5270:\tlearn: 0.0520512\ttotal: 13m 52s\tremaining: 12m 26s\n",
      "5271:\tlearn: 0.0520512\ttotal: 13m 52s\tremaining: 12m 26s\n",
      "5272:\tlearn: 0.0520512\ttotal: 13m 52s\tremaining: 12m 26s\n",
      "5273:\tlearn: 0.0520512\ttotal: 13m 52s\tremaining: 12m 26s\n",
      "5274:\tlearn: 0.0520512\ttotal: 13m 52s\tremaining: 12m 26s\n",
      "5275:\tlearn: 0.0520512\ttotal: 13m 53s\tremaining: 12m 25s\n",
      "5276:\tlearn: 0.0520512\ttotal: 13m 53s\tremaining: 12m 25s\n",
      "5277:\tlearn: 0.0520512\ttotal: 13m 53s\tremaining: 12m 25s\n",
      "5278:\tlearn: 0.0520512\ttotal: 13m 53s\tremaining: 12m 25s\n",
      "5279:\tlearn: 0.0520512\ttotal: 13m 53s\tremaining: 12m 25s\n",
      "5280:\tlearn: 0.0520512\ttotal: 13m 53s\tremaining: 12m 25s\n",
      "5281:\tlearn: 0.0520512\ttotal: 13m 53s\tremaining: 12m 24s\n",
      "5282:\tlearn: 0.0520512\ttotal: 13m 54s\tremaining: 12m 24s\n",
      "5283:\tlearn: 0.0520512\ttotal: 13m 54s\tremaining: 12m 24s\n",
      "5284:\tlearn: 0.0520512\ttotal: 13m 54s\tremaining: 12m 24s\n",
      "5285:\tlearn: 0.0520512\ttotal: 13m 54s\tremaining: 12m 24s\n",
      "5286:\tlearn: 0.0520512\ttotal: 13m 54s\tremaining: 12m 24s\n",
      "5287:\tlearn: 0.0520512\ttotal: 13m 54s\tremaining: 12m 23s\n",
      "5288:\tlearn: 0.0520512\ttotal: 13m 55s\tremaining: 12m 23s\n",
      "5289:\tlearn: 0.0520512\ttotal: 13m 55s\tremaining: 12m 23s\n",
      "5290:\tlearn: 0.0520512\ttotal: 13m 55s\tremaining: 12m 23s\n",
      "5291:\tlearn: 0.0520512\ttotal: 13m 55s\tremaining: 12m 23s\n",
      "5292:\tlearn: 0.0520512\ttotal: 13m 55s\tremaining: 12m 23s\n",
      "5293:\tlearn: 0.0520512\ttotal: 13m 55s\tremaining: 12m 22s\n",
      "5294:\tlearn: 0.0520512\ttotal: 13m 55s\tremaining: 12m 22s\n",
      "5295:\tlearn: 0.0520512\ttotal: 13m 56s\tremaining: 12m 22s\n",
      "5296:\tlearn: 0.0520512\ttotal: 13m 56s\tremaining: 12m 22s\n",
      "5297:\tlearn: 0.0520512\ttotal: 13m 56s\tremaining: 12m 22s\n",
      "5298:\tlearn: 0.0520512\ttotal: 13m 56s\tremaining: 12m 22s\n",
      "5299:\tlearn: 0.0520512\ttotal: 13m 56s\tremaining: 12m 22s\n",
      "5300:\tlearn: 0.0520512\ttotal: 13m 56s\tremaining: 12m 21s\n",
      "5301:\tlearn: 0.0520512\ttotal: 13m 57s\tremaining: 12m 21s\n",
      "5302:\tlearn: 0.0520512\ttotal: 13m 57s\tremaining: 12m 21s\n",
      "5303:\tlearn: 0.0520512\ttotal: 13m 57s\tremaining: 12m 21s\n",
      "5304:\tlearn: 0.0520512\ttotal: 13m 57s\tremaining: 12m 21s\n",
      "5305:\tlearn: 0.0520512\ttotal: 13m 57s\tremaining: 12m 21s\n",
      "5306:\tlearn: 0.0520512\ttotal: 13m 57s\tremaining: 12m 20s\n",
      "5307:\tlearn: 0.0520512\ttotal: 13m 58s\tremaining: 12m 20s\n",
      "5308:\tlearn: 0.0520512\ttotal: 13m 58s\tremaining: 12m 20s\n",
      "5309:\tlearn: 0.0520512\ttotal: 13m 58s\tremaining: 12m 20s\n",
      "5310:\tlearn: 0.0520512\ttotal: 13m 58s\tremaining: 12m 20s\n",
      "5311:\tlearn: 0.0520512\ttotal: 13m 58s\tremaining: 12m 20s\n",
      "5312:\tlearn: 0.0520512\ttotal: 13m 58s\tremaining: 12m 19s\n",
      "5313:\tlearn: 0.0520512\ttotal: 13m 58s\tremaining: 12m 19s\n",
      "5314:\tlearn: 0.0520512\ttotal: 13m 59s\tremaining: 12m 19s\n",
      "5315:\tlearn: 0.0520512\ttotal: 13m 59s\tremaining: 12m 19s\n",
      "5316:\tlearn: 0.0520512\ttotal: 13m 59s\tremaining: 12m 19s\n",
      "5317:\tlearn: 0.0520512\ttotal: 13m 59s\tremaining: 12m 19s\n",
      "5318:\tlearn: 0.0520512\ttotal: 13m 59s\tremaining: 12m 19s\n",
      "5319:\tlearn: 0.0520512\ttotal: 13m 59s\tremaining: 12m 18s\n",
      "5320:\tlearn: 0.0520512\ttotal: 14m\tremaining: 12m 18s\n",
      "5321:\tlearn: 0.0520512\ttotal: 14m\tremaining: 12m 18s\n",
      "5322:\tlearn: 0.0520512\ttotal: 14m\tremaining: 12m 18s\n",
      "5323:\tlearn: 0.0520512\ttotal: 14m\tremaining: 12m 18s\n",
      "5324:\tlearn: 0.0520512\ttotal: 14m\tremaining: 12m 18s\n",
      "5325:\tlearn: 0.0520512\ttotal: 14m\tremaining: 12m 17s\n",
      "5326:\tlearn: 0.0520512\ttotal: 14m\tremaining: 12m 17s\n",
      "5327:\tlearn: 0.0520512\ttotal: 14m 1s\tremaining: 12m 17s\n",
      "5328:\tlearn: 0.0520512\ttotal: 14m 1s\tremaining: 12m 17s\n",
      "5329:\tlearn: 0.0520512\ttotal: 14m 1s\tremaining: 12m 17s\n",
      "5330:\tlearn: 0.0520512\ttotal: 14m 1s\tremaining: 12m 17s\n",
      "5331:\tlearn: 0.0520512\ttotal: 14m 1s\tremaining: 12m 16s\n",
      "5332:\tlearn: 0.0520512\ttotal: 14m 1s\tremaining: 12m 16s\n",
      "5333:\tlearn: 0.0520512\ttotal: 14m 2s\tremaining: 12m 16s\n",
      "5334:\tlearn: 0.0520512\ttotal: 14m 2s\tremaining: 12m 16s\n",
      "5335:\tlearn: 0.0520512\ttotal: 14m 2s\tremaining: 12m 16s\n",
      "5336:\tlearn: 0.0520512\ttotal: 14m 2s\tremaining: 12m 16s\n",
      "5337:\tlearn: 0.0520512\ttotal: 14m 2s\tremaining: 12m 15s\n",
      "5338:\tlearn: 0.0520512\ttotal: 14m 2s\tremaining: 12m 15s\n",
      "5339:\tlearn: 0.0520512\ttotal: 14m 2s\tremaining: 12m 15s\n",
      "5340:\tlearn: 0.0520512\ttotal: 14m 3s\tremaining: 12m 15s\n",
      "5341:\tlearn: 0.0520512\ttotal: 14m 3s\tremaining: 12m 15s\n",
      "5342:\tlearn: 0.0520512\ttotal: 14m 3s\tremaining: 12m 15s\n",
      "5343:\tlearn: 0.0520512\ttotal: 14m 3s\tremaining: 12m 14s\n",
      "5344:\tlearn: 0.0520512\ttotal: 14m 3s\tremaining: 12m 14s\n",
      "5345:\tlearn: 0.0520512\ttotal: 14m 3s\tremaining: 12m 14s\n",
      "5346:\tlearn: 0.0520512\ttotal: 14m 4s\tremaining: 12m 14s\n",
      "5347:\tlearn: 0.0520512\ttotal: 14m 4s\tremaining: 12m 14s\n",
      "5348:\tlearn: 0.0520512\ttotal: 14m 4s\tremaining: 12m 14s\n",
      "5349:\tlearn: 0.0520512\ttotal: 14m 4s\tremaining: 12m 14s\n",
      "5350:\tlearn: 0.0520512\ttotal: 14m 4s\tremaining: 12m 13s\n",
      "5351:\tlearn: 0.0520512\ttotal: 14m 4s\tremaining: 12m 13s\n",
      "5352:\tlearn: 0.0520512\ttotal: 14m 5s\tremaining: 12m 13s\n",
      "5353:\tlearn: 0.0520512\ttotal: 14m 5s\tremaining: 12m 13s\n",
      "5354:\tlearn: 0.0520512\ttotal: 14m 5s\tremaining: 12m 13s\n",
      "5355:\tlearn: 0.0520512\ttotal: 14m 5s\tremaining: 12m 13s\n",
      "5356:\tlearn: 0.0520512\ttotal: 14m 5s\tremaining: 12m 12s\n",
      "5357:\tlearn: 0.0520512\ttotal: 14m 5s\tremaining: 12m 12s\n",
      "5358:\tlearn: 0.0520512\ttotal: 14m 5s\tremaining: 12m 12s\n",
      "5359:\tlearn: 0.0520512\ttotal: 14m 6s\tremaining: 12m 12s\n",
      "5360:\tlearn: 0.0520512\ttotal: 14m 6s\tremaining: 12m 12s\n",
      "5361:\tlearn: 0.0520512\ttotal: 14m 6s\tremaining: 12m 12s\n",
      "5362:\tlearn: 0.0520512\ttotal: 14m 6s\tremaining: 12m 11s\n",
      "5363:\tlearn: 0.0520512\ttotal: 14m 6s\tremaining: 12m 11s\n",
      "5364:\tlearn: 0.0520512\ttotal: 14m 6s\tremaining: 12m 11s\n",
      "5365:\tlearn: 0.0520512\ttotal: 14m 7s\tremaining: 12m 11s\n",
      "5366:\tlearn: 0.0520512\ttotal: 14m 7s\tremaining: 12m 11s\n",
      "5367:\tlearn: 0.0520512\ttotal: 14m 7s\tremaining: 12m 11s\n",
      "5368:\tlearn: 0.0520512\ttotal: 14m 7s\tremaining: 12m 11s\n",
      "5369:\tlearn: 0.0520512\ttotal: 14m 7s\tremaining: 12m 10s\n",
      "5370:\tlearn: 0.0520512\ttotal: 14m 7s\tremaining: 12m 10s\n",
      "5371:\tlearn: 0.0520512\ttotal: 14m 7s\tremaining: 12m 10s\n",
      "5372:\tlearn: 0.0520512\ttotal: 14m 8s\tremaining: 12m 10s\n",
      "5373:\tlearn: 0.0520512\ttotal: 14m 8s\tremaining: 12m 10s\n",
      "5374:\tlearn: 0.0520512\ttotal: 14m 8s\tremaining: 12m 10s\n",
      "5375:\tlearn: 0.0520512\ttotal: 14m 8s\tremaining: 12m 9s\n",
      "5376:\tlearn: 0.0520512\ttotal: 14m 8s\tremaining: 12m 9s\n",
      "5377:\tlearn: 0.0520512\ttotal: 14m 8s\tremaining: 12m 9s\n",
      "5378:\tlearn: 0.0520512\ttotal: 14m 9s\tremaining: 12m 9s\n",
      "5379:\tlearn: 0.0520512\ttotal: 14m 9s\tremaining: 12m 9s\n",
      "5380:\tlearn: 0.0520512\ttotal: 14m 9s\tremaining: 12m 9s\n",
      "5381:\tlearn: 0.0520512\ttotal: 14m 9s\tremaining: 12m 8s\n",
      "5382:\tlearn: 0.0520512\ttotal: 14m 9s\tremaining: 12m 8s\n",
      "5383:\tlearn: 0.0520512\ttotal: 14m 9s\tremaining: 12m 8s\n",
      "5384:\tlearn: 0.0520512\ttotal: 14m 10s\tremaining: 12m 8s\n",
      "5385:\tlearn: 0.0520512\ttotal: 14m 10s\tremaining: 12m 8s\n",
      "5386:\tlearn: 0.0520512\ttotal: 14m 10s\tremaining: 12m 8s\n",
      "5387:\tlearn: 0.0520512\ttotal: 14m 10s\tremaining: 12m 8s\n",
      "5388:\tlearn: 0.0520512\ttotal: 14m 10s\tremaining: 12m 7s\n",
      "5389:\tlearn: 0.0520512\ttotal: 14m 10s\tremaining: 12m 7s\n",
      "5390:\tlearn: 0.0520512\ttotal: 14m 10s\tremaining: 12m 7s\n",
      "5391:\tlearn: 0.0520512\ttotal: 14m 11s\tremaining: 12m 7s\n",
      "5392:\tlearn: 0.0520512\ttotal: 14m 11s\tremaining: 12m 7s\n",
      "5393:\tlearn: 0.0520512\ttotal: 14m 11s\tremaining: 12m 7s\n",
      "5394:\tlearn: 0.0520512\ttotal: 14m 11s\tremaining: 12m 6s\n",
      "5395:\tlearn: 0.0520512\ttotal: 14m 11s\tremaining: 12m 6s\n",
      "5396:\tlearn: 0.0520512\ttotal: 14m 11s\tremaining: 12m 6s\n",
      "5397:\tlearn: 0.0520512\ttotal: 14m 12s\tremaining: 12m 6s\n",
      "5398:\tlearn: 0.0520512\ttotal: 14m 12s\tremaining: 12m 6s\n",
      "5399:\tlearn: 0.0520512\ttotal: 14m 12s\tremaining: 12m 6s\n",
      "5400:\tlearn: 0.0520512\ttotal: 14m 12s\tremaining: 12m 5s\n",
      "5401:\tlearn: 0.0520512\ttotal: 14m 12s\tremaining: 12m 5s\n",
      "5402:\tlearn: 0.0520512\ttotal: 14m 12s\tremaining: 12m 5s\n",
      "5403:\tlearn: 0.0520512\ttotal: 14m 13s\tremaining: 12m 5s\n",
      "5404:\tlearn: 0.0520512\ttotal: 14m 13s\tremaining: 12m 5s\n",
      "5405:\tlearn: 0.0520512\ttotal: 14m 13s\tremaining: 12m 5s\n",
      "5406:\tlearn: 0.0520512\ttotal: 14m 13s\tremaining: 12m 5s\n",
      "5407:\tlearn: 0.0520512\ttotal: 14m 13s\tremaining: 12m 4s\n",
      "5408:\tlearn: 0.0520512\ttotal: 14m 13s\tremaining: 12m 4s\n",
      "5409:\tlearn: 0.0520512\ttotal: 14m 13s\tremaining: 12m 4s\n",
      "5410:\tlearn: 0.0520512\ttotal: 14m 14s\tremaining: 12m 4s\n",
      "5411:\tlearn: 0.0520512\ttotal: 14m 14s\tremaining: 12m 4s\n",
      "5412:\tlearn: 0.0520512\ttotal: 14m 14s\tremaining: 12m 4s\n",
      "5413:\tlearn: 0.0520512\ttotal: 14m 14s\tremaining: 12m 3s\n",
      "5414:\tlearn: 0.0520512\ttotal: 14m 14s\tremaining: 12m 3s\n",
      "5415:\tlearn: 0.0520512\ttotal: 14m 14s\tremaining: 12m 3s\n",
      "5416:\tlearn: 0.0520512\ttotal: 14m 15s\tremaining: 12m 3s\n",
      "5417:\tlearn: 0.0520512\ttotal: 14m 15s\tremaining: 12m 3s\n",
      "5418:\tlearn: 0.0520512\ttotal: 14m 15s\tremaining: 12m 3s\n",
      "5419:\tlearn: 0.0520512\ttotal: 14m 15s\tremaining: 12m 2s\n",
      "5420:\tlearn: 0.0520512\ttotal: 14m 15s\tremaining: 12m 2s\n",
      "5421:\tlearn: 0.0520512\ttotal: 14m 15s\tremaining: 12m 2s\n",
      "5422:\tlearn: 0.0520512\ttotal: 14m 15s\tremaining: 12m 2s\n",
      "5423:\tlearn: 0.0520512\ttotal: 14m 16s\tremaining: 12m 2s\n",
      "5424:\tlearn: 0.0520512\ttotal: 14m 16s\tremaining: 12m 2s\n",
      "5425:\tlearn: 0.0520512\ttotal: 14m 16s\tremaining: 12m 1s\n",
      "5426:\tlearn: 0.0520512\ttotal: 14m 16s\tremaining: 12m 1s\n",
      "5427:\tlearn: 0.0520512\ttotal: 14m 16s\tremaining: 12m 1s\n",
      "5428:\tlearn: 0.0520512\ttotal: 14m 16s\tremaining: 12m 1s\n",
      "5429:\tlearn: 0.0520512\ttotal: 14m 17s\tremaining: 12m 1s\n",
      "5430:\tlearn: 0.0520512\ttotal: 14m 17s\tremaining: 12m 1s\n",
      "5431:\tlearn: 0.0520512\ttotal: 14m 17s\tremaining: 12m\n",
      "5432:\tlearn: 0.0520512\ttotal: 14m 17s\tremaining: 12m\n",
      "5433:\tlearn: 0.0520512\ttotal: 14m 17s\tremaining: 12m\n",
      "5434:\tlearn: 0.0520512\ttotal: 14m 17s\tremaining: 12m\n",
      "5435:\tlearn: 0.0520512\ttotal: 14m 18s\tremaining: 12m\n",
      "5436:\tlearn: 0.0520512\ttotal: 14m 18s\tremaining: 12m\n",
      "5437:\tlearn: 0.0520512\ttotal: 14m 18s\tremaining: 12m\n",
      "5438:\tlearn: 0.0520512\ttotal: 14m 18s\tremaining: 11m 59s\n",
      "5439:\tlearn: 0.0520512\ttotal: 14m 18s\tremaining: 11m 59s\n",
      "5440:\tlearn: 0.0520512\ttotal: 14m 18s\tremaining: 11m 59s\n",
      "5441:\tlearn: 0.0520512\ttotal: 14m 18s\tremaining: 11m 59s\n",
      "5442:\tlearn: 0.0520512\ttotal: 14m 19s\tremaining: 11m 59s\n",
      "5443:\tlearn: 0.0520512\ttotal: 14m 19s\tremaining: 11m 59s\n",
      "5444:\tlearn: 0.0520512\ttotal: 14m 19s\tremaining: 11m 58s\n",
      "5445:\tlearn: 0.0520512\ttotal: 14m 19s\tremaining: 11m 58s\n",
      "5446:\tlearn: 0.0520512\ttotal: 14m 19s\tremaining: 11m 58s\n",
      "5447:\tlearn: 0.0520512\ttotal: 14m 19s\tremaining: 11m 58s\n",
      "5448:\tlearn: 0.0520512\ttotal: 14m 20s\tremaining: 11m 58s\n",
      "5449:\tlearn: 0.0520512\ttotal: 14m 20s\tremaining: 11m 58s\n",
      "5450:\tlearn: 0.0520512\ttotal: 14m 20s\tremaining: 11m 57s\n",
      "5451:\tlearn: 0.0520512\ttotal: 14m 20s\tremaining: 11m 57s\n",
      "5452:\tlearn: 0.0520512\ttotal: 14m 20s\tremaining: 11m 57s\n",
      "5453:\tlearn: 0.0520512\ttotal: 14m 20s\tremaining: 11m 57s\n",
      "5454:\tlearn: 0.0520512\ttotal: 14m 20s\tremaining: 11m 57s\n",
      "5455:\tlearn: 0.0520512\ttotal: 14m 21s\tremaining: 11m 57s\n",
      "5456:\tlearn: 0.0520512\ttotal: 14m 21s\tremaining: 11m 57s\n",
      "5457:\tlearn: 0.0520512\ttotal: 14m 21s\tremaining: 11m 56s\n",
      "5458:\tlearn: 0.0520512\ttotal: 14m 21s\tremaining: 11m 56s\n",
      "5459:\tlearn: 0.0520512\ttotal: 14m 21s\tremaining: 11m 56s\n",
      "5460:\tlearn: 0.0520512\ttotal: 14m 21s\tremaining: 11m 56s\n",
      "5461:\tlearn: 0.0520512\ttotal: 14m 22s\tremaining: 11m 56s\n",
      "5462:\tlearn: 0.0520512\ttotal: 14m 22s\tremaining: 11m 56s\n",
      "5463:\tlearn: 0.0520512\ttotal: 14m 22s\tremaining: 11m 55s\n",
      "5464:\tlearn: 0.0520512\ttotal: 14m 22s\tremaining: 11m 55s\n",
      "5465:\tlearn: 0.0520512\ttotal: 14m 22s\tremaining: 11m 55s\n",
      "5466:\tlearn: 0.0520512\ttotal: 14m 22s\tremaining: 11m 55s\n",
      "5467:\tlearn: 0.0520512\ttotal: 14m 22s\tremaining: 11m 55s\n",
      "5468:\tlearn: 0.0520512\ttotal: 14m 23s\tremaining: 11m 55s\n",
      "5469:\tlearn: 0.0520512\ttotal: 14m 23s\tremaining: 11m 54s\n",
      "5470:\tlearn: 0.0520512\ttotal: 14m 23s\tremaining: 11m 54s\n",
      "5471:\tlearn: 0.0520512\ttotal: 14m 23s\tremaining: 11m 54s\n",
      "5472:\tlearn: 0.0520512\ttotal: 14m 23s\tremaining: 11m 54s\n",
      "5473:\tlearn: 0.0520512\ttotal: 14m 23s\tremaining: 11m 54s\n",
      "5474:\tlearn: 0.0520512\ttotal: 14m 24s\tremaining: 11m 54s\n",
      "5475:\tlearn: 0.0520512\ttotal: 14m 24s\tremaining: 11m 53s\n",
      "5476:\tlearn: 0.0520512\ttotal: 14m 24s\tremaining: 11m 53s\n",
      "5477:\tlearn: 0.0520512\ttotal: 14m 24s\tremaining: 11m 53s\n",
      "5478:\tlearn: 0.0520512\ttotal: 14m 24s\tremaining: 11m 53s\n",
      "5479:\tlearn: 0.0520512\ttotal: 14m 24s\tremaining: 11m 53s\n",
      "5480:\tlearn: 0.0520512\ttotal: 14m 25s\tremaining: 11m 53s\n",
      "5481:\tlearn: 0.0520512\ttotal: 14m 25s\tremaining: 11m 53s\n",
      "5482:\tlearn: 0.0520512\ttotal: 14m 25s\tremaining: 11m 52s\n",
      "5483:\tlearn: 0.0520512\ttotal: 14m 25s\tremaining: 11m 52s\n",
      "5484:\tlearn: 0.0520512\ttotal: 14m 25s\tremaining: 11m 52s\n",
      "5485:\tlearn: 0.0520512\ttotal: 14m 25s\tremaining: 11m 52s\n",
      "5486:\tlearn: 0.0520512\ttotal: 14m 25s\tremaining: 11m 52s\n",
      "5487:\tlearn: 0.0520512\ttotal: 14m 26s\tremaining: 11m 52s\n",
      "5488:\tlearn: 0.0520512\ttotal: 14m 26s\tremaining: 11m 51s\n",
      "5489:\tlearn: 0.0520512\ttotal: 14m 26s\tremaining: 11m 51s\n",
      "5490:\tlearn: 0.0520512\ttotal: 14m 26s\tremaining: 11m 51s\n",
      "5491:\tlearn: 0.0520512\ttotal: 14m 26s\tremaining: 11m 51s\n",
      "5492:\tlearn: 0.0520512\ttotal: 14m 26s\tremaining: 11m 51s\n",
      "5493:\tlearn: 0.0520512\ttotal: 14m 27s\tremaining: 11m 51s\n",
      "5494:\tlearn: 0.0520512\ttotal: 14m 27s\tremaining: 11m 50s\n",
      "5495:\tlearn: 0.0520512\ttotal: 14m 27s\tremaining: 11m 50s\n",
      "5496:\tlearn: 0.0520512\ttotal: 14m 27s\tremaining: 11m 50s\n",
      "5497:\tlearn: 0.0520512\ttotal: 14m 27s\tremaining: 11m 50s\n",
      "5498:\tlearn: 0.0520512\ttotal: 14m 27s\tremaining: 11m 50s\n",
      "5499:\tlearn: 0.0520512\ttotal: 14m 28s\tremaining: 11m 50s\n",
      "5500:\tlearn: 0.0520512\ttotal: 14m 28s\tremaining: 11m 50s\n",
      "5501:\tlearn: 0.0520512\ttotal: 14m 28s\tremaining: 11m 49s\n",
      "5502:\tlearn: 0.0520512\ttotal: 14m 28s\tremaining: 11m 49s\n",
      "5503:\tlearn: 0.0520512\ttotal: 14m 28s\tremaining: 11m 49s\n",
      "5504:\tlearn: 0.0520512\ttotal: 14m 28s\tremaining: 11m 49s\n",
      "5505:\tlearn: 0.0520512\ttotal: 14m 28s\tremaining: 11m 49s\n",
      "5506:\tlearn: 0.0520512\ttotal: 14m 29s\tremaining: 11m 49s\n",
      "5507:\tlearn: 0.0520512\ttotal: 14m 29s\tremaining: 11m 48s\n",
      "5508:\tlearn: 0.0520512\ttotal: 14m 29s\tremaining: 11m 48s\n",
      "5509:\tlearn: 0.0520512\ttotal: 14m 29s\tremaining: 11m 48s\n",
      "5510:\tlearn: 0.0520512\ttotal: 14m 29s\tremaining: 11m 48s\n",
      "5511:\tlearn: 0.0520512\ttotal: 14m 29s\tremaining: 11m 48s\n",
      "5512:\tlearn: 0.0520512\ttotal: 14m 30s\tremaining: 11m 48s\n",
      "5513:\tlearn: 0.0520512\ttotal: 14m 30s\tremaining: 11m 47s\n",
      "5514:\tlearn: 0.0520512\ttotal: 14m 30s\tremaining: 11m 47s\n",
      "5515:\tlearn: 0.0520512\ttotal: 14m 30s\tremaining: 11m 47s\n",
      "5516:\tlearn: 0.0520512\ttotal: 14m 30s\tremaining: 11m 47s\n",
      "5517:\tlearn: 0.0520512\ttotal: 14m 30s\tremaining: 11m 47s\n",
      "5518:\tlearn: 0.0520512\ttotal: 14m 30s\tremaining: 11m 47s\n",
      "5519:\tlearn: 0.0520512\ttotal: 14m 31s\tremaining: 11m 47s\n",
      "5520:\tlearn: 0.0520512\ttotal: 14m 31s\tremaining: 11m 46s\n",
      "5521:\tlearn: 0.0520512\ttotal: 14m 31s\tremaining: 11m 46s\n",
      "5522:\tlearn: 0.0520512\ttotal: 14m 31s\tremaining: 11m 46s\n",
      "5523:\tlearn: 0.0520512\ttotal: 14m 31s\tremaining: 11m 46s\n",
      "5524:\tlearn: 0.0520512\ttotal: 14m 31s\tremaining: 11m 46s\n",
      "5525:\tlearn: 0.0520512\ttotal: 14m 32s\tremaining: 11m 46s\n",
      "5526:\tlearn: 0.0520512\ttotal: 14m 32s\tremaining: 11m 45s\n",
      "5527:\tlearn: 0.0520512\ttotal: 14m 32s\tremaining: 11m 45s\n",
      "5528:\tlearn: 0.0520512\ttotal: 14m 32s\tremaining: 11m 45s\n",
      "5529:\tlearn: 0.0520512\ttotal: 14m 32s\tremaining: 11m 45s\n",
      "5530:\tlearn: 0.0520512\ttotal: 14m 32s\tremaining: 11m 45s\n",
      "5531:\tlearn: 0.0520512\ttotal: 14m 33s\tremaining: 11m 45s\n",
      "5532:\tlearn: 0.0520512\ttotal: 14m 33s\tremaining: 11m 44s\n",
      "5533:\tlearn: 0.0520512\ttotal: 14m 33s\tremaining: 11m 44s\n",
      "5534:\tlearn: 0.0520512\ttotal: 14m 33s\tremaining: 11m 44s\n",
      "5535:\tlearn: 0.0520512\ttotal: 14m 33s\tremaining: 11m 44s\n",
      "5536:\tlearn: 0.0520512\ttotal: 14m 33s\tremaining: 11m 44s\n",
      "5537:\tlearn: 0.0520512\ttotal: 14m 33s\tremaining: 11m 44s\n",
      "5538:\tlearn: 0.0520512\ttotal: 14m 34s\tremaining: 11m 44s\n",
      "5539:\tlearn: 0.0520512\ttotal: 14m 34s\tremaining: 11m 43s\n",
      "5540:\tlearn: 0.0520512\ttotal: 14m 34s\tremaining: 11m 43s\n",
      "5541:\tlearn: 0.0520512\ttotal: 14m 34s\tremaining: 11m 43s\n",
      "5542:\tlearn: 0.0520512\ttotal: 14m 34s\tremaining: 11m 43s\n",
      "5543:\tlearn: 0.0520512\ttotal: 14m 34s\tremaining: 11m 43s\n",
      "5544:\tlearn: 0.0520512\ttotal: 14m 35s\tremaining: 11m 43s\n",
      "5545:\tlearn: 0.0520512\ttotal: 14m 35s\tremaining: 11m 42s\n",
      "5546:\tlearn: 0.0520512\ttotal: 14m 35s\tremaining: 11m 42s\n",
      "5547:\tlearn: 0.0520512\ttotal: 14m 35s\tremaining: 11m 42s\n",
      "5548:\tlearn: 0.0520512\ttotal: 14m 35s\tremaining: 11m 42s\n",
      "5549:\tlearn: 0.0520512\ttotal: 14m 35s\tremaining: 11m 42s\n",
      "5550:\tlearn: 0.0520512\ttotal: 14m 36s\tremaining: 11m 42s\n",
      "5551:\tlearn: 0.0520512\ttotal: 14m 36s\tremaining: 11m 41s\n",
      "5552:\tlearn: 0.0520512\ttotal: 14m 36s\tremaining: 11m 41s\n",
      "5553:\tlearn: 0.0520512\ttotal: 14m 36s\tremaining: 11m 41s\n",
      "5554:\tlearn: 0.0520512\ttotal: 14m 36s\tremaining: 11m 41s\n",
      "5555:\tlearn: 0.0520512\ttotal: 14m 36s\tremaining: 11m 41s\n",
      "5556:\tlearn: 0.0520512\ttotal: 14m 36s\tremaining: 11m 41s\n",
      "5557:\tlearn: 0.0520512\ttotal: 14m 37s\tremaining: 11m 41s\n",
      "5558:\tlearn: 0.0520512\ttotal: 14m 37s\tremaining: 11m 40s\n",
      "5559:\tlearn: 0.0520512\ttotal: 14m 37s\tremaining: 11m 40s\n",
      "5560:\tlearn: 0.0520512\ttotal: 14m 37s\tremaining: 11m 40s\n",
      "5561:\tlearn: 0.0520512\ttotal: 14m 37s\tremaining: 11m 40s\n",
      "5562:\tlearn: 0.0520512\ttotal: 14m 37s\tremaining: 11m 40s\n",
      "5563:\tlearn: 0.0520512\ttotal: 14m 38s\tremaining: 11m 40s\n",
      "5564:\tlearn: 0.0520512\ttotal: 14m 38s\tremaining: 11m 39s\n",
      "5565:\tlearn: 0.0520512\ttotal: 14m 38s\tremaining: 11m 39s\n",
      "5566:\tlearn: 0.0520512\ttotal: 14m 38s\tremaining: 11m 39s\n",
      "5567:\tlearn: 0.0520512\ttotal: 14m 38s\tremaining: 11m 39s\n",
      "5568:\tlearn: 0.0520512\ttotal: 14m 38s\tremaining: 11m 39s\n",
      "5569:\tlearn: 0.0520512\ttotal: 14m 39s\tremaining: 11m 39s\n",
      "5570:\tlearn: 0.0520512\ttotal: 14m 39s\tremaining: 11m 38s\n",
      "5571:\tlearn: 0.0520512\ttotal: 14m 39s\tremaining: 11m 38s\n",
      "5572:\tlearn: 0.0520512\ttotal: 14m 39s\tremaining: 11m 38s\n",
      "5573:\tlearn: 0.0520512\ttotal: 14m 39s\tremaining: 11m 38s\n",
      "5574:\tlearn: 0.0520512\ttotal: 14m 39s\tremaining: 11m 38s\n",
      "5575:\tlearn: 0.0520512\ttotal: 14m 39s\tremaining: 11m 38s\n",
      "5576:\tlearn: 0.0520512\ttotal: 14m 40s\tremaining: 11m 38s\n",
      "5577:\tlearn: 0.0520512\ttotal: 14m 40s\tremaining: 11m 37s\n",
      "5578:\tlearn: 0.0520512\ttotal: 14m 40s\tremaining: 11m 37s\n",
      "5579:\tlearn: 0.0520512\ttotal: 14m 40s\tremaining: 11m 37s\n",
      "5580:\tlearn: 0.0520512\ttotal: 14m 40s\tremaining: 11m 37s\n",
      "5581:\tlearn: 0.0520512\ttotal: 14m 40s\tremaining: 11m 37s\n",
      "5582:\tlearn: 0.0520512\ttotal: 14m 41s\tremaining: 11m 37s\n",
      "5583:\tlearn: 0.0520512\ttotal: 14m 41s\tremaining: 11m 36s\n",
      "5584:\tlearn: 0.0520512\ttotal: 14m 41s\tremaining: 11m 36s\n",
      "5585:\tlearn: 0.0520512\ttotal: 14m 41s\tremaining: 11m 36s\n",
      "5586:\tlearn: 0.0520512\ttotal: 14m 41s\tremaining: 11m 36s\n",
      "5587:\tlearn: 0.0520512\ttotal: 14m 41s\tremaining: 11m 36s\n",
      "5588:\tlearn: 0.0520512\ttotal: 14m 42s\tremaining: 11m 36s\n",
      "5589:\tlearn: 0.0520512\ttotal: 14m 42s\tremaining: 11m 35s\n",
      "5590:\tlearn: 0.0520512\ttotal: 14m 42s\tremaining: 11m 35s\n",
      "5591:\tlearn: 0.0520512\ttotal: 14m 42s\tremaining: 11m 35s\n",
      "5592:\tlearn: 0.0520512\ttotal: 14m 42s\tremaining: 11m 35s\n",
      "5593:\tlearn: 0.0520512\ttotal: 14m 42s\tremaining: 11m 35s\n",
      "5594:\tlearn: 0.0520512\ttotal: 14m 42s\tremaining: 11m 35s\n",
      "5595:\tlearn: 0.0520512\ttotal: 14m 43s\tremaining: 11m 35s\n",
      "5596:\tlearn: 0.0520512\ttotal: 14m 43s\tremaining: 11m 34s\n",
      "5597:\tlearn: 0.0520512\ttotal: 14m 43s\tremaining: 11m 34s\n",
      "5598:\tlearn: 0.0520512\ttotal: 14m 43s\tremaining: 11m 34s\n",
      "5599:\tlearn: 0.0520512\ttotal: 14m 43s\tremaining: 11m 34s\n",
      "5600:\tlearn: 0.0520512\ttotal: 14m 43s\tremaining: 11m 34s\n",
      "5601:\tlearn: 0.0520512\ttotal: 14m 44s\tremaining: 11m 34s\n",
      "5602:\tlearn: 0.0520512\ttotal: 14m 44s\tremaining: 11m 33s\n",
      "5603:\tlearn: 0.0520512\ttotal: 14m 44s\tremaining: 11m 33s\n",
      "5604:\tlearn: 0.0520512\ttotal: 14m 44s\tremaining: 11m 33s\n",
      "5605:\tlearn: 0.0520512\ttotal: 14m 44s\tremaining: 11m 33s\n",
      "5606:\tlearn: 0.0520512\ttotal: 14m 44s\tremaining: 11m 33s\n",
      "5607:\tlearn: 0.0520512\ttotal: 14m 45s\tremaining: 11m 33s\n",
      "5608:\tlearn: 0.0520512\ttotal: 14m 45s\tremaining: 11m 32s\n",
      "5609:\tlearn: 0.0520512\ttotal: 14m 45s\tremaining: 11m 32s\n",
      "5610:\tlearn: 0.0520512\ttotal: 14m 45s\tremaining: 11m 32s\n",
      "5611:\tlearn: 0.0520512\ttotal: 14m 45s\tremaining: 11m 32s\n",
      "5612:\tlearn: 0.0520512\ttotal: 14m 45s\tremaining: 11m 32s\n",
      "5613:\tlearn: 0.0520512\ttotal: 14m 45s\tremaining: 11m 32s\n",
      "5614:\tlearn: 0.0520512\ttotal: 14m 46s\tremaining: 11m 32s\n",
      "5615:\tlearn: 0.0520512\ttotal: 14m 46s\tremaining: 11m 31s\n",
      "5616:\tlearn: 0.0520512\ttotal: 14m 46s\tremaining: 11m 31s\n",
      "5617:\tlearn: 0.0520512\ttotal: 14m 46s\tremaining: 11m 31s\n",
      "5618:\tlearn: 0.0520512\ttotal: 14m 46s\tremaining: 11m 31s\n",
      "5619:\tlearn: 0.0520512\ttotal: 14m 46s\tremaining: 11m 31s\n",
      "5620:\tlearn: 0.0520512\ttotal: 14m 47s\tremaining: 11m 31s\n",
      "5621:\tlearn: 0.0520512\ttotal: 14m 47s\tremaining: 11m 30s\n",
      "5622:\tlearn: 0.0520512\ttotal: 14m 47s\tremaining: 11m 30s\n",
      "5623:\tlearn: 0.0520512\ttotal: 14m 47s\tremaining: 11m 30s\n",
      "5624:\tlearn: 0.0520512\ttotal: 14m 47s\tremaining: 11m 30s\n",
      "5625:\tlearn: 0.0520512\ttotal: 14m 47s\tremaining: 11m 30s\n",
      "5626:\tlearn: 0.0520512\ttotal: 14m 48s\tremaining: 11m 30s\n",
      "5627:\tlearn: 0.0520512\ttotal: 14m 48s\tremaining: 11m 29s\n",
      "5628:\tlearn: 0.0520512\ttotal: 14m 48s\tremaining: 11m 29s\n",
      "5629:\tlearn: 0.0520512\ttotal: 14m 48s\tremaining: 11m 29s\n",
      "5630:\tlearn: 0.0520512\ttotal: 14m 48s\tremaining: 11m 29s\n",
      "5631:\tlearn: 0.0520512\ttotal: 14m 48s\tremaining: 11m 29s\n",
      "5632:\tlearn: 0.0520512\ttotal: 14m 48s\tremaining: 11m 29s\n",
      "5633:\tlearn: 0.0520512\ttotal: 14m 49s\tremaining: 11m 29s\n",
      "5634:\tlearn: 0.0520512\ttotal: 14m 49s\tremaining: 11m 28s\n",
      "5635:\tlearn: 0.0520512\ttotal: 14m 49s\tremaining: 11m 28s\n",
      "5636:\tlearn: 0.0520512\ttotal: 14m 49s\tremaining: 11m 28s\n",
      "5637:\tlearn: 0.0520512\ttotal: 14m 49s\tremaining: 11m 28s\n",
      "5638:\tlearn: 0.0520512\ttotal: 14m 49s\tremaining: 11m 28s\n",
      "5639:\tlearn: 0.0520512\ttotal: 14m 50s\tremaining: 11m 28s\n",
      "5640:\tlearn: 0.0520512\ttotal: 14m 50s\tremaining: 11m 27s\n",
      "5641:\tlearn: 0.0520512\ttotal: 14m 50s\tremaining: 11m 27s\n",
      "5642:\tlearn: 0.0520512\ttotal: 14m 50s\tremaining: 11m 27s\n",
      "5643:\tlearn: 0.0520512\ttotal: 14m 50s\tremaining: 11m 27s\n",
      "5644:\tlearn: 0.0520512\ttotal: 14m 50s\tremaining: 11m 27s\n",
      "5645:\tlearn: 0.0520512\ttotal: 14m 51s\tremaining: 11m 27s\n",
      "5646:\tlearn: 0.0520512\ttotal: 14m 51s\tremaining: 11m 26s\n",
      "5647:\tlearn: 0.0520512\ttotal: 14m 51s\tremaining: 11m 26s\n",
      "5648:\tlearn: 0.0520512\ttotal: 14m 51s\tremaining: 11m 26s\n",
      "5649:\tlearn: 0.0520512\ttotal: 14m 51s\tremaining: 11m 26s\n",
      "5650:\tlearn: 0.0520512\ttotal: 14m 51s\tremaining: 11m 26s\n",
      "5651:\tlearn: 0.0520512\ttotal: 14m 51s\tremaining: 11m 26s\n",
      "5652:\tlearn: 0.0520512\ttotal: 14m 52s\tremaining: 11m 26s\n",
      "5653:\tlearn: 0.0520512\ttotal: 14m 52s\tremaining: 11m 25s\n",
      "5654:\tlearn: 0.0520512\ttotal: 14m 52s\tremaining: 11m 25s\n",
      "5655:\tlearn: 0.0520512\ttotal: 14m 52s\tremaining: 11m 25s\n",
      "5656:\tlearn: 0.0520512\ttotal: 14m 52s\tremaining: 11m 25s\n",
      "5657:\tlearn: 0.0520512\ttotal: 14m 52s\tremaining: 11m 25s\n",
      "5658:\tlearn: 0.0520512\ttotal: 14m 53s\tremaining: 11m 25s\n",
      "5659:\tlearn: 0.0520512\ttotal: 14m 53s\tremaining: 11m 24s\n",
      "5660:\tlearn: 0.0520512\ttotal: 14m 53s\tremaining: 11m 24s\n",
      "5661:\tlearn: 0.0520512\ttotal: 14m 53s\tremaining: 11m 24s\n",
      "5662:\tlearn: 0.0520512\ttotal: 14m 53s\tremaining: 11m 24s\n",
      "5663:\tlearn: 0.0520512\ttotal: 14m 53s\tremaining: 11m 24s\n",
      "5664:\tlearn: 0.0520512\ttotal: 14m 53s\tremaining: 11m 24s\n",
      "5665:\tlearn: 0.0520512\ttotal: 14m 54s\tremaining: 11m 23s\n",
      "5666:\tlearn: 0.0520512\ttotal: 14m 54s\tremaining: 11m 23s\n",
      "5667:\tlearn: 0.0520512\ttotal: 14m 54s\tremaining: 11m 23s\n",
      "5668:\tlearn: 0.0520512\ttotal: 14m 54s\tremaining: 11m 23s\n",
      "5669:\tlearn: 0.0520512\ttotal: 14m 54s\tremaining: 11m 23s\n",
      "5670:\tlearn: 0.0520512\ttotal: 14m 54s\tremaining: 11m 23s\n",
      "5671:\tlearn: 0.0520512\ttotal: 14m 55s\tremaining: 11m 23s\n",
      "5672:\tlearn: 0.0520512\ttotal: 14m 55s\tremaining: 11m 22s\n",
      "5673:\tlearn: 0.0520512\ttotal: 14m 55s\tremaining: 11m 22s\n",
      "5674:\tlearn: 0.0520512\ttotal: 14m 55s\tremaining: 11m 22s\n",
      "5675:\tlearn: 0.0520512\ttotal: 14m 55s\tremaining: 11m 22s\n",
      "5676:\tlearn: 0.0520512\ttotal: 14m 55s\tremaining: 11m 22s\n",
      "5677:\tlearn: 0.0520512\ttotal: 14m 56s\tremaining: 11m 22s\n",
      "5678:\tlearn: 0.0520512\ttotal: 14m 56s\tremaining: 11m 21s\n",
      "5679:\tlearn: 0.0520512\ttotal: 14m 56s\tremaining: 11m 21s\n",
      "5680:\tlearn: 0.0520512\ttotal: 14m 56s\tremaining: 11m 21s\n",
      "5681:\tlearn: 0.0520512\ttotal: 14m 56s\tremaining: 11m 21s\n",
      "5682:\tlearn: 0.0520512\ttotal: 14m 56s\tremaining: 11m 21s\n",
      "5683:\tlearn: 0.0520512\ttotal: 14m 56s\tremaining: 11m 21s\n",
      "5684:\tlearn: 0.0520512\ttotal: 14m 57s\tremaining: 11m 20s\n",
      "5685:\tlearn: 0.0520512\ttotal: 14m 57s\tremaining: 11m 20s\n",
      "5686:\tlearn: 0.0520512\ttotal: 14m 57s\tremaining: 11m 20s\n",
      "5687:\tlearn: 0.0520512\ttotal: 14m 57s\tremaining: 11m 20s\n",
      "5688:\tlearn: 0.0520512\ttotal: 14m 57s\tremaining: 11m 20s\n",
      "5689:\tlearn: 0.0520512\ttotal: 14m 57s\tremaining: 11m 20s\n",
      "5690:\tlearn: 0.0520512\ttotal: 14m 58s\tremaining: 11m 20s\n",
      "5691:\tlearn: 0.0520512\ttotal: 14m 58s\tremaining: 11m 19s\n",
      "5692:\tlearn: 0.0520512\ttotal: 14m 58s\tremaining: 11m 19s\n",
      "5693:\tlearn: 0.0520512\ttotal: 14m 58s\tremaining: 11m 19s\n",
      "5694:\tlearn: 0.0520512\ttotal: 14m 58s\tremaining: 11m 19s\n",
      "5695:\tlearn: 0.0520512\ttotal: 14m 58s\tremaining: 11m 19s\n",
      "5696:\tlearn: 0.0520512\ttotal: 14m 59s\tremaining: 11m 19s\n",
      "5697:\tlearn: 0.0520512\ttotal: 14m 59s\tremaining: 11m 18s\n",
      "5698:\tlearn: 0.0520512\ttotal: 14m 59s\tremaining: 11m 18s\n",
      "5699:\tlearn: 0.0520512\ttotal: 14m 59s\tremaining: 11m 18s\n",
      "5700:\tlearn: 0.0520512\ttotal: 14m 59s\tremaining: 11m 18s\n",
      "5701:\tlearn: 0.0520512\ttotal: 14m 59s\tremaining: 11m 18s\n",
      "5702:\tlearn: 0.0520512\ttotal: 14m 59s\tremaining: 11m 18s\n",
      "5703:\tlearn: 0.0520512\ttotal: 15m\tremaining: 11m 17s\n",
      "5704:\tlearn: 0.0520512\ttotal: 15m\tremaining: 11m 17s\n",
      "5705:\tlearn: 0.0520512\ttotal: 15m\tremaining: 11m 17s\n",
      "5706:\tlearn: 0.0520512\ttotal: 15m\tremaining: 11m 17s\n",
      "5707:\tlearn: 0.0520512\ttotal: 15m\tremaining: 11m 17s\n",
      "5708:\tlearn: 0.0520512\ttotal: 15m\tremaining: 11m 17s\n",
      "5709:\tlearn: 0.0520512\ttotal: 15m 1s\tremaining: 11m 16s\n",
      "5710:\tlearn: 0.0520512\ttotal: 15m 1s\tremaining: 11m 16s\n",
      "5711:\tlearn: 0.0520512\ttotal: 15m 1s\tremaining: 11m 16s\n",
      "5712:\tlearn: 0.0520512\ttotal: 15m 1s\tremaining: 11m 16s\n",
      "5713:\tlearn: 0.0520512\ttotal: 15m 1s\tremaining: 11m 16s\n",
      "5714:\tlearn: 0.0520512\ttotal: 15m 1s\tremaining: 11m 16s\n",
      "5715:\tlearn: 0.0520512\ttotal: 15m 1s\tremaining: 11m 16s\n",
      "5716:\tlearn: 0.0520512\ttotal: 15m 2s\tremaining: 11m 15s\n",
      "5717:\tlearn: 0.0520512\ttotal: 15m 2s\tremaining: 11m 15s\n",
      "5718:\tlearn: 0.0520512\ttotal: 15m 2s\tremaining: 11m 15s\n",
      "5719:\tlearn: 0.0520512\ttotal: 15m 2s\tremaining: 11m 15s\n",
      "5720:\tlearn: 0.0520512\ttotal: 15m 2s\tremaining: 11m 15s\n",
      "5721:\tlearn: 0.0520512\ttotal: 15m 2s\tremaining: 11m 15s\n",
      "5722:\tlearn: 0.0520512\ttotal: 15m 3s\tremaining: 11m 14s\n",
      "5723:\tlearn: 0.0520512\ttotal: 15m 3s\tremaining: 11m 14s\n",
      "5724:\tlearn: 0.0520512\ttotal: 15m 3s\tremaining: 11m 14s\n",
      "5725:\tlearn: 0.0520512\ttotal: 15m 3s\tremaining: 11m 14s\n",
      "5726:\tlearn: 0.0520512\ttotal: 15m 3s\tremaining: 11m 14s\n",
      "5727:\tlearn: 0.0520512\ttotal: 15m 3s\tremaining: 11m 14s\n",
      "5728:\tlearn: 0.0520512\ttotal: 15m 4s\tremaining: 11m 13s\n",
      "5729:\tlearn: 0.0520512\ttotal: 15m 4s\tremaining: 11m 13s\n",
      "5730:\tlearn: 0.0520512\ttotal: 15m 4s\tremaining: 11m 13s\n",
      "5731:\tlearn: 0.0520512\ttotal: 15m 4s\tremaining: 11m 13s\n",
      "5732:\tlearn: 0.0520512\ttotal: 15m 4s\tremaining: 11m 13s\n",
      "5733:\tlearn: 0.0520512\ttotal: 15m 4s\tremaining: 11m 13s\n",
      "5734:\tlearn: 0.0520512\ttotal: 15m 4s\tremaining: 11m 13s\n",
      "5735:\tlearn: 0.0520512\ttotal: 15m 5s\tremaining: 11m 12s\n",
      "5736:\tlearn: 0.0520512\ttotal: 15m 5s\tremaining: 11m 12s\n",
      "5737:\tlearn: 0.0520512\ttotal: 15m 5s\tremaining: 11m 12s\n",
      "5738:\tlearn: 0.0520512\ttotal: 15m 5s\tremaining: 11m 12s\n",
      "5739:\tlearn: 0.0520512\ttotal: 15m 5s\tremaining: 11m 12s\n",
      "5740:\tlearn: 0.0520512\ttotal: 15m 5s\tremaining: 11m 12s\n",
      "5741:\tlearn: 0.0520512\ttotal: 15m 6s\tremaining: 11m 11s\n",
      "5742:\tlearn: 0.0520512\ttotal: 15m 6s\tremaining: 11m 11s\n",
      "5743:\tlearn: 0.0520512\ttotal: 15m 6s\tremaining: 11m 11s\n",
      "5744:\tlearn: 0.0520512\ttotal: 15m 6s\tremaining: 11m 11s\n",
      "5745:\tlearn: 0.0520512\ttotal: 15m 6s\tremaining: 11m 11s\n",
      "5746:\tlearn: 0.0520512\ttotal: 15m 6s\tremaining: 11m 11s\n",
      "5747:\tlearn: 0.0520512\ttotal: 15m 6s\tremaining: 11m 10s\n",
      "5748:\tlearn: 0.0520512\ttotal: 15m 7s\tremaining: 11m 10s\n",
      "5749:\tlearn: 0.0520512\ttotal: 15m 7s\tremaining: 11m 10s\n",
      "5750:\tlearn: 0.0520512\ttotal: 15m 7s\tremaining: 11m 10s\n",
      "5751:\tlearn: 0.0520512\ttotal: 15m 7s\tremaining: 11m 10s\n",
      "5752:\tlearn: 0.0520512\ttotal: 15m 7s\tremaining: 11m 10s\n",
      "5753:\tlearn: 0.0520512\ttotal: 15m 7s\tremaining: 11m 9s\n",
      "5754:\tlearn: 0.0520512\ttotal: 15m 8s\tremaining: 11m 9s\n",
      "5755:\tlearn: 0.0520512\ttotal: 15m 8s\tremaining: 11m 9s\n",
      "5756:\tlearn: 0.0520512\ttotal: 15m 8s\tremaining: 11m 9s\n",
      "5757:\tlearn: 0.0520512\ttotal: 15m 8s\tremaining: 11m 9s\n",
      "5758:\tlearn: 0.0520512\ttotal: 15m 8s\tremaining: 11m 9s\n",
      "5759:\tlearn: 0.0520512\ttotal: 15m 8s\tremaining: 11m 9s\n",
      "5760:\tlearn: 0.0520512\ttotal: 15m 9s\tremaining: 11m 8s\n",
      "5761:\tlearn: 0.0520512\ttotal: 15m 9s\tremaining: 11m 8s\n",
      "5762:\tlearn: 0.0520512\ttotal: 15m 9s\tremaining: 11m 8s\n",
      "5763:\tlearn: 0.0520512\ttotal: 15m 9s\tremaining: 11m 8s\n",
      "5764:\tlearn: 0.0520512\ttotal: 15m 9s\tremaining: 11m 8s\n",
      "5765:\tlearn: 0.0520512\ttotal: 15m 9s\tremaining: 11m 8s\n",
      "5766:\tlearn: 0.0520512\ttotal: 15m 9s\tremaining: 11m 7s\n",
      "5767:\tlearn: 0.0520512\ttotal: 15m 10s\tremaining: 11m 7s\n",
      "5768:\tlearn: 0.0520512\ttotal: 15m 10s\tremaining: 11m 7s\n",
      "5769:\tlearn: 0.0520512\ttotal: 15m 10s\tremaining: 11m 7s\n",
      "5770:\tlearn: 0.0520512\ttotal: 15m 10s\tremaining: 11m 7s\n",
      "5771:\tlearn: 0.0520512\ttotal: 15m 10s\tremaining: 11m 7s\n",
      "5772:\tlearn: 0.0520512\ttotal: 15m 10s\tremaining: 11m 6s\n",
      "5773:\tlearn: 0.0520512\ttotal: 15m 11s\tremaining: 11m 6s\n",
      "5774:\tlearn: 0.0520512\ttotal: 15m 11s\tremaining: 11m 6s\n",
      "5775:\tlearn: 0.0520512\ttotal: 15m 11s\tremaining: 11m 6s\n",
      "5776:\tlearn: 0.0520512\ttotal: 15m 11s\tremaining: 11m 6s\n",
      "5777:\tlearn: 0.0520512\ttotal: 15m 11s\tremaining: 11m 6s\n",
      "5778:\tlearn: 0.0520512\ttotal: 15m 11s\tremaining: 11m 5s\n",
      "5779:\tlearn: 0.0520512\ttotal: 15m 11s\tremaining: 11m 5s\n",
      "5780:\tlearn: 0.0520512\ttotal: 15m 12s\tremaining: 11m 5s\n",
      "5781:\tlearn: 0.0520512\ttotal: 15m 12s\tremaining: 11m 5s\n",
      "5782:\tlearn: 0.0520512\ttotal: 15m 12s\tremaining: 11m 5s\n",
      "5783:\tlearn: 0.0520512\ttotal: 15m 12s\tremaining: 11m 5s\n",
      "5784:\tlearn: 0.0520512\ttotal: 15m 12s\tremaining: 11m 5s\n",
      "5785:\tlearn: 0.0520512\ttotal: 15m 12s\tremaining: 11m 4s\n",
      "5786:\tlearn: 0.0520512\ttotal: 15m 13s\tremaining: 11m 4s\n",
      "5787:\tlearn: 0.0520512\ttotal: 15m 13s\tremaining: 11m 4s\n",
      "5788:\tlearn: 0.0520512\ttotal: 15m 13s\tremaining: 11m 4s\n",
      "5789:\tlearn: 0.0520512\ttotal: 15m 13s\tremaining: 11m 4s\n",
      "5790:\tlearn: 0.0520512\ttotal: 15m 13s\tremaining: 11m 4s\n",
      "5791:\tlearn: 0.0520512\ttotal: 15m 13s\tremaining: 11m 3s\n",
      "5792:\tlearn: 0.0520512\ttotal: 15m 13s\tremaining: 11m 3s\n",
      "5793:\tlearn: 0.0520512\ttotal: 15m 14s\tremaining: 11m 3s\n",
      "5794:\tlearn: 0.0520512\ttotal: 15m 14s\tremaining: 11m 3s\n",
      "5795:\tlearn: 0.0520512\ttotal: 15m 14s\tremaining: 11m 3s\n",
      "5796:\tlearn: 0.0520512\ttotal: 15m 14s\tremaining: 11m 3s\n",
      "5797:\tlearn: 0.0520512\ttotal: 15m 14s\tremaining: 11m 2s\n",
      "5798:\tlearn: 0.0520512\ttotal: 15m 14s\tremaining: 11m 2s\n",
      "5799:\tlearn: 0.0520512\ttotal: 15m 15s\tremaining: 11m 2s\n",
      "5800:\tlearn: 0.0520512\ttotal: 15m 15s\tremaining: 11m 2s\n",
      "5801:\tlearn: 0.0520512\ttotal: 15m 15s\tremaining: 11m 2s\n",
      "5802:\tlearn: 0.0520512\ttotal: 15m 15s\tremaining: 11m 2s\n",
      "5803:\tlearn: 0.0520512\ttotal: 15m 15s\tremaining: 11m 2s\n",
      "5804:\tlearn: 0.0520512\ttotal: 15m 15s\tremaining: 11m 1s\n",
      "5805:\tlearn: 0.0520512\ttotal: 15m 16s\tremaining: 11m 1s\n",
      "5806:\tlearn: 0.0520512\ttotal: 15m 16s\tremaining: 11m 1s\n",
      "5807:\tlearn: 0.0520512\ttotal: 15m 16s\tremaining: 11m 1s\n",
      "5808:\tlearn: 0.0520512\ttotal: 15m 16s\tremaining: 11m 1s\n",
      "5809:\tlearn: 0.0520512\ttotal: 15m 16s\tremaining: 11m 1s\n",
      "5810:\tlearn: 0.0520512\ttotal: 15m 16s\tremaining: 11m\n",
      "5811:\tlearn: 0.0520512\ttotal: 15m 17s\tremaining: 11m\n",
      "5812:\tlearn: 0.0520512\ttotal: 15m 17s\tremaining: 11m\n",
      "5813:\tlearn: 0.0520512\ttotal: 15m 17s\tremaining: 11m\n",
      "5814:\tlearn: 0.0520512\ttotal: 15m 17s\tremaining: 11m\n",
      "5815:\tlearn: 0.0520512\ttotal: 15m 17s\tremaining: 11m\n",
      "5816:\tlearn: 0.0520512\ttotal: 15m 17s\tremaining: 11m\n",
      "5817:\tlearn: 0.0520512\ttotal: 15m 17s\tremaining: 10m 59s\n",
      "5818:\tlearn: 0.0520512\ttotal: 15m 18s\tremaining: 10m 59s\n",
      "5819:\tlearn: 0.0520512\ttotal: 15m 18s\tremaining: 10m 59s\n",
      "5820:\tlearn: 0.0520512\ttotal: 15m 18s\tremaining: 10m 59s\n",
      "5821:\tlearn: 0.0520512\ttotal: 15m 18s\tremaining: 10m 59s\n",
      "5822:\tlearn: 0.0520512\ttotal: 15m 18s\tremaining: 10m 59s\n",
      "5823:\tlearn: 0.0520512\ttotal: 15m 18s\tremaining: 10m 58s\n",
      "5824:\tlearn: 0.0520512\ttotal: 15m 19s\tremaining: 10m 58s\n",
      "5825:\tlearn: 0.0520512\ttotal: 15m 19s\tremaining: 10m 58s\n",
      "5826:\tlearn: 0.0520512\ttotal: 15m 19s\tremaining: 10m 58s\n",
      "5827:\tlearn: 0.0520512\ttotal: 15m 19s\tremaining: 10m 58s\n",
      "5828:\tlearn: 0.0520512\ttotal: 15m 19s\tremaining: 10m 58s\n",
      "5829:\tlearn: 0.0520512\ttotal: 15m 19s\tremaining: 10m 57s\n",
      "5830:\tlearn: 0.0520512\ttotal: 15m 20s\tremaining: 10m 57s\n",
      "5831:\tlearn: 0.0520512\ttotal: 15m 20s\tremaining: 10m 57s\n",
      "5832:\tlearn: 0.0520512\ttotal: 15m 20s\tremaining: 10m 57s\n",
      "5833:\tlearn: 0.0520512\ttotal: 15m 20s\tremaining: 10m 57s\n",
      "5834:\tlearn: 0.0520512\ttotal: 15m 20s\tremaining: 10m 57s\n",
      "5835:\tlearn: 0.0520512\ttotal: 15m 20s\tremaining: 10m 57s\n",
      "5836:\tlearn: 0.0520512\ttotal: 15m 21s\tremaining: 10m 56s\n",
      "5837:\tlearn: 0.0520512\ttotal: 15m 21s\tremaining: 10m 56s\n",
      "5838:\tlearn: 0.0520512\ttotal: 15m 21s\tremaining: 10m 56s\n",
      "5839:\tlearn: 0.0520512\ttotal: 15m 21s\tremaining: 10m 56s\n",
      "5840:\tlearn: 0.0520512\ttotal: 15m 21s\tremaining: 10m 56s\n",
      "5841:\tlearn: 0.0520512\ttotal: 15m 21s\tremaining: 10m 56s\n",
      "5842:\tlearn: 0.0520512\ttotal: 15m 21s\tremaining: 10m 55s\n",
      "5843:\tlearn: 0.0520512\ttotal: 15m 22s\tremaining: 10m 55s\n",
      "5844:\tlearn: 0.0520512\ttotal: 15m 22s\tremaining: 10m 55s\n",
      "5845:\tlearn: 0.0520512\ttotal: 15m 22s\tremaining: 10m 55s\n",
      "5846:\tlearn: 0.0520512\ttotal: 15m 22s\tremaining: 10m 55s\n",
      "5847:\tlearn: 0.0520512\ttotal: 15m 22s\tremaining: 10m 55s\n",
      "5848:\tlearn: 0.0520512\ttotal: 15m 22s\tremaining: 10m 54s\n",
      "5849:\tlearn: 0.0520512\ttotal: 15m 23s\tremaining: 10m 54s\n",
      "5850:\tlearn: 0.0520512\ttotal: 15m 23s\tremaining: 10m 54s\n",
      "5851:\tlearn: 0.0520512\ttotal: 15m 23s\tremaining: 10m 54s\n",
      "5852:\tlearn: 0.0520512\ttotal: 15m 23s\tremaining: 10m 54s\n",
      "5853:\tlearn: 0.0520512\ttotal: 15m 23s\tremaining: 10m 54s\n",
      "5854:\tlearn: 0.0520512\ttotal: 15m 23s\tremaining: 10m 54s\n",
      "5855:\tlearn: 0.0520512\ttotal: 15m 23s\tremaining: 10m 53s\n",
      "5856:\tlearn: 0.0520512\ttotal: 15m 24s\tremaining: 10m 53s\n",
      "5857:\tlearn: 0.0520512\ttotal: 15m 24s\tremaining: 10m 53s\n",
      "5858:\tlearn: 0.0520512\ttotal: 15m 24s\tremaining: 10m 53s\n",
      "5859:\tlearn: 0.0520512\ttotal: 15m 24s\tremaining: 10m 53s\n",
      "5860:\tlearn: 0.0520512\ttotal: 15m 24s\tremaining: 10m 53s\n",
      "5861:\tlearn: 0.0520512\ttotal: 15m 24s\tremaining: 10m 52s\n",
      "5862:\tlearn: 0.0520512\ttotal: 15m 25s\tremaining: 10m 52s\n",
      "5863:\tlearn: 0.0520512\ttotal: 15m 25s\tremaining: 10m 52s\n",
      "5864:\tlearn: 0.0520512\ttotal: 15m 25s\tremaining: 10m 52s\n",
      "5865:\tlearn: 0.0520512\ttotal: 15m 25s\tremaining: 10m 52s\n",
      "5866:\tlearn: 0.0520512\ttotal: 15m 25s\tremaining: 10m 52s\n",
      "5867:\tlearn: 0.0520512\ttotal: 15m 25s\tremaining: 10m 51s\n",
      "5868:\tlearn: 0.0520512\ttotal: 15m 25s\tremaining: 10m 51s\n",
      "5869:\tlearn: 0.0520512\ttotal: 15m 26s\tremaining: 10m 51s\n",
      "5870:\tlearn: 0.0520512\ttotal: 15m 26s\tremaining: 10m 51s\n",
      "5871:\tlearn: 0.0520512\ttotal: 15m 26s\tremaining: 10m 51s\n",
      "5872:\tlearn: 0.0520512\ttotal: 15m 26s\tremaining: 10m 51s\n",
      "5873:\tlearn: 0.0520512\ttotal: 15m 26s\tremaining: 10m 50s\n",
      "5874:\tlearn: 0.0520512\ttotal: 15m 26s\tremaining: 10m 50s\n",
      "5875:\tlearn: 0.0520512\ttotal: 15m 26s\tremaining: 10m 50s\n",
      "5876:\tlearn: 0.0520512\ttotal: 15m 27s\tremaining: 10m 50s\n",
      "5877:\tlearn: 0.0520512\ttotal: 15m 27s\tremaining: 10m 50s\n",
      "5878:\tlearn: 0.0520512\ttotal: 15m 27s\tremaining: 10m 50s\n",
      "5879:\tlearn: 0.0520512\ttotal: 15m 27s\tremaining: 10m 49s\n",
      "5880:\tlearn: 0.0520512\ttotal: 15m 27s\tremaining: 10m 49s\n",
      "5881:\tlearn: 0.0520512\ttotal: 15m 27s\tremaining: 10m 49s\n",
      "5882:\tlearn: 0.0520512\ttotal: 15m 28s\tremaining: 10m 49s\n",
      "5883:\tlearn: 0.0520512\ttotal: 15m 28s\tremaining: 10m 49s\n",
      "5884:\tlearn: 0.0520512\ttotal: 15m 28s\tremaining: 10m 49s\n",
      "5885:\tlearn: 0.0520512\ttotal: 15m 28s\tremaining: 10m 48s\n",
      "5886:\tlearn: 0.0520512\ttotal: 15m 28s\tremaining: 10m 48s\n",
      "5887:\tlearn: 0.0520512\ttotal: 15m 28s\tremaining: 10m 48s\n",
      "5888:\tlearn: 0.0520512\ttotal: 15m 28s\tremaining: 10m 48s\n",
      "5889:\tlearn: 0.0520512\ttotal: 15m 29s\tremaining: 10m 48s\n",
      "5890:\tlearn: 0.0520512\ttotal: 15m 29s\tremaining: 10m 48s\n",
      "5891:\tlearn: 0.0520512\ttotal: 15m 29s\tremaining: 10m 47s\n",
      "5892:\tlearn: 0.0520512\ttotal: 15m 29s\tremaining: 10m 47s\n",
      "5893:\tlearn: 0.0520512\ttotal: 15m 29s\tremaining: 10m 47s\n",
      "5894:\tlearn: 0.0520512\ttotal: 15m 29s\tremaining: 10m 47s\n",
      "5895:\tlearn: 0.0520512\ttotal: 15m 30s\tremaining: 10m 47s\n",
      "5896:\tlearn: 0.0520512\ttotal: 15m 30s\tremaining: 10m 47s\n",
      "5897:\tlearn: 0.0520512\ttotal: 15m 30s\tremaining: 10m 47s\n",
      "5898:\tlearn: 0.0520512\ttotal: 15m 30s\tremaining: 10m 46s\n",
      "5899:\tlearn: 0.0520512\ttotal: 15m 30s\tremaining: 10m 46s\n",
      "5900:\tlearn: 0.0520512\ttotal: 15m 30s\tremaining: 10m 46s\n",
      "5901:\tlearn: 0.0520512\ttotal: 15m 30s\tremaining: 10m 46s\n",
      "5902:\tlearn: 0.0520512\ttotal: 15m 31s\tremaining: 10m 46s\n",
      "5903:\tlearn: 0.0520512\ttotal: 15m 31s\tremaining: 10m 46s\n",
      "5904:\tlearn: 0.0520512\ttotal: 15m 31s\tremaining: 10m 45s\n",
      "5905:\tlearn: 0.0520512\ttotal: 15m 31s\tremaining: 10m 45s\n",
      "5906:\tlearn: 0.0520512\ttotal: 15m 31s\tremaining: 10m 45s\n",
      "5907:\tlearn: 0.0520512\ttotal: 15m 31s\tremaining: 10m 45s\n",
      "5908:\tlearn: 0.0520512\ttotal: 15m 31s\tremaining: 10m 45s\n",
      "5909:\tlearn: 0.0520512\ttotal: 15m 32s\tremaining: 10m 45s\n",
      "5910:\tlearn: 0.0520512\ttotal: 15m 32s\tremaining: 10m 44s\n",
      "5911:\tlearn: 0.0520512\ttotal: 15m 32s\tremaining: 10m 44s\n",
      "5912:\tlearn: 0.0520512\ttotal: 15m 32s\tremaining: 10m 44s\n",
      "5913:\tlearn: 0.0520512\ttotal: 15m 32s\tremaining: 10m 44s\n",
      "5914:\tlearn: 0.0520512\ttotal: 15m 32s\tremaining: 10m 44s\n",
      "5915:\tlearn: 0.0520512\ttotal: 15m 33s\tremaining: 10m 44s\n",
      "5916:\tlearn: 0.0520512\ttotal: 15m 33s\tremaining: 10m 43s\n",
      "5917:\tlearn: 0.0520512\ttotal: 15m 33s\tremaining: 10m 43s\n",
      "5918:\tlearn: 0.0520512\ttotal: 15m 33s\tremaining: 10m 43s\n",
      "5919:\tlearn: 0.0520512\ttotal: 15m 33s\tremaining: 10m 43s\n",
      "5920:\tlearn: 0.0520512\ttotal: 15m 33s\tremaining: 10m 43s\n",
      "5921:\tlearn: 0.0520512\ttotal: 15m 33s\tremaining: 10m 43s\n",
      "5922:\tlearn: 0.0520512\ttotal: 15m 34s\tremaining: 10m 42s\n",
      "5923:\tlearn: 0.0520512\ttotal: 15m 34s\tremaining: 10m 42s\n",
      "5924:\tlearn: 0.0520512\ttotal: 15m 34s\tremaining: 10m 42s\n",
      "5925:\tlearn: 0.0520512\ttotal: 15m 34s\tremaining: 10m 42s\n",
      "5926:\tlearn: 0.0520512\ttotal: 15m 34s\tremaining: 10m 42s\n",
      "5927:\tlearn: 0.0520512\ttotal: 15m 34s\tremaining: 10m 42s\n",
      "5928:\tlearn: 0.0520512\ttotal: 15m 34s\tremaining: 10m 41s\n",
      "5929:\tlearn: 0.0520512\ttotal: 15m 35s\tremaining: 10m 41s\n",
      "5930:\tlearn: 0.0520512\ttotal: 15m 35s\tremaining: 10m 41s\n",
      "5931:\tlearn: 0.0520512\ttotal: 15m 35s\tremaining: 10m 41s\n",
      "5932:\tlearn: 0.0520512\ttotal: 15m 35s\tremaining: 10m 41s\n",
      "5933:\tlearn: 0.0520512\ttotal: 15m 35s\tremaining: 10m 41s\n",
      "5934:\tlearn: 0.0520512\ttotal: 15m 35s\tremaining: 10m 41s\n",
      "5935:\tlearn: 0.0520512\ttotal: 15m 36s\tremaining: 10m 40s\n",
      "5936:\tlearn: 0.0520512\ttotal: 15m 36s\tremaining: 10m 40s\n",
      "5937:\tlearn: 0.0520512\ttotal: 15m 36s\tremaining: 10m 40s\n",
      "5938:\tlearn: 0.0520512\ttotal: 15m 36s\tremaining: 10m 40s\n",
      "5939:\tlearn: 0.0520512\ttotal: 15m 36s\tremaining: 10m 40s\n",
      "5940:\tlearn: 0.0520512\ttotal: 15m 36s\tremaining: 10m 40s\n",
      "5941:\tlearn: 0.0520512\ttotal: 15m 36s\tremaining: 10m 39s\n",
      "5942:\tlearn: 0.0520512\ttotal: 15m 37s\tremaining: 10m 39s\n",
      "5943:\tlearn: 0.0520512\ttotal: 15m 37s\tremaining: 10m 39s\n",
      "5944:\tlearn: 0.0520512\ttotal: 15m 37s\tremaining: 10m 39s\n",
      "5945:\tlearn: 0.0520512\ttotal: 15m 37s\tremaining: 10m 39s\n",
      "5946:\tlearn: 0.0520512\ttotal: 15m 37s\tremaining: 10m 39s\n",
      "5947:\tlearn: 0.0520512\ttotal: 15m 37s\tremaining: 10m 38s\n",
      "5948:\tlearn: 0.0520512\ttotal: 15m 38s\tremaining: 10m 38s\n",
      "5949:\tlearn: 0.0520512\ttotal: 15m 38s\tremaining: 10m 38s\n",
      "5950:\tlearn: 0.0520512\ttotal: 15m 38s\tremaining: 10m 38s\n",
      "5951:\tlearn: 0.0520512\ttotal: 15m 38s\tremaining: 10m 38s\n",
      "5952:\tlearn: 0.0520512\ttotal: 15m 38s\tremaining: 10m 38s\n",
      "5953:\tlearn: 0.0520512\ttotal: 15m 38s\tremaining: 10m 37s\n",
      "5954:\tlearn: 0.0520512\ttotal: 15m 38s\tremaining: 10m 37s\n",
      "5955:\tlearn: 0.0520512\ttotal: 15m 39s\tremaining: 10m 37s\n",
      "5956:\tlearn: 0.0520512\ttotal: 15m 39s\tremaining: 10m 37s\n",
      "5957:\tlearn: 0.0520512\ttotal: 15m 39s\tremaining: 10m 37s\n",
      "5958:\tlearn: 0.0520512\ttotal: 15m 39s\tremaining: 10m 37s\n",
      "5959:\tlearn: 0.0520512\ttotal: 15m 39s\tremaining: 10m 36s\n",
      "5960:\tlearn: 0.0520512\ttotal: 15m 39s\tremaining: 10m 36s\n",
      "5961:\tlearn: 0.0520512\ttotal: 15m 39s\tremaining: 10m 36s\n",
      "5962:\tlearn: 0.0520512\ttotal: 15m 40s\tremaining: 10m 36s\n",
      "5963:\tlearn: 0.0520512\ttotal: 15m 40s\tremaining: 10m 36s\n",
      "5964:\tlearn: 0.0520512\ttotal: 15m 40s\tremaining: 10m 36s\n",
      "5965:\tlearn: 0.0520512\ttotal: 15m 40s\tremaining: 10m 36s\n",
      "5966:\tlearn: 0.0520512\ttotal: 15m 40s\tremaining: 10m 35s\n",
      "5967:\tlearn: 0.0520512\ttotal: 15m 40s\tremaining: 10m 35s\n",
      "5968:\tlearn: 0.0520512\ttotal: 15m 41s\tremaining: 10m 35s\n",
      "5969:\tlearn: 0.0520512\ttotal: 15m 41s\tremaining: 10m 35s\n",
      "5970:\tlearn: 0.0520512\ttotal: 15m 41s\tremaining: 10m 35s\n",
      "5971:\tlearn: 0.0520512\ttotal: 15m 41s\tremaining: 10m 35s\n",
      "5972:\tlearn: 0.0520512\ttotal: 15m 41s\tremaining: 10m 34s\n",
      "5973:\tlearn: 0.0520512\ttotal: 15m 41s\tremaining: 10m 34s\n",
      "5974:\tlearn: 0.0520512\ttotal: 15m 41s\tremaining: 10m 34s\n",
      "5975:\tlearn: 0.0520512\ttotal: 15m 42s\tremaining: 10m 34s\n",
      "5976:\tlearn: 0.0520512\ttotal: 15m 42s\tremaining: 10m 34s\n",
      "5977:\tlearn: 0.0520512\ttotal: 15m 42s\tremaining: 10m 34s\n",
      "5978:\tlearn: 0.0520512\ttotal: 15m 42s\tremaining: 10m 33s\n",
      "5979:\tlearn: 0.0520512\ttotal: 15m 42s\tremaining: 10m 33s\n",
      "5980:\tlearn: 0.0520512\ttotal: 15m 42s\tremaining: 10m 33s\n",
      "5981:\tlearn: 0.0520512\ttotal: 15m 43s\tremaining: 10m 33s\n",
      "5982:\tlearn: 0.0520512\ttotal: 15m 43s\tremaining: 10m 33s\n",
      "5983:\tlearn: 0.0520512\ttotal: 15m 43s\tremaining: 10m 33s\n",
      "5984:\tlearn: 0.0520512\ttotal: 15m 43s\tremaining: 10m 32s\n",
      "5985:\tlearn: 0.0520512\ttotal: 15m 43s\tremaining: 10m 32s\n",
      "5986:\tlearn: 0.0520512\ttotal: 15m 43s\tremaining: 10m 32s\n",
      "5987:\tlearn: 0.0520512\ttotal: 15m 43s\tremaining: 10m 32s\n",
      "5988:\tlearn: 0.0520512\ttotal: 15m 44s\tremaining: 10m 32s\n",
      "5989:\tlearn: 0.0520512\ttotal: 15m 44s\tremaining: 10m 32s\n",
      "5990:\tlearn: 0.0520512\ttotal: 15m 44s\tremaining: 10m 31s\n",
      "5991:\tlearn: 0.0520512\ttotal: 15m 44s\tremaining: 10m 31s\n",
      "5992:\tlearn: 0.0520512\ttotal: 15m 44s\tremaining: 10m 31s\n",
      "5993:\tlearn: 0.0520512\ttotal: 15m 44s\tremaining: 10m 31s\n",
      "5994:\tlearn: 0.0520512\ttotal: 15m 44s\tremaining: 10m 31s\n",
      "5995:\tlearn: 0.0520512\ttotal: 15m 45s\tremaining: 10m 31s\n",
      "5996:\tlearn: 0.0520512\ttotal: 15m 45s\tremaining: 10m 30s\n",
      "5997:\tlearn: 0.0520512\ttotal: 15m 45s\tremaining: 10m 30s\n",
      "5998:\tlearn: 0.0520512\ttotal: 15m 45s\tremaining: 10m 30s\n",
      "5999:\tlearn: 0.0520512\ttotal: 15m 45s\tremaining: 10m 30s\n",
      "6000:\tlearn: 0.0520512\ttotal: 15m 45s\tremaining: 10m 30s\n",
      "6001:\tlearn: 0.0520512\ttotal: 15m 46s\tremaining: 10m 30s\n",
      "6002:\tlearn: 0.0520512\ttotal: 15m 46s\tremaining: 10m 30s\n",
      "6003:\tlearn: 0.0520512\ttotal: 15m 46s\tremaining: 10m 29s\n",
      "6004:\tlearn: 0.0520512\ttotal: 15m 46s\tremaining: 10m 29s\n",
      "6005:\tlearn: 0.0520512\ttotal: 15m 46s\tremaining: 10m 29s\n",
      "6006:\tlearn: 0.0520512\ttotal: 15m 46s\tremaining: 10m 29s\n",
      "6007:\tlearn: 0.0520512\ttotal: 15m 46s\tremaining: 10m 29s\n",
      "6008:\tlearn: 0.0520512\ttotal: 15m 47s\tremaining: 10m 29s\n",
      "6009:\tlearn: 0.0520512\ttotal: 15m 47s\tremaining: 10m 28s\n",
      "6010:\tlearn: 0.0520512\ttotal: 15m 47s\tremaining: 10m 28s\n",
      "6011:\tlearn: 0.0520512\ttotal: 15m 47s\tremaining: 10m 28s\n",
      "6012:\tlearn: 0.0520512\ttotal: 15m 47s\tremaining: 10m 28s\n",
      "6013:\tlearn: 0.0520512\ttotal: 15m 47s\tremaining: 10m 28s\n",
      "6014:\tlearn: 0.0520512\ttotal: 15m 47s\tremaining: 10m 28s\n",
      "6015:\tlearn: 0.0520512\ttotal: 15m 48s\tremaining: 10m 27s\n",
      "6016:\tlearn: 0.0520512\ttotal: 15m 48s\tremaining: 10m 27s\n",
      "6017:\tlearn: 0.0520512\ttotal: 15m 48s\tremaining: 10m 27s\n",
      "6018:\tlearn: 0.0520512\ttotal: 15m 48s\tremaining: 10m 27s\n",
      "6019:\tlearn: 0.0520512\ttotal: 15m 48s\tremaining: 10m 27s\n",
      "6020:\tlearn: 0.0520512\ttotal: 15m 48s\tremaining: 10m 27s\n",
      "6021:\tlearn: 0.0520512\ttotal: 15m 49s\tremaining: 10m 26s\n",
      "6022:\tlearn: 0.0520512\ttotal: 15m 49s\tremaining: 10m 26s\n",
      "6023:\tlearn: 0.0520512\ttotal: 15m 49s\tremaining: 10m 26s\n",
      "6024:\tlearn: 0.0520512\ttotal: 15m 49s\tremaining: 10m 26s\n",
      "6025:\tlearn: 0.0520512\ttotal: 15m 49s\tremaining: 10m 26s\n",
      "6026:\tlearn: 0.0520512\ttotal: 15m 49s\tremaining: 10m 26s\n",
      "6027:\tlearn: 0.0520512\ttotal: 15m 49s\tremaining: 10m 25s\n",
      "6028:\tlearn: 0.0520512\ttotal: 15m 50s\tremaining: 10m 25s\n",
      "6029:\tlearn: 0.0520512\ttotal: 15m 50s\tremaining: 10m 25s\n",
      "6030:\tlearn: 0.0520512\ttotal: 15m 50s\tremaining: 10m 25s\n",
      "6031:\tlearn: 0.0520512\ttotal: 15m 50s\tremaining: 10m 25s\n",
      "6032:\tlearn: 0.0520512\ttotal: 15m 50s\tremaining: 10m 25s\n",
      "6033:\tlearn: 0.0520512\ttotal: 15m 50s\tremaining: 10m 24s\n",
      "6034:\tlearn: 0.0520512\ttotal: 15m 51s\tremaining: 10m 24s\n",
      "6035:\tlearn: 0.0520512\ttotal: 15m 51s\tremaining: 10m 24s\n",
      "6036:\tlearn: 0.0520512\ttotal: 15m 51s\tremaining: 10m 24s\n",
      "6037:\tlearn: 0.0520512\ttotal: 15m 51s\tremaining: 10m 24s\n",
      "6038:\tlearn: 0.0520512\ttotal: 15m 51s\tremaining: 10m 24s\n",
      "6039:\tlearn: 0.0520512\ttotal: 15m 51s\tremaining: 10m 24s\n",
      "6040:\tlearn: 0.0520512\ttotal: 15m 51s\tremaining: 10m 23s\n",
      "6041:\tlearn: 0.0520512\ttotal: 15m 52s\tremaining: 10m 23s\n",
      "6042:\tlearn: 0.0520512\ttotal: 15m 52s\tremaining: 10m 23s\n",
      "6043:\tlearn: 0.0520512\ttotal: 15m 52s\tremaining: 10m 23s\n",
      "6044:\tlearn: 0.0520512\ttotal: 15m 52s\tremaining: 10m 23s\n",
      "6045:\tlearn: 0.0520512\ttotal: 15m 52s\tremaining: 10m 23s\n",
      "6046:\tlearn: 0.0520512\ttotal: 15m 52s\tremaining: 10m 22s\n",
      "6047:\tlearn: 0.0520512\ttotal: 15m 52s\tremaining: 10m 22s\n",
      "6048:\tlearn: 0.0520512\ttotal: 15m 53s\tremaining: 10m 22s\n",
      "6049:\tlearn: 0.0520512\ttotal: 15m 53s\tremaining: 10m 22s\n",
      "6050:\tlearn: 0.0520512\ttotal: 15m 53s\tremaining: 10m 22s\n",
      "6051:\tlearn: 0.0520512\ttotal: 15m 53s\tremaining: 10m 22s\n",
      "6052:\tlearn: 0.0520512\ttotal: 15m 53s\tremaining: 10m 21s\n",
      "6053:\tlearn: 0.0520512\ttotal: 15m 53s\tremaining: 10m 21s\n",
      "6054:\tlearn: 0.0520512\ttotal: 15m 54s\tremaining: 10m 21s\n",
      "6055:\tlearn: 0.0520512\ttotal: 15m 54s\tremaining: 10m 21s\n",
      "6056:\tlearn: 0.0520512\ttotal: 15m 54s\tremaining: 10m 21s\n",
      "6057:\tlearn: 0.0520512\ttotal: 15m 54s\tremaining: 10m 21s\n",
      "6058:\tlearn: 0.0520512\ttotal: 15m 54s\tremaining: 10m 20s\n",
      "6059:\tlearn: 0.0520512\ttotal: 15m 54s\tremaining: 10m 20s\n",
      "6060:\tlearn: 0.0520512\ttotal: 15m 54s\tremaining: 10m 20s\n",
      "6061:\tlearn: 0.0520512\ttotal: 15m 55s\tremaining: 10m 20s\n",
      "6062:\tlearn: 0.0520512\ttotal: 15m 55s\tremaining: 10m 20s\n",
      "6063:\tlearn: 0.0520512\ttotal: 15m 55s\tremaining: 10m 20s\n",
      "6064:\tlearn: 0.0520512\ttotal: 15m 55s\tremaining: 10m 19s\n",
      "6065:\tlearn: 0.0520512\ttotal: 15m 55s\tremaining: 10m 19s\n",
      "6066:\tlearn: 0.0520512\ttotal: 15m 55s\tremaining: 10m 19s\n",
      "6067:\tlearn: 0.0520512\ttotal: 15m 56s\tremaining: 10m 19s\n",
      "6068:\tlearn: 0.0520512\ttotal: 15m 56s\tremaining: 10m 19s\n",
      "6069:\tlearn: 0.0520512\ttotal: 15m 56s\tremaining: 10m 19s\n",
      "6070:\tlearn: 0.0520512\ttotal: 15m 56s\tremaining: 10m 19s\n",
      "6071:\tlearn: 0.0520512\ttotal: 15m 56s\tremaining: 10m 18s\n",
      "6072:\tlearn: 0.0520512\ttotal: 15m 56s\tremaining: 10m 18s\n",
      "6073:\tlearn: 0.0520512\ttotal: 15m 56s\tremaining: 10m 18s\n",
      "6074:\tlearn: 0.0520512\ttotal: 15m 57s\tremaining: 10m 18s\n",
      "6075:\tlearn: 0.0520512\ttotal: 15m 57s\tremaining: 10m 18s\n",
      "6076:\tlearn: 0.0520512\ttotal: 15m 57s\tremaining: 10m 18s\n",
      "6077:\tlearn: 0.0520512\ttotal: 15m 57s\tremaining: 10m 17s\n",
      "6078:\tlearn: 0.0520512\ttotal: 15m 57s\tremaining: 10m 17s\n",
      "6079:\tlearn: 0.0520512\ttotal: 15m 57s\tremaining: 10m 17s\n",
      "6080:\tlearn: 0.0520512\ttotal: 15m 57s\tremaining: 10m 17s\n",
      "6081:\tlearn: 0.0520512\ttotal: 15m 58s\tremaining: 10m 17s\n",
      "6082:\tlearn: 0.0520512\ttotal: 15m 58s\tremaining: 10m 17s\n",
      "6083:\tlearn: 0.0520512\ttotal: 15m 58s\tremaining: 10m 16s\n",
      "6084:\tlearn: 0.0520512\ttotal: 15m 58s\tremaining: 10m 16s\n",
      "6085:\tlearn: 0.0520512\ttotal: 15m 58s\tremaining: 10m 16s\n",
      "6086:\tlearn: 0.0520512\ttotal: 15m 58s\tremaining: 10m 16s\n",
      "6087:\tlearn: 0.0520512\ttotal: 15m 59s\tremaining: 10m 16s\n",
      "6088:\tlearn: 0.0520512\ttotal: 15m 59s\tremaining: 10m 16s\n",
      "6089:\tlearn: 0.0520512\ttotal: 15m 59s\tremaining: 10m 15s\n",
      "6090:\tlearn: 0.0520512\ttotal: 15m 59s\tremaining: 10m 15s\n",
      "6091:\tlearn: 0.0520512\ttotal: 15m 59s\tremaining: 10m 15s\n",
      "6092:\tlearn: 0.0520512\ttotal: 15m 59s\tremaining: 10m 15s\n",
      "6093:\tlearn: 0.0520512\ttotal: 15m 59s\tremaining: 10m 15s\n",
      "6094:\tlearn: 0.0520512\ttotal: 16m\tremaining: 10m 15s\n",
      "6095:\tlearn: 0.0520512\ttotal: 16m\tremaining: 10m 14s\n",
      "6096:\tlearn: 0.0520512\ttotal: 16m\tremaining: 10m 14s\n",
      "6097:\tlearn: 0.0520512\ttotal: 16m\tremaining: 10m 14s\n",
      "6098:\tlearn: 0.0520512\ttotal: 16m\tremaining: 10m 14s\n",
      "6099:\tlearn: 0.0520512\ttotal: 16m\tremaining: 10m 14s\n",
      "6100:\tlearn: 0.0520512\ttotal: 16m 1s\tremaining: 10m 14s\n",
      "6101:\tlearn: 0.0520512\ttotal: 16m 1s\tremaining: 10m 14s\n",
      "6102:\tlearn: 0.0520512\ttotal: 16m 1s\tremaining: 10m 13s\n",
      "6103:\tlearn: 0.0520512\ttotal: 16m 1s\tremaining: 10m 13s\n",
      "6104:\tlearn: 0.0520512\ttotal: 16m 1s\tremaining: 10m 13s\n",
      "6105:\tlearn: 0.0520512\ttotal: 16m 1s\tremaining: 10m 13s\n",
      "6106:\tlearn: 0.0520512\ttotal: 16m 1s\tremaining: 10m 13s\n",
      "6107:\tlearn: 0.0520512\ttotal: 16m 2s\tremaining: 10m 13s\n",
      "6108:\tlearn: 0.0520512\ttotal: 16m 2s\tremaining: 10m 12s\n",
      "6109:\tlearn: 0.0520512\ttotal: 16m 2s\tremaining: 10m 12s\n",
      "6110:\tlearn: 0.0520512\ttotal: 16m 2s\tremaining: 10m 12s\n",
      "6111:\tlearn: 0.0520512\ttotal: 16m 2s\tremaining: 10m 12s\n",
      "6112:\tlearn: 0.0520512\ttotal: 16m 2s\tremaining: 10m 12s\n",
      "6113:\tlearn: 0.0520512\ttotal: 16m 3s\tremaining: 10m 12s\n",
      "6114:\tlearn: 0.0520512\ttotal: 16m 3s\tremaining: 10m 11s\n",
      "6115:\tlearn: 0.0520512\ttotal: 16m 3s\tremaining: 10m 11s\n",
      "6116:\tlearn: 0.0520512\ttotal: 16m 3s\tremaining: 10m 11s\n",
      "6117:\tlearn: 0.0520512\ttotal: 16m 3s\tremaining: 10m 11s\n",
      "6118:\tlearn: 0.0520512\ttotal: 16m 3s\tremaining: 10m 11s\n",
      "6119:\tlearn: 0.0520512\ttotal: 16m 3s\tremaining: 10m 11s\n",
      "6120:\tlearn: 0.0520512\ttotal: 16m 4s\tremaining: 10m 10s\n",
      "6121:\tlearn: 0.0520512\ttotal: 16m 4s\tremaining: 10m 10s\n",
      "6122:\tlearn: 0.0520512\ttotal: 16m 4s\tremaining: 10m 10s\n",
      "6123:\tlearn: 0.0520512\ttotal: 16m 4s\tremaining: 10m 10s\n",
      "6124:\tlearn: 0.0520512\ttotal: 16m 4s\tremaining: 10m 10s\n",
      "6125:\tlearn: 0.0520512\ttotal: 16m 4s\tremaining: 10m 10s\n",
      "6126:\tlearn: 0.0520512\ttotal: 16m 4s\tremaining: 10m 9s\n",
      "6127:\tlearn: 0.0520512\ttotal: 16m 5s\tremaining: 10m 9s\n",
      "6128:\tlearn: 0.0520512\ttotal: 16m 5s\tremaining: 10m 9s\n",
      "6129:\tlearn: 0.0520512\ttotal: 16m 5s\tremaining: 10m 9s\n",
      "6130:\tlearn: 0.0520512\ttotal: 16m 5s\tremaining: 10m 9s\n",
      "6131:\tlearn: 0.0520512\ttotal: 16m 5s\tremaining: 10m 9s\n",
      "6132:\tlearn: 0.0520512\ttotal: 16m 5s\tremaining: 10m 9s\n",
      "6133:\tlearn: 0.0520512\ttotal: 16m 6s\tremaining: 10m 8s\n",
      "6134:\tlearn: 0.0520512\ttotal: 16m 6s\tremaining: 10m 8s\n",
      "6135:\tlearn: 0.0520512\ttotal: 16m 6s\tremaining: 10m 8s\n",
      "6136:\tlearn: 0.0520512\ttotal: 16m 6s\tremaining: 10m 8s\n",
      "6137:\tlearn: 0.0520512\ttotal: 16m 6s\tremaining: 10m 8s\n",
      "6138:\tlearn: 0.0520512\ttotal: 16m 6s\tremaining: 10m 8s\n",
      "6139:\tlearn: 0.0520512\ttotal: 16m 6s\tremaining: 10m 7s\n",
      "6140:\tlearn: 0.0520512\ttotal: 16m 7s\tremaining: 10m 7s\n",
      "6141:\tlearn: 0.0520512\ttotal: 16m 7s\tremaining: 10m 7s\n",
      "6142:\tlearn: 0.0520512\ttotal: 16m 7s\tremaining: 10m 7s\n",
      "6143:\tlearn: 0.0520512\ttotal: 16m 7s\tremaining: 10m 7s\n",
      "6144:\tlearn: 0.0520512\ttotal: 16m 7s\tremaining: 10m 7s\n",
      "6145:\tlearn: 0.0520512\ttotal: 16m 7s\tremaining: 10m 6s\n",
      "6146:\tlearn: 0.0520512\ttotal: 16m 7s\tremaining: 10m 6s\n",
      "6147:\tlearn: 0.0520512\ttotal: 16m 8s\tremaining: 10m 6s\n",
      "6148:\tlearn: 0.0520512\ttotal: 16m 8s\tremaining: 10m 6s\n",
      "6149:\tlearn: 0.0520512\ttotal: 16m 8s\tremaining: 10m 6s\n",
      "6150:\tlearn: 0.0520512\ttotal: 16m 8s\tremaining: 10m 6s\n",
      "6151:\tlearn: 0.0520512\ttotal: 16m 8s\tremaining: 10m 5s\n",
      "6152:\tlearn: 0.0520512\ttotal: 16m 8s\tremaining: 10m 5s\n",
      "6153:\tlearn: 0.0520512\ttotal: 16m 9s\tremaining: 10m 5s\n",
      "6154:\tlearn: 0.0520512\ttotal: 16m 9s\tremaining: 10m 5s\n",
      "6155:\tlearn: 0.0520512\ttotal: 16m 9s\tremaining: 10m 5s\n",
      "6156:\tlearn: 0.0520512\ttotal: 16m 9s\tremaining: 10m 5s\n",
      "6157:\tlearn: 0.0520512\ttotal: 16m 9s\tremaining: 10m 4s\n",
      "6158:\tlearn: 0.0520512\ttotal: 16m 9s\tremaining: 10m 4s\n",
      "6159:\tlearn: 0.0520512\ttotal: 16m 9s\tremaining: 10m 4s\n",
      "6160:\tlearn: 0.0520512\ttotal: 16m 10s\tremaining: 10m 4s\n",
      "6161:\tlearn: 0.0520512\ttotal: 16m 10s\tremaining: 10m 4s\n",
      "6162:\tlearn: 0.0520512\ttotal: 16m 10s\tremaining: 10m 4s\n",
      "6163:\tlearn: 0.0520512\ttotal: 16m 10s\tremaining: 10m 3s\n",
      "6164:\tlearn: 0.0520512\ttotal: 16m 10s\tremaining: 10m 3s\n",
      "6165:\tlearn: 0.0520512\ttotal: 16m 10s\tremaining: 10m 3s\n",
      "6166:\tlearn: 0.0520512\ttotal: 16m 11s\tremaining: 10m 3s\n",
      "6167:\tlearn: 0.0520512\ttotal: 16m 11s\tremaining: 10m 3s\n",
      "6168:\tlearn: 0.0520512\ttotal: 16m 11s\tremaining: 10m 3s\n",
      "6169:\tlearn: 0.0520512\ttotal: 16m 11s\tremaining: 10m 3s\n",
      "6170:\tlearn: 0.0520512\ttotal: 16m 11s\tremaining: 10m 2s\n",
      "6171:\tlearn: 0.0520512\ttotal: 16m 11s\tremaining: 10m 2s\n",
      "6172:\tlearn: 0.0520512\ttotal: 16m 11s\tremaining: 10m 2s\n",
      "6173:\tlearn: 0.0520512\ttotal: 16m 12s\tremaining: 10m 2s\n",
      "6174:\tlearn: 0.0520512\ttotal: 16m 12s\tremaining: 10m 2s\n",
      "6175:\tlearn: 0.0520512\ttotal: 16m 12s\tremaining: 10m 2s\n",
      "6176:\tlearn: 0.0520512\ttotal: 16m 12s\tremaining: 10m 1s\n",
      "6177:\tlearn: 0.0520512\ttotal: 16m 12s\tremaining: 10m 1s\n",
      "6178:\tlearn: 0.0520512\ttotal: 16m 12s\tremaining: 10m 1s\n",
      "6179:\tlearn: 0.0520512\ttotal: 16m 12s\tremaining: 10m 1s\n",
      "6180:\tlearn: 0.0520512\ttotal: 16m 13s\tremaining: 10m 1s\n",
      "6181:\tlearn: 0.0520512\ttotal: 16m 13s\tremaining: 10m 1s\n",
      "6182:\tlearn: 0.0520512\ttotal: 16m 13s\tremaining: 10m\n",
      "6183:\tlearn: 0.0520512\ttotal: 16m 13s\tremaining: 10m\n",
      "6184:\tlearn: 0.0520512\ttotal: 16m 13s\tremaining: 10m\n",
      "6185:\tlearn: 0.0520512\ttotal: 16m 13s\tremaining: 10m\n",
      "6186:\tlearn: 0.0520512\ttotal: 16m 14s\tremaining: 10m\n",
      "6187:\tlearn: 0.0520512\ttotal: 16m 14s\tremaining: 10m\n",
      "6188:\tlearn: 0.0520512\ttotal: 16m 14s\tremaining: 9m 59s\n",
      "6189:\tlearn: 0.0520512\ttotal: 16m 14s\tremaining: 9m 59s\n",
      "6190:\tlearn: 0.0520512\ttotal: 16m 14s\tremaining: 9m 59s\n",
      "6191:\tlearn: 0.0520512\ttotal: 16m 14s\tremaining: 9m 59s\n",
      "6192:\tlearn: 0.0520512\ttotal: 16m 14s\tremaining: 9m 59s\n",
      "6193:\tlearn: 0.0520512\ttotal: 16m 15s\tremaining: 9m 59s\n",
      "6194:\tlearn: 0.0520512\ttotal: 16m 15s\tremaining: 9m 59s\n",
      "6195:\tlearn: 0.0520512\ttotal: 16m 15s\tremaining: 9m 58s\n",
      "6196:\tlearn: 0.0520512\ttotal: 16m 15s\tremaining: 9m 58s\n",
      "6197:\tlearn: 0.0520512\ttotal: 16m 15s\tremaining: 9m 58s\n",
      "6198:\tlearn: 0.0520512\ttotal: 16m 15s\tremaining: 9m 58s\n",
      "6199:\tlearn: 0.0520512\ttotal: 16m 16s\tremaining: 9m 58s\n",
      "6200:\tlearn: 0.0520512\ttotal: 16m 16s\tremaining: 9m 58s\n",
      "6201:\tlearn: 0.0520512\ttotal: 16m 16s\tremaining: 9m 57s\n",
      "6202:\tlearn: 0.0520512\ttotal: 16m 16s\tremaining: 9m 57s\n",
      "6203:\tlearn: 0.0520512\ttotal: 16m 16s\tremaining: 9m 57s\n",
      "6204:\tlearn: 0.0520512\ttotal: 16m 16s\tremaining: 9m 57s\n",
      "6205:\tlearn: 0.0520512\ttotal: 16m 16s\tremaining: 9m 57s\n",
      "6206:\tlearn: 0.0520512\ttotal: 16m 17s\tremaining: 9m 57s\n",
      "6207:\tlearn: 0.0520512\ttotal: 16m 17s\tremaining: 9m 56s\n",
      "6208:\tlearn: 0.0520512\ttotal: 16m 17s\tremaining: 9m 56s\n",
      "6209:\tlearn: 0.0520512\ttotal: 16m 17s\tremaining: 9m 56s\n",
      "6210:\tlearn: 0.0520512\ttotal: 16m 17s\tremaining: 9m 56s\n",
      "6211:\tlearn: 0.0520512\ttotal: 16m 17s\tremaining: 9m 56s\n",
      "6212:\tlearn: 0.0520512\ttotal: 16m 17s\tremaining: 9m 56s\n",
      "6213:\tlearn: 0.0520512\ttotal: 16m 18s\tremaining: 9m 55s\n",
      "6214:\tlearn: 0.0520512\ttotal: 16m 18s\tremaining: 9m 55s\n",
      "6215:\tlearn: 0.0520512\ttotal: 16m 18s\tremaining: 9m 55s\n",
      "6216:\tlearn: 0.0520512\ttotal: 16m 18s\tremaining: 9m 55s\n",
      "6217:\tlearn: 0.0520512\ttotal: 16m 18s\tremaining: 9m 55s\n",
      "6218:\tlearn: 0.0520512\ttotal: 16m 18s\tremaining: 9m 55s\n",
      "6219:\tlearn: 0.0520512\ttotal: 16m 19s\tremaining: 9m 54s\n",
      "6220:\tlearn: 0.0520512\ttotal: 16m 19s\tremaining: 9m 54s\n",
      "6221:\tlearn: 0.0520512\ttotal: 16m 19s\tremaining: 9m 54s\n",
      "6222:\tlearn: 0.0520512\ttotal: 16m 19s\tremaining: 9m 54s\n",
      "6223:\tlearn: 0.0520512\ttotal: 16m 19s\tremaining: 9m 54s\n",
      "6224:\tlearn: 0.0520512\ttotal: 16m 19s\tremaining: 9m 54s\n",
      "6225:\tlearn: 0.0520512\ttotal: 16m 19s\tremaining: 9m 54s\n",
      "6226:\tlearn: 0.0520512\ttotal: 16m 20s\tremaining: 9m 53s\n",
      "6227:\tlearn: 0.0520512\ttotal: 16m 20s\tremaining: 9m 53s\n",
      "6228:\tlearn: 0.0520512\ttotal: 16m 20s\tremaining: 9m 53s\n",
      "6229:\tlearn: 0.0520512\ttotal: 16m 20s\tremaining: 9m 53s\n",
      "6230:\tlearn: 0.0520512\ttotal: 16m 20s\tremaining: 9m 53s\n",
      "6231:\tlearn: 0.0520512\ttotal: 16m 20s\tremaining: 9m 53s\n",
      "6232:\tlearn: 0.0520512\ttotal: 16m 21s\tremaining: 9m 52s\n",
      "6233:\tlearn: 0.0520512\ttotal: 16m 21s\tremaining: 9m 52s\n",
      "6234:\tlearn: 0.0520512\ttotal: 16m 21s\tremaining: 9m 52s\n",
      "6235:\tlearn: 0.0520512\ttotal: 16m 21s\tremaining: 9m 52s\n",
      "6236:\tlearn: 0.0520512\ttotal: 16m 21s\tremaining: 9m 52s\n",
      "6237:\tlearn: 0.0520512\ttotal: 16m 21s\tremaining: 9m 52s\n",
      "6238:\tlearn: 0.0520512\ttotal: 16m 21s\tremaining: 9m 51s\n",
      "6239:\tlearn: 0.0520512\ttotal: 16m 22s\tremaining: 9m 51s\n",
      "6240:\tlearn: 0.0520512\ttotal: 16m 22s\tremaining: 9m 51s\n",
      "6241:\tlearn: 0.0520512\ttotal: 16m 22s\tremaining: 9m 51s\n",
      "6242:\tlearn: 0.0520512\ttotal: 16m 22s\tremaining: 9m 51s\n",
      "6243:\tlearn: 0.0520512\ttotal: 16m 22s\tremaining: 9m 51s\n",
      "6244:\tlearn: 0.0520512\ttotal: 16m 22s\tremaining: 9m 50s\n",
      "6245:\tlearn: 0.0520512\ttotal: 16m 23s\tremaining: 9m 50s\n",
      "6246:\tlearn: 0.0520512\ttotal: 16m 23s\tremaining: 9m 50s\n",
      "6247:\tlearn: 0.0520512\ttotal: 16m 23s\tremaining: 9m 50s\n",
      "6248:\tlearn: 0.0520512\ttotal: 16m 23s\tremaining: 9m 50s\n",
      "6249:\tlearn: 0.0520512\ttotal: 16m 23s\tremaining: 9m 50s\n",
      "6250:\tlearn: 0.0520512\ttotal: 16m 23s\tremaining: 9m 50s\n",
      "6251:\tlearn: 0.0520512\ttotal: 16m 23s\tremaining: 9m 49s\n",
      "6252:\tlearn: 0.0520512\ttotal: 16m 24s\tremaining: 9m 49s\n",
      "6253:\tlearn: 0.0520512\ttotal: 16m 24s\tremaining: 9m 49s\n",
      "6254:\tlearn: 0.0520512\ttotal: 16m 24s\tremaining: 9m 49s\n",
      "6255:\tlearn: 0.0520512\ttotal: 16m 24s\tremaining: 9m 49s\n",
      "6256:\tlearn: 0.0520512\ttotal: 16m 24s\tremaining: 9m 49s\n",
      "6257:\tlearn: 0.0520512\ttotal: 16m 24s\tremaining: 9m 48s\n",
      "6258:\tlearn: 0.0520512\ttotal: 16m 24s\tremaining: 9m 48s\n",
      "6259:\tlearn: 0.0520512\ttotal: 16m 25s\tremaining: 9m 48s\n",
      "6260:\tlearn: 0.0520512\ttotal: 16m 25s\tremaining: 9m 48s\n",
      "6261:\tlearn: 0.0520512\ttotal: 16m 25s\tremaining: 9m 48s\n",
      "6262:\tlearn: 0.0520512\ttotal: 16m 25s\tremaining: 9m 48s\n",
      "6263:\tlearn: 0.0520512\ttotal: 16m 25s\tremaining: 9m 47s\n",
      "6264:\tlearn: 0.0520512\ttotal: 16m 25s\tremaining: 9m 47s\n",
      "6265:\tlearn: 0.0520512\ttotal: 16m 26s\tremaining: 9m 47s\n",
      "6266:\tlearn: 0.0520512\ttotal: 16m 26s\tremaining: 9m 47s\n",
      "6267:\tlearn: 0.0520512\ttotal: 16m 26s\tremaining: 9m 47s\n",
      "6268:\tlearn: 0.0520512\ttotal: 16m 26s\tremaining: 9m 47s\n",
      "6269:\tlearn: 0.0520512\ttotal: 16m 26s\tremaining: 9m 46s\n",
      "6270:\tlearn: 0.0520512\ttotal: 16m 26s\tremaining: 9m 46s\n",
      "6271:\tlearn: 0.0520512\ttotal: 16m 26s\tremaining: 9m 46s\n",
      "6272:\tlearn: 0.0520512\ttotal: 16m 27s\tremaining: 9m 46s\n",
      "6273:\tlearn: 0.0520512\ttotal: 16m 27s\tremaining: 9m 46s\n",
      "6274:\tlearn: 0.0520512\ttotal: 16m 27s\tremaining: 9m 46s\n",
      "6275:\tlearn: 0.0520512\ttotal: 16m 27s\tremaining: 9m 45s\n",
      "6276:\tlearn: 0.0520512\ttotal: 16m 27s\tremaining: 9m 45s\n",
      "6277:\tlearn: 0.0520512\ttotal: 16m 27s\tremaining: 9m 45s\n",
      "6278:\tlearn: 0.0520512\ttotal: 16m 28s\tremaining: 9m 45s\n",
      "6279:\tlearn: 0.0520512\ttotal: 16m 28s\tremaining: 9m 45s\n",
      "6280:\tlearn: 0.0520512\ttotal: 16m 28s\tremaining: 9m 45s\n",
      "6281:\tlearn: 0.0520512\ttotal: 16m 28s\tremaining: 9m 45s\n",
      "6282:\tlearn: 0.0520512\ttotal: 16m 28s\tremaining: 9m 44s\n",
      "6283:\tlearn: 0.0520512\ttotal: 16m 28s\tremaining: 9m 44s\n",
      "6284:\tlearn: 0.0520512\ttotal: 16m 28s\tremaining: 9m 44s\n",
      "6285:\tlearn: 0.0520512\ttotal: 16m 29s\tremaining: 9m 44s\n",
      "6286:\tlearn: 0.0520512\ttotal: 16m 29s\tremaining: 9m 44s\n",
      "6287:\tlearn: 0.0520512\ttotal: 16m 29s\tremaining: 9m 44s\n",
      "6288:\tlearn: 0.0520512\ttotal: 16m 29s\tremaining: 9m 43s\n",
      "6289:\tlearn: 0.0520512\ttotal: 16m 29s\tremaining: 9m 43s\n",
      "6290:\tlearn: 0.0520512\ttotal: 16m 29s\tremaining: 9m 43s\n",
      "6291:\tlearn: 0.0520512\ttotal: 16m 29s\tremaining: 9m 43s\n",
      "6292:\tlearn: 0.0520512\ttotal: 16m 30s\tremaining: 9m 43s\n",
      "6293:\tlearn: 0.0520512\ttotal: 16m 30s\tremaining: 9m 43s\n",
      "6294:\tlearn: 0.0520512\ttotal: 16m 30s\tremaining: 9m 42s\n",
      "6295:\tlearn: 0.0520512\ttotal: 16m 30s\tremaining: 9m 42s\n",
      "6296:\tlearn: 0.0520512\ttotal: 16m 30s\tremaining: 9m 42s\n",
      "6297:\tlearn: 0.0520512\ttotal: 16m 30s\tremaining: 9m 42s\n",
      "6298:\tlearn: 0.0520512\ttotal: 16m 31s\tremaining: 9m 42s\n",
      "6299:\tlearn: 0.0520512\ttotal: 16m 31s\tremaining: 9m 42s\n",
      "6300:\tlearn: 0.0520512\ttotal: 16m 31s\tremaining: 9m 41s\n",
      "6301:\tlearn: 0.0520512\ttotal: 16m 31s\tremaining: 9m 41s\n",
      "6302:\tlearn: 0.0520512\ttotal: 16m 31s\tremaining: 9m 41s\n",
      "6303:\tlearn: 0.0520512\ttotal: 16m 31s\tremaining: 9m 41s\n",
      "6304:\tlearn: 0.0520512\ttotal: 16m 31s\tremaining: 9m 41s\n",
      "6305:\tlearn: 0.0520512\ttotal: 16m 32s\tremaining: 9m 41s\n",
      "6306:\tlearn: 0.0520512\ttotal: 16m 32s\tremaining: 9m 40s\n",
      "6307:\tlearn: 0.0520512\ttotal: 16m 32s\tremaining: 9m 40s\n",
      "6308:\tlearn: 0.0520512\ttotal: 16m 32s\tremaining: 9m 40s\n",
      "6309:\tlearn: 0.0520512\ttotal: 16m 32s\tremaining: 9m 40s\n",
      "6310:\tlearn: 0.0520512\ttotal: 16m 32s\tremaining: 9m 40s\n",
      "6311:\tlearn: 0.0520512\ttotal: 16m 32s\tremaining: 9m 40s\n",
      "6312:\tlearn: 0.0520512\ttotal: 16m 33s\tremaining: 9m 40s\n",
      "6313:\tlearn: 0.0520512\ttotal: 16m 33s\tremaining: 9m 39s\n",
      "6314:\tlearn: 0.0520512\ttotal: 16m 33s\tremaining: 9m 39s\n",
      "6315:\tlearn: 0.0520512\ttotal: 16m 33s\tremaining: 9m 39s\n",
      "6316:\tlearn: 0.0520512\ttotal: 16m 33s\tremaining: 9m 39s\n",
      "6317:\tlearn: 0.0520512\ttotal: 16m 33s\tremaining: 9m 39s\n",
      "6318:\tlearn: 0.0520512\ttotal: 16m 34s\tremaining: 9m 39s\n",
      "6319:\tlearn: 0.0520512\ttotal: 16m 34s\tremaining: 9m 38s\n",
      "6320:\tlearn: 0.0520512\ttotal: 16m 34s\tremaining: 9m 38s\n",
      "6321:\tlearn: 0.0520512\ttotal: 16m 34s\tremaining: 9m 38s\n",
      "6322:\tlearn: 0.0520512\ttotal: 16m 34s\tremaining: 9m 38s\n",
      "6323:\tlearn: 0.0520512\ttotal: 16m 34s\tremaining: 9m 38s\n",
      "6324:\tlearn: 0.0520512\ttotal: 16m 34s\tremaining: 9m 38s\n",
      "6325:\tlearn: 0.0520512\ttotal: 16m 35s\tremaining: 9m 37s\n",
      "6326:\tlearn: 0.0520512\ttotal: 16m 35s\tremaining: 9m 37s\n",
      "6327:\tlearn: 0.0520512\ttotal: 16m 35s\tremaining: 9m 37s\n",
      "6328:\tlearn: 0.0520512\ttotal: 16m 35s\tremaining: 9m 37s\n",
      "6329:\tlearn: 0.0520512\ttotal: 16m 35s\tremaining: 9m 37s\n",
      "6330:\tlearn: 0.0520512\ttotal: 16m 35s\tremaining: 9m 37s\n",
      "6331:\tlearn: 0.0520512\ttotal: 16m 36s\tremaining: 9m 36s\n",
      "6332:\tlearn: 0.0520512\ttotal: 16m 36s\tremaining: 9m 36s\n",
      "6333:\tlearn: 0.0520512\ttotal: 16m 36s\tremaining: 9m 36s\n",
      "6334:\tlearn: 0.0520512\ttotal: 16m 36s\tremaining: 9m 36s\n",
      "6335:\tlearn: 0.0520512\ttotal: 16m 36s\tremaining: 9m 36s\n",
      "6336:\tlearn: 0.0520512\ttotal: 16m 36s\tremaining: 9m 36s\n",
      "6337:\tlearn: 0.0520512\ttotal: 16m 36s\tremaining: 9m 36s\n",
      "6338:\tlearn: 0.0520512\ttotal: 16m 37s\tremaining: 9m 35s\n",
      "6339:\tlearn: 0.0520512\ttotal: 16m 37s\tremaining: 9m 35s\n",
      "6340:\tlearn: 0.0520512\ttotal: 16m 37s\tremaining: 9m 35s\n",
      "6341:\tlearn: 0.0520512\ttotal: 16m 37s\tremaining: 9m 35s\n",
      "6342:\tlearn: 0.0520512\ttotal: 16m 37s\tremaining: 9m 35s\n",
      "6343:\tlearn: 0.0520512\ttotal: 16m 37s\tremaining: 9m 35s\n",
      "6344:\tlearn: 0.0520512\ttotal: 16m 38s\tremaining: 9m 34s\n",
      "6345:\tlearn: 0.0520512\ttotal: 16m 38s\tremaining: 9m 34s\n",
      "6346:\tlearn: 0.0520512\ttotal: 16m 38s\tremaining: 9m 34s\n",
      "6347:\tlearn: 0.0520512\ttotal: 16m 38s\tremaining: 9m 34s\n",
      "6348:\tlearn: 0.0520512\ttotal: 16m 38s\tremaining: 9m 34s\n",
      "6349:\tlearn: 0.0520512\ttotal: 16m 38s\tremaining: 9m 34s\n",
      "6350:\tlearn: 0.0520512\ttotal: 16m 38s\tremaining: 9m 33s\n",
      "6351:\tlearn: 0.0520512\ttotal: 16m 39s\tremaining: 9m 33s\n",
      "6352:\tlearn: 0.0520512\ttotal: 16m 39s\tremaining: 9m 33s\n",
      "6353:\tlearn: 0.0520512\ttotal: 16m 39s\tremaining: 9m 33s\n",
      "6354:\tlearn: 0.0520512\ttotal: 16m 39s\tremaining: 9m 33s\n",
      "6355:\tlearn: 0.0520512\ttotal: 16m 39s\tremaining: 9m 33s\n",
      "6356:\tlearn: 0.0520512\ttotal: 16m 39s\tremaining: 9m 32s\n",
      "6357:\tlearn: 0.0520512\ttotal: 16m 39s\tremaining: 9m 32s\n",
      "6358:\tlearn: 0.0520512\ttotal: 16m 40s\tremaining: 9m 32s\n",
      "6359:\tlearn: 0.0520512\ttotal: 16m 40s\tremaining: 9m 32s\n",
      "6360:\tlearn: 0.0520512\ttotal: 16m 40s\tremaining: 9m 32s\n",
      "6361:\tlearn: 0.0520512\ttotal: 16m 40s\tremaining: 9m 32s\n",
      "6362:\tlearn: 0.0520512\ttotal: 16m 40s\tremaining: 9m 32s\n",
      "6363:\tlearn: 0.0520512\ttotal: 16m 40s\tremaining: 9m 31s\n",
      "6364:\tlearn: 0.0520512\ttotal: 16m 41s\tremaining: 9m 31s\n",
      "6365:\tlearn: 0.0520512\ttotal: 16m 41s\tremaining: 9m 31s\n",
      "6366:\tlearn: 0.0520512\ttotal: 16m 41s\tremaining: 9m 31s\n",
      "6367:\tlearn: 0.0520512\ttotal: 16m 41s\tremaining: 9m 31s\n",
      "6368:\tlearn: 0.0520512\ttotal: 16m 41s\tremaining: 9m 31s\n",
      "6369:\tlearn: 0.0520512\ttotal: 16m 41s\tremaining: 9m 30s\n",
      "6370:\tlearn: 0.0520512\ttotal: 16m 42s\tremaining: 9m 30s\n",
      "6371:\tlearn: 0.0520512\ttotal: 16m 42s\tremaining: 9m 30s\n",
      "6372:\tlearn: 0.0520512\ttotal: 16m 42s\tremaining: 9m 30s\n",
      "6373:\tlearn: 0.0520512\ttotal: 16m 42s\tremaining: 9m 30s\n",
      "6374:\tlearn: 0.0520512\ttotal: 16m 42s\tremaining: 9m 30s\n",
      "6375:\tlearn: 0.0520512\ttotal: 16m 42s\tremaining: 9m 29s\n",
      "6376:\tlearn: 0.0520512\ttotal: 16m 42s\tremaining: 9m 29s\n",
      "6377:\tlearn: 0.0520512\ttotal: 16m 43s\tremaining: 9m 29s\n",
      "6378:\tlearn: 0.0520512\ttotal: 16m 43s\tremaining: 9m 29s\n",
      "6379:\tlearn: 0.0520512\ttotal: 16m 43s\tremaining: 9m 29s\n",
      "6380:\tlearn: 0.0520512\ttotal: 16m 43s\tremaining: 9m 29s\n",
      "6381:\tlearn: 0.0520512\ttotal: 16m 43s\tremaining: 9m 28s\n",
      "6382:\tlearn: 0.0520512\ttotal: 16m 43s\tremaining: 9m 28s\n",
      "6383:\tlearn: 0.0520512\ttotal: 16m 43s\tremaining: 9m 28s\n",
      "6384:\tlearn: 0.0520512\ttotal: 16m 44s\tremaining: 9m 28s\n",
      "6385:\tlearn: 0.0520512\ttotal: 16m 44s\tremaining: 9m 28s\n",
      "6386:\tlearn: 0.0520512\ttotal: 16m 44s\tremaining: 9m 28s\n",
      "6387:\tlearn: 0.0520512\ttotal: 16m 44s\tremaining: 9m 28s\n",
      "6388:\tlearn: 0.0520512\ttotal: 16m 44s\tremaining: 9m 27s\n",
      "6389:\tlearn: 0.0520512\ttotal: 16m 44s\tremaining: 9m 27s\n",
      "6390:\tlearn: 0.0520512\ttotal: 16m 45s\tremaining: 9m 27s\n",
      "6391:\tlearn: 0.0520512\ttotal: 16m 45s\tremaining: 9m 27s\n",
      "6392:\tlearn: 0.0520512\ttotal: 16m 45s\tremaining: 9m 27s\n",
      "6393:\tlearn: 0.0520512\ttotal: 16m 45s\tremaining: 9m 27s\n",
      "6394:\tlearn: 0.0520512\ttotal: 16m 45s\tremaining: 9m 26s\n",
      "6395:\tlearn: 0.0520512\ttotal: 16m 45s\tremaining: 9m 26s\n",
      "6396:\tlearn: 0.0520512\ttotal: 16m 45s\tremaining: 9m 26s\n",
      "6397:\tlearn: 0.0520512\ttotal: 16m 46s\tremaining: 9m 26s\n",
      "6398:\tlearn: 0.0520512\ttotal: 16m 46s\tremaining: 9m 26s\n",
      "6399:\tlearn: 0.0520512\ttotal: 16m 46s\tremaining: 9m 26s\n",
      "6400:\tlearn: 0.0520512\ttotal: 16m 46s\tremaining: 9m 25s\n",
      "6401:\tlearn: 0.0520512\ttotal: 16m 46s\tremaining: 9m 25s\n",
      "6402:\tlearn: 0.0520512\ttotal: 16m 46s\tremaining: 9m 25s\n",
      "6403:\tlearn: 0.0520512\ttotal: 16m 47s\tremaining: 9m 25s\n",
      "6404:\tlearn: 0.0520512\ttotal: 16m 47s\tremaining: 9m 25s\n",
      "6405:\tlearn: 0.0520512\ttotal: 16m 47s\tremaining: 9m 25s\n",
      "6406:\tlearn: 0.0520512\ttotal: 16m 47s\tremaining: 9m 25s\n",
      "6407:\tlearn: 0.0520512\ttotal: 16m 47s\tremaining: 9m 24s\n",
      "6408:\tlearn: 0.0520512\ttotal: 16m 47s\tremaining: 9m 24s\n",
      "6409:\tlearn: 0.0520512\ttotal: 16m 47s\tremaining: 9m 24s\n",
      "6410:\tlearn: 0.0520512\ttotal: 16m 48s\tremaining: 9m 24s\n",
      "6411:\tlearn: 0.0520512\ttotal: 16m 48s\tremaining: 9m 24s\n",
      "6412:\tlearn: 0.0520512\ttotal: 16m 48s\tremaining: 9m 24s\n",
      "6413:\tlearn: 0.0520512\ttotal: 16m 48s\tremaining: 9m 23s\n",
      "6414:\tlearn: 0.0520512\ttotal: 16m 48s\tremaining: 9m 23s\n",
      "6415:\tlearn: 0.0520512\ttotal: 16m 48s\tremaining: 9m 23s\n",
      "6416:\tlearn: 0.0520512\ttotal: 16m 49s\tremaining: 9m 23s\n",
      "6417:\tlearn: 0.0520512\ttotal: 16m 49s\tremaining: 9m 23s\n",
      "6418:\tlearn: 0.0520512\ttotal: 16m 49s\tremaining: 9m 23s\n",
      "6419:\tlearn: 0.0520512\ttotal: 16m 49s\tremaining: 9m 22s\n",
      "6420:\tlearn: 0.0520512\ttotal: 16m 49s\tremaining: 9m 22s\n",
      "6421:\tlearn: 0.0520512\ttotal: 16m 49s\tremaining: 9m 22s\n",
      "6422:\tlearn: 0.0520512\ttotal: 16m 49s\tremaining: 9m 22s\n",
      "6423:\tlearn: 0.0520512\ttotal: 16m 50s\tremaining: 9m 22s\n",
      "6424:\tlearn: 0.0520512\ttotal: 16m 50s\tremaining: 9m 22s\n",
      "6425:\tlearn: 0.0520512\ttotal: 16m 50s\tremaining: 9m 21s\n",
      "6426:\tlearn: 0.0520512\ttotal: 16m 50s\tremaining: 9m 21s\n",
      "6427:\tlearn: 0.0520512\ttotal: 16m 50s\tremaining: 9m 21s\n",
      "6428:\tlearn: 0.0520512\ttotal: 16m 50s\tremaining: 9m 21s\n",
      "6429:\tlearn: 0.0520512\ttotal: 16m 51s\tremaining: 9m 21s\n",
      "6430:\tlearn: 0.0520512\ttotal: 16m 51s\tremaining: 9m 21s\n",
      "6431:\tlearn: 0.0520512\ttotal: 16m 51s\tremaining: 9m 20s\n",
      "6432:\tlearn: 0.0520512\ttotal: 16m 51s\tremaining: 9m 20s\n",
      "6433:\tlearn: 0.0520512\ttotal: 16m 51s\tremaining: 9m 20s\n",
      "6434:\tlearn: 0.0520512\ttotal: 16m 51s\tremaining: 9m 20s\n",
      "6435:\tlearn: 0.0520512\ttotal: 16m 51s\tremaining: 9m 20s\n",
      "6436:\tlearn: 0.0520512\ttotal: 16m 52s\tremaining: 9m 20s\n",
      "6437:\tlearn: 0.0520512\ttotal: 16m 52s\tremaining: 9m 20s\n",
      "6438:\tlearn: 0.0520512\ttotal: 16m 52s\tremaining: 9m 19s\n",
      "6439:\tlearn: 0.0520512\ttotal: 16m 52s\tremaining: 9m 19s\n",
      "6440:\tlearn: 0.0520512\ttotal: 16m 52s\tremaining: 9m 19s\n",
      "6441:\tlearn: 0.0520512\ttotal: 16m 52s\tremaining: 9m 19s\n",
      "6442:\tlearn: 0.0520512\ttotal: 16m 52s\tremaining: 9m 19s\n",
      "6443:\tlearn: 0.0520512\ttotal: 16m 53s\tremaining: 9m 19s\n",
      "6444:\tlearn: 0.0520512\ttotal: 16m 53s\tremaining: 9m 18s\n",
      "6445:\tlearn: 0.0520512\ttotal: 16m 53s\tremaining: 9m 18s\n",
      "6446:\tlearn: 0.0520512\ttotal: 16m 53s\tremaining: 9m 18s\n",
      "6447:\tlearn: 0.0520512\ttotal: 16m 53s\tremaining: 9m 18s\n",
      "6448:\tlearn: 0.0520512\ttotal: 16m 53s\tremaining: 9m 18s\n",
      "6449:\tlearn: 0.0520512\ttotal: 16m 54s\tremaining: 9m 18s\n",
      "6450:\tlearn: 0.0520512\ttotal: 16m 54s\tremaining: 9m 17s\n",
      "6451:\tlearn: 0.0520512\ttotal: 16m 54s\tremaining: 9m 17s\n",
      "6452:\tlearn: 0.0520512\ttotal: 16m 54s\tremaining: 9m 17s\n",
      "6453:\tlearn: 0.0520512\ttotal: 16m 54s\tremaining: 9m 17s\n",
      "6454:\tlearn: 0.0520512\ttotal: 16m 54s\tremaining: 9m 17s\n",
      "6455:\tlearn: 0.0520512\ttotal: 16m 54s\tremaining: 9m 17s\n",
      "6456:\tlearn: 0.0520512\ttotal: 16m 55s\tremaining: 9m 17s\n",
      "6457:\tlearn: 0.0520512\ttotal: 16m 55s\tremaining: 9m 16s\n",
      "6458:\tlearn: 0.0520512\ttotal: 16m 55s\tremaining: 9m 16s\n",
      "6459:\tlearn: 0.0520512\ttotal: 16m 55s\tremaining: 9m 16s\n",
      "6460:\tlearn: 0.0520512\ttotal: 16m 55s\tremaining: 9m 16s\n",
      "6461:\tlearn: 0.0520512\ttotal: 16m 55s\tremaining: 9m 16s\n",
      "6462:\tlearn: 0.0520512\ttotal: 16m 56s\tremaining: 9m 16s\n",
      "6463:\tlearn: 0.0520512\ttotal: 16m 56s\tremaining: 9m 15s\n",
      "6464:\tlearn: 0.0520512\ttotal: 16m 56s\tremaining: 9m 15s\n",
      "6465:\tlearn: 0.0520512\ttotal: 16m 56s\tremaining: 9m 15s\n",
      "6466:\tlearn: 0.0520512\ttotal: 16m 56s\tremaining: 9m 15s\n",
      "6467:\tlearn: 0.0520512\ttotal: 16m 56s\tremaining: 9m 15s\n",
      "6468:\tlearn: 0.0520512\ttotal: 16m 56s\tremaining: 9m 15s\n",
      "6469:\tlearn: 0.0520512\ttotal: 16m 57s\tremaining: 9m 14s\n",
      "6470:\tlearn: 0.0520512\ttotal: 16m 57s\tremaining: 9m 14s\n",
      "6471:\tlearn: 0.0520512\ttotal: 16m 57s\tremaining: 9m 14s\n",
      "6472:\tlearn: 0.0520512\ttotal: 16m 57s\tremaining: 9m 14s\n",
      "6473:\tlearn: 0.0520512\ttotal: 16m 57s\tremaining: 9m 14s\n",
      "6474:\tlearn: 0.0520512\ttotal: 16m 57s\tremaining: 9m 14s\n",
      "6475:\tlearn: 0.0520512\ttotal: 16m 58s\tremaining: 9m 13s\n",
      "6476:\tlearn: 0.0520512\ttotal: 16m 58s\tremaining: 9m 13s\n",
      "6477:\tlearn: 0.0520512\ttotal: 16m 58s\tremaining: 9m 13s\n",
      "6478:\tlearn: 0.0520512\ttotal: 16m 58s\tremaining: 9m 13s\n",
      "6479:\tlearn: 0.0520512\ttotal: 16m 58s\tremaining: 9m 13s\n",
      "6480:\tlearn: 0.0520512\ttotal: 16m 58s\tremaining: 9m 13s\n",
      "6481:\tlearn: 0.0520512\ttotal: 16m 58s\tremaining: 9m 13s\n",
      "6482:\tlearn: 0.0520512\ttotal: 16m 59s\tremaining: 9m 12s\n",
      "6483:\tlearn: 0.0520512\ttotal: 16m 59s\tremaining: 9m 12s\n",
      "6484:\tlearn: 0.0520512\ttotal: 16m 59s\tremaining: 9m 12s\n",
      "6485:\tlearn: 0.0520512\ttotal: 16m 59s\tremaining: 9m 12s\n",
      "6486:\tlearn: 0.0520512\ttotal: 16m 59s\tremaining: 9m 12s\n",
      "6487:\tlearn: 0.0520512\ttotal: 16m 59s\tremaining: 9m 12s\n",
      "6488:\tlearn: 0.0520512\ttotal: 17m\tremaining: 9m 11s\n",
      "6489:\tlearn: 0.0520512\ttotal: 17m\tremaining: 9m 11s\n",
      "6490:\tlearn: 0.0520512\ttotal: 17m\tremaining: 9m 11s\n",
      "6491:\tlearn: 0.0520512\ttotal: 17m\tremaining: 9m 11s\n",
      "6492:\tlearn: 0.0520512\ttotal: 17m\tremaining: 9m 11s\n",
      "6493:\tlearn: 0.0520512\ttotal: 17m\tremaining: 9m 11s\n",
      "6494:\tlearn: 0.0520512\ttotal: 17m\tremaining: 9m 10s\n",
      "6495:\tlearn: 0.0520512\ttotal: 17m 1s\tremaining: 9m 10s\n",
      "6496:\tlearn: 0.0520512\ttotal: 17m 1s\tremaining: 9m 10s\n",
      "6497:\tlearn: 0.0520512\ttotal: 17m 1s\tremaining: 9m 10s\n",
      "6498:\tlearn: 0.0520512\ttotal: 17m 1s\tremaining: 9m 10s\n",
      "6499:\tlearn: 0.0520512\ttotal: 17m 1s\tremaining: 9m 10s\n",
      "6500:\tlearn: 0.0520512\ttotal: 17m 1s\tremaining: 9m 9s\n",
      "6501:\tlearn: 0.0520512\ttotal: 17m 1s\tremaining: 9m 9s\n",
      "6502:\tlearn: 0.0520512\ttotal: 17m 2s\tremaining: 9m 9s\n",
      "6503:\tlearn: 0.0520512\ttotal: 17m 2s\tremaining: 9m 9s\n",
      "6504:\tlearn: 0.0520512\ttotal: 17m 2s\tremaining: 9m 9s\n",
      "6505:\tlearn: 0.0520512\ttotal: 17m 2s\tremaining: 9m 9s\n",
      "6506:\tlearn: 0.0520512\ttotal: 17m 2s\tremaining: 9m 9s\n",
      "6507:\tlearn: 0.0520512\ttotal: 17m 2s\tremaining: 9m 8s\n",
      "6508:\tlearn: 0.0520512\ttotal: 17m 3s\tremaining: 9m 8s\n",
      "6509:\tlearn: 0.0520512\ttotal: 17m 3s\tremaining: 9m 8s\n",
      "6510:\tlearn: 0.0520512\ttotal: 17m 3s\tremaining: 9m 8s\n",
      "6511:\tlearn: 0.0520512\ttotal: 17m 3s\tremaining: 9m 8s\n",
      "6512:\tlearn: 0.0520512\ttotal: 17m 3s\tremaining: 9m 8s\n",
      "6513:\tlearn: 0.0520512\ttotal: 17m 3s\tremaining: 9m 7s\n",
      "6514:\tlearn: 0.0520512\ttotal: 17m 3s\tremaining: 9m 7s\n",
      "6515:\tlearn: 0.0520512\ttotal: 17m 4s\tremaining: 9m 7s\n",
      "6516:\tlearn: 0.0520512\ttotal: 17m 4s\tremaining: 9m 7s\n",
      "6517:\tlearn: 0.0520512\ttotal: 17m 4s\tremaining: 9m 7s\n",
      "6518:\tlearn: 0.0520512\ttotal: 17m 4s\tremaining: 9m 7s\n",
      "6519:\tlearn: 0.0520512\ttotal: 17m 4s\tremaining: 9m 6s\n",
      "6520:\tlearn: 0.0520512\ttotal: 17m 4s\tremaining: 9m 6s\n",
      "6521:\tlearn: 0.0520512\ttotal: 17m 5s\tremaining: 9m 6s\n",
      "6522:\tlearn: 0.0520512\ttotal: 17m 5s\tremaining: 9m 6s\n",
      "6523:\tlearn: 0.0520512\ttotal: 17m 5s\tremaining: 9m 6s\n",
      "6524:\tlearn: 0.0520512\ttotal: 17m 5s\tremaining: 9m 6s\n",
      "6525:\tlearn: 0.0520512\ttotal: 17m 5s\tremaining: 9m 5s\n",
      "6526:\tlearn: 0.0520512\ttotal: 17m 5s\tremaining: 9m 5s\n",
      "6527:\tlearn: 0.0520512\ttotal: 17m 5s\tremaining: 9m 5s\n",
      "6528:\tlearn: 0.0520512\ttotal: 17m 6s\tremaining: 9m 5s\n",
      "6529:\tlearn: 0.0520512\ttotal: 17m 6s\tremaining: 9m 5s\n",
      "6530:\tlearn: 0.0520512\ttotal: 17m 6s\tremaining: 9m 5s\n",
      "6531:\tlearn: 0.0520512\ttotal: 17m 6s\tremaining: 9m 5s\n",
      "6532:\tlearn: 0.0520512\ttotal: 17m 6s\tremaining: 9m 4s\n",
      "6533:\tlearn: 0.0520512\ttotal: 17m 6s\tremaining: 9m 4s\n",
      "6534:\tlearn: 0.0520512\ttotal: 17m 7s\tremaining: 9m 4s\n",
      "6535:\tlearn: 0.0520512\ttotal: 17m 7s\tremaining: 9m 4s\n",
      "6536:\tlearn: 0.0520512\ttotal: 17m 7s\tremaining: 9m 4s\n",
      "6537:\tlearn: 0.0520512\ttotal: 17m 7s\tremaining: 9m 4s\n",
      "6538:\tlearn: 0.0520512\ttotal: 17m 7s\tremaining: 9m 3s\n",
      "6539:\tlearn: 0.0520512\ttotal: 17m 7s\tremaining: 9m 3s\n",
      "6540:\tlearn: 0.0520512\ttotal: 17m 7s\tremaining: 9m 3s\n",
      "6541:\tlearn: 0.0520512\ttotal: 17m 8s\tremaining: 9m 3s\n",
      "6542:\tlearn: 0.0520512\ttotal: 17m 8s\tremaining: 9m 3s\n",
      "6543:\tlearn: 0.0520512\ttotal: 17m 8s\tremaining: 9m 3s\n",
      "6544:\tlearn: 0.0520512\ttotal: 17m 8s\tremaining: 9m 2s\n",
      "6545:\tlearn: 0.0520512\ttotal: 17m 8s\tremaining: 9m 2s\n",
      "6546:\tlearn: 0.0520512\ttotal: 17m 8s\tremaining: 9m 2s\n",
      "6547:\tlearn: 0.0520512\ttotal: 17m 9s\tremaining: 9m 2s\n",
      "6548:\tlearn: 0.0520512\ttotal: 17m 9s\tremaining: 9m 2s\n",
      "6549:\tlearn: 0.0520512\ttotal: 17m 9s\tremaining: 9m 2s\n",
      "6550:\tlearn: 0.0520512\ttotal: 17m 9s\tremaining: 9m 1s\n",
      "6551:\tlearn: 0.0520512\ttotal: 17m 9s\tremaining: 9m 1s\n",
      "6552:\tlearn: 0.0520512\ttotal: 17m 9s\tremaining: 9m 1s\n",
      "6553:\tlearn: 0.0520512\ttotal: 17m 9s\tremaining: 9m 1s\n",
      "6554:\tlearn: 0.0520512\ttotal: 17m 10s\tremaining: 9m 1s\n",
      "6555:\tlearn: 0.0520512\ttotal: 17m 10s\tremaining: 9m 1s\n",
      "6556:\tlearn: 0.0520512\ttotal: 17m 10s\tremaining: 9m 1s\n",
      "6557:\tlearn: 0.0520512\ttotal: 17m 10s\tremaining: 9m\n",
      "6558:\tlearn: 0.0520512\ttotal: 17m 10s\tremaining: 9m\n",
      "6559:\tlearn: 0.0520512\ttotal: 17m 10s\tremaining: 9m\n",
      "6560:\tlearn: 0.0520512\ttotal: 17m 10s\tremaining: 9m\n",
      "6561:\tlearn: 0.0520512\ttotal: 17m 11s\tremaining: 9m\n",
      "6562:\tlearn: 0.0520512\ttotal: 17m 11s\tremaining: 9m\n",
      "6563:\tlearn: 0.0520512\ttotal: 17m 11s\tremaining: 8m 59s\n",
      "6564:\tlearn: 0.0520512\ttotal: 17m 11s\tremaining: 8m 59s\n",
      "6565:\tlearn: 0.0520512\ttotal: 17m 11s\tremaining: 8m 59s\n",
      "6566:\tlearn: 0.0520512\ttotal: 17m 11s\tremaining: 8m 59s\n",
      "6567:\tlearn: 0.0520512\ttotal: 17m 12s\tremaining: 8m 59s\n",
      "6568:\tlearn: 0.0520512\ttotal: 17m 12s\tremaining: 8m 59s\n",
      "6569:\tlearn: 0.0520512\ttotal: 17m 12s\tremaining: 8m 58s\n",
      "6570:\tlearn: 0.0520512\ttotal: 17m 12s\tremaining: 8m 58s\n",
      "6571:\tlearn: 0.0520512\ttotal: 17m 12s\tremaining: 8m 58s\n",
      "6572:\tlearn: 0.0520512\ttotal: 17m 12s\tremaining: 8m 58s\n",
      "6573:\tlearn: 0.0520512\ttotal: 17m 12s\tremaining: 8m 58s\n",
      "6574:\tlearn: 0.0520512\ttotal: 17m 13s\tremaining: 8m 58s\n",
      "6575:\tlearn: 0.0520512\ttotal: 17m 13s\tremaining: 8m 58s\n",
      "6576:\tlearn: 0.0520512\ttotal: 17m 13s\tremaining: 8m 57s\n",
      "6577:\tlearn: 0.0520512\ttotal: 17m 13s\tremaining: 8m 57s\n",
      "6578:\tlearn: 0.0520512\ttotal: 17m 13s\tremaining: 8m 57s\n",
      "6579:\tlearn: 0.0520512\ttotal: 17m 13s\tremaining: 8m 57s\n",
      "6580:\tlearn: 0.0520512\ttotal: 17m 14s\tremaining: 8m 57s\n",
      "6581:\tlearn: 0.0520512\ttotal: 17m 14s\tremaining: 8m 57s\n",
      "6582:\tlearn: 0.0520512\ttotal: 17m 14s\tremaining: 8m 56s\n",
      "6583:\tlearn: 0.0520512\ttotal: 17m 14s\tremaining: 8m 56s\n",
      "6584:\tlearn: 0.0520512\ttotal: 17m 14s\tremaining: 8m 56s\n",
      "6585:\tlearn: 0.0520512\ttotal: 17m 14s\tremaining: 8m 56s\n",
      "6586:\tlearn: 0.0520512\ttotal: 17m 14s\tremaining: 8m 56s\n",
      "6587:\tlearn: 0.0520512\ttotal: 17m 15s\tremaining: 8m 56s\n",
      "6588:\tlearn: 0.0520512\ttotal: 17m 15s\tremaining: 8m 55s\n",
      "6589:\tlearn: 0.0520512\ttotal: 17m 15s\tremaining: 8m 55s\n",
      "6590:\tlearn: 0.0520512\ttotal: 17m 15s\tremaining: 8m 55s\n",
      "6591:\tlearn: 0.0520512\ttotal: 17m 15s\tremaining: 8m 55s\n",
      "6592:\tlearn: 0.0520512\ttotal: 17m 15s\tremaining: 8m 55s\n",
      "6593:\tlearn: 0.0520512\ttotal: 17m 15s\tremaining: 8m 55s\n",
      "6594:\tlearn: 0.0520512\ttotal: 17m 16s\tremaining: 8m 54s\n",
      "6595:\tlearn: 0.0520512\ttotal: 17m 16s\tremaining: 8m 54s\n",
      "6596:\tlearn: 0.0520512\ttotal: 17m 16s\tremaining: 8m 54s\n",
      "6597:\tlearn: 0.0520512\ttotal: 17m 16s\tremaining: 8m 54s\n",
      "6598:\tlearn: 0.0520512\ttotal: 17m 16s\tremaining: 8m 54s\n",
      "6599:\tlearn: 0.0520512\ttotal: 17m 16s\tremaining: 8m 54s\n",
      "6600:\tlearn: 0.0520512\ttotal: 17m 17s\tremaining: 8m 54s\n",
      "6601:\tlearn: 0.0520512\ttotal: 17m 17s\tremaining: 8m 53s\n",
      "6602:\tlearn: 0.0520512\ttotal: 17m 17s\tremaining: 8m 53s\n",
      "6603:\tlearn: 0.0520512\ttotal: 17m 17s\tremaining: 8m 53s\n",
      "6604:\tlearn: 0.0520512\ttotal: 17m 17s\tremaining: 8m 53s\n",
      "6605:\tlearn: 0.0520512\ttotal: 17m 17s\tremaining: 8m 53s\n",
      "6606:\tlearn: 0.0520512\ttotal: 17m 17s\tremaining: 8m 53s\n",
      "6607:\tlearn: 0.0520512\ttotal: 17m 18s\tremaining: 8m 52s\n",
      "6608:\tlearn: 0.0520512\ttotal: 17m 18s\tremaining: 8m 52s\n",
      "6609:\tlearn: 0.0520512\ttotal: 17m 18s\tremaining: 8m 52s\n",
      "6610:\tlearn: 0.0520512\ttotal: 17m 18s\tremaining: 8m 52s\n",
      "6611:\tlearn: 0.0520512\ttotal: 17m 18s\tremaining: 8m 52s\n",
      "6612:\tlearn: 0.0520512\ttotal: 17m 18s\tremaining: 8m 52s\n",
      "6613:\tlearn: 0.0520512\ttotal: 17m 19s\tremaining: 8m 51s\n",
      "6614:\tlearn: 0.0520512\ttotal: 17m 19s\tremaining: 8m 51s\n",
      "6615:\tlearn: 0.0520512\ttotal: 17m 19s\tremaining: 8m 51s\n",
      "6616:\tlearn: 0.0520512\ttotal: 17m 19s\tremaining: 8m 51s\n",
      "6617:\tlearn: 0.0520512\ttotal: 17m 19s\tremaining: 8m 51s\n",
      "6618:\tlearn: 0.0520512\ttotal: 17m 19s\tremaining: 8m 51s\n",
      "6619:\tlearn: 0.0520512\ttotal: 17m 19s\tremaining: 8m 50s\n",
      "6620:\tlearn: 0.0520512\ttotal: 17m 20s\tremaining: 8m 50s\n",
      "6621:\tlearn: 0.0520512\ttotal: 17m 20s\tremaining: 8m 50s\n",
      "6622:\tlearn: 0.0520512\ttotal: 17m 20s\tremaining: 8m 50s\n",
      "6623:\tlearn: 0.0520512\ttotal: 17m 20s\tremaining: 8m 50s\n",
      "6624:\tlearn: 0.0520512\ttotal: 17m 20s\tremaining: 8m 50s\n",
      "6625:\tlearn: 0.0520512\ttotal: 17m 20s\tremaining: 8m 50s\n",
      "6626:\tlearn: 0.0520512\ttotal: 17m 21s\tremaining: 8m 49s\n",
      "6627:\tlearn: 0.0520512\ttotal: 17m 21s\tremaining: 8m 49s\n",
      "6628:\tlearn: 0.0520512\ttotal: 17m 21s\tremaining: 8m 49s\n",
      "6629:\tlearn: 0.0520512\ttotal: 17m 21s\tremaining: 8m 49s\n",
      "6630:\tlearn: 0.0520512\ttotal: 17m 21s\tremaining: 8m 49s\n",
      "6631:\tlearn: 0.0520512\ttotal: 17m 21s\tremaining: 8m 49s\n",
      "6632:\tlearn: 0.0520512\ttotal: 17m 21s\tremaining: 8m 48s\n",
      "6633:\tlearn: 0.0520512\ttotal: 17m 22s\tremaining: 8m 48s\n",
      "6634:\tlearn: 0.0520512\ttotal: 17m 22s\tremaining: 8m 48s\n",
      "6635:\tlearn: 0.0520512\ttotal: 17m 22s\tremaining: 8m 48s\n",
      "6636:\tlearn: 0.0520512\ttotal: 17m 22s\tremaining: 8m 48s\n",
      "6637:\tlearn: 0.0520512\ttotal: 17m 22s\tremaining: 8m 48s\n",
      "6638:\tlearn: 0.0520512\ttotal: 17m 22s\tremaining: 8m 47s\n",
      "6639:\tlearn: 0.0520512\ttotal: 17m 23s\tremaining: 8m 47s\n",
      "6640:\tlearn: 0.0520512\ttotal: 17m 23s\tremaining: 8m 47s\n",
      "6641:\tlearn: 0.0520512\ttotal: 17m 23s\tremaining: 8m 47s\n",
      "6642:\tlearn: 0.0520512\ttotal: 17m 23s\tremaining: 8m 47s\n",
      "6643:\tlearn: 0.0520512\ttotal: 17m 23s\tremaining: 8m 47s\n",
      "6644:\tlearn: 0.0520512\ttotal: 17m 23s\tremaining: 8m 46s\n",
      "6645:\tlearn: 0.0520512\ttotal: 17m 23s\tremaining: 8m 46s\n",
      "6646:\tlearn: 0.0520512\ttotal: 17m 24s\tremaining: 8m 46s\n",
      "6647:\tlearn: 0.0520512\ttotal: 17m 24s\tremaining: 8m 46s\n",
      "6648:\tlearn: 0.0520512\ttotal: 17m 24s\tremaining: 8m 46s\n",
      "6649:\tlearn: 0.0520512\ttotal: 17m 24s\tremaining: 8m 46s\n",
      "6650:\tlearn: 0.0520512\ttotal: 17m 24s\tremaining: 8m 46s\n",
      "6651:\tlearn: 0.0520512\ttotal: 17m 24s\tremaining: 8m 45s\n",
      "6652:\tlearn: 0.0520512\ttotal: 17m 24s\tremaining: 8m 45s\n",
      "6653:\tlearn: 0.0520512\ttotal: 17m 25s\tremaining: 8m 45s\n",
      "6654:\tlearn: 0.0520512\ttotal: 17m 25s\tremaining: 8m 45s\n",
      "6655:\tlearn: 0.0520512\ttotal: 17m 25s\tremaining: 8m 45s\n",
      "6656:\tlearn: 0.0520512\ttotal: 17m 25s\tremaining: 8m 45s\n",
      "6657:\tlearn: 0.0520512\ttotal: 17m 25s\tremaining: 8m 44s\n",
      "6658:\tlearn: 0.0520512\ttotal: 17m 25s\tremaining: 8m 44s\n",
      "6659:\tlearn: 0.0520512\ttotal: 17m 26s\tremaining: 8m 44s\n",
      "6660:\tlearn: 0.0520512\ttotal: 17m 26s\tremaining: 8m 44s\n",
      "6661:\tlearn: 0.0520512\ttotal: 17m 26s\tremaining: 8m 44s\n",
      "6662:\tlearn: 0.0520512\ttotal: 17m 26s\tremaining: 8m 44s\n",
      "6663:\tlearn: 0.0520512\ttotal: 17m 26s\tremaining: 8m 43s\n",
      "6664:\tlearn: 0.0520512\ttotal: 17m 26s\tremaining: 8m 43s\n",
      "6665:\tlearn: 0.0520512\ttotal: 17m 26s\tremaining: 8m 43s\n",
      "6666:\tlearn: 0.0520512\ttotal: 17m 27s\tremaining: 8m 43s\n",
      "6667:\tlearn: 0.0520512\ttotal: 17m 27s\tremaining: 8m 43s\n",
      "6668:\tlearn: 0.0520512\ttotal: 17m 27s\tremaining: 8m 43s\n",
      "6669:\tlearn: 0.0520512\ttotal: 17m 27s\tremaining: 8m 43s\n",
      "6670:\tlearn: 0.0520512\ttotal: 17m 27s\tremaining: 8m 42s\n",
      "6671:\tlearn: 0.0520512\ttotal: 17m 27s\tremaining: 8m 42s\n",
      "6672:\tlearn: 0.0520512\ttotal: 17m 28s\tremaining: 8m 42s\n",
      "6673:\tlearn: 0.0520512\ttotal: 17m 28s\tremaining: 8m 42s\n",
      "6674:\tlearn: 0.0520512\ttotal: 17m 28s\tremaining: 8m 42s\n",
      "6675:\tlearn: 0.0520512\ttotal: 17m 28s\tremaining: 8m 42s\n",
      "6676:\tlearn: 0.0520512\ttotal: 17m 28s\tremaining: 8m 41s\n",
      "6677:\tlearn: 0.0520512\ttotal: 17m 28s\tremaining: 8m 41s\n",
      "6678:\tlearn: 0.0520512\ttotal: 17m 29s\tremaining: 8m 41s\n",
      "6679:\tlearn: 0.0520512\ttotal: 17m 29s\tremaining: 8m 41s\n",
      "6680:\tlearn: 0.0520512\ttotal: 17m 29s\tremaining: 8m 41s\n",
      "6681:\tlearn: 0.0520512\ttotal: 17m 29s\tremaining: 8m 41s\n",
      "6682:\tlearn: 0.0520512\ttotal: 17m 29s\tremaining: 8m 40s\n",
      "6683:\tlearn: 0.0520512\ttotal: 17m 29s\tremaining: 8m 40s\n",
      "6684:\tlearn: 0.0520512\ttotal: 17m 29s\tremaining: 8m 40s\n",
      "6685:\tlearn: 0.0520512\ttotal: 17m 30s\tremaining: 8m 40s\n",
      "6686:\tlearn: 0.0520512\ttotal: 17m 30s\tremaining: 8m 40s\n",
      "6687:\tlearn: 0.0520512\ttotal: 17m 30s\tremaining: 8m 40s\n",
      "6688:\tlearn: 0.0520512\ttotal: 17m 30s\tremaining: 8m 40s\n",
      "6689:\tlearn: 0.0520512\ttotal: 17m 30s\tremaining: 8m 39s\n",
      "6690:\tlearn: 0.0520512\ttotal: 17m 30s\tremaining: 8m 39s\n",
      "6691:\tlearn: 0.0520512\ttotal: 17m 31s\tremaining: 8m 39s\n",
      "6692:\tlearn: 0.0520512\ttotal: 17m 31s\tremaining: 8m 39s\n",
      "6693:\tlearn: 0.0520512\ttotal: 17m 31s\tremaining: 8m 39s\n",
      "6694:\tlearn: 0.0520512\ttotal: 17m 31s\tremaining: 8m 39s\n",
      "6695:\tlearn: 0.0520512\ttotal: 17m 31s\tremaining: 8m 38s\n",
      "6696:\tlearn: 0.0520512\ttotal: 17m 31s\tremaining: 8m 38s\n",
      "6697:\tlearn: 0.0520512\ttotal: 17m 32s\tremaining: 8m 38s\n",
      "6698:\tlearn: 0.0520512\ttotal: 17m 32s\tremaining: 8m 38s\n",
      "6699:\tlearn: 0.0520512\ttotal: 17m 32s\tremaining: 8m 38s\n",
      "6700:\tlearn: 0.0520512\ttotal: 17m 32s\tremaining: 8m 38s\n",
      "6701:\tlearn: 0.0520512\ttotal: 17m 32s\tremaining: 8m 37s\n",
      "6702:\tlearn: 0.0520512\ttotal: 17m 32s\tremaining: 8m 37s\n",
      "6703:\tlearn: 0.0520512\ttotal: 17m 32s\tremaining: 8m 37s\n",
      "6704:\tlearn: 0.0520512\ttotal: 17m 33s\tremaining: 8m 37s\n",
      "6705:\tlearn: 0.0520512\ttotal: 17m 33s\tremaining: 8m 37s\n",
      "6706:\tlearn: 0.0520512\ttotal: 17m 33s\tremaining: 8m 37s\n",
      "6707:\tlearn: 0.0520512\ttotal: 17m 33s\tremaining: 8m 37s\n",
      "6708:\tlearn: 0.0520512\ttotal: 17m 33s\tremaining: 8m 36s\n",
      "6709:\tlearn: 0.0520512\ttotal: 17m 33s\tremaining: 8m 36s\n",
      "6710:\tlearn: 0.0520512\ttotal: 17m 33s\tremaining: 8m 36s\n",
      "6711:\tlearn: 0.0520512\ttotal: 17m 34s\tremaining: 8m 36s\n",
      "6712:\tlearn: 0.0520512\ttotal: 17m 34s\tremaining: 8m 36s\n",
      "6713:\tlearn: 0.0520512\ttotal: 17m 34s\tremaining: 8m 36s\n",
      "6714:\tlearn: 0.0520512\ttotal: 17m 34s\tremaining: 8m 35s\n",
      "6715:\tlearn: 0.0520512\ttotal: 17m 34s\tremaining: 8m 35s\n",
      "6716:\tlearn: 0.0520512\ttotal: 17m 34s\tremaining: 8m 35s\n",
      "6717:\tlearn: 0.0520512\ttotal: 17m 35s\tremaining: 8m 35s\n",
      "6718:\tlearn: 0.0520512\ttotal: 17m 35s\tremaining: 8m 35s\n",
      "6719:\tlearn: 0.0520512\ttotal: 17m 35s\tremaining: 8m 35s\n",
      "6720:\tlearn: 0.0520512\ttotal: 17m 35s\tremaining: 8m 34s\n",
      "6721:\tlearn: 0.0520512\ttotal: 17m 35s\tremaining: 8m 34s\n",
      "6722:\tlearn: 0.0520512\ttotal: 17m 35s\tremaining: 8m 34s\n",
      "6723:\tlearn: 0.0520512\ttotal: 17m 35s\tremaining: 8m 34s\n",
      "6724:\tlearn: 0.0520512\ttotal: 17m 36s\tremaining: 8m 34s\n",
      "6725:\tlearn: 0.0520512\ttotal: 17m 36s\tremaining: 8m 34s\n",
      "6726:\tlearn: 0.0520512\ttotal: 17m 36s\tremaining: 8m 33s\n",
      "6727:\tlearn: 0.0520512\ttotal: 17m 36s\tremaining: 8m 33s\n",
      "6728:\tlearn: 0.0520512\ttotal: 17m 36s\tremaining: 8m 33s\n",
      "6729:\tlearn: 0.0520512\ttotal: 17m 36s\tremaining: 8m 33s\n",
      "6730:\tlearn: 0.0520512\ttotal: 17m 37s\tremaining: 8m 33s\n",
      "6731:\tlearn: 0.0520512\ttotal: 17m 37s\tremaining: 8m 33s\n",
      "6732:\tlearn: 0.0520512\ttotal: 17m 37s\tremaining: 8m 33s\n",
      "6733:\tlearn: 0.0520512\ttotal: 17m 37s\tremaining: 8m 32s\n",
      "6734:\tlearn: 0.0520512\ttotal: 17m 37s\tremaining: 8m 32s\n",
      "6735:\tlearn: 0.0520512\ttotal: 17m 37s\tremaining: 8m 32s\n",
      "6736:\tlearn: 0.0520512\ttotal: 17m 37s\tremaining: 8m 32s\n",
      "6737:\tlearn: 0.0520512\ttotal: 17m 38s\tremaining: 8m 32s\n",
      "6738:\tlearn: 0.0520512\ttotal: 17m 38s\tremaining: 8m 32s\n",
      "6739:\tlearn: 0.0520512\ttotal: 17m 38s\tremaining: 8m 31s\n",
      "6740:\tlearn: 0.0520512\ttotal: 17m 38s\tremaining: 8m 31s\n",
      "6741:\tlearn: 0.0520512\ttotal: 17m 38s\tremaining: 8m 31s\n",
      "6742:\tlearn: 0.0520512\ttotal: 17m 38s\tremaining: 8m 31s\n",
      "6743:\tlearn: 0.0520512\ttotal: 17m 38s\tremaining: 8m 31s\n",
      "6744:\tlearn: 0.0520512\ttotal: 17m 39s\tremaining: 8m 31s\n",
      "6745:\tlearn: 0.0520512\ttotal: 17m 39s\tremaining: 8m 30s\n",
      "6746:\tlearn: 0.0520512\ttotal: 17m 39s\tremaining: 8m 30s\n",
      "6747:\tlearn: 0.0520512\ttotal: 17m 39s\tremaining: 8m 30s\n",
      "6748:\tlearn: 0.0520512\ttotal: 17m 39s\tremaining: 8m 30s\n",
      "6749:\tlearn: 0.0520512\ttotal: 17m 39s\tremaining: 8m 30s\n",
      "6750:\tlearn: 0.0520512\ttotal: 17m 40s\tremaining: 8m 30s\n",
      "6751:\tlearn: 0.0520512\ttotal: 17m 40s\tremaining: 8m 30s\n",
      "6752:\tlearn: 0.0520512\ttotal: 17m 40s\tremaining: 8m 29s\n",
      "6753:\tlearn: 0.0520512\ttotal: 17m 40s\tremaining: 8m 29s\n",
      "6754:\tlearn: 0.0520512\ttotal: 17m 40s\tremaining: 8m 29s\n",
      "6755:\tlearn: 0.0520512\ttotal: 17m 40s\tremaining: 8m 29s\n",
      "6756:\tlearn: 0.0520512\ttotal: 17m 40s\tremaining: 8m 29s\n",
      "6757:\tlearn: 0.0520512\ttotal: 17m 41s\tremaining: 8m 29s\n",
      "6758:\tlearn: 0.0520512\ttotal: 17m 41s\tremaining: 8m 28s\n",
      "6759:\tlearn: 0.0520512\ttotal: 17m 41s\tremaining: 8m 28s\n",
      "6760:\tlearn: 0.0520512\ttotal: 17m 41s\tremaining: 8m 28s\n",
      "6761:\tlearn: 0.0520512\ttotal: 17m 41s\tremaining: 8m 28s\n",
      "6762:\tlearn: 0.0520512\ttotal: 17m 41s\tremaining: 8m 28s\n",
      "6763:\tlearn: 0.0520512\ttotal: 17m 42s\tremaining: 8m 28s\n",
      "6764:\tlearn: 0.0520512\ttotal: 17m 42s\tremaining: 8m 27s\n",
      "6765:\tlearn: 0.0520512\ttotal: 17m 42s\tremaining: 8m 27s\n",
      "6766:\tlearn: 0.0520512\ttotal: 17m 42s\tremaining: 8m 27s\n",
      "6767:\tlearn: 0.0520512\ttotal: 17m 42s\tremaining: 8m 27s\n",
      "6768:\tlearn: 0.0520512\ttotal: 17m 42s\tremaining: 8m 27s\n",
      "6769:\tlearn: 0.0520512\ttotal: 17m 42s\tremaining: 8m 27s\n",
      "6770:\tlearn: 0.0520512\ttotal: 17m 43s\tremaining: 8m 26s\n",
      "6771:\tlearn: 0.0520512\ttotal: 17m 43s\tremaining: 8m 26s\n",
      "6772:\tlearn: 0.0520512\ttotal: 17m 43s\tremaining: 8m 26s\n",
      "6773:\tlearn: 0.0520512\ttotal: 17m 43s\tremaining: 8m 26s\n",
      "6774:\tlearn: 0.0520512\ttotal: 17m 43s\tremaining: 8m 26s\n",
      "6775:\tlearn: 0.0520512\ttotal: 17m 43s\tremaining: 8m 26s\n",
      "6776:\tlearn: 0.0520512\ttotal: 17m 43s\tremaining: 8m 26s\n",
      "6777:\tlearn: 0.0520512\ttotal: 17m 44s\tremaining: 8m 25s\n",
      "6778:\tlearn: 0.0520512\ttotal: 17m 44s\tremaining: 8m 25s\n",
      "6779:\tlearn: 0.0520512\ttotal: 17m 44s\tremaining: 8m 25s\n",
      "6780:\tlearn: 0.0520512\ttotal: 17m 44s\tremaining: 8m 25s\n",
      "6781:\tlearn: 0.0520512\ttotal: 17m 44s\tremaining: 8m 25s\n",
      "6782:\tlearn: 0.0520512\ttotal: 17m 44s\tremaining: 8m 25s\n",
      "6783:\tlearn: 0.0520512\ttotal: 17m 45s\tremaining: 8m 24s\n",
      "6784:\tlearn: 0.0520512\ttotal: 17m 45s\tremaining: 8m 24s\n",
      "6785:\tlearn: 0.0520512\ttotal: 17m 45s\tremaining: 8m 24s\n",
      "6786:\tlearn: 0.0520512\ttotal: 17m 45s\tremaining: 8m 24s\n",
      "6787:\tlearn: 0.0520512\ttotal: 17m 45s\tremaining: 8m 24s\n",
      "6788:\tlearn: 0.0520512\ttotal: 17m 45s\tremaining: 8m 24s\n",
      "6789:\tlearn: 0.0520512\ttotal: 17m 45s\tremaining: 8m 23s\n",
      "6790:\tlearn: 0.0520512\ttotal: 17m 46s\tremaining: 8m 23s\n",
      "6791:\tlearn: 0.0520512\ttotal: 17m 46s\tremaining: 8m 23s\n",
      "6792:\tlearn: 0.0520512\ttotal: 17m 46s\tremaining: 8m 23s\n",
      "6793:\tlearn: 0.0520512\ttotal: 17m 46s\tremaining: 8m 23s\n",
      "6794:\tlearn: 0.0520512\ttotal: 17m 46s\tremaining: 8m 23s\n",
      "6795:\tlearn: 0.0520512\ttotal: 17m 46s\tremaining: 8m 22s\n",
      "6796:\tlearn: 0.0520512\ttotal: 17m 47s\tremaining: 8m 22s\n",
      "6797:\tlearn: 0.0520512\ttotal: 17m 47s\tremaining: 8m 22s\n",
      "6798:\tlearn: 0.0520512\ttotal: 17m 47s\tremaining: 8m 22s\n",
      "6799:\tlearn: 0.0520512\ttotal: 17m 47s\tremaining: 8m 22s\n",
      "6800:\tlearn: 0.0520512\ttotal: 17m 47s\tremaining: 8m 22s\n",
      "6801:\tlearn: 0.0520512\ttotal: 17m 47s\tremaining: 8m 22s\n",
      "6802:\tlearn: 0.0520512\ttotal: 17m 47s\tremaining: 8m 21s\n",
      "6803:\tlearn: 0.0520512\ttotal: 17m 48s\tremaining: 8m 21s\n",
      "6804:\tlearn: 0.0520512\ttotal: 17m 48s\tremaining: 8m 21s\n",
      "6805:\tlearn: 0.0520512\ttotal: 17m 48s\tremaining: 8m 21s\n",
      "6806:\tlearn: 0.0520512\ttotal: 17m 48s\tremaining: 8m 21s\n",
      "6807:\tlearn: 0.0520512\ttotal: 17m 48s\tremaining: 8m 21s\n",
      "6808:\tlearn: 0.0520512\ttotal: 17m 48s\tremaining: 8m 20s\n",
      "6809:\tlearn: 0.0520512\ttotal: 17m 49s\tremaining: 8m 20s\n",
      "6810:\tlearn: 0.0520512\ttotal: 17m 49s\tremaining: 8m 20s\n",
      "6811:\tlearn: 0.0520512\ttotal: 17m 49s\tremaining: 8m 20s\n",
      "6812:\tlearn: 0.0520512\ttotal: 17m 49s\tremaining: 8m 20s\n",
      "6813:\tlearn: 0.0520512\ttotal: 17m 49s\tremaining: 8m 20s\n",
      "6814:\tlearn: 0.0520512\ttotal: 17m 49s\tremaining: 8m 19s\n",
      "6815:\tlearn: 0.0520512\ttotal: 17m 49s\tremaining: 8m 19s\n",
      "6816:\tlearn: 0.0520512\ttotal: 17m 50s\tremaining: 8m 19s\n",
      "6817:\tlearn: 0.0520512\ttotal: 17m 50s\tremaining: 8m 19s\n",
      "6818:\tlearn: 0.0520512\ttotal: 17m 50s\tremaining: 8m 19s\n",
      "6819:\tlearn: 0.0520512\ttotal: 17m 50s\tremaining: 8m 19s\n",
      "6820:\tlearn: 0.0520512\ttotal: 17m 50s\tremaining: 8m 19s\n",
      "6821:\tlearn: 0.0520512\ttotal: 17m 50s\tremaining: 8m 18s\n",
      "6822:\tlearn: 0.0520512\ttotal: 17m 50s\tremaining: 8m 18s\n",
      "6823:\tlearn: 0.0520512\ttotal: 17m 51s\tremaining: 8m 18s\n",
      "6824:\tlearn: 0.0520512\ttotal: 17m 51s\tremaining: 8m 18s\n",
      "6825:\tlearn: 0.0520512\ttotal: 17m 51s\tremaining: 8m 18s\n",
      "6826:\tlearn: 0.0520512\ttotal: 17m 51s\tremaining: 8m 18s\n",
      "6827:\tlearn: 0.0520512\ttotal: 17m 51s\tremaining: 8m 17s\n",
      "6828:\tlearn: 0.0520512\ttotal: 17m 51s\tremaining: 8m 17s\n",
      "6829:\tlearn: 0.0520512\ttotal: 17m 52s\tremaining: 8m 17s\n",
      "6830:\tlearn: 0.0520512\ttotal: 17m 52s\tremaining: 8m 17s\n",
      "6831:\tlearn: 0.0520512\ttotal: 17m 52s\tremaining: 8m 17s\n",
      "6832:\tlearn: 0.0520512\ttotal: 17m 52s\tremaining: 8m 17s\n",
      "6833:\tlearn: 0.0520512\ttotal: 17m 52s\tremaining: 8m 16s\n",
      "6834:\tlearn: 0.0520512\ttotal: 17m 52s\tremaining: 8m 16s\n",
      "6835:\tlearn: 0.0520512\ttotal: 17m 52s\tremaining: 8m 16s\n",
      "6836:\tlearn: 0.0520512\ttotal: 17m 53s\tremaining: 8m 16s\n",
      "6837:\tlearn: 0.0520512\ttotal: 17m 53s\tremaining: 8m 16s\n",
      "6838:\tlearn: 0.0520512\ttotal: 17m 53s\tremaining: 8m 16s\n",
      "6839:\tlearn: 0.0520512\ttotal: 17m 53s\tremaining: 8m 15s\n",
      "6840:\tlearn: 0.0520512\ttotal: 17m 53s\tremaining: 8m 15s\n",
      "6841:\tlearn: 0.0520512\ttotal: 17m 53s\tremaining: 8m 15s\n",
      "6842:\tlearn: 0.0520512\ttotal: 17m 54s\tremaining: 8m 15s\n",
      "6843:\tlearn: 0.0520512\ttotal: 17m 54s\tremaining: 8m 15s\n",
      "6844:\tlearn: 0.0520512\ttotal: 17m 54s\tremaining: 8m 15s\n",
      "6845:\tlearn: 0.0520512\ttotal: 17m 54s\tremaining: 8m 15s\n",
      "6846:\tlearn: 0.0520512\ttotal: 17m 54s\tremaining: 8m 14s\n",
      "6847:\tlearn: 0.0520512\ttotal: 17m 54s\tremaining: 8m 14s\n",
      "6848:\tlearn: 0.0520512\ttotal: 17m 54s\tremaining: 8m 14s\n",
      "6849:\tlearn: 0.0520512\ttotal: 17m 55s\tremaining: 8m 14s\n",
      "6850:\tlearn: 0.0520512\ttotal: 17m 55s\tremaining: 8m 14s\n",
      "6851:\tlearn: 0.0520512\ttotal: 17m 55s\tremaining: 8m 14s\n",
      "6852:\tlearn: 0.0520512\ttotal: 17m 55s\tremaining: 8m 13s\n",
      "6853:\tlearn: 0.0520512\ttotal: 17m 55s\tremaining: 8m 13s\n",
      "6854:\tlearn: 0.0520512\ttotal: 17m 55s\tremaining: 8m 13s\n",
      "6855:\tlearn: 0.0520512\ttotal: 17m 55s\tremaining: 8m 13s\n",
      "6856:\tlearn: 0.0520512\ttotal: 17m 56s\tremaining: 8m 13s\n",
      "6857:\tlearn: 0.0520512\ttotal: 17m 56s\tremaining: 8m 13s\n",
      "6858:\tlearn: 0.0520512\ttotal: 17m 56s\tremaining: 8m 12s\n",
      "6859:\tlearn: 0.0520512\ttotal: 17m 56s\tremaining: 8m 12s\n",
      "6860:\tlearn: 0.0520512\ttotal: 17m 56s\tremaining: 8m 12s\n",
      "6861:\tlearn: 0.0520512\ttotal: 17m 56s\tremaining: 8m 12s\n",
      "6862:\tlearn: 0.0520512\ttotal: 17m 57s\tremaining: 8m 12s\n",
      "6863:\tlearn: 0.0520512\ttotal: 17m 57s\tremaining: 8m 12s\n",
      "6864:\tlearn: 0.0520512\ttotal: 17m 57s\tremaining: 8m 12s\n",
      "6865:\tlearn: 0.0520512\ttotal: 17m 57s\tremaining: 8m 11s\n",
      "6866:\tlearn: 0.0520512\ttotal: 17m 57s\tremaining: 8m 11s\n",
      "6867:\tlearn: 0.0520512\ttotal: 17m 57s\tremaining: 8m 11s\n",
      "6868:\tlearn: 0.0520512\ttotal: 17m 58s\tremaining: 8m 11s\n",
      "6869:\tlearn: 0.0520512\ttotal: 17m 58s\tremaining: 8m 11s\n",
      "6870:\tlearn: 0.0520512\ttotal: 17m 58s\tremaining: 8m 11s\n",
      "6871:\tlearn: 0.0520512\ttotal: 17m 58s\tremaining: 8m 10s\n",
      "6872:\tlearn: 0.0520512\ttotal: 17m 58s\tremaining: 8m 10s\n",
      "6873:\tlearn: 0.0520512\ttotal: 17m 58s\tremaining: 8m 10s\n",
      "6874:\tlearn: 0.0520512\ttotal: 17m 58s\tremaining: 8m 10s\n",
      "6875:\tlearn: 0.0520512\ttotal: 17m 59s\tremaining: 8m 10s\n",
      "6876:\tlearn: 0.0520512\ttotal: 17m 59s\tremaining: 8m 10s\n",
      "6877:\tlearn: 0.0520512\ttotal: 17m 59s\tremaining: 8m 9s\n",
      "6878:\tlearn: 0.0520512\ttotal: 17m 59s\tremaining: 8m 9s\n",
      "6879:\tlearn: 0.0520512\ttotal: 17m 59s\tremaining: 8m 9s\n",
      "6880:\tlearn: 0.0520512\ttotal: 17m 59s\tremaining: 8m 9s\n",
      "6881:\tlearn: 0.0520512\ttotal: 17m 59s\tremaining: 8m 9s\n",
      "6882:\tlearn: 0.0520512\ttotal: 18m\tremaining: 8m 9s\n",
      "6883:\tlearn: 0.0520512\ttotal: 18m\tremaining: 8m 8s\n",
      "6884:\tlearn: 0.0520512\ttotal: 18m\tremaining: 8m 8s\n",
      "6885:\tlearn: 0.0520512\ttotal: 18m\tremaining: 8m 8s\n",
      "6886:\tlearn: 0.0520512\ttotal: 18m\tremaining: 8m 8s\n",
      "6887:\tlearn: 0.0520512\ttotal: 18m\tremaining: 8m 8s\n",
      "6888:\tlearn: 0.0520512\ttotal: 18m 1s\tremaining: 8m 8s\n",
      "6889:\tlearn: 0.0520512\ttotal: 18m 1s\tremaining: 8m 8s\n",
      "6890:\tlearn: 0.0520512\ttotal: 18m 1s\tremaining: 8m 7s\n",
      "6891:\tlearn: 0.0520512\ttotal: 18m 1s\tremaining: 8m 7s\n",
      "6892:\tlearn: 0.0520512\ttotal: 18m 1s\tremaining: 8m 7s\n",
      "6893:\tlearn: 0.0520512\ttotal: 18m 1s\tremaining: 8m 7s\n",
      "6894:\tlearn: 0.0520512\ttotal: 18m 1s\tremaining: 8m 7s\n",
      "6895:\tlearn: 0.0520512\ttotal: 18m 2s\tremaining: 8m 7s\n",
      "6896:\tlearn: 0.0520512\ttotal: 18m 2s\tremaining: 8m 6s\n",
      "6897:\tlearn: 0.0520512\ttotal: 18m 2s\tremaining: 8m 6s\n",
      "6898:\tlearn: 0.0520512\ttotal: 18m 2s\tremaining: 8m 6s\n",
      "6899:\tlearn: 0.0520512\ttotal: 18m 2s\tremaining: 8m 6s\n",
      "6900:\tlearn: 0.0520512\ttotal: 18m 2s\tremaining: 8m 6s\n",
      "6901:\tlearn: 0.0520512\ttotal: 18m 3s\tremaining: 8m 6s\n",
      "6902:\tlearn: 0.0520512\ttotal: 18m 3s\tremaining: 8m 5s\n",
      "6903:\tlearn: 0.0520512\ttotal: 18m 3s\tremaining: 8m 5s\n",
      "6904:\tlearn: 0.0520512\ttotal: 18m 3s\tremaining: 8m 5s\n",
      "6905:\tlearn: 0.0520512\ttotal: 18m 3s\tremaining: 8m 5s\n",
      "6906:\tlearn: 0.0520512\ttotal: 18m 3s\tremaining: 8m 5s\n",
      "6907:\tlearn: 0.0520512\ttotal: 18m 3s\tremaining: 8m 5s\n",
      "6908:\tlearn: 0.0520512\ttotal: 18m 4s\tremaining: 8m 5s\n",
      "6909:\tlearn: 0.0520512\ttotal: 18m 4s\tremaining: 8m 4s\n",
      "6910:\tlearn: 0.0520512\ttotal: 18m 4s\tremaining: 8m 4s\n",
      "6911:\tlearn: 0.0520512\ttotal: 18m 4s\tremaining: 8m 4s\n",
      "6912:\tlearn: 0.0520512\ttotal: 18m 4s\tremaining: 8m 4s\n",
      "6913:\tlearn: 0.0520512\ttotal: 18m 4s\tremaining: 8m 4s\n",
      "6914:\tlearn: 0.0520512\ttotal: 18m 5s\tremaining: 8m 4s\n",
      "6915:\tlearn: 0.0520512\ttotal: 18m 5s\tremaining: 8m 3s\n",
      "6916:\tlearn: 0.0520512\ttotal: 18m 5s\tremaining: 8m 3s\n",
      "6917:\tlearn: 0.0520512\ttotal: 18m 5s\tremaining: 8m 3s\n",
      "6918:\tlearn: 0.0520512\ttotal: 18m 5s\tremaining: 8m 3s\n",
      "6919:\tlearn: 0.0520512\ttotal: 18m 5s\tremaining: 8m 3s\n",
      "6920:\tlearn: 0.0520512\ttotal: 18m 5s\tremaining: 8m 3s\n",
      "6921:\tlearn: 0.0520512\ttotal: 18m 6s\tremaining: 8m 2s\n",
      "6922:\tlearn: 0.0520512\ttotal: 18m 6s\tremaining: 8m 2s\n",
      "6923:\tlearn: 0.0520512\ttotal: 18m 6s\tremaining: 8m 2s\n",
      "6924:\tlearn: 0.0520512\ttotal: 18m 6s\tremaining: 8m 2s\n",
      "6925:\tlearn: 0.0520512\ttotal: 18m 6s\tremaining: 8m 2s\n",
      "6926:\tlearn: 0.0520512\ttotal: 18m 6s\tremaining: 8m 2s\n",
      "6927:\tlearn: 0.0520512\ttotal: 18m 7s\tremaining: 8m 2s\n",
      "6928:\tlearn: 0.0520512\ttotal: 18m 7s\tremaining: 8m 1s\n",
      "6929:\tlearn: 0.0520512\ttotal: 18m 7s\tremaining: 8m 1s\n",
      "6930:\tlearn: 0.0520512\ttotal: 18m 7s\tremaining: 8m 1s\n",
      "6931:\tlearn: 0.0520512\ttotal: 18m 7s\tremaining: 8m 1s\n",
      "6932:\tlearn: 0.0520512\ttotal: 18m 7s\tremaining: 8m 1s\n",
      "6933:\tlearn: 0.0520512\ttotal: 18m 7s\tremaining: 8m 1s\n",
      "6934:\tlearn: 0.0520512\ttotal: 18m 8s\tremaining: 8m\n",
      "6935:\tlearn: 0.0520512\ttotal: 18m 8s\tremaining: 8m\n",
      "6936:\tlearn: 0.0520512\ttotal: 18m 8s\tremaining: 8m\n",
      "6937:\tlearn: 0.0520512\ttotal: 18m 8s\tremaining: 8m\n",
      "6938:\tlearn: 0.0520512\ttotal: 18m 8s\tremaining: 8m\n",
      "6939:\tlearn: 0.0520512\ttotal: 18m 8s\tremaining: 8m\n",
      "6940:\tlearn: 0.0520512\ttotal: 18m 9s\tremaining: 7m 59s\n",
      "6941:\tlearn: 0.0520512\ttotal: 18m 9s\tremaining: 7m 59s\n",
      "6942:\tlearn: 0.0520512\ttotal: 18m 9s\tremaining: 7m 59s\n",
      "6943:\tlearn: 0.0520512\ttotal: 18m 9s\tremaining: 7m 59s\n",
      "6944:\tlearn: 0.0520512\ttotal: 18m 9s\tremaining: 7m 59s\n",
      "6945:\tlearn: 0.0520512\ttotal: 18m 9s\tremaining: 7m 59s\n",
      "6946:\tlearn: 0.0520512\ttotal: 18m 9s\tremaining: 7m 58s\n",
      "6947:\tlearn: 0.0520512\ttotal: 18m 10s\tremaining: 7m 58s\n",
      "6948:\tlearn: 0.0520512\ttotal: 18m 10s\tremaining: 7m 58s\n",
      "6949:\tlearn: 0.0520512\ttotal: 18m 10s\tremaining: 7m 58s\n",
      "6950:\tlearn: 0.0520512\ttotal: 18m 10s\tremaining: 7m 58s\n",
      "6951:\tlearn: 0.0520512\ttotal: 18m 10s\tremaining: 7m 58s\n",
      "6952:\tlearn: 0.0520512\ttotal: 18m 10s\tremaining: 7m 58s\n",
      "6953:\tlearn: 0.0520512\ttotal: 18m 10s\tremaining: 7m 57s\n",
      "6954:\tlearn: 0.0520512\ttotal: 18m 11s\tremaining: 7m 57s\n",
      "6955:\tlearn: 0.0520512\ttotal: 18m 11s\tremaining: 7m 57s\n",
      "6956:\tlearn: 0.0520512\ttotal: 18m 11s\tremaining: 7m 57s\n",
      "6957:\tlearn: 0.0520512\ttotal: 18m 11s\tremaining: 7m 57s\n",
      "6958:\tlearn: 0.0520512\ttotal: 18m 11s\tremaining: 7m 57s\n",
      "6959:\tlearn: 0.0520512\ttotal: 18m 11s\tremaining: 7m 56s\n",
      "6960:\tlearn: 0.0520512\ttotal: 18m 12s\tremaining: 7m 56s\n",
      "6961:\tlearn: 0.0520512\ttotal: 18m 12s\tremaining: 7m 56s\n",
      "6962:\tlearn: 0.0520512\ttotal: 18m 12s\tremaining: 7m 56s\n",
      "6963:\tlearn: 0.0520512\ttotal: 18m 12s\tremaining: 7m 56s\n",
      "6964:\tlearn: 0.0520512\ttotal: 18m 12s\tremaining: 7m 56s\n",
      "6965:\tlearn: 0.0520512\ttotal: 18m 12s\tremaining: 7m 55s\n",
      "6966:\tlearn: 0.0520512\ttotal: 18m 12s\tremaining: 7m 55s\n",
      "6967:\tlearn: 0.0520512\ttotal: 18m 13s\tremaining: 7m 55s\n",
      "6968:\tlearn: 0.0520512\ttotal: 18m 13s\tremaining: 7m 55s\n",
      "6969:\tlearn: 0.0520512\ttotal: 18m 13s\tremaining: 7m 55s\n",
      "6970:\tlearn: 0.0520512\ttotal: 18m 13s\tremaining: 7m 55s\n",
      "6971:\tlearn: 0.0520512\ttotal: 18m 13s\tremaining: 7m 55s\n",
      "6972:\tlearn: 0.0520512\ttotal: 18m 13s\tremaining: 7m 54s\n",
      "6973:\tlearn: 0.0520512\ttotal: 18m 14s\tremaining: 7m 54s\n",
      "6974:\tlearn: 0.0520512\ttotal: 18m 14s\tremaining: 7m 54s\n",
      "6975:\tlearn: 0.0520512\ttotal: 18m 14s\tremaining: 7m 54s\n",
      "6976:\tlearn: 0.0520512\ttotal: 18m 14s\tremaining: 7m 54s\n",
      "6977:\tlearn: 0.0520512\ttotal: 18m 14s\tremaining: 7m 54s\n",
      "6978:\tlearn: 0.0520512\ttotal: 18m 14s\tremaining: 7m 53s\n",
      "6979:\tlearn: 0.0520512\ttotal: 18m 14s\tremaining: 7m 53s\n",
      "6980:\tlearn: 0.0520512\ttotal: 18m 15s\tremaining: 7m 53s\n",
      "6981:\tlearn: 0.0520512\ttotal: 18m 15s\tremaining: 7m 53s\n",
      "6982:\tlearn: 0.0520512\ttotal: 18m 15s\tremaining: 7m 53s\n",
      "6983:\tlearn: 0.0520512\ttotal: 18m 15s\tremaining: 7m 53s\n",
      "6984:\tlearn: 0.0520512\ttotal: 18m 15s\tremaining: 7m 52s\n",
      "6985:\tlearn: 0.0520512\ttotal: 18m 15s\tremaining: 7m 52s\n",
      "6986:\tlearn: 0.0520512\ttotal: 18m 16s\tremaining: 7m 52s\n",
      "6987:\tlearn: 0.0520512\ttotal: 18m 16s\tremaining: 7m 52s\n",
      "6988:\tlearn: 0.0520512\ttotal: 18m 16s\tremaining: 7m 52s\n",
      "6989:\tlearn: 0.0520512\ttotal: 18m 16s\tremaining: 7m 52s\n",
      "6990:\tlearn: 0.0520512\ttotal: 18m 16s\tremaining: 7m 52s\n",
      "6991:\tlearn: 0.0520512\ttotal: 18m 16s\tremaining: 7m 51s\n",
      "6992:\tlearn: 0.0520512\ttotal: 18m 16s\tremaining: 7m 51s\n",
      "6993:\tlearn: 0.0520512\ttotal: 18m 17s\tremaining: 7m 51s\n",
      "6994:\tlearn: 0.0520512\ttotal: 18m 17s\tremaining: 7m 51s\n",
      "6995:\tlearn: 0.0520512\ttotal: 18m 17s\tremaining: 7m 51s\n",
      "6996:\tlearn: 0.0520512\ttotal: 18m 17s\tremaining: 7m 51s\n",
      "6997:\tlearn: 0.0520512\ttotal: 18m 17s\tremaining: 7m 50s\n",
      "6998:\tlearn: 0.0520512\ttotal: 18m 17s\tremaining: 7m 50s\n",
      "6999:\tlearn: 0.0520512\ttotal: 18m 18s\tremaining: 7m 50s\n",
      "7000:\tlearn: 0.0520512\ttotal: 18m 18s\tremaining: 7m 50s\n",
      "7001:\tlearn: 0.0520512\ttotal: 18m 18s\tremaining: 7m 50s\n",
      "7002:\tlearn: 0.0520512\ttotal: 18m 18s\tremaining: 7m 50s\n",
      "7003:\tlearn: 0.0520512\ttotal: 18m 18s\tremaining: 7m 49s\n",
      "7004:\tlearn: 0.0520512\ttotal: 18m 18s\tremaining: 7m 49s\n",
      "7005:\tlearn: 0.0520512\ttotal: 18m 18s\tremaining: 7m 49s\n",
      "7006:\tlearn: 0.0520512\ttotal: 18m 19s\tremaining: 7m 49s\n",
      "7007:\tlearn: 0.0520512\ttotal: 18m 19s\tremaining: 7m 49s\n",
      "7008:\tlearn: 0.0520512\ttotal: 18m 19s\tremaining: 7m 49s\n",
      "7009:\tlearn: 0.0520512\ttotal: 18m 19s\tremaining: 7m 48s\n",
      "7010:\tlearn: 0.0520512\ttotal: 18m 19s\tremaining: 7m 48s\n",
      "7011:\tlearn: 0.0520512\ttotal: 18m 19s\tremaining: 7m 48s\n",
      "7012:\tlearn: 0.0520512\ttotal: 18m 19s\tremaining: 7m 48s\n",
      "7013:\tlearn: 0.0520512\ttotal: 18m 20s\tremaining: 7m 48s\n",
      "7014:\tlearn: 0.0520512\ttotal: 18m 20s\tremaining: 7m 48s\n",
      "7015:\tlearn: 0.0520512\ttotal: 18m 20s\tremaining: 7m 48s\n",
      "7016:\tlearn: 0.0520512\ttotal: 18m 20s\tremaining: 7m 47s\n",
      "7017:\tlearn: 0.0520512\ttotal: 18m 20s\tremaining: 7m 47s\n",
      "7018:\tlearn: 0.0520512\ttotal: 18m 20s\tremaining: 7m 47s\n",
      "7019:\tlearn: 0.0520512\ttotal: 18m 21s\tremaining: 7m 47s\n",
      "7020:\tlearn: 0.0520512\ttotal: 18m 21s\tremaining: 7m 47s\n",
      "7021:\tlearn: 0.0520512\ttotal: 18m 21s\tremaining: 7m 47s\n",
      "7022:\tlearn: 0.0520512\ttotal: 18m 21s\tremaining: 7m 46s\n",
      "7023:\tlearn: 0.0520512\ttotal: 18m 21s\tremaining: 7m 46s\n",
      "7024:\tlearn: 0.0520512\ttotal: 18m 21s\tremaining: 7m 46s\n",
      "7025:\tlearn: 0.0520512\ttotal: 18m 21s\tremaining: 7m 46s\n",
      "7026:\tlearn: 0.0520512\ttotal: 18m 22s\tremaining: 7m 46s\n",
      "7027:\tlearn: 0.0520512\ttotal: 18m 22s\tremaining: 7m 46s\n",
      "7028:\tlearn: 0.0520512\ttotal: 18m 22s\tremaining: 7m 45s\n",
      "7029:\tlearn: 0.0520512\ttotal: 18m 22s\tremaining: 7m 45s\n",
      "7030:\tlearn: 0.0520512\ttotal: 18m 22s\tremaining: 7m 45s\n",
      "7031:\tlearn: 0.0520512\ttotal: 18m 22s\tremaining: 7m 45s\n",
      "7032:\tlearn: 0.0520512\ttotal: 18m 23s\tremaining: 7m 45s\n",
      "7033:\tlearn: 0.0520512\ttotal: 18m 23s\tremaining: 7m 45s\n",
      "7034:\tlearn: 0.0520512\ttotal: 18m 23s\tremaining: 7m 45s\n",
      "7035:\tlearn: 0.0520512\ttotal: 18m 23s\tremaining: 7m 44s\n",
      "7036:\tlearn: 0.0520512\ttotal: 18m 23s\tremaining: 7m 44s\n",
      "7037:\tlearn: 0.0520512\ttotal: 18m 23s\tremaining: 7m 44s\n",
      "7038:\tlearn: 0.0520512\ttotal: 18m 23s\tremaining: 7m 44s\n",
      "7039:\tlearn: 0.0520512\ttotal: 18m 24s\tremaining: 7m 44s\n",
      "7040:\tlearn: 0.0520512\ttotal: 18m 24s\tremaining: 7m 44s\n",
      "7041:\tlearn: 0.0520512\ttotal: 18m 24s\tremaining: 7m 43s\n",
      "7042:\tlearn: 0.0520512\ttotal: 18m 24s\tremaining: 7m 43s\n",
      "7043:\tlearn: 0.0520512\ttotal: 18m 24s\tremaining: 7m 43s\n",
      "7044:\tlearn: 0.0520512\ttotal: 18m 24s\tremaining: 7m 43s\n",
      "7045:\tlearn: 0.0520512\ttotal: 18m 24s\tremaining: 7m 43s\n",
      "7046:\tlearn: 0.0520512\ttotal: 18m 25s\tremaining: 7m 43s\n",
      "7047:\tlearn: 0.0520512\ttotal: 18m 25s\tremaining: 7m 42s\n",
      "7048:\tlearn: 0.0520512\ttotal: 18m 25s\tremaining: 7m 42s\n",
      "7049:\tlearn: 0.0520512\ttotal: 18m 25s\tremaining: 7m 42s\n",
      "7050:\tlearn: 0.0520512\ttotal: 18m 25s\tremaining: 7m 42s\n",
      "7051:\tlearn: 0.0520512\ttotal: 18m 25s\tremaining: 7m 42s\n",
      "7052:\tlearn: 0.0520512\ttotal: 18m 26s\tremaining: 7m 42s\n",
      "7053:\tlearn: 0.0520512\ttotal: 18m 26s\tremaining: 7m 41s\n",
      "7054:\tlearn: 0.0520512\ttotal: 18m 26s\tremaining: 7m 41s\n",
      "7055:\tlearn: 0.0520512\ttotal: 18m 26s\tremaining: 7m 41s\n",
      "7056:\tlearn: 0.0520512\ttotal: 18m 26s\tremaining: 7m 41s\n",
      "7057:\tlearn: 0.0520512\ttotal: 18m 26s\tremaining: 7m 41s\n",
      "7058:\tlearn: 0.0520512\ttotal: 18m 26s\tremaining: 7m 41s\n",
      "7059:\tlearn: 0.0520512\ttotal: 18m 27s\tremaining: 7m 41s\n",
      "7060:\tlearn: 0.0520512\ttotal: 18m 27s\tremaining: 7m 40s\n",
      "7061:\tlearn: 0.0520512\ttotal: 18m 27s\tremaining: 7m 40s\n",
      "7062:\tlearn: 0.0520512\ttotal: 18m 27s\tremaining: 7m 40s\n",
      "7063:\tlearn: 0.0520512\ttotal: 18m 27s\tremaining: 7m 40s\n",
      "7064:\tlearn: 0.0520512\ttotal: 18m 27s\tremaining: 7m 40s\n",
      "7065:\tlearn: 0.0520512\ttotal: 18m 28s\tremaining: 7m 40s\n",
      "7066:\tlearn: 0.0520512\ttotal: 18m 28s\tremaining: 7m 39s\n",
      "7067:\tlearn: 0.0520512\ttotal: 18m 28s\tremaining: 7m 39s\n",
      "7068:\tlearn: 0.0520512\ttotal: 18m 28s\tremaining: 7m 39s\n",
      "7069:\tlearn: 0.0520512\ttotal: 18m 28s\tremaining: 7m 39s\n",
      "7070:\tlearn: 0.0520512\ttotal: 18m 28s\tremaining: 7m 39s\n",
      "7071:\tlearn: 0.0520512\ttotal: 18m 28s\tremaining: 7m 39s\n",
      "7072:\tlearn: 0.0520512\ttotal: 18m 29s\tremaining: 7m 38s\n",
      "7073:\tlearn: 0.0520512\ttotal: 18m 29s\tremaining: 7m 38s\n",
      "7074:\tlearn: 0.0520512\ttotal: 18m 29s\tremaining: 7m 38s\n",
      "7075:\tlearn: 0.0520512\ttotal: 18m 29s\tremaining: 7m 38s\n",
      "7076:\tlearn: 0.0520512\ttotal: 18m 29s\tremaining: 7m 38s\n",
      "7077:\tlearn: 0.0520512\ttotal: 18m 29s\tremaining: 7m 38s\n",
      "7078:\tlearn: 0.0520512\ttotal: 18m 29s\tremaining: 7m 38s\n",
      "7079:\tlearn: 0.0520512\ttotal: 18m 30s\tremaining: 7m 37s\n",
      "7080:\tlearn: 0.0520512\ttotal: 18m 30s\tremaining: 7m 37s\n",
      "7081:\tlearn: 0.0520512\ttotal: 18m 30s\tremaining: 7m 37s\n",
      "7082:\tlearn: 0.0520512\ttotal: 18m 30s\tremaining: 7m 37s\n",
      "7083:\tlearn: 0.0520512\ttotal: 18m 30s\tremaining: 7m 37s\n",
      "7084:\tlearn: 0.0520512\ttotal: 18m 30s\tremaining: 7m 37s\n",
      "7085:\tlearn: 0.0520512\ttotal: 18m 31s\tremaining: 7m 36s\n",
      "7086:\tlearn: 0.0520512\ttotal: 18m 31s\tremaining: 7m 36s\n",
      "7087:\tlearn: 0.0520512\ttotal: 18m 31s\tremaining: 7m 36s\n",
      "7088:\tlearn: 0.0520512\ttotal: 18m 31s\tremaining: 7m 36s\n",
      "7089:\tlearn: 0.0520512\ttotal: 18m 31s\tremaining: 7m 36s\n",
      "7090:\tlearn: 0.0520512\ttotal: 18m 31s\tremaining: 7m 36s\n",
      "7091:\tlearn: 0.0520512\ttotal: 18m 31s\tremaining: 7m 35s\n",
      "7092:\tlearn: 0.0520512\ttotal: 18m 32s\tremaining: 7m 35s\n",
      "7093:\tlearn: 0.0520512\ttotal: 18m 32s\tremaining: 7m 35s\n",
      "7094:\tlearn: 0.0520512\ttotal: 18m 32s\tremaining: 7m 35s\n",
      "7095:\tlearn: 0.0520512\ttotal: 18m 32s\tremaining: 7m 35s\n",
      "7096:\tlearn: 0.0520512\ttotal: 18m 32s\tremaining: 7m 35s\n",
      "7097:\tlearn: 0.0520512\ttotal: 18m 32s\tremaining: 7m 35s\n",
      "7098:\tlearn: 0.0520512\ttotal: 18m 33s\tremaining: 7m 34s\n",
      "7099:\tlearn: 0.0520512\ttotal: 18m 33s\tremaining: 7m 34s\n",
      "7100:\tlearn: 0.0520512\ttotal: 18m 33s\tremaining: 7m 34s\n",
      "7101:\tlearn: 0.0520512\ttotal: 18m 33s\tremaining: 7m 34s\n",
      "7102:\tlearn: 0.0520512\ttotal: 18m 33s\tremaining: 7m 34s\n",
      "7103:\tlearn: 0.0520512\ttotal: 18m 33s\tremaining: 7m 34s\n",
      "7104:\tlearn: 0.0520512\ttotal: 18m 33s\tremaining: 7m 33s\n",
      "7105:\tlearn: 0.0520512\ttotal: 18m 34s\tremaining: 7m 33s\n",
      "7106:\tlearn: 0.0520512\ttotal: 18m 34s\tremaining: 7m 33s\n",
      "7107:\tlearn: 0.0520512\ttotal: 18m 34s\tremaining: 7m 33s\n",
      "7108:\tlearn: 0.0520512\ttotal: 18m 34s\tremaining: 7m 33s\n",
      "7109:\tlearn: 0.0520512\ttotal: 18m 34s\tremaining: 7m 33s\n",
      "7110:\tlearn: 0.0520512\ttotal: 18m 34s\tremaining: 7m 32s\n",
      "7111:\tlearn: 0.0520512\ttotal: 18m 35s\tremaining: 7m 32s\n",
      "7112:\tlearn: 0.0520512\ttotal: 18m 35s\tremaining: 7m 32s\n",
      "7113:\tlearn: 0.0520512\ttotal: 18m 35s\tremaining: 7m 32s\n",
      "7114:\tlearn: 0.0520512\ttotal: 18m 35s\tremaining: 7m 32s\n",
      "7115:\tlearn: 0.0520512\ttotal: 18m 35s\tremaining: 7m 32s\n",
      "7116:\tlearn: 0.0520512\ttotal: 18m 35s\tremaining: 7m 32s\n",
      "7117:\tlearn: 0.0520512\ttotal: 18m 36s\tremaining: 7m 31s\n",
      "7118:\tlearn: 0.0520512\ttotal: 18m 36s\tremaining: 7m 31s\n",
      "7119:\tlearn: 0.0520512\ttotal: 18m 36s\tremaining: 7m 31s\n",
      "7120:\tlearn: 0.0520512\ttotal: 18m 36s\tremaining: 7m 31s\n",
      "7121:\tlearn: 0.0520512\ttotal: 18m 36s\tremaining: 7m 31s\n",
      "7122:\tlearn: 0.0520512\ttotal: 18m 36s\tremaining: 7m 31s\n",
      "7123:\tlearn: 0.0520512\ttotal: 18m 37s\tremaining: 7m 30s\n",
      "7124:\tlearn: 0.0520512\ttotal: 18m 37s\tremaining: 7m 30s\n",
      "7125:\tlearn: 0.0520512\ttotal: 18m 37s\tremaining: 7m 30s\n",
      "7126:\tlearn: 0.0520512\ttotal: 18m 37s\tremaining: 7m 30s\n",
      "7127:\tlearn: 0.0520512\ttotal: 18m 37s\tremaining: 7m 30s\n",
      "7128:\tlearn: 0.0520512\ttotal: 18m 37s\tremaining: 7m 30s\n",
      "7129:\tlearn: 0.0520512\ttotal: 18m 38s\tremaining: 7m 30s\n",
      "7130:\tlearn: 0.0520512\ttotal: 18m 38s\tremaining: 7m 29s\n",
      "7131:\tlearn: 0.0520512\ttotal: 18m 38s\tremaining: 7m 29s\n",
      "7132:\tlearn: 0.0520512\ttotal: 18m 38s\tremaining: 7m 29s\n",
      "7133:\tlearn: 0.0520512\ttotal: 18m 38s\tremaining: 7m 29s\n",
      "7134:\tlearn: 0.0520512\ttotal: 18m 38s\tremaining: 7m 29s\n",
      "7135:\tlearn: 0.0520512\ttotal: 18m 38s\tremaining: 7m 29s\n",
      "7136:\tlearn: 0.0520512\ttotal: 18m 39s\tremaining: 7m 28s\n",
      "7137:\tlearn: 0.0520512\ttotal: 18m 39s\tremaining: 7m 28s\n",
      "7138:\tlearn: 0.0520512\ttotal: 18m 39s\tremaining: 7m 28s\n",
      "7139:\tlearn: 0.0520512\ttotal: 18m 39s\tremaining: 7m 28s\n",
      "7140:\tlearn: 0.0520512\ttotal: 18m 39s\tremaining: 7m 28s\n",
      "7141:\tlearn: 0.0520512\ttotal: 18m 39s\tremaining: 7m 28s\n",
      "7142:\tlearn: 0.0520512\ttotal: 18m 40s\tremaining: 7m 28s\n",
      "7143:\tlearn: 0.0520512\ttotal: 18m 40s\tremaining: 7m 27s\n",
      "7144:\tlearn: 0.0520512\ttotal: 18m 40s\tremaining: 7m 27s\n",
      "7145:\tlearn: 0.0520512\ttotal: 18m 40s\tremaining: 7m 27s\n",
      "7146:\tlearn: 0.0520512\ttotal: 18m 40s\tremaining: 7m 27s\n",
      "7147:\tlearn: 0.0520512\ttotal: 18m 40s\tremaining: 7m 27s\n",
      "7148:\tlearn: 0.0520512\ttotal: 18m 41s\tremaining: 7m 27s\n",
      "7149:\tlearn: 0.0520512\ttotal: 18m 41s\tremaining: 7m 26s\n",
      "7150:\tlearn: 0.0520512\ttotal: 18m 41s\tremaining: 7m 26s\n",
      "7151:\tlearn: 0.0520512\ttotal: 18m 41s\tremaining: 7m 26s\n",
      "7152:\tlearn: 0.0520512\ttotal: 18m 41s\tremaining: 7m 26s\n",
      "7153:\tlearn: 0.0520512\ttotal: 18m 41s\tremaining: 7m 26s\n",
      "7154:\tlearn: 0.0520512\ttotal: 18m 41s\tremaining: 7m 26s\n",
      "7155:\tlearn: 0.0520512\ttotal: 18m 42s\tremaining: 7m 25s\n",
      "7156:\tlearn: 0.0520512\ttotal: 18m 42s\tremaining: 7m 25s\n",
      "7157:\tlearn: 0.0520512\ttotal: 18m 42s\tremaining: 7m 25s\n",
      "7158:\tlearn: 0.0520512\ttotal: 18m 42s\tremaining: 7m 25s\n",
      "7159:\tlearn: 0.0520512\ttotal: 18m 42s\tremaining: 7m 25s\n",
      "7160:\tlearn: 0.0520512\ttotal: 18m 43s\tremaining: 7m 25s\n",
      "7161:\tlearn: 0.0520512\ttotal: 18m 43s\tremaining: 7m 25s\n",
      "7162:\tlearn: 0.0520512\ttotal: 18m 43s\tremaining: 7m 24s\n",
      "7163:\tlearn: 0.0520512\ttotal: 18m 43s\tremaining: 7m 24s\n",
      "7164:\tlearn: 0.0520512\ttotal: 18m 43s\tremaining: 7m 24s\n",
      "7165:\tlearn: 0.0520512\ttotal: 18m 43s\tremaining: 7m 24s\n",
      "7166:\tlearn: 0.0520512\ttotal: 18m 44s\tremaining: 7m 24s\n",
      "7167:\tlearn: 0.0520512\ttotal: 18m 44s\tremaining: 7m 24s\n",
      "7168:\tlearn: 0.0520512\ttotal: 18m 44s\tremaining: 7m 24s\n",
      "7169:\tlearn: 0.0520512\ttotal: 18m 44s\tremaining: 7m 23s\n",
      "7170:\tlearn: 0.0520512\ttotal: 18m 44s\tremaining: 7m 23s\n",
      "7171:\tlearn: 0.0520512\ttotal: 18m 44s\tremaining: 7m 23s\n",
      "7172:\tlearn: 0.0520512\ttotal: 18m 45s\tremaining: 7m 23s\n",
      "7173:\tlearn: 0.0520512\ttotal: 18m 45s\tremaining: 7m 23s\n",
      "7174:\tlearn: 0.0520512\ttotal: 18m 45s\tremaining: 7m 23s\n",
      "7175:\tlearn: 0.0520512\ttotal: 18m 45s\tremaining: 7m 22s\n",
      "7176:\tlearn: 0.0520512\ttotal: 18m 45s\tremaining: 7m 22s\n",
      "7177:\tlearn: 0.0520512\ttotal: 18m 45s\tremaining: 7m 22s\n",
      "7178:\tlearn: 0.0520512\ttotal: 18m 46s\tremaining: 7m 22s\n",
      "7179:\tlearn: 0.0520512\ttotal: 18m 46s\tremaining: 7m 22s\n",
      "7180:\tlearn: 0.0520512\ttotal: 18m 46s\tremaining: 7m 22s\n",
      "7181:\tlearn: 0.0520512\ttotal: 18m 46s\tremaining: 7m 22s\n",
      "7182:\tlearn: 0.0520512\ttotal: 18m 46s\tremaining: 7m 21s\n",
      "7183:\tlearn: 0.0520512\ttotal: 18m 46s\tremaining: 7m 21s\n",
      "7184:\tlearn: 0.0520512\ttotal: 18m 47s\tremaining: 7m 21s\n",
      "7185:\tlearn: 0.0520512\ttotal: 18m 47s\tremaining: 7m 21s\n",
      "7186:\tlearn: 0.0520512\ttotal: 18m 47s\tremaining: 7m 21s\n",
      "7187:\tlearn: 0.0520512\ttotal: 18m 47s\tremaining: 7m 21s\n",
      "7188:\tlearn: 0.0520512\ttotal: 18m 47s\tremaining: 7m 20s\n",
      "7189:\tlearn: 0.0520512\ttotal: 18m 48s\tremaining: 7m 20s\n",
      "7190:\tlearn: 0.0520512\ttotal: 18m 48s\tremaining: 7m 20s\n",
      "7191:\tlearn: 0.0520512\ttotal: 18m 48s\tremaining: 7m 20s\n",
      "7192:\tlearn: 0.0520512\ttotal: 18m 48s\tremaining: 7m 20s\n",
      "7193:\tlearn: 0.0520512\ttotal: 18m 48s\tremaining: 7m 20s\n",
      "7194:\tlearn: 0.0520512\ttotal: 18m 48s\tremaining: 7m 20s\n",
      "7195:\tlearn: 0.0520512\ttotal: 18m 49s\tremaining: 7m 19s\n",
      "7196:\tlearn: 0.0520512\ttotal: 18m 49s\tremaining: 7m 19s\n",
      "7197:\tlearn: 0.0520512\ttotal: 18m 49s\tremaining: 7m 19s\n",
      "7198:\tlearn: 0.0520512\ttotal: 18m 49s\tremaining: 7m 19s\n",
      "7199:\tlearn: 0.0520512\ttotal: 18m 49s\tremaining: 7m 19s\n",
      "7200:\tlearn: 0.0520512\ttotal: 18m 49s\tremaining: 7m 19s\n",
      "7201:\tlearn: 0.0520512\ttotal: 18m 50s\tremaining: 7m 19s\n",
      "7202:\tlearn: 0.0520512\ttotal: 18m 50s\tremaining: 7m 18s\n",
      "7203:\tlearn: 0.0520512\ttotal: 18m 50s\tremaining: 7m 18s\n",
      "7204:\tlearn: 0.0520512\ttotal: 18m 50s\tremaining: 7m 18s\n",
      "7205:\tlearn: 0.0520512\ttotal: 18m 50s\tremaining: 7m 18s\n",
      "7206:\tlearn: 0.0520512\ttotal: 18m 50s\tremaining: 7m 18s\n",
      "7207:\tlearn: 0.0520512\ttotal: 18m 51s\tremaining: 7m 18s\n",
      "7208:\tlearn: 0.0520512\ttotal: 18m 51s\tremaining: 7m 17s\n",
      "7209:\tlearn: 0.0520512\ttotal: 18m 51s\tremaining: 7m 17s\n",
      "7210:\tlearn: 0.0520512\ttotal: 18m 51s\tremaining: 7m 17s\n",
      "7211:\tlearn: 0.0520512\ttotal: 18m 51s\tremaining: 7m 17s\n",
      "7212:\tlearn: 0.0520512\ttotal: 18m 51s\tremaining: 7m 17s\n",
      "7213:\tlearn: 0.0520512\ttotal: 18m 51s\tremaining: 7m 17s\n",
      "7214:\tlearn: 0.0520512\ttotal: 18m 52s\tremaining: 7m 17s\n",
      "7215:\tlearn: 0.0520512\ttotal: 18m 52s\tremaining: 7m 16s\n",
      "7216:\tlearn: 0.0520512\ttotal: 18m 52s\tremaining: 7m 16s\n",
      "7217:\tlearn: 0.0520512\ttotal: 18m 52s\tremaining: 7m 16s\n",
      "7218:\tlearn: 0.0520512\ttotal: 18m 52s\tremaining: 7m 16s\n",
      "7219:\tlearn: 0.0520512\ttotal: 18m 52s\tremaining: 7m 16s\n",
      "7220:\tlearn: 0.0520512\ttotal: 18m 53s\tremaining: 7m 16s\n",
      "7221:\tlearn: 0.0520512\ttotal: 18m 53s\tremaining: 7m 15s\n",
      "7222:\tlearn: 0.0520512\ttotal: 18m 53s\tremaining: 7m 15s\n",
      "7223:\tlearn: 0.0520512\ttotal: 18m 53s\tremaining: 7m 15s\n",
      "7224:\tlearn: 0.0520512\ttotal: 18m 53s\tremaining: 7m 15s\n",
      "7225:\tlearn: 0.0520512\ttotal: 18m 53s\tremaining: 7m 15s\n",
      "7226:\tlearn: 0.0520512\ttotal: 18m 54s\tremaining: 7m 15s\n",
      "7227:\tlearn: 0.0520512\ttotal: 18m 54s\tremaining: 7m 14s\n",
      "7228:\tlearn: 0.0520512\ttotal: 18m 54s\tremaining: 7m 14s\n",
      "7229:\tlearn: 0.0520512\ttotal: 18m 54s\tremaining: 7m 14s\n",
      "7230:\tlearn: 0.0520512\ttotal: 18m 54s\tremaining: 7m 14s\n",
      "7231:\tlearn: 0.0520512\ttotal: 18m 54s\tremaining: 7m 14s\n",
      "7232:\tlearn: 0.0520512\ttotal: 18m 55s\tremaining: 7m 14s\n",
      "7233:\tlearn: 0.0520512\ttotal: 18m 55s\tremaining: 7m 14s\n",
      "7234:\tlearn: 0.0520512\ttotal: 18m 55s\tremaining: 7m 13s\n",
      "7235:\tlearn: 0.0520512\ttotal: 18m 55s\tremaining: 7m 13s\n",
      "7236:\tlearn: 0.0520512\ttotal: 18m 55s\tremaining: 7m 13s\n",
      "7237:\tlearn: 0.0520512\ttotal: 18m 55s\tremaining: 7m 13s\n",
      "7238:\tlearn: 0.0520512\ttotal: 18m 56s\tremaining: 7m 13s\n",
      "7239:\tlearn: 0.0520512\ttotal: 18m 56s\tremaining: 7m 13s\n",
      "7240:\tlearn: 0.0520512\ttotal: 18m 56s\tremaining: 7m 12s\n",
      "7241:\tlearn: 0.0520512\ttotal: 18m 56s\tremaining: 7m 12s\n",
      "7242:\tlearn: 0.0520512\ttotal: 18m 56s\tremaining: 7m 12s\n",
      "7243:\tlearn: 0.0520512\ttotal: 18m 56s\tremaining: 7m 12s\n",
      "7244:\tlearn: 0.0520512\ttotal: 18m 56s\tremaining: 7m 12s\n",
      "7245:\tlearn: 0.0520512\ttotal: 18m 57s\tremaining: 7m 12s\n",
      "7246:\tlearn: 0.0520512\ttotal: 18m 57s\tremaining: 7m 12s\n",
      "7247:\tlearn: 0.0520512\ttotal: 18m 57s\tremaining: 7m 11s\n",
      "7248:\tlearn: 0.0520512\ttotal: 18m 57s\tremaining: 7m 11s\n",
      "7249:\tlearn: 0.0520512\ttotal: 18m 57s\tremaining: 7m 11s\n",
      "7250:\tlearn: 0.0520512\ttotal: 18m 57s\tremaining: 7m 11s\n",
      "7251:\tlearn: 0.0520512\ttotal: 18m 58s\tremaining: 7m 11s\n",
      "7252:\tlearn: 0.0520512\ttotal: 18m 58s\tremaining: 7m 11s\n",
      "7253:\tlearn: 0.0520512\ttotal: 18m 58s\tremaining: 7m 10s\n",
      "7254:\tlearn: 0.0520512\ttotal: 18m 58s\tremaining: 7m 10s\n",
      "7255:\tlearn: 0.0520512\ttotal: 18m 58s\tremaining: 7m 10s\n",
      "7256:\tlearn: 0.0520512\ttotal: 18m 58s\tremaining: 7m 10s\n",
      "7257:\tlearn: 0.0520512\ttotal: 18m 59s\tremaining: 7m 10s\n",
      "7258:\tlearn: 0.0520512\ttotal: 18m 59s\tremaining: 7m 10s\n",
      "7259:\tlearn: 0.0520512\ttotal: 18m 59s\tremaining: 7m 10s\n",
      "7260:\tlearn: 0.0520512\ttotal: 18m 59s\tremaining: 7m 9s\n",
      "7261:\tlearn: 0.0520512\ttotal: 18m 59s\tremaining: 7m 9s\n",
      "7262:\tlearn: 0.0520512\ttotal: 18m 59s\tremaining: 7m 9s\n",
      "7263:\tlearn: 0.0520512\ttotal: 19m\tremaining: 7m 9s\n",
      "7264:\tlearn: 0.0520512\ttotal: 19m\tremaining: 7m 9s\n",
      "7265:\tlearn: 0.0520512\ttotal: 19m\tremaining: 7m 9s\n",
      "7266:\tlearn: 0.0520512\ttotal: 19m\tremaining: 7m 8s\n",
      "7267:\tlearn: 0.0520512\ttotal: 19m\tremaining: 7m 8s\n",
      "7268:\tlearn: 0.0520512\ttotal: 19m\tremaining: 7m 8s\n",
      "7269:\tlearn: 0.0520512\ttotal: 19m\tremaining: 7m 8s\n",
      "7270:\tlearn: 0.0520512\ttotal: 19m 1s\tremaining: 7m 8s\n",
      "7271:\tlearn: 0.0520512\ttotal: 19m 1s\tremaining: 7m 8s\n",
      "7272:\tlearn: 0.0520512\ttotal: 19m 1s\tremaining: 7m 7s\n",
      "7273:\tlearn: 0.0520512\ttotal: 19m 1s\tremaining: 7m 7s\n",
      "7274:\tlearn: 0.0520512\ttotal: 19m 1s\tremaining: 7m 7s\n",
      "7275:\tlearn: 0.0520512\ttotal: 19m 1s\tremaining: 7m 7s\n",
      "7276:\tlearn: 0.0520512\ttotal: 19m 2s\tremaining: 7m 7s\n",
      "7277:\tlearn: 0.0520512\ttotal: 19m 2s\tremaining: 7m 7s\n",
      "7278:\tlearn: 0.0520512\ttotal: 19m 2s\tremaining: 7m 7s\n",
      "7279:\tlearn: 0.0520512\ttotal: 19m 2s\tremaining: 7m 6s\n",
      "7280:\tlearn: 0.0520512\ttotal: 19m 2s\tremaining: 7m 6s\n",
      "7281:\tlearn: 0.0520512\ttotal: 19m 2s\tremaining: 7m 6s\n",
      "7282:\tlearn: 0.0520512\ttotal: 19m 3s\tremaining: 7m 6s\n",
      "7283:\tlearn: 0.0520512\ttotal: 19m 3s\tremaining: 7m 6s\n",
      "7284:\tlearn: 0.0520512\ttotal: 19m 3s\tremaining: 7m 6s\n",
      "7285:\tlearn: 0.0520512\ttotal: 19m 3s\tremaining: 7m 5s\n",
      "7286:\tlearn: 0.0520512\ttotal: 19m 3s\tremaining: 7m 5s\n",
      "7287:\tlearn: 0.0520512\ttotal: 19m 3s\tremaining: 7m 5s\n",
      "7288:\tlearn: 0.0520512\ttotal: 19m 4s\tremaining: 7m 5s\n",
      "7289:\tlearn: 0.0520512\ttotal: 19m 4s\tremaining: 7m 5s\n",
      "7290:\tlearn: 0.0520512\ttotal: 19m 4s\tremaining: 7m 5s\n",
      "7291:\tlearn: 0.0520512\ttotal: 19m 4s\tremaining: 7m 5s\n",
      "7292:\tlearn: 0.0520512\ttotal: 19m 4s\tremaining: 7m 4s\n",
      "7293:\tlearn: 0.0520512\ttotal: 19m 4s\tremaining: 7m 4s\n",
      "7294:\tlearn: 0.0520512\ttotal: 19m 4s\tremaining: 7m 4s\n",
      "7295:\tlearn: 0.0520512\ttotal: 19m 5s\tremaining: 7m 4s\n",
      "7296:\tlearn: 0.0520512\ttotal: 19m 5s\tremaining: 7m 4s\n",
      "7297:\tlearn: 0.0520512\ttotal: 19m 5s\tremaining: 7m 4s\n",
      "7298:\tlearn: 0.0520512\ttotal: 19m 5s\tremaining: 7m 3s\n",
      "7299:\tlearn: 0.0520512\ttotal: 19m 5s\tremaining: 7m 3s\n",
      "7300:\tlearn: 0.0520512\ttotal: 19m 5s\tremaining: 7m 3s\n",
      "7301:\tlearn: 0.0520512\ttotal: 19m 6s\tremaining: 7m 3s\n",
      "7302:\tlearn: 0.0520512\ttotal: 19m 6s\tremaining: 7m 3s\n",
      "7303:\tlearn: 0.0520512\ttotal: 19m 6s\tremaining: 7m 3s\n",
      "7304:\tlearn: 0.0520512\ttotal: 19m 6s\tremaining: 7m 3s\n",
      "7305:\tlearn: 0.0520512\ttotal: 19m 6s\tremaining: 7m 2s\n",
      "7306:\tlearn: 0.0520512\ttotal: 19m 6s\tremaining: 7m 2s\n",
      "7307:\tlearn: 0.0520512\ttotal: 19m 7s\tremaining: 7m 2s\n",
      "7308:\tlearn: 0.0520512\ttotal: 19m 7s\tremaining: 7m 2s\n",
      "7309:\tlearn: 0.0520512\ttotal: 19m 7s\tremaining: 7m 2s\n",
      "7310:\tlearn: 0.0520512\ttotal: 19m 7s\tremaining: 7m 2s\n",
      "7311:\tlearn: 0.0520512\ttotal: 19m 7s\tremaining: 7m 1s\n",
      "7312:\tlearn: 0.0520512\ttotal: 19m 7s\tremaining: 7m 1s\n",
      "7313:\tlearn: 0.0520512\ttotal: 19m 8s\tremaining: 7m 1s\n",
      "7314:\tlearn: 0.0520512\ttotal: 19m 8s\tremaining: 7m 1s\n",
      "7315:\tlearn: 0.0520512\ttotal: 19m 8s\tremaining: 7m 1s\n",
      "7316:\tlearn: 0.0520512\ttotal: 19m 8s\tremaining: 7m 1s\n",
      "7317:\tlearn: 0.0520512\ttotal: 19m 8s\tremaining: 7m\n",
      "7318:\tlearn: 0.0520512\ttotal: 19m 8s\tremaining: 7m\n",
      "7319:\tlearn: 0.0520512\ttotal: 19m 9s\tremaining: 7m\n",
      "7320:\tlearn: 0.0520512\ttotal: 19m 9s\tremaining: 7m\n",
      "7321:\tlearn: 0.0520512\ttotal: 19m 9s\tremaining: 7m\n",
      "7322:\tlearn: 0.0520512\ttotal: 19m 9s\tremaining: 7m\n",
      "7323:\tlearn: 0.0520512\ttotal: 19m 9s\tremaining: 7m\n",
      "7324:\tlearn: 0.0520512\ttotal: 19m 9s\tremaining: 6m 59s\n",
      "7325:\tlearn: 0.0520512\ttotal: 19m 10s\tremaining: 6m 59s\n",
      "7326:\tlearn: 0.0520512\ttotal: 19m 10s\tremaining: 6m 59s\n",
      "7327:\tlearn: 0.0520512\ttotal: 19m 10s\tremaining: 6m 59s\n",
      "7328:\tlearn: 0.0520512\ttotal: 19m 10s\tremaining: 6m 59s\n",
      "7329:\tlearn: 0.0520512\ttotal: 19m 10s\tremaining: 6m 59s\n",
      "7330:\tlearn: 0.0520512\ttotal: 19m 10s\tremaining: 6m 58s\n",
      "7331:\tlearn: 0.0520512\ttotal: 19m 10s\tremaining: 6m 58s\n",
      "7332:\tlearn: 0.0520512\ttotal: 19m 11s\tremaining: 6m 58s\n",
      "7333:\tlearn: 0.0520512\ttotal: 19m 11s\tremaining: 6m 58s\n",
      "7334:\tlearn: 0.0520512\ttotal: 19m 11s\tremaining: 6m 58s\n",
      "7335:\tlearn: 0.0520512\ttotal: 19m 11s\tremaining: 6m 58s\n",
      "7336:\tlearn: 0.0520512\ttotal: 19m 11s\tremaining: 6m 58s\n",
      "7337:\tlearn: 0.0520512\ttotal: 19m 12s\tremaining: 6m 57s\n",
      "7338:\tlearn: 0.0520512\ttotal: 19m 12s\tremaining: 6m 57s\n",
      "7339:\tlearn: 0.0520512\ttotal: 19m 12s\tremaining: 6m 57s\n",
      "7340:\tlearn: 0.0520512\ttotal: 19m 12s\tremaining: 6m 57s\n",
      "7341:\tlearn: 0.0520512\ttotal: 19m 12s\tremaining: 6m 57s\n",
      "7342:\tlearn: 0.0520512\ttotal: 19m 12s\tremaining: 6m 57s\n",
      "7343:\tlearn: 0.0520512\ttotal: 19m 13s\tremaining: 6m 57s\n",
      "7344:\tlearn: 0.0520512\ttotal: 19m 13s\tremaining: 6m 56s\n",
      "7345:\tlearn: 0.0520512\ttotal: 19m 13s\tremaining: 6m 56s\n",
      "7346:\tlearn: 0.0520512\ttotal: 19m 13s\tremaining: 6m 56s\n",
      "7347:\tlearn: 0.0520512\ttotal: 19m 13s\tremaining: 6m 56s\n",
      "7348:\tlearn: 0.0520512\ttotal: 19m 13s\tremaining: 6m 56s\n",
      "7349:\tlearn: 0.0520512\ttotal: 19m 14s\tremaining: 6m 56s\n",
      "7350:\tlearn: 0.0520512\ttotal: 19m 14s\tremaining: 6m 55s\n",
      "7351:\tlearn: 0.0520512\ttotal: 19m 14s\tremaining: 6m 55s\n",
      "7352:\tlearn: 0.0520512\ttotal: 19m 14s\tremaining: 6m 55s\n",
      "7353:\tlearn: 0.0520512\ttotal: 19m 14s\tremaining: 6m 55s\n",
      "7354:\tlearn: 0.0520512\ttotal: 19m 14s\tremaining: 6m 55s\n",
      "7355:\tlearn: 0.0520512\ttotal: 19m 15s\tremaining: 6m 55s\n",
      "7356:\tlearn: 0.0520512\ttotal: 19m 15s\tremaining: 6m 54s\n",
      "7357:\tlearn: 0.0520512\ttotal: 19m 15s\tremaining: 6m 54s\n",
      "7358:\tlearn: 0.0520512\ttotal: 19m 15s\tremaining: 6m 54s\n",
      "7359:\tlearn: 0.0520512\ttotal: 19m 15s\tremaining: 6m 54s\n",
      "7360:\tlearn: 0.0520512\ttotal: 19m 15s\tremaining: 6m 54s\n",
      "7361:\tlearn: 0.0520512\ttotal: 19m 15s\tremaining: 6m 54s\n",
      "7362:\tlearn: 0.0520512\ttotal: 19m 16s\tremaining: 6m 54s\n",
      "7363:\tlearn: 0.0520512\ttotal: 19m 16s\tremaining: 6m 53s\n",
      "7364:\tlearn: 0.0520512\ttotal: 19m 16s\tremaining: 6m 53s\n",
      "7365:\tlearn: 0.0520512\ttotal: 19m 16s\tremaining: 6m 53s\n",
      "7366:\tlearn: 0.0520512\ttotal: 19m 16s\tremaining: 6m 53s\n",
      "7367:\tlearn: 0.0520512\ttotal: 19m 16s\tremaining: 6m 53s\n",
      "7368:\tlearn: 0.0520512\ttotal: 19m 17s\tremaining: 6m 53s\n",
      "7369:\tlearn: 0.0520512\ttotal: 19m 17s\tremaining: 6m 52s\n",
      "7370:\tlearn: 0.0520512\ttotal: 19m 17s\tremaining: 6m 52s\n",
      "7371:\tlearn: 0.0520512\ttotal: 19m 17s\tremaining: 6m 52s\n",
      "7372:\tlearn: 0.0520512\ttotal: 19m 17s\tremaining: 6m 52s\n",
      "7373:\tlearn: 0.0520512\ttotal: 19m 17s\tremaining: 6m 52s\n",
      "7374:\tlearn: 0.0520512\ttotal: 19m 18s\tremaining: 6m 52s\n",
      "7375:\tlearn: 0.0520512\ttotal: 19m 18s\tremaining: 6m 52s\n",
      "7376:\tlearn: 0.0520512\ttotal: 19m 18s\tremaining: 6m 51s\n",
      "7377:\tlearn: 0.0520512\ttotal: 19m 18s\tremaining: 6m 51s\n",
      "7378:\tlearn: 0.0520512\ttotal: 19m 18s\tremaining: 6m 51s\n",
      "7379:\tlearn: 0.0520512\ttotal: 19m 18s\tremaining: 6m 51s\n",
      "7380:\tlearn: 0.0520512\ttotal: 19m 19s\tremaining: 6m 51s\n",
      "7381:\tlearn: 0.0520512\ttotal: 19m 19s\tremaining: 6m 51s\n",
      "7382:\tlearn: 0.0520512\ttotal: 19m 19s\tremaining: 6m 50s\n",
      "7383:\tlearn: 0.0520512\ttotal: 19m 19s\tremaining: 6m 50s\n",
      "7384:\tlearn: 0.0520512\ttotal: 19m 19s\tremaining: 6m 50s\n",
      "7385:\tlearn: 0.0520512\ttotal: 19m 19s\tremaining: 6m 50s\n",
      "7386:\tlearn: 0.0520512\ttotal: 19m 20s\tremaining: 6m 50s\n",
      "7387:\tlearn: 0.0520512\ttotal: 19m 20s\tremaining: 6m 50s\n",
      "7388:\tlearn: 0.0520512\ttotal: 19m 20s\tremaining: 6m 50s\n",
      "7389:\tlearn: 0.0520512\ttotal: 19m 20s\tremaining: 6m 49s\n",
      "7390:\tlearn: 0.0520512\ttotal: 19m 20s\tremaining: 6m 49s\n",
      "7391:\tlearn: 0.0520512\ttotal: 19m 20s\tremaining: 6m 49s\n",
      "7392:\tlearn: 0.0520512\ttotal: 19m 21s\tremaining: 6m 49s\n",
      "7393:\tlearn: 0.0520512\ttotal: 19m 21s\tremaining: 6m 49s\n",
      "7394:\tlearn: 0.0520512\ttotal: 19m 21s\tremaining: 6m 49s\n",
      "7395:\tlearn: 0.0520512\ttotal: 19m 21s\tremaining: 6m 48s\n",
      "7396:\tlearn: 0.0520512\ttotal: 19m 21s\tremaining: 6m 48s\n",
      "7397:\tlearn: 0.0520512\ttotal: 19m 21s\tremaining: 6m 48s\n",
      "7398:\tlearn: 0.0520512\ttotal: 19m 22s\tremaining: 6m 48s\n",
      "7399:\tlearn: 0.0520512\ttotal: 19m 22s\tremaining: 6m 48s\n",
      "7400:\tlearn: 0.0520512\ttotal: 19m 22s\tremaining: 6m 48s\n",
      "7401:\tlearn: 0.0520512\ttotal: 19m 22s\tremaining: 6m 48s\n",
      "7402:\tlearn: 0.0520512\ttotal: 19m 22s\tremaining: 6m 47s\n",
      "7403:\tlearn: 0.0520512\ttotal: 19m 22s\tremaining: 6m 47s\n",
      "7404:\tlearn: 0.0520512\ttotal: 19m 23s\tremaining: 6m 47s\n",
      "7405:\tlearn: 0.0520512\ttotal: 19m 23s\tremaining: 6m 47s\n",
      "7406:\tlearn: 0.0520512\ttotal: 19m 23s\tremaining: 6m 47s\n",
      "7407:\tlearn: 0.0520512\ttotal: 19m 23s\tremaining: 6m 47s\n",
      "7408:\tlearn: 0.0520512\ttotal: 19m 23s\tremaining: 6m 46s\n",
      "7409:\tlearn: 0.0520512\ttotal: 19m 23s\tremaining: 6m 46s\n",
      "7410:\tlearn: 0.0520512\ttotal: 19m 24s\tremaining: 6m 46s\n",
      "7411:\tlearn: 0.0520512\ttotal: 19m 24s\tremaining: 6m 46s\n",
      "7412:\tlearn: 0.0520512\ttotal: 19m 24s\tremaining: 6m 46s\n",
      "7413:\tlearn: 0.0520512\ttotal: 19m 24s\tremaining: 6m 46s\n",
      "7414:\tlearn: 0.0520512\ttotal: 19m 24s\tremaining: 6m 46s\n",
      "7415:\tlearn: 0.0520512\ttotal: 19m 24s\tremaining: 6m 45s\n",
      "7416:\tlearn: 0.0520512\ttotal: 19m 25s\tremaining: 6m 45s\n",
      "7417:\tlearn: 0.0520512\ttotal: 19m 25s\tremaining: 6m 45s\n",
      "7418:\tlearn: 0.0520512\ttotal: 19m 25s\tremaining: 6m 45s\n",
      "7419:\tlearn: 0.0520512\ttotal: 19m 25s\tremaining: 6m 45s\n",
      "7420:\tlearn: 0.0520512\ttotal: 19m 25s\tremaining: 6m 45s\n",
      "7421:\tlearn: 0.0520512\ttotal: 19m 25s\tremaining: 6m 44s\n",
      "7422:\tlearn: 0.0520512\ttotal: 19m 26s\tremaining: 6m 44s\n",
      "7423:\tlearn: 0.0520512\ttotal: 19m 26s\tremaining: 6m 44s\n",
      "7424:\tlearn: 0.0520512\ttotal: 19m 26s\tremaining: 6m 44s\n",
      "7425:\tlearn: 0.0520512\ttotal: 19m 26s\tremaining: 6m 44s\n",
      "7426:\tlearn: 0.0520512\ttotal: 19m 26s\tremaining: 6m 44s\n",
      "7427:\tlearn: 0.0520512\ttotal: 19m 26s\tremaining: 6m 44s\n",
      "7428:\tlearn: 0.0520512\ttotal: 19m 27s\tremaining: 6m 43s\n",
      "7429:\tlearn: 0.0520512\ttotal: 19m 27s\tremaining: 6m 43s\n",
      "7430:\tlearn: 0.0520512\ttotal: 19m 27s\tremaining: 6m 43s\n",
      "7431:\tlearn: 0.0520512\ttotal: 19m 27s\tremaining: 6m 43s\n",
      "7432:\tlearn: 0.0520512\ttotal: 19m 27s\tremaining: 6m 43s\n",
      "7433:\tlearn: 0.0520512\ttotal: 19m 27s\tremaining: 6m 43s\n",
      "7434:\tlearn: 0.0520512\ttotal: 19m 28s\tremaining: 6m 42s\n",
      "7435:\tlearn: 0.0520512\ttotal: 19m 28s\tremaining: 6m 42s\n",
      "7436:\tlearn: 0.0520512\ttotal: 19m 28s\tremaining: 6m 42s\n",
      "7437:\tlearn: 0.0520512\ttotal: 19m 28s\tremaining: 6m 42s\n",
      "7438:\tlearn: 0.0520512\ttotal: 19m 28s\tremaining: 6m 42s\n",
      "7439:\tlearn: 0.0520512\ttotal: 19m 28s\tremaining: 6m 42s\n",
      "7440:\tlearn: 0.0520512\ttotal: 19m 29s\tremaining: 6m 42s\n",
      "7441:\tlearn: 0.0520512\ttotal: 19m 29s\tremaining: 6m 41s\n",
      "7442:\tlearn: 0.0520512\ttotal: 19m 29s\tremaining: 6m 41s\n",
      "7443:\tlearn: 0.0520512\ttotal: 19m 29s\tremaining: 6m 41s\n",
      "7444:\tlearn: 0.0520512\ttotal: 19m 29s\tremaining: 6m 41s\n",
      "7445:\tlearn: 0.0520512\ttotal: 19m 29s\tremaining: 6m 41s\n",
      "7446:\tlearn: 0.0520512\ttotal: 19m 30s\tremaining: 6m 41s\n",
      "7447:\tlearn: 0.0520512\ttotal: 19m 30s\tremaining: 6m 40s\n",
      "7448:\tlearn: 0.0520512\ttotal: 19m 30s\tremaining: 6m 40s\n",
      "7449:\tlearn: 0.0520512\ttotal: 19m 30s\tremaining: 6m 40s\n",
      "7450:\tlearn: 0.0520512\ttotal: 19m 30s\tremaining: 6m 40s\n",
      "7451:\tlearn: 0.0520512\ttotal: 19m 30s\tremaining: 6m 40s\n",
      "7452:\tlearn: 0.0520512\ttotal: 19m 31s\tremaining: 6m 40s\n",
      "7453:\tlearn: 0.0520512\ttotal: 19m 31s\tremaining: 6m 40s\n",
      "7454:\tlearn: 0.0520512\ttotal: 19m 31s\tremaining: 6m 39s\n",
      "7455:\tlearn: 0.0520512\ttotal: 19m 31s\tremaining: 6m 39s\n",
      "7456:\tlearn: 0.0520512\ttotal: 19m 31s\tremaining: 6m 39s\n",
      "7457:\tlearn: 0.0520512\ttotal: 19m 31s\tremaining: 6m 39s\n",
      "7458:\tlearn: 0.0520512\ttotal: 19m 31s\tremaining: 6m 39s\n",
      "7459:\tlearn: 0.0520512\ttotal: 19m 32s\tremaining: 6m 39s\n",
      "7460:\tlearn: 0.0520512\ttotal: 19m 32s\tremaining: 6m 38s\n",
      "7461:\tlearn: 0.0520512\ttotal: 19m 32s\tremaining: 6m 38s\n",
      "7462:\tlearn: 0.0520512\ttotal: 19m 32s\tremaining: 6m 38s\n",
      "7463:\tlearn: 0.0520512\ttotal: 19m 32s\tremaining: 6m 38s\n",
      "7464:\tlearn: 0.0520512\ttotal: 19m 32s\tremaining: 6m 38s\n",
      "7465:\tlearn: 0.0520512\ttotal: 19m 33s\tremaining: 6m 38s\n",
      "7466:\tlearn: 0.0520512\ttotal: 19m 33s\tremaining: 6m 38s\n",
      "7467:\tlearn: 0.0520512\ttotal: 19m 33s\tremaining: 6m 37s\n",
      "7468:\tlearn: 0.0520512\ttotal: 19m 33s\tremaining: 6m 37s\n",
      "7469:\tlearn: 0.0520512\ttotal: 19m 33s\tremaining: 6m 37s\n",
      "7470:\tlearn: 0.0520512\ttotal: 19m 33s\tremaining: 6m 37s\n",
      "7471:\tlearn: 0.0520512\ttotal: 19m 34s\tremaining: 6m 37s\n",
      "7472:\tlearn: 0.0520512\ttotal: 19m 34s\tremaining: 6m 37s\n",
      "7473:\tlearn: 0.0520512\ttotal: 19m 34s\tremaining: 6m 36s\n",
      "7474:\tlearn: 0.0520512\ttotal: 19m 34s\tremaining: 6m 36s\n",
      "7475:\tlearn: 0.0520512\ttotal: 19m 34s\tremaining: 6m 36s\n",
      "7476:\tlearn: 0.0520512\ttotal: 19m 35s\tremaining: 6m 36s\n",
      "7477:\tlearn: 0.0520512\ttotal: 19m 35s\tremaining: 6m 36s\n",
      "7478:\tlearn: 0.0520512\ttotal: 19m 35s\tremaining: 6m 36s\n",
      "7479:\tlearn: 0.0520512\ttotal: 19m 35s\tremaining: 6m 36s\n",
      "7480:\tlearn: 0.0520512\ttotal: 19m 35s\tremaining: 6m 35s\n",
      "7481:\tlearn: 0.0520512\ttotal: 19m 35s\tremaining: 6m 35s\n",
      "7482:\tlearn: 0.0520512\ttotal: 19m 36s\tremaining: 6m 35s\n",
      "7483:\tlearn: 0.0520512\ttotal: 19m 36s\tremaining: 6m 35s\n",
      "7484:\tlearn: 0.0520512\ttotal: 19m 36s\tremaining: 6m 35s\n",
      "7485:\tlearn: 0.0520512\ttotal: 19m 36s\tremaining: 6m 35s\n",
      "7486:\tlearn: 0.0520512\ttotal: 19m 36s\tremaining: 6m 34s\n",
      "7487:\tlearn: 0.0520512\ttotal: 19m 36s\tremaining: 6m 34s\n",
      "7488:\tlearn: 0.0520512\ttotal: 19m 37s\tremaining: 6m 34s\n",
      "7489:\tlearn: 0.0520512\ttotal: 19m 37s\tremaining: 6m 34s\n",
      "7490:\tlearn: 0.0520512\ttotal: 19m 37s\tremaining: 6m 34s\n",
      "7491:\tlearn: 0.0520512\ttotal: 19m 37s\tremaining: 6m 34s\n",
      "7492:\tlearn: 0.0520512\ttotal: 19m 37s\tremaining: 6m 34s\n",
      "7493:\tlearn: 0.0520512\ttotal: 19m 37s\tremaining: 6m 33s\n",
      "7494:\tlearn: 0.0520512\ttotal: 19m 38s\tremaining: 6m 33s\n",
      "7495:\tlearn: 0.0520512\ttotal: 19m 38s\tremaining: 6m 33s\n",
      "7496:\tlearn: 0.0520512\ttotal: 19m 38s\tremaining: 6m 33s\n",
      "7497:\tlearn: 0.0520512\ttotal: 19m 38s\tremaining: 6m 33s\n",
      "7498:\tlearn: 0.0520512\ttotal: 19m 38s\tremaining: 6m 33s\n",
      "7499:\tlearn: 0.0520512\ttotal: 19m 38s\tremaining: 6m 32s\n",
      "7500:\tlearn: 0.0520512\ttotal: 19m 39s\tremaining: 6m 32s\n",
      "7501:\tlearn: 0.0520512\ttotal: 19m 39s\tremaining: 6m 32s\n",
      "7502:\tlearn: 0.0520512\ttotal: 19m 39s\tremaining: 6m 32s\n",
      "7503:\tlearn: 0.0520512\ttotal: 19m 39s\tremaining: 6m 32s\n",
      "7504:\tlearn: 0.0520512\ttotal: 19m 39s\tremaining: 6m 32s\n",
      "7505:\tlearn: 0.0520512\ttotal: 19m 39s\tremaining: 6m 32s\n",
      "7506:\tlearn: 0.0520512\ttotal: 19m 40s\tremaining: 6m 31s\n",
      "7507:\tlearn: 0.0520512\ttotal: 19m 40s\tremaining: 6m 31s\n",
      "7508:\tlearn: 0.0520512\ttotal: 19m 40s\tremaining: 6m 31s\n",
      "7509:\tlearn: 0.0520512\ttotal: 19m 40s\tremaining: 6m 31s\n",
      "7510:\tlearn: 0.0520512\ttotal: 19m 40s\tremaining: 6m 31s\n",
      "7511:\tlearn: 0.0520512\ttotal: 19m 40s\tremaining: 6m 31s\n",
      "7512:\tlearn: 0.0520512\ttotal: 19m 41s\tremaining: 6m 30s\n",
      "7513:\tlearn: 0.0520512\ttotal: 19m 41s\tremaining: 6m 30s\n",
      "7514:\tlearn: 0.0520512\ttotal: 19m 41s\tremaining: 6m 30s\n",
      "7515:\tlearn: 0.0520512\ttotal: 19m 41s\tremaining: 6m 30s\n",
      "7516:\tlearn: 0.0520512\ttotal: 19m 41s\tremaining: 6m 30s\n",
      "7517:\tlearn: 0.0520512\ttotal: 19m 41s\tremaining: 6m 30s\n",
      "7518:\tlearn: 0.0520512\ttotal: 19m 42s\tremaining: 6m 30s\n",
      "7519:\tlearn: 0.0520512\ttotal: 19m 42s\tremaining: 6m 29s\n",
      "7520:\tlearn: 0.0520512\ttotal: 19m 42s\tremaining: 6m 29s\n",
      "7521:\tlearn: 0.0520512\ttotal: 19m 42s\tremaining: 6m 29s\n",
      "7522:\tlearn: 0.0520512\ttotal: 19m 42s\tremaining: 6m 29s\n",
      "7523:\tlearn: 0.0520512\ttotal: 19m 42s\tremaining: 6m 29s\n",
      "7524:\tlearn: 0.0520512\ttotal: 19m 43s\tremaining: 6m 29s\n",
      "7525:\tlearn: 0.0520512\ttotal: 19m 43s\tremaining: 6m 28s\n",
      "7526:\tlearn: 0.0520512\ttotal: 19m 43s\tremaining: 6m 28s\n",
      "7527:\tlearn: 0.0520512\ttotal: 19m 43s\tremaining: 6m 28s\n",
      "7528:\tlearn: 0.0520512\ttotal: 19m 43s\tremaining: 6m 28s\n",
      "7529:\tlearn: 0.0520512\ttotal: 19m 43s\tremaining: 6m 28s\n",
      "7530:\tlearn: 0.0520512\ttotal: 19m 44s\tremaining: 6m 28s\n",
      "7531:\tlearn: 0.0520512\ttotal: 19m 44s\tremaining: 6m 28s\n",
      "7532:\tlearn: 0.0520512\ttotal: 19m 44s\tremaining: 6m 27s\n",
      "7533:\tlearn: 0.0520512\ttotal: 19m 44s\tremaining: 6m 27s\n",
      "7534:\tlearn: 0.0520512\ttotal: 19m 44s\tremaining: 6m 27s\n",
      "7535:\tlearn: 0.0520512\ttotal: 19m 45s\tremaining: 6m 27s\n",
      "7536:\tlearn: 0.0520512\ttotal: 19m 45s\tremaining: 6m 27s\n",
      "7537:\tlearn: 0.0520512\ttotal: 19m 45s\tremaining: 6m 27s\n",
      "7538:\tlearn: 0.0520512\ttotal: 19m 45s\tremaining: 6m 27s\n",
      "7539:\tlearn: 0.0520512\ttotal: 19m 45s\tremaining: 6m 26s\n",
      "7540:\tlearn: 0.0520512\ttotal: 19m 45s\tremaining: 6m 26s\n",
      "7541:\tlearn: 0.0520512\ttotal: 19m 46s\tremaining: 6m 26s\n",
      "7542:\tlearn: 0.0520512\ttotal: 19m 46s\tremaining: 6m 26s\n",
      "7543:\tlearn: 0.0520512\ttotal: 19m 46s\tremaining: 6m 26s\n",
      "7544:\tlearn: 0.0520512\ttotal: 19m 46s\tremaining: 6m 26s\n",
      "7545:\tlearn: 0.0520512\ttotal: 19m 46s\tremaining: 6m 25s\n",
      "7546:\tlearn: 0.0520512\ttotal: 19m 46s\tremaining: 6m 25s\n",
      "7547:\tlearn: 0.0520512\ttotal: 19m 47s\tremaining: 6m 25s\n",
      "7548:\tlearn: 0.0520512\ttotal: 19m 47s\tremaining: 6m 25s\n",
      "7549:\tlearn: 0.0520512\ttotal: 19m 47s\tremaining: 6m 25s\n",
      "7550:\tlearn: 0.0520512\ttotal: 19m 47s\tremaining: 6m 25s\n",
      "7551:\tlearn: 0.0520512\ttotal: 19m 47s\tremaining: 6m 25s\n",
      "7552:\tlearn: 0.0520512\ttotal: 19m 47s\tremaining: 6m 24s\n",
      "7553:\tlearn: 0.0520512\ttotal: 19m 48s\tremaining: 6m 24s\n",
      "7554:\tlearn: 0.0520512\ttotal: 19m 48s\tremaining: 6m 24s\n",
      "7555:\tlearn: 0.0520512\ttotal: 19m 48s\tremaining: 6m 24s\n",
      "7556:\tlearn: 0.0520512\ttotal: 19m 48s\tremaining: 6m 24s\n",
      "7557:\tlearn: 0.0520512\ttotal: 19m 48s\tremaining: 6m 24s\n",
      "7558:\tlearn: 0.0520512\ttotal: 19m 48s\tremaining: 6m 23s\n",
      "7559:\tlearn: 0.0520512\ttotal: 19m 49s\tremaining: 6m 23s\n",
      "7560:\tlearn: 0.0520512\ttotal: 19m 49s\tremaining: 6m 23s\n",
      "7561:\tlearn: 0.0520512\ttotal: 19m 49s\tremaining: 6m 23s\n",
      "7562:\tlearn: 0.0520512\ttotal: 19m 49s\tremaining: 6m 23s\n",
      "7563:\tlearn: 0.0520512\ttotal: 19m 49s\tremaining: 6m 23s\n",
      "7564:\tlearn: 0.0520512\ttotal: 19m 49s\tremaining: 6m 22s\n",
      "7565:\tlearn: 0.0520512\ttotal: 19m 49s\tremaining: 6m 22s\n",
      "7566:\tlearn: 0.0520512\ttotal: 19m 50s\tremaining: 6m 22s\n",
      "7567:\tlearn: 0.0520512\ttotal: 19m 50s\tremaining: 6m 22s\n",
      "7568:\tlearn: 0.0520512\ttotal: 19m 50s\tremaining: 6m 22s\n",
      "7569:\tlearn: 0.0520512\ttotal: 19m 50s\tremaining: 6m 22s\n",
      "7570:\tlearn: 0.0520512\ttotal: 19m 50s\tremaining: 6m 22s\n",
      "7571:\tlearn: 0.0520512\ttotal: 19m 50s\tremaining: 6m 21s\n",
      "7572:\tlearn: 0.0520512\ttotal: 19m 51s\tremaining: 6m 21s\n",
      "7573:\tlearn: 0.0520512\ttotal: 19m 51s\tremaining: 6m 21s\n",
      "7574:\tlearn: 0.0520512\ttotal: 19m 51s\tremaining: 6m 21s\n",
      "7575:\tlearn: 0.0520512\ttotal: 19m 51s\tremaining: 6m 21s\n",
      "7576:\tlearn: 0.0520512\ttotal: 19m 51s\tremaining: 6m 21s\n",
      "7577:\tlearn: 0.0520512\ttotal: 19m 51s\tremaining: 6m 20s\n",
      "7578:\tlearn: 0.0520512\ttotal: 19m 52s\tremaining: 6m 20s\n",
      "7579:\tlearn: 0.0520512\ttotal: 19m 52s\tremaining: 6m 20s\n",
      "7580:\tlearn: 0.0520512\ttotal: 19m 52s\tremaining: 6m 20s\n",
      "7581:\tlearn: 0.0520512\ttotal: 19m 52s\tremaining: 6m 20s\n",
      "7582:\tlearn: 0.0520512\ttotal: 19m 52s\tremaining: 6m 20s\n",
      "7583:\tlearn: 0.0520512\ttotal: 19m 52s\tremaining: 6m 20s\n",
      "7584:\tlearn: 0.0520512\ttotal: 19m 53s\tremaining: 6m 19s\n",
      "7585:\tlearn: 0.0520512\ttotal: 19m 53s\tremaining: 6m 19s\n",
      "7586:\tlearn: 0.0520512\ttotal: 19m 53s\tremaining: 6m 19s\n",
      "7587:\tlearn: 0.0520512\ttotal: 19m 53s\tremaining: 6m 19s\n",
      "7588:\tlearn: 0.0520512\ttotal: 19m 53s\tremaining: 6m 19s\n",
      "7589:\tlearn: 0.0520512\ttotal: 19m 53s\tremaining: 6m 19s\n",
      "7590:\tlearn: 0.0520512\ttotal: 19m 54s\tremaining: 6m 18s\n",
      "7591:\tlearn: 0.0520512\ttotal: 19m 54s\tremaining: 6m 18s\n",
      "7592:\tlearn: 0.0520512\ttotal: 19m 54s\tremaining: 6m 18s\n",
      "7593:\tlearn: 0.0520512\ttotal: 19m 54s\tremaining: 6m 18s\n",
      "7594:\tlearn: 0.0520512\ttotal: 19m 54s\tremaining: 6m 18s\n",
      "7595:\tlearn: 0.0520512\ttotal: 19m 54s\tremaining: 6m 18s\n",
      "7596:\tlearn: 0.0520512\ttotal: 19m 55s\tremaining: 6m 18s\n",
      "7597:\tlearn: 0.0520512\ttotal: 19m 55s\tremaining: 6m 17s\n",
      "7598:\tlearn: 0.0520512\ttotal: 19m 55s\tremaining: 6m 17s\n",
      "7599:\tlearn: 0.0520512\ttotal: 19m 55s\tremaining: 6m 17s\n",
      "7600:\tlearn: 0.0520512\ttotal: 19m 55s\tremaining: 6m 17s\n",
      "7601:\tlearn: 0.0520512\ttotal: 19m 55s\tremaining: 6m 17s\n",
      "7602:\tlearn: 0.0520512\ttotal: 19m 56s\tremaining: 6m 17s\n",
      "7603:\tlearn: 0.0520512\ttotal: 19m 56s\tremaining: 6m 16s\n",
      "7604:\tlearn: 0.0520512\ttotal: 19m 56s\tremaining: 6m 16s\n",
      "7605:\tlearn: 0.0520512\ttotal: 19m 56s\tremaining: 6m 16s\n",
      "7606:\tlearn: 0.0520512\ttotal: 19m 56s\tremaining: 6m 16s\n",
      "7607:\tlearn: 0.0520512\ttotal: 19m 56s\tremaining: 6m 16s\n",
      "7608:\tlearn: 0.0520512\ttotal: 19m 57s\tremaining: 6m 16s\n",
      "7609:\tlearn: 0.0520512\ttotal: 19m 57s\tremaining: 6m 16s\n",
      "7610:\tlearn: 0.0520512\ttotal: 19m 57s\tremaining: 6m 15s\n",
      "7611:\tlearn: 0.0520512\ttotal: 19m 57s\tremaining: 6m 15s\n",
      "7612:\tlearn: 0.0520512\ttotal: 19m 57s\tremaining: 6m 15s\n",
      "7613:\tlearn: 0.0520512\ttotal: 19m 57s\tremaining: 6m 15s\n",
      "7614:\tlearn: 0.0520512\ttotal: 19m 58s\tremaining: 6m 15s\n",
      "7615:\tlearn: 0.0520512\ttotal: 19m 58s\tremaining: 6m 15s\n",
      "7616:\tlearn: 0.0520512\ttotal: 19m 58s\tremaining: 6m 14s\n",
      "7617:\tlearn: 0.0520512\ttotal: 19m 58s\tremaining: 6m 14s\n",
      "7618:\tlearn: 0.0520512\ttotal: 19m 58s\tremaining: 6m 14s\n",
      "7619:\tlearn: 0.0520512\ttotal: 19m 58s\tremaining: 6m 14s\n",
      "7620:\tlearn: 0.0520512\ttotal: 19m 59s\tremaining: 6m 14s\n",
      "7621:\tlearn: 0.0520512\ttotal: 19m 59s\tremaining: 6m 14s\n",
      "7622:\tlearn: 0.0520512\ttotal: 19m 59s\tremaining: 6m 14s\n",
      "7623:\tlearn: 0.0520512\ttotal: 19m 59s\tremaining: 6m 13s\n",
      "7624:\tlearn: 0.0520512\ttotal: 19m 59s\tremaining: 6m 13s\n",
      "7625:\tlearn: 0.0520512\ttotal: 19m 59s\tremaining: 6m 13s\n",
      "7626:\tlearn: 0.0520512\ttotal: 20m\tremaining: 6m 13s\n",
      "7627:\tlearn: 0.0520512\ttotal: 20m\tremaining: 6m 13s\n",
      "7628:\tlearn: 0.0520512\ttotal: 20m\tremaining: 6m 13s\n",
      "7629:\tlearn: 0.0520512\ttotal: 20m\tremaining: 6m 12s\n",
      "7630:\tlearn: 0.0520512\ttotal: 20m\tremaining: 6m 12s\n",
      "7631:\tlearn: 0.0520512\ttotal: 20m\tremaining: 6m 12s\n",
      "7632:\tlearn: 0.0520512\ttotal: 20m 1s\tremaining: 6m 12s\n",
      "7633:\tlearn: 0.0520512\ttotal: 20m 1s\tremaining: 6m 12s\n",
      "7634:\tlearn: 0.0520512\ttotal: 20m 1s\tremaining: 6m 12s\n",
      "7635:\tlearn: 0.0520512\ttotal: 20m 1s\tremaining: 6m 11s\n",
      "7636:\tlearn: 0.0520512\ttotal: 20m 1s\tremaining: 6m 11s\n",
      "7637:\tlearn: 0.0520512\ttotal: 20m 1s\tremaining: 6m 11s\n",
      "7638:\tlearn: 0.0520512\ttotal: 20m 2s\tremaining: 6m 11s\n",
      "7639:\tlearn: 0.0520512\ttotal: 20m 2s\tremaining: 6m 11s\n",
      "7640:\tlearn: 0.0520512\ttotal: 20m 2s\tremaining: 6m 11s\n",
      "7641:\tlearn: 0.0520512\ttotal: 20m 2s\tremaining: 6m 11s\n",
      "7642:\tlearn: 0.0520512\ttotal: 20m 2s\tremaining: 6m 10s\n",
      "7643:\tlearn: 0.0520512\ttotal: 20m 2s\tremaining: 6m 10s\n",
      "7644:\tlearn: 0.0520512\ttotal: 20m 3s\tremaining: 6m 10s\n",
      "7645:\tlearn: 0.0520512\ttotal: 20m 3s\tremaining: 6m 10s\n",
      "7646:\tlearn: 0.0520512\ttotal: 20m 3s\tremaining: 6m 10s\n",
      "7647:\tlearn: 0.0520512\ttotal: 20m 3s\tremaining: 6m 10s\n",
      "7648:\tlearn: 0.0520512\ttotal: 20m 3s\tremaining: 6m 9s\n",
      "7649:\tlearn: 0.0520512\ttotal: 20m 3s\tremaining: 6m 9s\n",
      "7650:\tlearn: 0.0520512\ttotal: 20m 4s\tremaining: 6m 9s\n",
      "7651:\tlearn: 0.0520512\ttotal: 20m 4s\tremaining: 6m 9s\n",
      "7652:\tlearn: 0.0520512\ttotal: 20m 4s\tremaining: 6m 9s\n",
      "7653:\tlearn: 0.0520512\ttotal: 20m 4s\tremaining: 6m 9s\n",
      "7654:\tlearn: 0.0520512\ttotal: 20m 4s\tremaining: 6m 9s\n",
      "7655:\tlearn: 0.0520512\ttotal: 20m 4s\tremaining: 6m 8s\n",
      "7656:\tlearn: 0.0520512\ttotal: 20m 5s\tremaining: 6m 8s\n",
      "7657:\tlearn: 0.0520512\ttotal: 20m 5s\tremaining: 6m 8s\n",
      "7658:\tlearn: 0.0520512\ttotal: 20m 5s\tremaining: 6m 8s\n",
      "7659:\tlearn: 0.0520512\ttotal: 20m 5s\tremaining: 6m 8s\n",
      "7660:\tlearn: 0.0520512\ttotal: 20m 5s\tremaining: 6m 8s\n",
      "7661:\tlearn: 0.0520512\ttotal: 20m 6s\tremaining: 6m 8s\n",
      "7662:\tlearn: 0.0520512\ttotal: 20m 6s\tremaining: 6m 7s\n",
      "7663:\tlearn: 0.0520512\ttotal: 20m 6s\tremaining: 6m 7s\n",
      "7664:\tlearn: 0.0520512\ttotal: 20m 6s\tremaining: 6m 7s\n",
      "7665:\tlearn: 0.0520512\ttotal: 20m 6s\tremaining: 6m 7s\n",
      "7666:\tlearn: 0.0520512\ttotal: 20m 6s\tremaining: 6m 7s\n",
      "7667:\tlearn: 0.0520512\ttotal: 20m 7s\tremaining: 6m 7s\n",
      "7668:\tlearn: 0.0520512\ttotal: 20m 7s\tremaining: 6m 6s\n",
      "7669:\tlearn: 0.0520512\ttotal: 20m 7s\tremaining: 6m 6s\n",
      "7670:\tlearn: 0.0520512\ttotal: 20m 7s\tremaining: 6m 6s\n",
      "7671:\tlearn: 0.0520512\ttotal: 20m 7s\tremaining: 6m 6s\n",
      "7672:\tlearn: 0.0520512\ttotal: 20m 7s\tremaining: 6m 6s\n",
      "7673:\tlearn: 0.0520512\ttotal: 20m 8s\tremaining: 6m 6s\n",
      "7674:\tlearn: 0.0520512\ttotal: 20m 8s\tremaining: 6m 6s\n",
      "7675:\tlearn: 0.0520512\ttotal: 20m 8s\tremaining: 6m 5s\n",
      "7676:\tlearn: 0.0520512\ttotal: 20m 8s\tremaining: 6m 5s\n",
      "7677:\tlearn: 0.0520512\ttotal: 20m 8s\tremaining: 6m 5s\n",
      "7678:\tlearn: 0.0520512\ttotal: 20m 8s\tremaining: 6m 5s\n",
      "7679:\tlearn: 0.0520512\ttotal: 20m 9s\tremaining: 6m 5s\n",
      "7680:\tlearn: 0.0520512\ttotal: 20m 9s\tremaining: 6m 5s\n",
      "7681:\tlearn: 0.0520512\ttotal: 20m 9s\tremaining: 6m 4s\n",
      "7682:\tlearn: 0.0520512\ttotal: 20m 9s\tremaining: 6m 4s\n",
      "7683:\tlearn: 0.0520512\ttotal: 20m 9s\tremaining: 6m 4s\n",
      "7684:\tlearn: 0.0520512\ttotal: 20m 9s\tremaining: 6m 4s\n",
      "7685:\tlearn: 0.0520512\ttotal: 20m 10s\tremaining: 6m 4s\n",
      "7686:\tlearn: 0.0520512\ttotal: 20m 10s\tremaining: 6m 4s\n",
      "7687:\tlearn: 0.0520512\ttotal: 20m 10s\tremaining: 6m 4s\n",
      "7688:\tlearn: 0.0520512\ttotal: 20m 10s\tremaining: 6m 3s\n",
      "7689:\tlearn: 0.0520512\ttotal: 20m 10s\tremaining: 6m 3s\n",
      "7690:\tlearn: 0.0520512\ttotal: 20m 10s\tremaining: 6m 3s\n",
      "7691:\tlearn: 0.0520512\ttotal: 20m 11s\tremaining: 6m 3s\n",
      "7692:\tlearn: 0.0520512\ttotal: 20m 11s\tremaining: 6m 3s\n",
      "7693:\tlearn: 0.0520512\ttotal: 20m 11s\tremaining: 6m 3s\n",
      "7694:\tlearn: 0.0520512\ttotal: 20m 11s\tremaining: 6m 2s\n",
      "7695:\tlearn: 0.0520512\ttotal: 20m 11s\tremaining: 6m 2s\n",
      "7696:\tlearn: 0.0520512\ttotal: 20m 11s\tremaining: 6m 2s\n",
      "7697:\tlearn: 0.0520512\ttotal: 20m 12s\tremaining: 6m 2s\n",
      "7698:\tlearn: 0.0520512\ttotal: 20m 12s\tremaining: 6m 2s\n",
      "7699:\tlearn: 0.0520512\ttotal: 20m 12s\tremaining: 6m 2s\n",
      "7700:\tlearn: 0.0520512\ttotal: 20m 12s\tremaining: 6m 2s\n",
      "7701:\tlearn: 0.0520512\ttotal: 20m 12s\tremaining: 6m 1s\n",
      "7702:\tlearn: 0.0520512\ttotal: 20m 12s\tremaining: 6m 1s\n",
      "7703:\tlearn: 0.0520512\ttotal: 20m 13s\tremaining: 6m 1s\n",
      "7704:\tlearn: 0.0520512\ttotal: 20m 13s\tremaining: 6m 1s\n",
      "7705:\tlearn: 0.0520512\ttotal: 20m 13s\tremaining: 6m 1s\n",
      "7706:\tlearn: 0.0520512\ttotal: 20m 13s\tremaining: 6m 1s\n",
      "7707:\tlearn: 0.0520512\ttotal: 20m 13s\tremaining: 6m\n",
      "7708:\tlearn: 0.0520512\ttotal: 20m 13s\tremaining: 6m\n",
      "7709:\tlearn: 0.0520512\ttotal: 20m 14s\tremaining: 6m\n",
      "7710:\tlearn: 0.0520512\ttotal: 20m 14s\tremaining: 6m\n",
      "7711:\tlearn: 0.0520512\ttotal: 20m 14s\tremaining: 6m\n",
      "7712:\tlearn: 0.0520512\ttotal: 20m 14s\tremaining: 6m\n",
      "7713:\tlearn: 0.0520512\ttotal: 20m 14s\tremaining: 5m 59s\n",
      "7714:\tlearn: 0.0520512\ttotal: 20m 14s\tremaining: 5m 59s\n",
      "7715:\tlearn: 0.0520512\ttotal: 20m 14s\tremaining: 5m 59s\n",
      "7716:\tlearn: 0.0520512\ttotal: 20m 15s\tremaining: 5m 59s\n",
      "7717:\tlearn: 0.0520512\ttotal: 20m 15s\tremaining: 5m 59s\n",
      "7718:\tlearn: 0.0520512\ttotal: 20m 15s\tremaining: 5m 59s\n",
      "7719:\tlearn: 0.0520512\ttotal: 20m 15s\tremaining: 5m 59s\n",
      "7720:\tlearn: 0.0520512\ttotal: 20m 15s\tremaining: 5m 58s\n",
      "7721:\tlearn: 0.0520512\ttotal: 20m 15s\tremaining: 5m 58s\n",
      "7722:\tlearn: 0.0520512\ttotal: 20m 16s\tremaining: 5m 58s\n",
      "7723:\tlearn: 0.0520512\ttotal: 20m 16s\tremaining: 5m 58s\n",
      "7724:\tlearn: 0.0520512\ttotal: 20m 16s\tremaining: 5m 58s\n",
      "7725:\tlearn: 0.0520512\ttotal: 20m 16s\tremaining: 5m 58s\n",
      "7726:\tlearn: 0.0520512\ttotal: 20m 16s\tremaining: 5m 57s\n",
      "7727:\tlearn: 0.0520512\ttotal: 20m 16s\tremaining: 5m 57s\n",
      "7728:\tlearn: 0.0520512\ttotal: 20m 16s\tremaining: 5m 57s\n",
      "7729:\tlearn: 0.0520512\ttotal: 20m 17s\tremaining: 5m 57s\n",
      "7730:\tlearn: 0.0520512\ttotal: 20m 17s\tremaining: 5m 57s\n",
      "7731:\tlearn: 0.0520512\ttotal: 20m 17s\tremaining: 5m 57s\n",
      "7732:\tlearn: 0.0520512\ttotal: 20m 17s\tremaining: 5m 56s\n",
      "7733:\tlearn: 0.0520512\ttotal: 20m 17s\tremaining: 5m 56s\n",
      "7734:\tlearn: 0.0520512\ttotal: 20m 17s\tremaining: 5m 56s\n",
      "7735:\tlearn: 0.0520512\ttotal: 20m 18s\tremaining: 5m 56s\n",
      "7736:\tlearn: 0.0520512\ttotal: 20m 18s\tremaining: 5m 56s\n",
      "7737:\tlearn: 0.0520512\ttotal: 20m 18s\tremaining: 5m 56s\n",
      "7738:\tlearn: 0.0520512\ttotal: 20m 18s\tremaining: 5m 56s\n",
      "7739:\tlearn: 0.0520512\ttotal: 20m 18s\tremaining: 5m 55s\n",
      "7740:\tlearn: 0.0520512\ttotal: 20m 18s\tremaining: 5m 55s\n",
      "7741:\tlearn: 0.0520512\ttotal: 20m 19s\tremaining: 5m 55s\n",
      "7742:\tlearn: 0.0520512\ttotal: 20m 19s\tremaining: 5m 55s\n",
      "7743:\tlearn: 0.0520512\ttotal: 20m 19s\tremaining: 5m 55s\n",
      "7744:\tlearn: 0.0520512\ttotal: 20m 19s\tremaining: 5m 55s\n",
      "7745:\tlearn: 0.0520512\ttotal: 20m 19s\tremaining: 5m 54s\n",
      "7746:\tlearn: 0.0520512\ttotal: 20m 19s\tremaining: 5m 54s\n",
      "7747:\tlearn: 0.0520512\ttotal: 20m 20s\tremaining: 5m 54s\n",
      "7748:\tlearn: 0.0520512\ttotal: 20m 20s\tremaining: 5m 54s\n",
      "7749:\tlearn: 0.0520512\ttotal: 20m 20s\tremaining: 5m 54s\n",
      "7750:\tlearn: 0.0520512\ttotal: 20m 20s\tremaining: 5m 54s\n",
      "7751:\tlearn: 0.0520512\ttotal: 20m 20s\tremaining: 5m 54s\n",
      "7752:\tlearn: 0.0520512\ttotal: 20m 20s\tremaining: 5m 53s\n",
      "7753:\tlearn: 0.0520512\ttotal: 20m 21s\tremaining: 5m 53s\n",
      "7754:\tlearn: 0.0520512\ttotal: 20m 21s\tremaining: 5m 53s\n",
      "7755:\tlearn: 0.0520512\ttotal: 20m 21s\tremaining: 5m 53s\n",
      "7756:\tlearn: 0.0520512\ttotal: 20m 21s\tremaining: 5m 53s\n",
      "7757:\tlearn: 0.0520512\ttotal: 20m 21s\tremaining: 5m 53s\n",
      "7758:\tlearn: 0.0520512\ttotal: 20m 21s\tremaining: 5m 52s\n",
      "7759:\tlearn: 0.0520512\ttotal: 20m 22s\tremaining: 5m 52s\n",
      "7760:\tlearn: 0.0520512\ttotal: 20m 22s\tremaining: 5m 52s\n",
      "7761:\tlearn: 0.0520512\ttotal: 20m 22s\tremaining: 5m 52s\n",
      "7762:\tlearn: 0.0520512\ttotal: 20m 22s\tremaining: 5m 52s\n",
      "7763:\tlearn: 0.0520512\ttotal: 20m 22s\tremaining: 5m 52s\n",
      "7764:\tlearn: 0.0520512\ttotal: 20m 22s\tremaining: 5m 51s\n",
      "7765:\tlearn: 0.0520512\ttotal: 20m 23s\tremaining: 5m 51s\n",
      "7766:\tlearn: 0.0520512\ttotal: 20m 23s\tremaining: 5m 51s\n",
      "7767:\tlearn: 0.0520512\ttotal: 20m 23s\tremaining: 5m 51s\n",
      "7768:\tlearn: 0.0520512\ttotal: 20m 23s\tremaining: 5m 51s\n",
      "7769:\tlearn: 0.0520512\ttotal: 20m 23s\tremaining: 5m 51s\n",
      "7770:\tlearn: 0.0520512\ttotal: 20m 23s\tremaining: 5m 51s\n",
      "7771:\tlearn: 0.0520512\ttotal: 20m 24s\tremaining: 5m 50s\n",
      "7772:\tlearn: 0.0520512\ttotal: 20m 24s\tremaining: 5m 50s\n",
      "7773:\tlearn: 0.0520512\ttotal: 20m 24s\tremaining: 5m 50s\n",
      "7774:\tlearn: 0.0520512\ttotal: 20m 24s\tremaining: 5m 50s\n",
      "7775:\tlearn: 0.0520512\ttotal: 20m 24s\tremaining: 5m 50s\n",
      "7776:\tlearn: 0.0520512\ttotal: 20m 24s\tremaining: 5m 50s\n",
      "7777:\tlearn: 0.0520512\ttotal: 20m 25s\tremaining: 5m 49s\n",
      "7778:\tlearn: 0.0520512\ttotal: 20m 25s\tremaining: 5m 49s\n",
      "7779:\tlearn: 0.0520512\ttotal: 20m 25s\tremaining: 5m 49s\n",
      "7780:\tlearn: 0.0520512\ttotal: 20m 25s\tremaining: 5m 49s\n",
      "7781:\tlearn: 0.0520512\ttotal: 20m 25s\tremaining: 5m 49s\n",
      "7782:\tlearn: 0.0520512\ttotal: 20m 25s\tremaining: 5m 49s\n",
      "7783:\tlearn: 0.0520512\ttotal: 20m 26s\tremaining: 5m 49s\n",
      "7784:\tlearn: 0.0520512\ttotal: 20m 26s\tremaining: 5m 48s\n",
      "7785:\tlearn: 0.0520512\ttotal: 20m 26s\tremaining: 5m 48s\n",
      "7786:\tlearn: 0.0520512\ttotal: 20m 26s\tremaining: 5m 48s\n",
      "7787:\tlearn: 0.0520512\ttotal: 20m 26s\tremaining: 5m 48s\n",
      "7788:\tlearn: 0.0520512\ttotal: 20m 26s\tremaining: 5m 48s\n",
      "7789:\tlearn: 0.0520512\ttotal: 20m 27s\tremaining: 5m 48s\n",
      "7790:\tlearn: 0.0520512\ttotal: 20m 27s\tremaining: 5m 47s\n",
      "7791:\tlearn: 0.0520512\ttotal: 20m 27s\tremaining: 5m 47s\n",
      "7792:\tlearn: 0.0520512\ttotal: 20m 27s\tremaining: 5m 47s\n",
      "7793:\tlearn: 0.0520512\ttotal: 20m 27s\tremaining: 5m 47s\n",
      "7794:\tlearn: 0.0520512\ttotal: 20m 27s\tremaining: 5m 47s\n",
      "7795:\tlearn: 0.0520512\ttotal: 20m 28s\tremaining: 5m 47s\n",
      "7796:\tlearn: 0.0520512\ttotal: 20m 28s\tremaining: 5m 47s\n",
      "7797:\tlearn: 0.0520512\ttotal: 20m 28s\tremaining: 5m 46s\n",
      "7798:\tlearn: 0.0520512\ttotal: 20m 28s\tremaining: 5m 46s\n",
      "7799:\tlearn: 0.0520512\ttotal: 20m 28s\tremaining: 5m 46s\n",
      "7800:\tlearn: 0.0520512\ttotal: 20m 28s\tremaining: 5m 46s\n",
      "7801:\tlearn: 0.0520512\ttotal: 20m 29s\tremaining: 5m 46s\n",
      "7802:\tlearn: 0.0520512\ttotal: 20m 29s\tremaining: 5m 46s\n",
      "7803:\tlearn: 0.0520512\ttotal: 20m 29s\tremaining: 5m 45s\n",
      "7804:\tlearn: 0.0520512\ttotal: 20m 29s\tremaining: 5m 45s\n",
      "7805:\tlearn: 0.0520512\ttotal: 20m 29s\tremaining: 5m 45s\n",
      "7806:\tlearn: 0.0520512\ttotal: 20m 29s\tremaining: 5m 45s\n",
      "7807:\tlearn: 0.0520512\ttotal: 20m 30s\tremaining: 5m 45s\n",
      "7808:\tlearn: 0.0520512\ttotal: 20m 30s\tremaining: 5m 45s\n",
      "7809:\tlearn: 0.0520512\ttotal: 20m 30s\tremaining: 5m 44s\n",
      "7810:\tlearn: 0.0520512\ttotal: 20m 30s\tremaining: 5m 44s\n",
      "7811:\tlearn: 0.0520512\ttotal: 20m 30s\tremaining: 5m 44s\n",
      "7812:\tlearn: 0.0520512\ttotal: 20m 30s\tremaining: 5m 44s\n",
      "7813:\tlearn: 0.0520512\ttotal: 20m 30s\tremaining: 5m 44s\n",
      "7814:\tlearn: 0.0520512\ttotal: 20m 31s\tremaining: 5m 44s\n",
      "7815:\tlearn: 0.0520512\ttotal: 20m 31s\tremaining: 5m 44s\n",
      "7816:\tlearn: 0.0520512\ttotal: 20m 31s\tremaining: 5m 43s\n",
      "7817:\tlearn: 0.0520512\ttotal: 20m 31s\tremaining: 5m 43s\n",
      "7818:\tlearn: 0.0520512\ttotal: 20m 31s\tremaining: 5m 43s\n",
      "7819:\tlearn: 0.0520512\ttotal: 20m 31s\tremaining: 5m 43s\n",
      "7820:\tlearn: 0.0520512\ttotal: 20m 32s\tremaining: 5m 43s\n",
      "7821:\tlearn: 0.0520512\ttotal: 20m 32s\tremaining: 5m 43s\n",
      "7822:\tlearn: 0.0520512\ttotal: 20m 32s\tremaining: 5m 42s\n",
      "7823:\tlearn: 0.0520512\ttotal: 20m 32s\tremaining: 5m 42s\n",
      "7824:\tlearn: 0.0520512\ttotal: 20m 32s\tremaining: 5m 42s\n",
      "7825:\tlearn: 0.0520512\ttotal: 20m 32s\tremaining: 5m 42s\n",
      "7826:\tlearn: 0.0520512\ttotal: 20m 33s\tremaining: 5m 42s\n",
      "7827:\tlearn: 0.0520512\ttotal: 20m 33s\tremaining: 5m 42s\n",
      "7828:\tlearn: 0.0520512\ttotal: 20m 33s\tremaining: 5m 42s\n",
      "7829:\tlearn: 0.0520512\ttotal: 20m 33s\tremaining: 5m 41s\n",
      "7830:\tlearn: 0.0520512\ttotal: 20m 33s\tremaining: 5m 41s\n",
      "7831:\tlearn: 0.0520512\ttotal: 20m 33s\tremaining: 5m 41s\n",
      "7832:\tlearn: 0.0520512\ttotal: 20m 34s\tremaining: 5m 41s\n",
      "7833:\tlearn: 0.0520512\ttotal: 20m 34s\tremaining: 5m 41s\n",
      "7834:\tlearn: 0.0520512\ttotal: 20m 34s\tremaining: 5m 41s\n",
      "7835:\tlearn: 0.0520512\ttotal: 20m 34s\tremaining: 5m 40s\n",
      "7836:\tlearn: 0.0520512\ttotal: 20m 34s\tremaining: 5m 40s\n",
      "7837:\tlearn: 0.0520512\ttotal: 20m 34s\tremaining: 5m 40s\n",
      "7838:\tlearn: 0.0520512\ttotal: 20m 35s\tremaining: 5m 40s\n",
      "7839:\tlearn: 0.0520512\ttotal: 20m 35s\tremaining: 5m 40s\n",
      "7840:\tlearn: 0.0520512\ttotal: 20m 35s\tremaining: 5m 40s\n",
      "7841:\tlearn: 0.0520512\ttotal: 20m 35s\tremaining: 5m 40s\n",
      "7842:\tlearn: 0.0520512\ttotal: 20m 35s\tremaining: 5m 39s\n",
      "7843:\tlearn: 0.0520512\ttotal: 20m 35s\tremaining: 5m 39s\n",
      "7844:\tlearn: 0.0520512\ttotal: 20m 36s\tremaining: 5m 39s\n",
      "7845:\tlearn: 0.0520512\ttotal: 20m 36s\tremaining: 5m 39s\n",
      "7846:\tlearn: 0.0520512\ttotal: 20m 36s\tremaining: 5m 39s\n",
      "7847:\tlearn: 0.0520512\ttotal: 20m 36s\tremaining: 5m 39s\n",
      "7848:\tlearn: 0.0520512\ttotal: 20m 36s\tremaining: 5m 38s\n",
      "7849:\tlearn: 0.0520512\ttotal: 20m 36s\tremaining: 5m 38s\n",
      "7850:\tlearn: 0.0520512\ttotal: 20m 37s\tremaining: 5m 38s\n",
      "7851:\tlearn: 0.0520512\ttotal: 20m 37s\tremaining: 5m 38s\n",
      "7852:\tlearn: 0.0520512\ttotal: 20m 37s\tremaining: 5m 38s\n",
      "7853:\tlearn: 0.0520512\ttotal: 20m 37s\tremaining: 5m 38s\n",
      "7854:\tlearn: 0.0520512\ttotal: 20m 37s\tremaining: 5m 37s\n",
      "7855:\tlearn: 0.0520512\ttotal: 20m 37s\tremaining: 5m 37s\n",
      "7856:\tlearn: 0.0520512\ttotal: 20m 37s\tremaining: 5m 37s\n",
      "7857:\tlearn: 0.0520512\ttotal: 20m 38s\tremaining: 5m 37s\n",
      "7858:\tlearn: 0.0520512\ttotal: 20m 38s\tremaining: 5m 37s\n",
      "7859:\tlearn: 0.0520512\ttotal: 20m 38s\tremaining: 5m 37s\n",
      "7860:\tlearn: 0.0520512\ttotal: 20m 38s\tremaining: 5m 37s\n",
      "7861:\tlearn: 0.0520512\ttotal: 20m 38s\tremaining: 5m 36s\n",
      "7862:\tlearn: 0.0520512\ttotal: 20m 39s\tremaining: 5m 36s\n",
      "7863:\tlearn: 0.0520512\ttotal: 20m 39s\tremaining: 5m 36s\n",
      "7864:\tlearn: 0.0520512\ttotal: 20m 39s\tremaining: 5m 36s\n",
      "7865:\tlearn: 0.0520512\ttotal: 20m 39s\tremaining: 5m 36s\n",
      "7866:\tlearn: 0.0520512\ttotal: 20m 39s\tremaining: 5m 36s\n",
      "7867:\tlearn: 0.0520512\ttotal: 20m 39s\tremaining: 5m 35s\n",
      "7868:\tlearn: 0.0520512\ttotal: 20m 39s\tremaining: 5m 35s\n",
      "7869:\tlearn: 0.0520512\ttotal: 20m 40s\tremaining: 5m 35s\n",
      "7870:\tlearn: 0.0520512\ttotal: 20m 40s\tremaining: 5m 35s\n",
      "7871:\tlearn: 0.0520512\ttotal: 20m 40s\tremaining: 5m 35s\n",
      "7872:\tlearn: 0.0520512\ttotal: 20m 40s\tremaining: 5m 35s\n",
      "7873:\tlearn: 0.0520512\ttotal: 20m 40s\tremaining: 5m 35s\n",
      "7874:\tlearn: 0.0520512\ttotal: 20m 40s\tremaining: 5m 34s\n",
      "7875:\tlearn: 0.0520512\ttotal: 20m 41s\tremaining: 5m 34s\n",
      "7876:\tlearn: 0.0520512\ttotal: 20m 41s\tremaining: 5m 34s\n",
      "7877:\tlearn: 0.0520512\ttotal: 20m 41s\tremaining: 5m 34s\n",
      "7878:\tlearn: 0.0520512\ttotal: 20m 41s\tremaining: 5m 34s\n",
      "7879:\tlearn: 0.0520512\ttotal: 20m 41s\tremaining: 5m 34s\n",
      "7880:\tlearn: 0.0520512\ttotal: 20m 41s\tremaining: 5m 33s\n",
      "7881:\tlearn: 0.0520512\ttotal: 20m 42s\tremaining: 5m 33s\n",
      "7882:\tlearn: 0.0520512\ttotal: 20m 42s\tremaining: 5m 33s\n",
      "7883:\tlearn: 0.0520512\ttotal: 20m 42s\tremaining: 5m 33s\n",
      "7884:\tlearn: 0.0520512\ttotal: 20m 42s\tremaining: 5m 33s\n",
      "7885:\tlearn: 0.0520512\ttotal: 20m 42s\tremaining: 5m 33s\n",
      "7886:\tlearn: 0.0520512\ttotal: 20m 42s\tremaining: 5m 32s\n",
      "7887:\tlearn: 0.0520512\ttotal: 20m 43s\tremaining: 5m 32s\n",
      "7888:\tlearn: 0.0520512\ttotal: 20m 43s\tremaining: 5m 32s\n",
      "7889:\tlearn: 0.0520512\ttotal: 20m 43s\tremaining: 5m 32s\n",
      "7890:\tlearn: 0.0520512\ttotal: 20m 43s\tremaining: 5m 32s\n",
      "7891:\tlearn: 0.0520512\ttotal: 20m 43s\tremaining: 5m 32s\n",
      "7892:\tlearn: 0.0520512\ttotal: 20m 43s\tremaining: 5m 32s\n",
      "7893:\tlearn: 0.0520512\ttotal: 20m 44s\tremaining: 5m 31s\n",
      "7894:\tlearn: 0.0520512\ttotal: 20m 44s\tremaining: 5m 31s\n",
      "7895:\tlearn: 0.0520512\ttotal: 20m 44s\tremaining: 5m 31s\n",
      "7896:\tlearn: 0.0520512\ttotal: 20m 44s\tremaining: 5m 31s\n",
      "7897:\tlearn: 0.0520512\ttotal: 20m 44s\tremaining: 5m 31s\n",
      "7898:\tlearn: 0.0520512\ttotal: 20m 44s\tremaining: 5m 31s\n",
      "7899:\tlearn: 0.0520512\ttotal: 20m 45s\tremaining: 5m 30s\n",
      "7900:\tlearn: 0.0520512\ttotal: 20m 45s\tremaining: 5m 30s\n",
      "7901:\tlearn: 0.0520512\ttotal: 20m 45s\tremaining: 5m 30s\n",
      "7902:\tlearn: 0.0520512\ttotal: 20m 45s\tremaining: 5m 30s\n",
      "7903:\tlearn: 0.0520512\ttotal: 20m 45s\tremaining: 5m 30s\n",
      "7904:\tlearn: 0.0520512\ttotal: 20m 45s\tremaining: 5m 30s\n",
      "7905:\tlearn: 0.0520512\ttotal: 20m 46s\tremaining: 5m 30s\n",
      "7906:\tlearn: 0.0520512\ttotal: 20m 46s\tremaining: 5m 29s\n",
      "7907:\tlearn: 0.0520512\ttotal: 20m 46s\tremaining: 5m 29s\n",
      "7908:\tlearn: 0.0520512\ttotal: 20m 46s\tremaining: 5m 29s\n",
      "7909:\tlearn: 0.0520512\ttotal: 20m 46s\tremaining: 5m 29s\n",
      "7910:\tlearn: 0.0520512\ttotal: 20m 46s\tremaining: 5m 29s\n",
      "7911:\tlearn: 0.0520512\ttotal: 20m 47s\tremaining: 5m 29s\n",
      "7912:\tlearn: 0.0520512\ttotal: 20m 47s\tremaining: 5m 28s\n",
      "7913:\tlearn: 0.0520512\ttotal: 20m 47s\tremaining: 5m 28s\n",
      "7914:\tlearn: 0.0520512\ttotal: 20m 47s\tremaining: 5m 28s\n",
      "7915:\tlearn: 0.0520512\ttotal: 20m 47s\tremaining: 5m 28s\n",
      "7916:\tlearn: 0.0520512\ttotal: 20m 47s\tremaining: 5m 28s\n",
      "7917:\tlearn: 0.0520512\ttotal: 20m 47s\tremaining: 5m 28s\n",
      "7918:\tlearn: 0.0520512\ttotal: 20m 48s\tremaining: 5m 27s\n",
      "7919:\tlearn: 0.0520512\ttotal: 20m 48s\tremaining: 5m 27s\n",
      "7920:\tlearn: 0.0520512\ttotal: 20m 48s\tremaining: 5m 27s\n",
      "7921:\tlearn: 0.0520512\ttotal: 20m 48s\tremaining: 5m 27s\n",
      "7922:\tlearn: 0.0520512\ttotal: 20m 48s\tremaining: 5m 27s\n",
      "7923:\tlearn: 0.0520512\ttotal: 20m 48s\tremaining: 5m 27s\n",
      "7924:\tlearn: 0.0520512\ttotal: 20m 49s\tremaining: 5m 27s\n",
      "7925:\tlearn: 0.0520512\ttotal: 20m 49s\tremaining: 5m 26s\n",
      "7926:\tlearn: 0.0520512\ttotal: 20m 49s\tremaining: 5m 26s\n",
      "7927:\tlearn: 0.0520512\ttotal: 20m 49s\tremaining: 5m 26s\n",
      "7928:\tlearn: 0.0520512\ttotal: 20m 49s\tremaining: 5m 26s\n",
      "7929:\tlearn: 0.0520512\ttotal: 20m 49s\tremaining: 5m 26s\n",
      "7930:\tlearn: 0.0520512\ttotal: 20m 50s\tremaining: 5m 26s\n",
      "7931:\tlearn: 0.0520512\ttotal: 20m 50s\tremaining: 5m 25s\n",
      "7932:\tlearn: 0.0520512\ttotal: 20m 50s\tremaining: 5m 25s\n",
      "7933:\tlearn: 0.0520512\ttotal: 20m 50s\tremaining: 5m 25s\n",
      "7934:\tlearn: 0.0520512\ttotal: 20m 50s\tremaining: 5m 25s\n",
      "7935:\tlearn: 0.0520512\ttotal: 20m 50s\tremaining: 5m 25s\n",
      "7936:\tlearn: 0.0520512\ttotal: 20m 51s\tremaining: 5m 25s\n",
      "7937:\tlearn: 0.0520512\ttotal: 20m 51s\tremaining: 5m 25s\n",
      "7938:\tlearn: 0.0520512\ttotal: 20m 51s\tremaining: 5m 24s\n",
      "7939:\tlearn: 0.0520512\ttotal: 20m 51s\tremaining: 5m 24s\n",
      "7940:\tlearn: 0.0520512\ttotal: 20m 51s\tremaining: 5m 24s\n",
      "7941:\tlearn: 0.0520512\ttotal: 20m 51s\tremaining: 5m 24s\n",
      "7942:\tlearn: 0.0520512\ttotal: 20m 52s\tremaining: 5m 24s\n",
      "7943:\tlearn: 0.0520512\ttotal: 20m 52s\tremaining: 5m 24s\n",
      "7944:\tlearn: 0.0520512\ttotal: 20m 52s\tremaining: 5m 23s\n",
      "7945:\tlearn: 0.0520512\ttotal: 20m 52s\tremaining: 5m 23s\n",
      "7946:\tlearn: 0.0520512\ttotal: 20m 52s\tremaining: 5m 23s\n",
      "7947:\tlearn: 0.0520512\ttotal: 20m 52s\tremaining: 5m 23s\n",
      "7948:\tlearn: 0.0520512\ttotal: 20m 53s\tremaining: 5m 23s\n",
      "7949:\tlearn: 0.0520512\ttotal: 20m 53s\tremaining: 5m 23s\n",
      "7950:\tlearn: 0.0520512\ttotal: 20m 53s\tremaining: 5m 23s\n",
      "7951:\tlearn: 0.0520512\ttotal: 20m 53s\tremaining: 5m 22s\n",
      "7952:\tlearn: 0.0520512\ttotal: 20m 53s\tremaining: 5m 22s\n",
      "7953:\tlearn: 0.0520512\ttotal: 20m 53s\tremaining: 5m 22s\n",
      "7954:\tlearn: 0.0520512\ttotal: 20m 54s\tremaining: 5m 22s\n",
      "7955:\tlearn: 0.0520512\ttotal: 20m 54s\tremaining: 5m 22s\n",
      "7956:\tlearn: 0.0520512\ttotal: 20m 54s\tremaining: 5m 22s\n",
      "7957:\tlearn: 0.0520512\ttotal: 20m 54s\tremaining: 5m 21s\n",
      "7958:\tlearn: 0.0520512\ttotal: 20m 54s\tremaining: 5m 21s\n",
      "7959:\tlearn: 0.0520512\ttotal: 20m 54s\tremaining: 5m 21s\n",
      "7960:\tlearn: 0.0520512\ttotal: 20m 55s\tremaining: 5m 21s\n",
      "7961:\tlearn: 0.0520512\ttotal: 20m 55s\tremaining: 5m 21s\n",
      "7962:\tlearn: 0.0520512\ttotal: 20m 55s\tremaining: 5m 21s\n",
      "7963:\tlearn: 0.0520512\ttotal: 20m 55s\tremaining: 5m 20s\n",
      "7964:\tlearn: 0.0520512\ttotal: 20m 55s\tremaining: 5m 20s\n",
      "7965:\tlearn: 0.0520512\ttotal: 20m 55s\tremaining: 5m 20s\n",
      "7966:\tlearn: 0.0520512\ttotal: 20m 56s\tremaining: 5m 20s\n",
      "7967:\tlearn: 0.0520512\ttotal: 20m 56s\tremaining: 5m 20s\n",
      "7968:\tlearn: 0.0520512\ttotal: 20m 56s\tremaining: 5m 20s\n",
      "7969:\tlearn: 0.0520512\ttotal: 20m 56s\tremaining: 5m 20s\n",
      "7970:\tlearn: 0.0520512\ttotal: 20m 56s\tremaining: 5m 19s\n",
      "7971:\tlearn: 0.0520512\ttotal: 20m 56s\tremaining: 5m 19s\n",
      "7972:\tlearn: 0.0520512\ttotal: 20m 57s\tremaining: 5m 19s\n",
      "7973:\tlearn: 0.0520512\ttotal: 20m 57s\tremaining: 5m 19s\n",
      "7974:\tlearn: 0.0520512\ttotal: 20m 57s\tremaining: 5m 19s\n",
      "7975:\tlearn: 0.0520512\ttotal: 20m 57s\tremaining: 5m 19s\n",
      "7976:\tlearn: 0.0520512\ttotal: 20m 57s\tremaining: 5m 18s\n",
      "7977:\tlearn: 0.0520512\ttotal: 20m 57s\tremaining: 5m 18s\n",
      "7978:\tlearn: 0.0520512\ttotal: 20m 58s\tremaining: 5m 18s\n",
      "7979:\tlearn: 0.0520512\ttotal: 20m 58s\tremaining: 5m 18s\n",
      "7980:\tlearn: 0.0520512\ttotal: 20m 58s\tremaining: 5m 18s\n",
      "7981:\tlearn: 0.0520512\ttotal: 20m 58s\tremaining: 5m 18s\n",
      "7982:\tlearn: 0.0520512\ttotal: 20m 58s\tremaining: 5m 18s\n",
      "7983:\tlearn: 0.0520512\ttotal: 20m 58s\tremaining: 5m 17s\n",
      "7984:\tlearn: 0.0520512\ttotal: 20m 59s\tremaining: 5m 17s\n",
      "7985:\tlearn: 0.0520512\ttotal: 20m 59s\tremaining: 5m 17s\n",
      "7986:\tlearn: 0.0520512\ttotal: 20m 59s\tremaining: 5m 17s\n",
      "7987:\tlearn: 0.0520512\ttotal: 20m 59s\tremaining: 5m 17s\n",
      "7988:\tlearn: 0.0520512\ttotal: 20m 59s\tremaining: 5m 17s\n",
      "7989:\tlearn: 0.0520512\ttotal: 20m 59s\tremaining: 5m 16s\n",
      "7990:\tlearn: 0.0520512\ttotal: 21m\tremaining: 5m 16s\n",
      "7991:\tlearn: 0.0520512\ttotal: 21m\tremaining: 5m 16s\n",
      "7992:\tlearn: 0.0520512\ttotal: 21m\tremaining: 5m 16s\n",
      "7993:\tlearn: 0.0520512\ttotal: 21m\tremaining: 5m 16s\n",
      "7994:\tlearn: 0.0520512\ttotal: 21m\tremaining: 5m 16s\n",
      "7995:\tlearn: 0.0520512\ttotal: 21m\tremaining: 5m 15s\n",
      "7996:\tlearn: 0.0520512\ttotal: 21m 1s\tremaining: 5m 15s\n",
      "7997:\tlearn: 0.0520512\ttotal: 21m 1s\tremaining: 5m 15s\n",
      "7998:\tlearn: 0.0520512\ttotal: 21m 1s\tremaining: 5m 15s\n",
      "7999:\tlearn: 0.0520512\ttotal: 21m 1s\tremaining: 5m 15s\n",
      "8000:\tlearn: 0.0520512\ttotal: 21m 1s\tremaining: 5m 15s\n",
      "8001:\tlearn: 0.0520512\ttotal: 21m 1s\tremaining: 5m 15s\n",
      "8002:\tlearn: 0.0520512\ttotal: 21m 1s\tremaining: 5m 14s\n",
      "8003:\tlearn: 0.0520512\ttotal: 21m 2s\tremaining: 5m 14s\n",
      "8004:\tlearn: 0.0520512\ttotal: 21m 2s\tremaining: 5m 14s\n",
      "8005:\tlearn: 0.0520512\ttotal: 21m 2s\tremaining: 5m 14s\n",
      "8006:\tlearn: 0.0520512\ttotal: 21m 2s\tremaining: 5m 14s\n",
      "8007:\tlearn: 0.0520512\ttotal: 21m 2s\tremaining: 5m 14s\n",
      "8008:\tlearn: 0.0520512\ttotal: 21m 2s\tremaining: 5m 13s\n",
      "8009:\tlearn: 0.0520512\ttotal: 21m 3s\tremaining: 5m 13s\n",
      "8010:\tlearn: 0.0520512\ttotal: 21m 3s\tremaining: 5m 13s\n",
      "8011:\tlearn: 0.0520512\ttotal: 21m 3s\tremaining: 5m 13s\n",
      "8012:\tlearn: 0.0520512\ttotal: 21m 3s\tremaining: 5m 13s\n",
      "8013:\tlearn: 0.0520512\ttotal: 21m 3s\tremaining: 5m 13s\n",
      "8014:\tlearn: 0.0520512\ttotal: 21m 3s\tremaining: 5m 13s\n",
      "8015:\tlearn: 0.0520512\ttotal: 21m 4s\tremaining: 5m 12s\n",
      "8016:\tlearn: 0.0520512\ttotal: 21m 4s\tremaining: 5m 12s\n",
      "8017:\tlearn: 0.0520512\ttotal: 21m 4s\tremaining: 5m 12s\n",
      "8018:\tlearn: 0.0520512\ttotal: 21m 4s\tremaining: 5m 12s\n",
      "8019:\tlearn: 0.0520512\ttotal: 21m 4s\tremaining: 5m 12s\n",
      "8020:\tlearn: 0.0520512\ttotal: 21m 4s\tremaining: 5m 12s\n",
      "8021:\tlearn: 0.0520512\ttotal: 21m 5s\tremaining: 5m 11s\n",
      "8022:\tlearn: 0.0520512\ttotal: 21m 5s\tremaining: 5m 11s\n",
      "8023:\tlearn: 0.0520512\ttotal: 21m 5s\tremaining: 5m 11s\n",
      "8024:\tlearn: 0.0520512\ttotal: 21m 5s\tremaining: 5m 11s\n",
      "8025:\tlearn: 0.0520512\ttotal: 21m 5s\tremaining: 5m 11s\n",
      "8026:\tlearn: 0.0520512\ttotal: 21m 5s\tremaining: 5m 11s\n",
      "8027:\tlearn: 0.0520512\ttotal: 21m 6s\tremaining: 5m 11s\n",
      "8028:\tlearn: 0.0520512\ttotal: 21m 6s\tremaining: 5m 10s\n",
      "8029:\tlearn: 0.0520512\ttotal: 21m 6s\tremaining: 5m 10s\n",
      "8030:\tlearn: 0.0520512\ttotal: 21m 6s\tremaining: 5m 10s\n",
      "8031:\tlearn: 0.0520512\ttotal: 21m 6s\tremaining: 5m 10s\n",
      "8032:\tlearn: 0.0520512\ttotal: 21m 6s\tremaining: 5m 10s\n",
      "8033:\tlearn: 0.0520512\ttotal: 21m 7s\tremaining: 5m 10s\n",
      "8034:\tlearn: 0.0520512\ttotal: 21m 7s\tremaining: 5m 9s\n",
      "8035:\tlearn: 0.0520512\ttotal: 21m 7s\tremaining: 5m 9s\n",
      "8036:\tlearn: 0.0520512\ttotal: 21m 7s\tremaining: 5m 9s\n",
      "8037:\tlearn: 0.0520512\ttotal: 21m 7s\tremaining: 5m 9s\n",
      "8038:\tlearn: 0.0520512\ttotal: 21m 7s\tremaining: 5m 9s\n",
      "8039:\tlearn: 0.0520512\ttotal: 21m 8s\tremaining: 5m 9s\n",
      "8040:\tlearn: 0.0520512\ttotal: 21m 8s\tremaining: 5m 8s\n",
      "8041:\tlearn: 0.0520512\ttotal: 21m 8s\tremaining: 5m 8s\n",
      "8042:\tlearn: 0.0520512\ttotal: 21m 8s\tremaining: 5m 8s\n",
      "8043:\tlearn: 0.0520512\ttotal: 21m 8s\tremaining: 5m 8s\n",
      "8044:\tlearn: 0.0520512\ttotal: 21m 8s\tremaining: 5m 8s\n",
      "8045:\tlearn: 0.0520512\ttotal: 21m 8s\tremaining: 5m 8s\n",
      "8046:\tlearn: 0.0520512\ttotal: 21m 9s\tremaining: 5m 8s\n",
      "8047:\tlearn: 0.0520512\ttotal: 21m 9s\tremaining: 5m 7s\n",
      "8048:\tlearn: 0.0520512\ttotal: 21m 9s\tremaining: 5m 7s\n",
      "8049:\tlearn: 0.0520512\ttotal: 21m 9s\tremaining: 5m 7s\n",
      "8050:\tlearn: 0.0520512\ttotal: 21m 9s\tremaining: 5m 7s\n",
      "8051:\tlearn: 0.0520512\ttotal: 21m 9s\tremaining: 5m 7s\n",
      "8052:\tlearn: 0.0520512\ttotal: 21m 10s\tremaining: 5m 7s\n",
      "8053:\tlearn: 0.0520512\ttotal: 21m 10s\tremaining: 5m 6s\n",
      "8054:\tlearn: 0.0520512\ttotal: 21m 10s\tremaining: 5m 6s\n",
      "8055:\tlearn: 0.0520512\ttotal: 21m 10s\tremaining: 5m 6s\n",
      "8056:\tlearn: 0.0520512\ttotal: 21m 10s\tremaining: 5m 6s\n",
      "8057:\tlearn: 0.0520512\ttotal: 21m 10s\tremaining: 5m 6s\n",
      "8058:\tlearn: 0.0520512\ttotal: 21m 11s\tremaining: 5m 6s\n",
      "8059:\tlearn: 0.0520512\ttotal: 21m 11s\tremaining: 5m 5s\n",
      "8060:\tlearn: 0.0520512\ttotal: 21m 11s\tremaining: 5m 5s\n",
      "8061:\tlearn: 0.0520512\ttotal: 21m 11s\tremaining: 5m 5s\n",
      "8062:\tlearn: 0.0520512\ttotal: 21m 11s\tremaining: 5m 5s\n",
      "8063:\tlearn: 0.0520512\ttotal: 21m 11s\tremaining: 5m 5s\n",
      "8064:\tlearn: 0.0520512\ttotal: 21m 12s\tremaining: 5m 5s\n",
      "8065:\tlearn: 0.0520512\ttotal: 21m 12s\tremaining: 5m 5s\n",
      "8066:\tlearn: 0.0520512\ttotal: 21m 12s\tremaining: 5m 4s\n",
      "8067:\tlearn: 0.0520512\ttotal: 21m 12s\tremaining: 5m 4s\n",
      "8068:\tlearn: 0.0520512\ttotal: 21m 12s\tremaining: 5m 4s\n",
      "8069:\tlearn: 0.0520512\ttotal: 21m 12s\tremaining: 5m 4s\n",
      "8070:\tlearn: 0.0520512\ttotal: 21m 13s\tremaining: 5m 4s\n",
      "8071:\tlearn: 0.0520512\ttotal: 21m 13s\tremaining: 5m 4s\n",
      "8072:\tlearn: 0.0520512\ttotal: 21m 13s\tremaining: 5m 3s\n",
      "8073:\tlearn: 0.0520512\ttotal: 21m 13s\tremaining: 5m 3s\n",
      "8074:\tlearn: 0.0520512\ttotal: 21m 13s\tremaining: 5m 3s\n",
      "8075:\tlearn: 0.0520512\ttotal: 21m 13s\tremaining: 5m 3s\n",
      "8076:\tlearn: 0.0520512\ttotal: 21m 14s\tremaining: 5m 3s\n",
      "8077:\tlearn: 0.0520512\ttotal: 21m 14s\tremaining: 5m 3s\n",
      "8078:\tlearn: 0.0520512\ttotal: 21m 14s\tremaining: 5m 3s\n",
      "8079:\tlearn: 0.0520512\ttotal: 21m 14s\tremaining: 5m 2s\n",
      "8080:\tlearn: 0.0520512\ttotal: 21m 14s\tremaining: 5m 2s\n",
      "8081:\tlearn: 0.0520512\ttotal: 21m 14s\tremaining: 5m 2s\n",
      "8082:\tlearn: 0.0520512\ttotal: 21m 15s\tremaining: 5m 2s\n",
      "8083:\tlearn: 0.0520512\ttotal: 21m 15s\tremaining: 5m 2s\n",
      "8084:\tlearn: 0.0520512\ttotal: 21m 15s\tremaining: 5m 2s\n",
      "8085:\tlearn: 0.0520512\ttotal: 21m 15s\tremaining: 5m 1s\n",
      "8086:\tlearn: 0.0520512\ttotal: 21m 15s\tremaining: 5m 1s\n",
      "8087:\tlearn: 0.0520512\ttotal: 21m 15s\tremaining: 5m 1s\n",
      "8088:\tlearn: 0.0520512\ttotal: 21m 16s\tremaining: 5m 1s\n",
      "8089:\tlearn: 0.0520512\ttotal: 21m 16s\tremaining: 5m 1s\n",
      "8090:\tlearn: 0.0520512\ttotal: 21m 16s\tremaining: 5m 1s\n",
      "8091:\tlearn: 0.0520512\ttotal: 21m 16s\tremaining: 5m 1s\n",
      "8092:\tlearn: 0.0520512\ttotal: 21m 16s\tremaining: 5m\n",
      "8093:\tlearn: 0.0520512\ttotal: 21m 16s\tremaining: 5m\n",
      "8094:\tlearn: 0.0520512\ttotal: 21m 17s\tremaining: 5m\n",
      "8095:\tlearn: 0.0520512\ttotal: 21m 17s\tremaining: 5m\n",
      "8096:\tlearn: 0.0520512\ttotal: 21m 17s\tremaining: 5m\n",
      "8097:\tlearn: 0.0520512\ttotal: 21m 17s\tremaining: 5m\n",
      "8098:\tlearn: 0.0520512\ttotal: 21m 17s\tremaining: 4m 59s\n",
      "8099:\tlearn: 0.0520512\ttotal: 21m 17s\tremaining: 4m 59s\n",
      "8100:\tlearn: 0.0520512\ttotal: 21m 18s\tremaining: 4m 59s\n",
      "8101:\tlearn: 0.0520512\ttotal: 21m 18s\tremaining: 4m 59s\n",
      "8102:\tlearn: 0.0520512\ttotal: 21m 18s\tremaining: 4m 59s\n",
      "8103:\tlearn: 0.0520512\ttotal: 21m 18s\tremaining: 4m 59s\n",
      "8104:\tlearn: 0.0520512\ttotal: 21m 18s\tremaining: 4m 58s\n",
      "8105:\tlearn: 0.0520512\ttotal: 21m 18s\tremaining: 4m 58s\n",
      "8106:\tlearn: 0.0520512\ttotal: 21m 19s\tremaining: 4m 58s\n",
      "8107:\tlearn: 0.0520512\ttotal: 21m 19s\tremaining: 4m 58s\n",
      "8108:\tlearn: 0.0520512\ttotal: 21m 19s\tremaining: 4m 58s\n",
      "8109:\tlearn: 0.0520512\ttotal: 21m 19s\tremaining: 4m 58s\n",
      "8110:\tlearn: 0.0520512\ttotal: 21m 19s\tremaining: 4m 58s\n",
      "8111:\tlearn: 0.0520512\ttotal: 21m 19s\tremaining: 4m 57s\n",
      "8112:\tlearn: 0.0520512\ttotal: 21m 20s\tremaining: 4m 57s\n",
      "8113:\tlearn: 0.0520512\ttotal: 21m 20s\tremaining: 4m 57s\n",
      "8114:\tlearn: 0.0520512\ttotal: 21m 20s\tremaining: 4m 57s\n",
      "8115:\tlearn: 0.0520512\ttotal: 21m 20s\tremaining: 4m 57s\n",
      "8116:\tlearn: 0.0520512\ttotal: 21m 20s\tremaining: 4m 57s\n",
      "8117:\tlearn: 0.0520512\ttotal: 21m 20s\tremaining: 4m 56s\n",
      "8118:\tlearn: 0.0520512\ttotal: 21m 21s\tremaining: 4m 56s\n",
      "8119:\tlearn: 0.0520512\ttotal: 21m 21s\tremaining: 4m 56s\n",
      "8120:\tlearn: 0.0520512\ttotal: 21m 21s\tremaining: 4m 56s\n",
      "8121:\tlearn: 0.0520512\ttotal: 21m 21s\tremaining: 4m 56s\n",
      "8122:\tlearn: 0.0520512\ttotal: 21m 21s\tremaining: 4m 56s\n",
      "8123:\tlearn: 0.0520512\ttotal: 21m 21s\tremaining: 4m 56s\n",
      "8124:\tlearn: 0.0520512\ttotal: 21m 22s\tremaining: 4m 55s\n",
      "8125:\tlearn: 0.0520512\ttotal: 21m 22s\tremaining: 4m 55s\n",
      "8126:\tlearn: 0.0520512\ttotal: 21m 22s\tremaining: 4m 55s\n",
      "8127:\tlearn: 0.0520512\ttotal: 21m 22s\tremaining: 4m 55s\n",
      "8128:\tlearn: 0.0520512\ttotal: 21m 22s\tremaining: 4m 55s\n",
      "8129:\tlearn: 0.0520512\ttotal: 21m 22s\tremaining: 4m 55s\n",
      "8130:\tlearn: 0.0520512\ttotal: 21m 23s\tremaining: 4m 54s\n",
      "8131:\tlearn: 0.0520512\ttotal: 21m 23s\tremaining: 4m 54s\n",
      "8132:\tlearn: 0.0520512\ttotal: 21m 23s\tremaining: 4m 54s\n",
      "8133:\tlearn: 0.0520512\ttotal: 21m 23s\tremaining: 4m 54s\n",
      "8134:\tlearn: 0.0520512\ttotal: 21m 23s\tremaining: 4m 54s\n",
      "8135:\tlearn: 0.0520512\ttotal: 21m 23s\tremaining: 4m 54s\n",
      "8136:\tlearn: 0.0520512\ttotal: 21m 23s\tremaining: 4m 53s\n",
      "8137:\tlearn: 0.0520512\ttotal: 21m 24s\tremaining: 4m 53s\n",
      "8138:\tlearn: 0.0520512\ttotal: 21m 24s\tremaining: 4m 53s\n",
      "8139:\tlearn: 0.0520512\ttotal: 21m 24s\tremaining: 4m 53s\n",
      "8140:\tlearn: 0.0520512\ttotal: 21m 24s\tremaining: 4m 53s\n",
      "8141:\tlearn: 0.0520512\ttotal: 21m 24s\tremaining: 4m 53s\n",
      "8142:\tlearn: 0.0520512\ttotal: 21m 24s\tremaining: 4m 53s\n",
      "8143:\tlearn: 0.0520512\ttotal: 21m 25s\tremaining: 4m 52s\n",
      "8144:\tlearn: 0.0520512\ttotal: 21m 25s\tremaining: 4m 52s\n",
      "8145:\tlearn: 0.0520512\ttotal: 21m 25s\tremaining: 4m 52s\n",
      "8146:\tlearn: 0.0520512\ttotal: 21m 25s\tremaining: 4m 52s\n",
      "8147:\tlearn: 0.0520512\ttotal: 21m 25s\tremaining: 4m 52s\n",
      "8148:\tlearn: 0.0520512\ttotal: 21m 25s\tremaining: 4m 52s\n",
      "8149:\tlearn: 0.0520512\ttotal: 21m 26s\tremaining: 4m 51s\n",
      "8150:\tlearn: 0.0520512\ttotal: 21m 26s\tremaining: 4m 51s\n",
      "8151:\tlearn: 0.0520512\ttotal: 21m 26s\tremaining: 4m 51s\n",
      "8152:\tlearn: 0.0520512\ttotal: 21m 26s\tremaining: 4m 51s\n",
      "8153:\tlearn: 0.0520512\ttotal: 21m 26s\tremaining: 4m 51s\n",
      "8154:\tlearn: 0.0520512\ttotal: 21m 26s\tremaining: 4m 51s\n",
      "8155:\tlearn: 0.0520512\ttotal: 21m 27s\tremaining: 4m 51s\n",
      "8156:\tlearn: 0.0520512\ttotal: 21m 27s\tremaining: 4m 50s\n",
      "8157:\tlearn: 0.0520512\ttotal: 21m 27s\tremaining: 4m 50s\n",
      "8158:\tlearn: 0.0520512\ttotal: 21m 27s\tremaining: 4m 50s\n",
      "8159:\tlearn: 0.0520512\ttotal: 21m 27s\tremaining: 4m 50s\n",
      "8160:\tlearn: 0.0520512\ttotal: 21m 27s\tremaining: 4m 50s\n",
      "8161:\tlearn: 0.0520512\ttotal: 21m 28s\tremaining: 4m 50s\n",
      "8162:\tlearn: 0.0520512\ttotal: 21m 28s\tremaining: 4m 49s\n",
      "8163:\tlearn: 0.0520512\ttotal: 21m 28s\tremaining: 4m 49s\n",
      "8164:\tlearn: 0.0520512\ttotal: 21m 28s\tremaining: 4m 49s\n",
      "8165:\tlearn: 0.0520512\ttotal: 21m 28s\tremaining: 4m 49s\n",
      "8166:\tlearn: 0.0520512\ttotal: 21m 28s\tremaining: 4m 49s\n",
      "8167:\tlearn: 0.0520512\ttotal: 21m 29s\tremaining: 4m 49s\n",
      "8168:\tlearn: 0.0520512\ttotal: 21m 29s\tremaining: 4m 48s\n",
      "8169:\tlearn: 0.0520512\ttotal: 21m 29s\tremaining: 4m 48s\n",
      "8170:\tlearn: 0.0520512\ttotal: 21m 29s\tremaining: 4m 48s\n",
      "8171:\tlearn: 0.0520512\ttotal: 21m 29s\tremaining: 4m 48s\n",
      "8172:\tlearn: 0.0520512\ttotal: 21m 29s\tremaining: 4m 48s\n",
      "8173:\tlearn: 0.0520512\ttotal: 21m 30s\tremaining: 4m 48s\n",
      "8174:\tlearn: 0.0520512\ttotal: 21m 30s\tremaining: 4m 48s\n",
      "8175:\tlearn: 0.0520512\ttotal: 21m 30s\tremaining: 4m 47s\n",
      "8176:\tlearn: 0.0520512\ttotal: 21m 30s\tremaining: 4m 47s\n",
      "8177:\tlearn: 0.0520512\ttotal: 21m 30s\tremaining: 4m 47s\n",
      "8178:\tlearn: 0.0520512\ttotal: 21m 30s\tremaining: 4m 47s\n",
      "8179:\tlearn: 0.0520512\ttotal: 21m 31s\tremaining: 4m 47s\n",
      "8180:\tlearn: 0.0520512\ttotal: 21m 31s\tremaining: 4m 47s\n",
      "8181:\tlearn: 0.0520512\ttotal: 21m 31s\tremaining: 4m 46s\n",
      "8182:\tlearn: 0.0520512\ttotal: 21m 31s\tremaining: 4m 46s\n",
      "8183:\tlearn: 0.0520512\ttotal: 21m 31s\tremaining: 4m 46s\n",
      "8184:\tlearn: 0.0520512\ttotal: 21m 31s\tremaining: 4m 46s\n",
      "8185:\tlearn: 0.0520512\ttotal: 21m 32s\tremaining: 4m 46s\n",
      "8186:\tlearn: 0.0520512\ttotal: 21m 32s\tremaining: 4m 46s\n",
      "8187:\tlearn: 0.0520512\ttotal: 21m 32s\tremaining: 4m 46s\n",
      "8188:\tlearn: 0.0520512\ttotal: 21m 32s\tremaining: 4m 45s\n",
      "8189:\tlearn: 0.0520512\ttotal: 21m 32s\tremaining: 4m 45s\n",
      "8190:\tlearn: 0.0520512\ttotal: 21m 32s\tremaining: 4m 45s\n",
      "8191:\tlearn: 0.0520512\ttotal: 21m 33s\tremaining: 4m 45s\n",
      "8192:\tlearn: 0.0520512\ttotal: 21m 33s\tremaining: 4m 45s\n",
      "8193:\tlearn: 0.0520512\ttotal: 21m 33s\tremaining: 4m 45s\n",
      "8194:\tlearn: 0.0520512\ttotal: 21m 33s\tremaining: 4m 44s\n",
      "8195:\tlearn: 0.0520512\ttotal: 21m 33s\tremaining: 4m 44s\n",
      "8196:\tlearn: 0.0520512\ttotal: 21m 33s\tremaining: 4m 44s\n",
      "8197:\tlearn: 0.0520512\ttotal: 21m 34s\tremaining: 4m 44s\n",
      "8198:\tlearn: 0.0520512\ttotal: 21m 34s\tremaining: 4m 44s\n",
      "8199:\tlearn: 0.0520512\ttotal: 21m 34s\tremaining: 4m 44s\n",
      "8200:\tlearn: 0.0520512\ttotal: 21m 34s\tremaining: 4m 43s\n",
      "8201:\tlearn: 0.0520512\ttotal: 21m 34s\tremaining: 4m 43s\n",
      "8202:\tlearn: 0.0520512\ttotal: 21m 34s\tremaining: 4m 43s\n",
      "8203:\tlearn: 0.0520512\ttotal: 21m 35s\tremaining: 4m 43s\n",
      "8204:\tlearn: 0.0520512\ttotal: 21m 35s\tremaining: 4m 43s\n",
      "8205:\tlearn: 0.0520512\ttotal: 21m 35s\tremaining: 4m 43s\n",
      "8206:\tlearn: 0.0520512\ttotal: 21m 35s\tremaining: 4m 43s\n",
      "8207:\tlearn: 0.0520512\ttotal: 21m 35s\tremaining: 4m 42s\n",
      "8208:\tlearn: 0.0520512\ttotal: 21m 35s\tremaining: 4m 42s\n",
      "8209:\tlearn: 0.0520512\ttotal: 21m 36s\tremaining: 4m 42s\n",
      "8210:\tlearn: 0.0520512\ttotal: 21m 36s\tremaining: 4m 42s\n",
      "8211:\tlearn: 0.0520512\ttotal: 21m 36s\tremaining: 4m 42s\n",
      "8212:\tlearn: 0.0520512\ttotal: 21m 36s\tremaining: 4m 42s\n",
      "8213:\tlearn: 0.0520512\ttotal: 21m 36s\tremaining: 4m 41s\n",
      "8214:\tlearn: 0.0520512\ttotal: 21m 36s\tremaining: 4m 41s\n",
      "8215:\tlearn: 0.0520512\ttotal: 21m 37s\tremaining: 4m 41s\n",
      "8216:\tlearn: 0.0520512\ttotal: 21m 37s\tremaining: 4m 41s\n",
      "8217:\tlearn: 0.0520512\ttotal: 21m 37s\tremaining: 4m 41s\n",
      "8218:\tlearn: 0.0520512\ttotal: 21m 37s\tremaining: 4m 41s\n",
      "8219:\tlearn: 0.0520512\ttotal: 21m 37s\tremaining: 4m 41s\n",
      "8220:\tlearn: 0.0520512\ttotal: 21m 37s\tremaining: 4m 40s\n",
      "8221:\tlearn: 0.0520512\ttotal: 21m 38s\tremaining: 4m 40s\n",
      "8222:\tlearn: 0.0520512\ttotal: 21m 38s\tremaining: 4m 40s\n",
      "8223:\tlearn: 0.0520512\ttotal: 21m 38s\tremaining: 4m 40s\n",
      "8224:\tlearn: 0.0520512\ttotal: 21m 38s\tremaining: 4m 40s\n",
      "8225:\tlearn: 0.0520512\ttotal: 21m 38s\tremaining: 4m 40s\n",
      "8226:\tlearn: 0.0520512\ttotal: 21m 38s\tremaining: 4m 39s\n",
      "8227:\tlearn: 0.0520512\ttotal: 21m 39s\tremaining: 4m 39s\n",
      "8228:\tlearn: 0.0520512\ttotal: 21m 39s\tremaining: 4m 39s\n",
      "8229:\tlearn: 0.0520512\ttotal: 21m 39s\tremaining: 4m 39s\n",
      "8230:\tlearn: 0.0520512\ttotal: 21m 39s\tremaining: 4m 39s\n",
      "8231:\tlearn: 0.0520512\ttotal: 21m 39s\tremaining: 4m 39s\n",
      "8232:\tlearn: 0.0520512\ttotal: 21m 39s\tremaining: 4m 38s\n",
      "8233:\tlearn: 0.0520512\ttotal: 21m 40s\tremaining: 4m 38s\n",
      "8234:\tlearn: 0.0520512\ttotal: 21m 40s\tremaining: 4m 38s\n",
      "8235:\tlearn: 0.0520512\ttotal: 21m 40s\tremaining: 4m 38s\n",
      "8236:\tlearn: 0.0520512\ttotal: 21m 40s\tremaining: 4m 38s\n",
      "8237:\tlearn: 0.0520512\ttotal: 21m 40s\tremaining: 4m 38s\n",
      "8238:\tlearn: 0.0520512\ttotal: 21m 40s\tremaining: 4m 38s\n",
      "8239:\tlearn: 0.0520512\ttotal: 21m 40s\tremaining: 4m 37s\n",
      "8240:\tlearn: 0.0520512\ttotal: 21m 41s\tremaining: 4m 37s\n",
      "8241:\tlearn: 0.0520512\ttotal: 21m 41s\tremaining: 4m 37s\n",
      "8242:\tlearn: 0.0520512\ttotal: 21m 41s\tremaining: 4m 37s\n",
      "8243:\tlearn: 0.0520512\ttotal: 21m 41s\tremaining: 4m 37s\n",
      "8244:\tlearn: 0.0520512\ttotal: 21m 41s\tremaining: 4m 37s\n",
      "8245:\tlearn: 0.0520512\ttotal: 21m 41s\tremaining: 4m 36s\n",
      "8246:\tlearn: 0.0520512\ttotal: 21m 42s\tremaining: 4m 36s\n",
      "8247:\tlearn: 0.0520512\ttotal: 21m 42s\tremaining: 4m 36s\n",
      "8248:\tlearn: 0.0520512\ttotal: 21m 42s\tremaining: 4m 36s\n",
      "8249:\tlearn: 0.0520512\ttotal: 21m 42s\tremaining: 4m 36s\n",
      "8250:\tlearn: 0.0520512\ttotal: 21m 42s\tremaining: 4m 36s\n",
      "8251:\tlearn: 0.0520512\ttotal: 21m 42s\tremaining: 4m 35s\n",
      "8252:\tlearn: 0.0520512\ttotal: 21m 43s\tremaining: 4m 35s\n",
      "8253:\tlearn: 0.0520512\ttotal: 21m 43s\tremaining: 4m 35s\n",
      "8254:\tlearn: 0.0520512\ttotal: 21m 43s\tremaining: 4m 35s\n",
      "8255:\tlearn: 0.0520512\ttotal: 21m 43s\tremaining: 4m 35s\n",
      "8256:\tlearn: 0.0520512\ttotal: 21m 43s\tremaining: 4m 35s\n",
      "8257:\tlearn: 0.0520512\ttotal: 21m 43s\tremaining: 4m 35s\n",
      "8258:\tlearn: 0.0520512\ttotal: 21m 44s\tremaining: 4m 34s\n",
      "8259:\tlearn: 0.0520512\ttotal: 21m 44s\tremaining: 4m 34s\n",
      "8260:\tlearn: 0.0520512\ttotal: 21m 44s\tremaining: 4m 34s\n",
      "8261:\tlearn: 0.0520512\ttotal: 21m 44s\tremaining: 4m 34s\n",
      "8262:\tlearn: 0.0520512\ttotal: 21m 44s\tremaining: 4m 34s\n",
      "8263:\tlearn: 0.0520512\ttotal: 21m 44s\tremaining: 4m 34s\n",
      "8264:\tlearn: 0.0520512\ttotal: 21m 44s\tremaining: 4m 33s\n",
      "8265:\tlearn: 0.0520512\ttotal: 21m 45s\tremaining: 4m 33s\n",
      "8266:\tlearn: 0.0520512\ttotal: 21m 45s\tremaining: 4m 33s\n",
      "8267:\tlearn: 0.0520512\ttotal: 21m 45s\tremaining: 4m 33s\n",
      "8268:\tlearn: 0.0520512\ttotal: 21m 45s\tremaining: 4m 33s\n",
      "8269:\tlearn: 0.0520512\ttotal: 21m 45s\tremaining: 4m 33s\n",
      "8270:\tlearn: 0.0520512\ttotal: 21m 45s\tremaining: 4m 33s\n",
      "8271:\tlearn: 0.0520512\ttotal: 21m 46s\tremaining: 4m 32s\n",
      "8272:\tlearn: 0.0520512\ttotal: 21m 46s\tremaining: 4m 32s\n",
      "8273:\tlearn: 0.0520512\ttotal: 21m 46s\tremaining: 4m 32s\n",
      "8274:\tlearn: 0.0520512\ttotal: 21m 46s\tremaining: 4m 32s\n",
      "8275:\tlearn: 0.0520512\ttotal: 21m 46s\tremaining: 4m 32s\n",
      "8276:\tlearn: 0.0520512\ttotal: 21m 46s\tremaining: 4m 32s\n",
      "8277:\tlearn: 0.0520512\ttotal: 21m 47s\tremaining: 4m 31s\n",
      "8278:\tlearn: 0.0520512\ttotal: 21m 47s\tremaining: 4m 31s\n",
      "8279:\tlearn: 0.0520512\ttotal: 21m 47s\tremaining: 4m 31s\n",
      "8280:\tlearn: 0.0520512\ttotal: 21m 47s\tremaining: 4m 31s\n",
      "8281:\tlearn: 0.0520512\ttotal: 21m 47s\tremaining: 4m 31s\n",
      "8282:\tlearn: 0.0520512\ttotal: 21m 47s\tremaining: 4m 31s\n",
      "8283:\tlearn: 0.0520512\ttotal: 21m 48s\tremaining: 4m 30s\n",
      "8284:\tlearn: 0.0520512\ttotal: 21m 48s\tremaining: 4m 30s\n",
      "8285:\tlearn: 0.0520512\ttotal: 21m 48s\tremaining: 4m 30s\n",
      "8286:\tlearn: 0.0520512\ttotal: 21m 48s\tremaining: 4m 30s\n",
      "8287:\tlearn: 0.0520512\ttotal: 21m 48s\tremaining: 4m 30s\n",
      "8288:\tlearn: 0.0520512\ttotal: 21m 48s\tremaining: 4m 30s\n",
      "8289:\tlearn: 0.0520512\ttotal: 21m 49s\tremaining: 4m 30s\n",
      "8290:\tlearn: 0.0520512\ttotal: 21m 49s\tremaining: 4m 29s\n",
      "8291:\tlearn: 0.0520512\ttotal: 21m 49s\tremaining: 4m 29s\n",
      "8292:\tlearn: 0.0520512\ttotal: 21m 49s\tremaining: 4m 29s\n",
      "8293:\tlearn: 0.0520512\ttotal: 21m 49s\tremaining: 4m 29s\n",
      "8294:\tlearn: 0.0520512\ttotal: 21m 49s\tremaining: 4m 29s\n",
      "8295:\tlearn: 0.0520512\ttotal: 21m 50s\tremaining: 4m 29s\n",
      "8296:\tlearn: 0.0520512\ttotal: 21m 50s\tremaining: 4m 28s\n",
      "8297:\tlearn: 0.0520512\ttotal: 21m 50s\tremaining: 4m 28s\n",
      "8298:\tlearn: 0.0520512\ttotal: 21m 50s\tremaining: 4m 28s\n",
      "8299:\tlearn: 0.0520512\ttotal: 21m 50s\tremaining: 4m 28s\n",
      "8300:\tlearn: 0.0520512\ttotal: 21m 50s\tremaining: 4m 28s\n",
      "8301:\tlearn: 0.0520512\ttotal: 21m 50s\tremaining: 4m 28s\n",
      "8302:\tlearn: 0.0520512\ttotal: 21m 51s\tremaining: 4m 27s\n",
      "8303:\tlearn: 0.0520512\ttotal: 21m 51s\tremaining: 4m 27s\n",
      "8304:\tlearn: 0.0520512\ttotal: 21m 51s\tremaining: 4m 27s\n",
      "8305:\tlearn: 0.0520512\ttotal: 21m 51s\tremaining: 4m 27s\n",
      "8306:\tlearn: 0.0520512\ttotal: 21m 51s\tremaining: 4m 27s\n",
      "8307:\tlearn: 0.0520512\ttotal: 21m 51s\tremaining: 4m 27s\n",
      "8308:\tlearn: 0.0520512\ttotal: 21m 52s\tremaining: 4m 27s\n",
      "8309:\tlearn: 0.0520512\ttotal: 21m 52s\tremaining: 4m 26s\n",
      "8310:\tlearn: 0.0520512\ttotal: 21m 52s\tremaining: 4m 26s\n",
      "8311:\tlearn: 0.0520512\ttotal: 21m 52s\tremaining: 4m 26s\n",
      "8312:\tlearn: 0.0520512\ttotal: 21m 52s\tremaining: 4m 26s\n",
      "8313:\tlearn: 0.0520512\ttotal: 21m 52s\tremaining: 4m 26s\n",
      "8314:\tlearn: 0.0520512\ttotal: 21m 53s\tremaining: 4m 26s\n",
      "8315:\tlearn: 0.0520512\ttotal: 21m 53s\tremaining: 4m 25s\n",
      "8316:\tlearn: 0.0520512\ttotal: 21m 53s\tremaining: 4m 25s\n",
      "8317:\tlearn: 0.0520512\ttotal: 21m 53s\tremaining: 4m 25s\n",
      "8318:\tlearn: 0.0520512\ttotal: 21m 53s\tremaining: 4m 25s\n",
      "8319:\tlearn: 0.0520512\ttotal: 21m 53s\tremaining: 4m 25s\n",
      "8320:\tlearn: 0.0520512\ttotal: 21m 54s\tremaining: 4m 25s\n",
      "8321:\tlearn: 0.0520512\ttotal: 21m 54s\tremaining: 4m 24s\n",
      "8322:\tlearn: 0.0520512\ttotal: 21m 54s\tremaining: 4m 24s\n",
      "8323:\tlearn: 0.0520512\ttotal: 21m 54s\tremaining: 4m 24s\n",
      "8324:\tlearn: 0.0520512\ttotal: 21m 54s\tremaining: 4m 24s\n",
      "8325:\tlearn: 0.0520512\ttotal: 21m 54s\tremaining: 4m 24s\n",
      "8326:\tlearn: 0.0520512\ttotal: 21m 54s\tremaining: 4m 24s\n",
      "8327:\tlearn: 0.0520512\ttotal: 21m 55s\tremaining: 4m 24s\n",
      "8328:\tlearn: 0.0520512\ttotal: 21m 55s\tremaining: 4m 23s\n",
      "8329:\tlearn: 0.0520512\ttotal: 21m 55s\tremaining: 4m 23s\n",
      "8330:\tlearn: 0.0520512\ttotal: 21m 55s\tremaining: 4m 23s\n",
      "8331:\tlearn: 0.0520512\ttotal: 21m 55s\tremaining: 4m 23s\n",
      "8332:\tlearn: 0.0520512\ttotal: 21m 55s\tremaining: 4m 23s\n",
      "8333:\tlearn: 0.0520512\ttotal: 21m 56s\tremaining: 4m 23s\n",
      "8334:\tlearn: 0.0520512\ttotal: 21m 56s\tremaining: 4m 22s\n",
      "8335:\tlearn: 0.0520512\ttotal: 21m 56s\tremaining: 4m 22s\n",
      "8336:\tlearn: 0.0520512\ttotal: 21m 56s\tremaining: 4m 22s\n",
      "8337:\tlearn: 0.0520512\ttotal: 21m 56s\tremaining: 4m 22s\n",
      "8338:\tlearn: 0.0520512\ttotal: 21m 56s\tremaining: 4m 22s\n",
      "8339:\tlearn: 0.0520512\ttotal: 21m 57s\tremaining: 4m 22s\n",
      "8340:\tlearn: 0.0520512\ttotal: 21m 57s\tremaining: 4m 21s\n",
      "8341:\tlearn: 0.0520512\ttotal: 21m 57s\tremaining: 4m 21s\n",
      "8342:\tlearn: 0.0520512\ttotal: 21m 57s\tremaining: 4m 21s\n",
      "8343:\tlearn: 0.0520512\ttotal: 21m 57s\tremaining: 4m 21s\n",
      "8344:\tlearn: 0.0520512\ttotal: 21m 57s\tremaining: 4m 21s\n",
      "8345:\tlearn: 0.0520512\ttotal: 21m 58s\tremaining: 4m 21s\n",
      "8346:\tlearn: 0.0520512\ttotal: 21m 58s\tremaining: 4m 21s\n",
      "8347:\tlearn: 0.0520512\ttotal: 21m 58s\tremaining: 4m 20s\n",
      "8348:\tlearn: 0.0520512\ttotal: 21m 58s\tremaining: 4m 20s\n",
      "8349:\tlearn: 0.0520512\ttotal: 21m 58s\tremaining: 4m 20s\n",
      "8350:\tlearn: 0.0520512\ttotal: 21m 58s\tremaining: 4m 20s\n",
      "8351:\tlearn: 0.0520512\ttotal: 21m 59s\tremaining: 4m 20s\n",
      "8352:\tlearn: 0.0520512\ttotal: 21m 59s\tremaining: 4m 20s\n",
      "8353:\tlearn: 0.0520512\ttotal: 21m 59s\tremaining: 4m 19s\n",
      "8354:\tlearn: 0.0520512\ttotal: 21m 59s\tremaining: 4m 19s\n",
      "8355:\tlearn: 0.0520512\ttotal: 21m 59s\tremaining: 4m 19s\n",
      "8356:\tlearn: 0.0520512\ttotal: 21m 59s\tremaining: 4m 19s\n",
      "8357:\tlearn: 0.0520512\ttotal: 21m 59s\tremaining: 4m 19s\n",
      "8358:\tlearn: 0.0520512\ttotal: 22m\tremaining: 4m 19s\n",
      "8359:\tlearn: 0.0520512\ttotal: 22m\tremaining: 4m 19s\n",
      "8360:\tlearn: 0.0520512\ttotal: 22m\tremaining: 4m 18s\n",
      "8361:\tlearn: 0.0520512\ttotal: 22m\tremaining: 4m 18s\n",
      "8362:\tlearn: 0.0520512\ttotal: 22m\tremaining: 4m 18s\n",
      "8363:\tlearn: 0.0520512\ttotal: 22m\tremaining: 4m 18s\n",
      "8364:\tlearn: 0.0520512\ttotal: 22m 1s\tremaining: 4m 18s\n",
      "8365:\tlearn: 0.0520512\ttotal: 22m 1s\tremaining: 4m 18s\n",
      "8366:\tlearn: 0.0520512\ttotal: 22m 1s\tremaining: 4m 17s\n",
      "8367:\tlearn: 0.0520512\ttotal: 22m 1s\tremaining: 4m 17s\n",
      "8368:\tlearn: 0.0520512\ttotal: 22m 1s\tremaining: 4m 17s\n",
      "8369:\tlearn: 0.0520512\ttotal: 22m 1s\tremaining: 4m 17s\n",
      "8370:\tlearn: 0.0520512\ttotal: 22m 2s\tremaining: 4m 17s\n",
      "8371:\tlearn: 0.0520512\ttotal: 22m 2s\tremaining: 4m 17s\n",
      "8372:\tlearn: 0.0520512\ttotal: 22m 2s\tremaining: 4m 16s\n",
      "8373:\tlearn: 0.0520512\ttotal: 22m 2s\tremaining: 4m 16s\n",
      "8374:\tlearn: 0.0520512\ttotal: 22m 2s\tremaining: 4m 16s\n",
      "8375:\tlearn: 0.0520512\ttotal: 22m 2s\tremaining: 4m 16s\n",
      "8376:\tlearn: 0.0520512\ttotal: 22m 3s\tremaining: 4m 16s\n",
      "8377:\tlearn: 0.0520512\ttotal: 22m 3s\tremaining: 4m 16s\n",
      "8378:\tlearn: 0.0520512\ttotal: 22m 3s\tremaining: 4m 16s\n",
      "8379:\tlearn: 0.0520512\ttotal: 22m 3s\tremaining: 4m 15s\n",
      "8380:\tlearn: 0.0520512\ttotal: 22m 3s\tremaining: 4m 15s\n",
      "8381:\tlearn: 0.0520512\ttotal: 22m 3s\tremaining: 4m 15s\n",
      "8382:\tlearn: 0.0520512\ttotal: 22m 4s\tremaining: 4m 15s\n",
      "8383:\tlearn: 0.0520512\ttotal: 22m 4s\tremaining: 4m 15s\n",
      "8384:\tlearn: 0.0520512\ttotal: 22m 4s\tremaining: 4m 15s\n",
      "8385:\tlearn: 0.0520512\ttotal: 22m 4s\tremaining: 4m 14s\n",
      "8386:\tlearn: 0.0520512\ttotal: 22m 4s\tremaining: 4m 14s\n",
      "8387:\tlearn: 0.0520512\ttotal: 22m 4s\tremaining: 4m 14s\n",
      "8388:\tlearn: 0.0520512\ttotal: 22m 5s\tremaining: 4m 14s\n",
      "8389:\tlearn: 0.0520512\ttotal: 22m 5s\tremaining: 4m 14s\n",
      "8390:\tlearn: 0.0520512\ttotal: 22m 5s\tremaining: 4m 14s\n",
      "8391:\tlearn: 0.0520512\ttotal: 22m 5s\tremaining: 4m 13s\n",
      "8392:\tlearn: 0.0520512\ttotal: 22m 5s\tremaining: 4m 13s\n",
      "8393:\tlearn: 0.0520512\ttotal: 22m 5s\tremaining: 4m 13s\n",
      "8394:\tlearn: 0.0520512\ttotal: 22m 5s\tremaining: 4m 13s\n",
      "8395:\tlearn: 0.0520512\ttotal: 22m 6s\tremaining: 4m 13s\n",
      "8396:\tlearn: 0.0520512\ttotal: 22m 6s\tremaining: 4m 13s\n",
      "8397:\tlearn: 0.0520512\ttotal: 22m 6s\tremaining: 4m 13s\n",
      "8398:\tlearn: 0.0520512\ttotal: 22m 6s\tremaining: 4m 12s\n",
      "8399:\tlearn: 0.0520512\ttotal: 22m 6s\tremaining: 4m 12s\n",
      "8400:\tlearn: 0.0520512\ttotal: 22m 6s\tremaining: 4m 12s\n",
      "8401:\tlearn: 0.0520512\ttotal: 22m 7s\tremaining: 4m 12s\n",
      "8402:\tlearn: 0.0520512\ttotal: 22m 7s\tremaining: 4m 12s\n",
      "8403:\tlearn: 0.0520512\ttotal: 22m 7s\tremaining: 4m 12s\n",
      "8404:\tlearn: 0.0520512\ttotal: 22m 7s\tremaining: 4m 11s\n",
      "8405:\tlearn: 0.0520512\ttotal: 22m 7s\tremaining: 4m 11s\n",
      "8406:\tlearn: 0.0520512\ttotal: 22m 7s\tremaining: 4m 11s\n",
      "8407:\tlearn: 0.0520512\ttotal: 22m 8s\tremaining: 4m 11s\n",
      "8408:\tlearn: 0.0520512\ttotal: 22m 8s\tremaining: 4m 11s\n",
      "8409:\tlearn: 0.0520512\ttotal: 22m 8s\tremaining: 4m 11s\n",
      "8410:\tlearn: 0.0520512\ttotal: 22m 8s\tremaining: 4m 10s\n",
      "8411:\tlearn: 0.0520512\ttotal: 22m 8s\tremaining: 4m 10s\n",
      "8412:\tlearn: 0.0520512\ttotal: 22m 8s\tremaining: 4m 10s\n",
      "8413:\tlearn: 0.0520512\ttotal: 22m 9s\tremaining: 4m 10s\n",
      "8414:\tlearn: 0.0520512\ttotal: 22m 9s\tremaining: 4m 10s\n",
      "8415:\tlearn: 0.0520512\ttotal: 22m 9s\tremaining: 4m 10s\n",
      "8416:\tlearn: 0.0520512\ttotal: 22m 9s\tremaining: 4m 10s\n",
      "8417:\tlearn: 0.0520512\ttotal: 22m 9s\tremaining: 4m 9s\n",
      "8418:\tlearn: 0.0520512\ttotal: 22m 9s\tremaining: 4m 9s\n",
      "8419:\tlearn: 0.0520512\ttotal: 22m 10s\tremaining: 4m 9s\n",
      "8420:\tlearn: 0.0520512\ttotal: 22m 10s\tremaining: 4m 9s\n",
      "8421:\tlearn: 0.0520512\ttotal: 22m 10s\tremaining: 4m 9s\n",
      "8422:\tlearn: 0.0520512\ttotal: 22m 10s\tremaining: 4m 9s\n",
      "8423:\tlearn: 0.0520512\ttotal: 22m 10s\tremaining: 4m 8s\n",
      "8424:\tlearn: 0.0520512\ttotal: 22m 10s\tremaining: 4m 8s\n",
      "8425:\tlearn: 0.0520512\ttotal: 22m 11s\tremaining: 4m 8s\n",
      "8426:\tlearn: 0.0520512\ttotal: 22m 11s\tremaining: 4m 8s\n",
      "8427:\tlearn: 0.0520512\ttotal: 22m 11s\tremaining: 4m 8s\n",
      "8428:\tlearn: 0.0520512\ttotal: 22m 11s\tremaining: 4m 8s\n",
      "8429:\tlearn: 0.0520512\ttotal: 22m 11s\tremaining: 4m 8s\n",
      "8430:\tlearn: 0.0520512\ttotal: 22m 11s\tremaining: 4m 7s\n",
      "8431:\tlearn: 0.0520512\ttotal: 22m 12s\tremaining: 4m 7s\n",
      "8432:\tlearn: 0.0520512\ttotal: 22m 12s\tremaining: 4m 7s\n",
      "8433:\tlearn: 0.0520512\ttotal: 22m 12s\tremaining: 4m 7s\n",
      "8434:\tlearn: 0.0520512\ttotal: 22m 12s\tremaining: 4m 7s\n",
      "8435:\tlearn: 0.0520512\ttotal: 22m 12s\tremaining: 4m 7s\n",
      "8436:\tlearn: 0.0520512\ttotal: 22m 12s\tremaining: 4m 6s\n",
      "8437:\tlearn: 0.0520512\ttotal: 22m 12s\tremaining: 4m 6s\n",
      "8438:\tlearn: 0.0520512\ttotal: 22m 13s\tremaining: 4m 6s\n",
      "8439:\tlearn: 0.0520512\ttotal: 22m 13s\tremaining: 4m 6s\n",
      "8440:\tlearn: 0.0520512\ttotal: 22m 13s\tremaining: 4m 6s\n",
      "8441:\tlearn: 0.0520512\ttotal: 22m 13s\tremaining: 4m 6s\n",
      "8442:\tlearn: 0.0520512\ttotal: 22m 13s\tremaining: 4m 5s\n",
      "8443:\tlearn: 0.0520512\ttotal: 22m 13s\tremaining: 4m 5s\n",
      "8444:\tlearn: 0.0520512\ttotal: 22m 14s\tremaining: 4m 5s\n",
      "8445:\tlearn: 0.0520512\ttotal: 22m 14s\tremaining: 4m 5s\n",
      "8446:\tlearn: 0.0520512\ttotal: 22m 14s\tremaining: 4m 5s\n",
      "8447:\tlearn: 0.0520512\ttotal: 22m 14s\tremaining: 4m 5s\n",
      "8448:\tlearn: 0.0520512\ttotal: 22m 14s\tremaining: 4m 5s\n",
      "8449:\tlearn: 0.0520512\ttotal: 22m 14s\tremaining: 4m 4s\n",
      "8450:\tlearn: 0.0520512\ttotal: 22m 15s\tremaining: 4m 4s\n",
      "8451:\tlearn: 0.0520512\ttotal: 22m 15s\tremaining: 4m 4s\n",
      "8452:\tlearn: 0.0520512\ttotal: 22m 15s\tremaining: 4m 4s\n",
      "8453:\tlearn: 0.0520512\ttotal: 22m 15s\tremaining: 4m 4s\n",
      "8454:\tlearn: 0.0520512\ttotal: 22m 15s\tremaining: 4m 4s\n",
      "8455:\tlearn: 0.0520512\ttotal: 22m 15s\tremaining: 4m 3s\n",
      "8456:\tlearn: 0.0520512\ttotal: 22m 16s\tremaining: 4m 3s\n",
      "8457:\tlearn: 0.0520512\ttotal: 22m 16s\tremaining: 4m 3s\n",
      "8458:\tlearn: 0.0520512\ttotal: 22m 16s\tremaining: 4m 3s\n",
      "8459:\tlearn: 0.0520512\ttotal: 22m 16s\tremaining: 4m 3s\n",
      "8460:\tlearn: 0.0520512\ttotal: 22m 16s\tremaining: 4m 3s\n",
      "8461:\tlearn: 0.0520512\ttotal: 22m 16s\tremaining: 4m 2s\n",
      "8462:\tlearn: 0.0520512\ttotal: 22m 17s\tremaining: 4m 2s\n",
      "8463:\tlearn: 0.0520512\ttotal: 22m 17s\tremaining: 4m 2s\n",
      "8464:\tlearn: 0.0520512\ttotal: 22m 17s\tremaining: 4m 2s\n",
      "8465:\tlearn: 0.0520512\ttotal: 22m 17s\tremaining: 4m 2s\n",
      "8466:\tlearn: 0.0520512\ttotal: 22m 17s\tremaining: 4m 2s\n",
      "8467:\tlearn: 0.0520512\ttotal: 22m 17s\tremaining: 4m 2s\n",
      "8468:\tlearn: 0.0520512\ttotal: 22m 18s\tremaining: 4m 1s\n",
      "8469:\tlearn: 0.0520512\ttotal: 22m 18s\tremaining: 4m 1s\n",
      "8470:\tlearn: 0.0520512\ttotal: 22m 18s\tremaining: 4m 1s\n",
      "8471:\tlearn: 0.0520512\ttotal: 22m 18s\tremaining: 4m 1s\n",
      "8472:\tlearn: 0.0520512\ttotal: 22m 18s\tremaining: 4m 1s\n",
      "8473:\tlearn: 0.0520512\ttotal: 22m 18s\tremaining: 4m 1s\n",
      "8474:\tlearn: 0.0520512\ttotal: 22m 19s\tremaining: 4m\n",
      "8475:\tlearn: 0.0520512\ttotal: 22m 19s\tremaining: 4m\n",
      "8476:\tlearn: 0.0520512\ttotal: 22m 19s\tremaining: 4m\n",
      "8477:\tlearn: 0.0520512\ttotal: 22m 19s\tremaining: 4m\n",
      "8478:\tlearn: 0.0520512\ttotal: 22m 19s\tremaining: 4m\n",
      "8479:\tlearn: 0.0520512\ttotal: 22m 19s\tremaining: 4m\n",
      "8480:\tlearn: 0.0520512\ttotal: 22m 20s\tremaining: 4m\n",
      "8481:\tlearn: 0.0520512\ttotal: 22m 20s\tremaining: 3m 59s\n",
      "8482:\tlearn: 0.0520512\ttotal: 22m 20s\tremaining: 3m 59s\n",
      "8483:\tlearn: 0.0520512\ttotal: 22m 20s\tremaining: 3m 59s\n",
      "8484:\tlearn: 0.0520512\ttotal: 22m 20s\tremaining: 3m 59s\n",
      "8485:\tlearn: 0.0520512\ttotal: 22m 20s\tremaining: 3m 59s\n",
      "8486:\tlearn: 0.0520512\ttotal: 22m 21s\tremaining: 3m 59s\n",
      "8487:\tlearn: 0.0520512\ttotal: 22m 21s\tremaining: 3m 58s\n",
      "8488:\tlearn: 0.0520512\ttotal: 22m 21s\tremaining: 3m 58s\n",
      "8489:\tlearn: 0.0520512\ttotal: 22m 21s\tremaining: 3m 58s\n",
      "8490:\tlearn: 0.0520512\ttotal: 22m 21s\tremaining: 3m 58s\n",
      "8491:\tlearn: 0.0520512\ttotal: 22m 21s\tremaining: 3m 58s\n",
      "8492:\tlearn: 0.0520512\ttotal: 22m 21s\tremaining: 3m 58s\n",
      "8493:\tlearn: 0.0520512\ttotal: 22m 22s\tremaining: 3m 57s\n",
      "8494:\tlearn: 0.0520512\ttotal: 22m 22s\tremaining: 3m 57s\n",
      "8495:\tlearn: 0.0520512\ttotal: 22m 22s\tremaining: 3m 57s\n",
      "8496:\tlearn: 0.0520512\ttotal: 22m 22s\tremaining: 3m 57s\n",
      "8497:\tlearn: 0.0520512\ttotal: 22m 22s\tremaining: 3m 57s\n",
      "8498:\tlearn: 0.0520512\ttotal: 22m 22s\tremaining: 3m 57s\n",
      "8499:\tlearn: 0.0520512\ttotal: 22m 23s\tremaining: 3m 57s\n",
      "8500:\tlearn: 0.0520512\ttotal: 22m 23s\tremaining: 3m 56s\n",
      "8501:\tlearn: 0.0520512\ttotal: 22m 23s\tremaining: 3m 56s\n",
      "8502:\tlearn: 0.0520512\ttotal: 22m 23s\tremaining: 3m 56s\n",
      "8503:\tlearn: 0.0520512\ttotal: 22m 23s\tremaining: 3m 56s\n",
      "8504:\tlearn: 0.0520512\ttotal: 22m 23s\tremaining: 3m 56s\n",
      "8505:\tlearn: 0.0520512\ttotal: 22m 24s\tremaining: 3m 56s\n",
      "8506:\tlearn: 0.0520512\ttotal: 22m 24s\tremaining: 3m 55s\n",
      "8507:\tlearn: 0.0520512\ttotal: 22m 24s\tremaining: 3m 55s\n",
      "8508:\tlearn: 0.0520512\ttotal: 22m 24s\tremaining: 3m 55s\n",
      "8509:\tlearn: 0.0520512\ttotal: 22m 24s\tremaining: 3m 55s\n",
      "8510:\tlearn: 0.0520512\ttotal: 22m 24s\tremaining: 3m 55s\n",
      "8511:\tlearn: 0.0520512\ttotal: 22m 25s\tremaining: 3m 55s\n",
      "8512:\tlearn: 0.0520512\ttotal: 22m 25s\tremaining: 3m 54s\n",
      "8513:\tlearn: 0.0520512\ttotal: 22m 25s\tremaining: 3m 54s\n",
      "8514:\tlearn: 0.0520512\ttotal: 22m 25s\tremaining: 3m 54s\n",
      "8515:\tlearn: 0.0520512\ttotal: 22m 25s\tremaining: 3m 54s\n",
      "8516:\tlearn: 0.0520512\ttotal: 22m 25s\tremaining: 3m 54s\n",
      "8517:\tlearn: 0.0520512\ttotal: 22m 26s\tremaining: 3m 54s\n",
      "8518:\tlearn: 0.0520512\ttotal: 22m 26s\tremaining: 3m 54s\n",
      "8519:\tlearn: 0.0520512\ttotal: 22m 26s\tremaining: 3m 53s\n",
      "8520:\tlearn: 0.0520512\ttotal: 22m 26s\tremaining: 3m 53s\n",
      "8521:\tlearn: 0.0520512\ttotal: 22m 26s\tremaining: 3m 53s\n",
      "8522:\tlearn: 0.0520512\ttotal: 22m 26s\tremaining: 3m 53s\n",
      "8523:\tlearn: 0.0520512\ttotal: 22m 27s\tremaining: 3m 53s\n",
      "8524:\tlearn: 0.0520512\ttotal: 22m 27s\tremaining: 3m 53s\n",
      "8525:\tlearn: 0.0520512\ttotal: 22m 27s\tremaining: 3m 52s\n",
      "8526:\tlearn: 0.0520512\ttotal: 22m 27s\tremaining: 3m 52s\n",
      "8527:\tlearn: 0.0520512\ttotal: 22m 27s\tremaining: 3m 52s\n",
      "8528:\tlearn: 0.0520512\ttotal: 22m 27s\tremaining: 3m 52s\n",
      "8529:\tlearn: 0.0520512\ttotal: 22m 28s\tremaining: 3m 52s\n",
      "8530:\tlearn: 0.0520512\ttotal: 22m 28s\tremaining: 3m 52s\n",
      "8531:\tlearn: 0.0520512\ttotal: 22m 28s\tremaining: 3m 51s\n",
      "8532:\tlearn: 0.0520512\ttotal: 22m 28s\tremaining: 3m 51s\n",
      "8533:\tlearn: 0.0520512\ttotal: 22m 28s\tremaining: 3m 51s\n",
      "8534:\tlearn: 0.0520512\ttotal: 22m 28s\tremaining: 3m 51s\n",
      "8535:\tlearn: 0.0520512\ttotal: 22m 28s\tremaining: 3m 51s\n",
      "8536:\tlearn: 0.0520512\ttotal: 22m 29s\tremaining: 3m 51s\n",
      "8537:\tlearn: 0.0520512\ttotal: 22m 29s\tremaining: 3m 51s\n",
      "8538:\tlearn: 0.0520512\ttotal: 22m 29s\tremaining: 3m 50s\n",
      "8539:\tlearn: 0.0520512\ttotal: 22m 29s\tremaining: 3m 50s\n",
      "8540:\tlearn: 0.0520512\ttotal: 22m 29s\tremaining: 3m 50s\n",
      "8541:\tlearn: 0.0520512\ttotal: 22m 29s\tremaining: 3m 50s\n",
      "8542:\tlearn: 0.0520512\ttotal: 22m 30s\tremaining: 3m 50s\n",
      "8543:\tlearn: 0.0520512\ttotal: 22m 30s\tremaining: 3m 50s\n",
      "8544:\tlearn: 0.0520512\ttotal: 22m 30s\tremaining: 3m 49s\n",
      "8545:\tlearn: 0.0520512\ttotal: 22m 30s\tremaining: 3m 49s\n",
      "8546:\tlearn: 0.0520512\ttotal: 22m 30s\tremaining: 3m 49s\n",
      "8547:\tlearn: 0.0520512\ttotal: 22m 30s\tremaining: 3m 49s\n",
      "8548:\tlearn: 0.0520512\ttotal: 22m 31s\tremaining: 3m 49s\n",
      "8549:\tlearn: 0.0520512\ttotal: 22m 31s\tremaining: 3m 49s\n",
      "8550:\tlearn: 0.0520512\ttotal: 22m 31s\tremaining: 3m 49s\n",
      "8551:\tlearn: 0.0520512\ttotal: 22m 31s\tremaining: 3m 48s\n",
      "8552:\tlearn: 0.0520512\ttotal: 22m 31s\tremaining: 3m 48s\n",
      "8553:\tlearn: 0.0520512\ttotal: 22m 31s\tremaining: 3m 48s\n",
      "8554:\tlearn: 0.0520512\ttotal: 22m 32s\tremaining: 3m 48s\n",
      "8555:\tlearn: 0.0520512\ttotal: 22m 32s\tremaining: 3m 48s\n",
      "8556:\tlearn: 0.0520512\ttotal: 22m 32s\tremaining: 3m 48s\n",
      "8557:\tlearn: 0.0520512\ttotal: 22m 32s\tremaining: 3m 47s\n",
      "8558:\tlearn: 0.0520512\ttotal: 22m 32s\tremaining: 3m 47s\n",
      "8559:\tlearn: 0.0520512\ttotal: 22m 32s\tremaining: 3m 47s\n",
      "8560:\tlearn: 0.0520512\ttotal: 22m 33s\tremaining: 3m 47s\n",
      "8561:\tlearn: 0.0520512\ttotal: 22m 33s\tremaining: 3m 47s\n",
      "8562:\tlearn: 0.0520512\ttotal: 22m 33s\tremaining: 3m 47s\n",
      "8563:\tlearn: 0.0520512\ttotal: 22m 33s\tremaining: 3m 46s\n",
      "8564:\tlearn: 0.0520512\ttotal: 22m 33s\tremaining: 3m 46s\n",
      "8565:\tlearn: 0.0520512\ttotal: 22m 33s\tremaining: 3m 46s\n",
      "8566:\tlearn: 0.0520512\ttotal: 22m 34s\tremaining: 3m 46s\n",
      "8567:\tlearn: 0.0520512\ttotal: 22m 34s\tremaining: 3m 46s\n",
      "8568:\tlearn: 0.0520512\ttotal: 22m 34s\tremaining: 3m 46s\n",
      "8569:\tlearn: 0.0520512\ttotal: 22m 34s\tremaining: 3m 46s\n",
      "8570:\tlearn: 0.0520512\ttotal: 22m 34s\tremaining: 3m 45s\n",
      "8571:\tlearn: 0.0520512\ttotal: 22m 34s\tremaining: 3m 45s\n",
      "8572:\tlearn: 0.0520512\ttotal: 22m 34s\tremaining: 3m 45s\n",
      "8573:\tlearn: 0.0520512\ttotal: 22m 35s\tremaining: 3m 45s\n",
      "8574:\tlearn: 0.0520512\ttotal: 22m 35s\tremaining: 3m 45s\n",
      "8575:\tlearn: 0.0520512\ttotal: 22m 35s\tremaining: 3m 45s\n",
      "8576:\tlearn: 0.0520512\ttotal: 22m 35s\tremaining: 3m 44s\n",
      "8577:\tlearn: 0.0520512\ttotal: 22m 35s\tremaining: 3m 44s\n",
      "8578:\tlearn: 0.0520512\ttotal: 22m 35s\tremaining: 3m 44s\n",
      "8579:\tlearn: 0.0520512\ttotal: 22m 36s\tremaining: 3m 44s\n",
      "8580:\tlearn: 0.0520512\ttotal: 22m 36s\tremaining: 3m 44s\n",
      "8581:\tlearn: 0.0520512\ttotal: 22m 36s\tremaining: 3m 44s\n",
      "8582:\tlearn: 0.0520512\ttotal: 22m 36s\tremaining: 3m 43s\n",
      "8583:\tlearn: 0.0520512\ttotal: 22m 36s\tremaining: 3m 43s\n",
      "8584:\tlearn: 0.0520512\ttotal: 22m 36s\tremaining: 3m 43s\n",
      "8585:\tlearn: 0.0520512\ttotal: 22m 37s\tremaining: 3m 43s\n",
      "8586:\tlearn: 0.0520512\ttotal: 22m 37s\tremaining: 3m 43s\n",
      "8587:\tlearn: 0.0520512\ttotal: 22m 37s\tremaining: 3m 43s\n",
      "8588:\tlearn: 0.0520512\ttotal: 22m 37s\tremaining: 3m 43s\n",
      "8589:\tlearn: 0.0520512\ttotal: 22m 37s\tremaining: 3m 42s\n",
      "8590:\tlearn: 0.0520512\ttotal: 22m 37s\tremaining: 3m 42s\n",
      "8591:\tlearn: 0.0520512\ttotal: 22m 38s\tremaining: 3m 42s\n",
      "8592:\tlearn: 0.0520512\ttotal: 22m 38s\tremaining: 3m 42s\n",
      "8593:\tlearn: 0.0520512\ttotal: 22m 38s\tremaining: 3m 42s\n",
      "8594:\tlearn: 0.0520512\ttotal: 22m 38s\tremaining: 3m 42s\n",
      "8595:\tlearn: 0.0520512\ttotal: 22m 38s\tremaining: 3m 41s\n",
      "8596:\tlearn: 0.0520512\ttotal: 22m 38s\tremaining: 3m 41s\n",
      "8597:\tlearn: 0.0520512\ttotal: 22m 39s\tremaining: 3m 41s\n",
      "8598:\tlearn: 0.0520512\ttotal: 22m 39s\tremaining: 3m 41s\n",
      "8599:\tlearn: 0.0520512\ttotal: 22m 39s\tremaining: 3m 41s\n",
      "8600:\tlearn: 0.0520512\ttotal: 22m 39s\tremaining: 3m 41s\n",
      "8601:\tlearn: 0.0520512\ttotal: 22m 39s\tremaining: 3m 40s\n",
      "8602:\tlearn: 0.0520512\ttotal: 22m 39s\tremaining: 3m 40s\n",
      "8603:\tlearn: 0.0520512\ttotal: 22m 40s\tremaining: 3m 40s\n",
      "8604:\tlearn: 0.0520512\ttotal: 22m 40s\tremaining: 3m 40s\n",
      "8605:\tlearn: 0.0520512\ttotal: 22m 40s\tremaining: 3m 40s\n",
      "8606:\tlearn: 0.0520512\ttotal: 22m 40s\tremaining: 3m 40s\n",
      "8607:\tlearn: 0.0520512\ttotal: 22m 40s\tremaining: 3m 40s\n",
      "8608:\tlearn: 0.0520512\ttotal: 22m 40s\tremaining: 3m 39s\n",
      "8609:\tlearn: 0.0520512\ttotal: 22m 41s\tremaining: 3m 39s\n",
      "8610:\tlearn: 0.0520512\ttotal: 22m 41s\tremaining: 3m 39s\n",
      "8611:\tlearn: 0.0520512\ttotal: 22m 41s\tremaining: 3m 39s\n",
      "8612:\tlearn: 0.0520512\ttotal: 22m 41s\tremaining: 3m 39s\n",
      "8613:\tlearn: 0.0520512\ttotal: 22m 41s\tremaining: 3m 39s\n",
      "8614:\tlearn: 0.0520512\ttotal: 22m 41s\tremaining: 3m 38s\n",
      "8615:\tlearn: 0.0520512\ttotal: 22m 42s\tremaining: 3m 38s\n",
      "8616:\tlearn: 0.0520512\ttotal: 22m 42s\tremaining: 3m 38s\n",
      "8617:\tlearn: 0.0520512\ttotal: 22m 42s\tremaining: 3m 38s\n",
      "8618:\tlearn: 0.0520512\ttotal: 22m 42s\tremaining: 3m 38s\n",
      "8619:\tlearn: 0.0520512\ttotal: 22m 42s\tremaining: 3m 38s\n",
      "8620:\tlearn: 0.0520512\ttotal: 22m 42s\tremaining: 3m 37s\n",
      "8621:\tlearn: 0.0520512\ttotal: 22m 42s\tremaining: 3m 37s\n",
      "8622:\tlearn: 0.0520512\ttotal: 22m 43s\tremaining: 3m 37s\n",
      "8623:\tlearn: 0.0520512\ttotal: 22m 43s\tremaining: 3m 37s\n",
      "8624:\tlearn: 0.0520512\ttotal: 22m 43s\tremaining: 3m 37s\n",
      "8625:\tlearn: 0.0520512\ttotal: 22m 43s\tremaining: 3m 37s\n",
      "8626:\tlearn: 0.0520512\ttotal: 22m 43s\tremaining: 3m 37s\n",
      "8627:\tlearn: 0.0520512\ttotal: 22m 43s\tremaining: 3m 36s\n",
      "8628:\tlearn: 0.0520512\ttotal: 22m 44s\tremaining: 3m 36s\n",
      "8629:\tlearn: 0.0520512\ttotal: 22m 44s\tremaining: 3m 36s\n",
      "8630:\tlearn: 0.0520512\ttotal: 22m 44s\tremaining: 3m 36s\n",
      "8631:\tlearn: 0.0520512\ttotal: 22m 44s\tremaining: 3m 36s\n",
      "8632:\tlearn: 0.0520512\ttotal: 22m 44s\tremaining: 3m 36s\n",
      "8633:\tlearn: 0.0520512\ttotal: 22m 44s\tremaining: 3m 35s\n",
      "8634:\tlearn: 0.0520512\ttotal: 22m 45s\tremaining: 3m 35s\n",
      "8635:\tlearn: 0.0520512\ttotal: 22m 45s\tremaining: 3m 35s\n",
      "8636:\tlearn: 0.0520512\ttotal: 22m 45s\tremaining: 3m 35s\n",
      "8637:\tlearn: 0.0520512\ttotal: 22m 45s\tremaining: 3m 35s\n",
      "8638:\tlearn: 0.0520512\ttotal: 22m 45s\tremaining: 3m 35s\n",
      "8639:\tlearn: 0.0520512\ttotal: 22m 45s\tremaining: 3m 35s\n",
      "8640:\tlearn: 0.0520512\ttotal: 22m 46s\tremaining: 3m 34s\n",
      "8641:\tlearn: 0.0520512\ttotal: 22m 46s\tremaining: 3m 34s\n",
      "8642:\tlearn: 0.0520512\ttotal: 22m 46s\tremaining: 3m 34s\n",
      "8643:\tlearn: 0.0520512\ttotal: 22m 46s\tremaining: 3m 34s\n",
      "8644:\tlearn: 0.0520512\ttotal: 22m 46s\tremaining: 3m 34s\n",
      "8645:\tlearn: 0.0520512\ttotal: 22m 46s\tremaining: 3m 34s\n",
      "8646:\tlearn: 0.0520512\ttotal: 22m 47s\tremaining: 3m 33s\n",
      "8647:\tlearn: 0.0520512\ttotal: 22m 47s\tremaining: 3m 33s\n",
      "8648:\tlearn: 0.0520512\ttotal: 22m 47s\tremaining: 3m 33s\n",
      "8649:\tlearn: 0.0520512\ttotal: 22m 47s\tremaining: 3m 33s\n",
      "8650:\tlearn: 0.0520512\ttotal: 22m 47s\tremaining: 3m 33s\n",
      "8651:\tlearn: 0.0520512\ttotal: 22m 47s\tremaining: 3m 33s\n",
      "8652:\tlearn: 0.0520512\ttotal: 22m 48s\tremaining: 3m 32s\n",
      "8653:\tlearn: 0.0520512\ttotal: 22m 48s\tremaining: 3m 32s\n",
      "8654:\tlearn: 0.0520512\ttotal: 22m 48s\tremaining: 3m 32s\n",
      "8655:\tlearn: 0.0520512\ttotal: 22m 48s\tremaining: 3m 32s\n",
      "8656:\tlearn: 0.0520512\ttotal: 22m 48s\tremaining: 3m 32s\n",
      "8657:\tlearn: 0.0520512\ttotal: 22m 48s\tremaining: 3m 32s\n",
      "8658:\tlearn: 0.0520512\ttotal: 22m 49s\tremaining: 3m 32s\n",
      "8659:\tlearn: 0.0520512\ttotal: 22m 49s\tremaining: 3m 31s\n",
      "8660:\tlearn: 0.0520512\ttotal: 22m 49s\tremaining: 3m 31s\n",
      "8661:\tlearn: 0.0520512\ttotal: 22m 49s\tremaining: 3m 31s\n",
      "8662:\tlearn: 0.0520512\ttotal: 22m 49s\tremaining: 3m 31s\n",
      "8663:\tlearn: 0.0520512\ttotal: 22m 49s\tremaining: 3m 31s\n",
      "8664:\tlearn: 0.0520512\ttotal: 22m 49s\tremaining: 3m 31s\n",
      "8665:\tlearn: 0.0520512\ttotal: 22m 50s\tremaining: 3m 30s\n",
      "8666:\tlearn: 0.0520512\ttotal: 22m 50s\tremaining: 3m 30s\n",
      "8667:\tlearn: 0.0520512\ttotal: 22m 50s\tremaining: 3m 30s\n",
      "8668:\tlearn: 0.0520512\ttotal: 22m 50s\tremaining: 3m 30s\n",
      "8669:\tlearn: 0.0520512\ttotal: 22m 50s\tremaining: 3m 30s\n",
      "8670:\tlearn: 0.0520512\ttotal: 22m 50s\tremaining: 3m 30s\n",
      "8671:\tlearn: 0.0520512\ttotal: 22m 51s\tremaining: 3m 29s\n",
      "8672:\tlearn: 0.0520512\ttotal: 22m 51s\tremaining: 3m 29s\n",
      "8673:\tlearn: 0.0520512\ttotal: 22m 51s\tremaining: 3m 29s\n",
      "8674:\tlearn: 0.0520512\ttotal: 22m 51s\tremaining: 3m 29s\n",
      "8675:\tlearn: 0.0520512\ttotal: 22m 51s\tremaining: 3m 29s\n",
      "8676:\tlearn: 0.0520512\ttotal: 22m 51s\tremaining: 3m 29s\n",
      "8677:\tlearn: 0.0520512\ttotal: 22m 52s\tremaining: 3m 29s\n",
      "8678:\tlearn: 0.0520512\ttotal: 22m 52s\tremaining: 3m 28s\n",
      "8679:\tlearn: 0.0520512\ttotal: 22m 52s\tremaining: 3m 28s\n",
      "8680:\tlearn: 0.0520512\ttotal: 22m 52s\tremaining: 3m 28s\n",
      "8681:\tlearn: 0.0520512\ttotal: 22m 52s\tremaining: 3m 28s\n",
      "8682:\tlearn: 0.0520512\ttotal: 22m 52s\tremaining: 3m 28s\n",
      "8683:\tlearn: 0.0520512\ttotal: 22m 53s\tremaining: 3m 28s\n",
      "8684:\tlearn: 0.0520512\ttotal: 22m 53s\tremaining: 3m 27s\n",
      "8685:\tlearn: 0.0520512\ttotal: 22m 53s\tremaining: 3m 27s\n",
      "8686:\tlearn: 0.0520512\ttotal: 22m 53s\tremaining: 3m 27s\n",
      "8687:\tlearn: 0.0520512\ttotal: 22m 53s\tremaining: 3m 27s\n",
      "8688:\tlearn: 0.0520512\ttotal: 22m 53s\tremaining: 3m 27s\n",
      "8689:\tlearn: 0.0520512\ttotal: 22m 54s\tremaining: 3m 27s\n",
      "8690:\tlearn: 0.0520512\ttotal: 22m 54s\tremaining: 3m 26s\n",
      "8691:\tlearn: 0.0520512\ttotal: 22m 54s\tremaining: 3m 26s\n",
      "8692:\tlearn: 0.0520512\ttotal: 22m 54s\tremaining: 3m 26s\n",
      "8693:\tlearn: 0.0520512\ttotal: 22m 54s\tremaining: 3m 26s\n",
      "8694:\tlearn: 0.0520512\ttotal: 22m 54s\tremaining: 3m 26s\n",
      "8695:\tlearn: 0.0520512\ttotal: 22m 55s\tremaining: 3m 26s\n",
      "8696:\tlearn: 0.0520512\ttotal: 22m 55s\tremaining: 3m 26s\n",
      "8697:\tlearn: 0.0520512\ttotal: 22m 55s\tremaining: 3m 25s\n",
      "8698:\tlearn: 0.0520512\ttotal: 22m 55s\tremaining: 3m 25s\n",
      "8699:\tlearn: 0.0520512\ttotal: 22m 55s\tremaining: 3m 25s\n",
      "8700:\tlearn: 0.0520512\ttotal: 22m 55s\tremaining: 3m 25s\n",
      "8701:\tlearn: 0.0520512\ttotal: 22m 56s\tremaining: 3m 25s\n",
      "8702:\tlearn: 0.0520512\ttotal: 22m 56s\tremaining: 3m 25s\n",
      "8703:\tlearn: 0.0520512\ttotal: 22m 56s\tremaining: 3m 24s\n",
      "8704:\tlearn: 0.0520512\ttotal: 22m 56s\tremaining: 3m 24s\n",
      "8705:\tlearn: 0.0520512\ttotal: 22m 56s\tremaining: 3m 24s\n",
      "8706:\tlearn: 0.0520512\ttotal: 22m 56s\tremaining: 3m 24s\n",
      "8707:\tlearn: 0.0520512\ttotal: 22m 56s\tremaining: 3m 24s\n",
      "8708:\tlearn: 0.0520512\ttotal: 22m 57s\tremaining: 3m 24s\n",
      "8709:\tlearn: 0.0520512\ttotal: 22m 57s\tremaining: 3m 23s\n",
      "8710:\tlearn: 0.0520512\ttotal: 22m 57s\tremaining: 3m 23s\n",
      "8711:\tlearn: 0.0520512\ttotal: 22m 57s\tremaining: 3m 23s\n",
      "8712:\tlearn: 0.0520512\ttotal: 22m 57s\tremaining: 3m 23s\n",
      "8713:\tlearn: 0.0520512\ttotal: 22m 57s\tremaining: 3m 23s\n",
      "8714:\tlearn: 0.0520512\ttotal: 22m 58s\tremaining: 3m 23s\n",
      "8715:\tlearn: 0.0520512\ttotal: 22m 58s\tremaining: 3m 23s\n",
      "8716:\tlearn: 0.0520512\ttotal: 22m 58s\tremaining: 3m 22s\n",
      "8717:\tlearn: 0.0520512\ttotal: 22m 58s\tremaining: 3m 22s\n",
      "8718:\tlearn: 0.0520512\ttotal: 22m 58s\tremaining: 3m 22s\n",
      "8719:\tlearn: 0.0520512\ttotal: 22m 58s\tremaining: 3m 22s\n",
      "8720:\tlearn: 0.0520512\ttotal: 22m 59s\tremaining: 3m 22s\n",
      "8721:\tlearn: 0.0520512\ttotal: 22m 59s\tremaining: 3m 22s\n",
      "8722:\tlearn: 0.0520512\ttotal: 22m 59s\tremaining: 3m 21s\n",
      "8723:\tlearn: 0.0520512\ttotal: 22m 59s\tremaining: 3m 21s\n",
      "8724:\tlearn: 0.0520512\ttotal: 22m 59s\tremaining: 3m 21s\n",
      "8725:\tlearn: 0.0520512\ttotal: 22m 59s\tremaining: 3m 21s\n",
      "8726:\tlearn: 0.0520512\ttotal: 23m\tremaining: 3m 21s\n",
      "8727:\tlearn: 0.0520512\ttotal: 23m\tremaining: 3m 21s\n",
      "8728:\tlearn: 0.0520512\ttotal: 23m\tremaining: 3m 20s\n",
      "8729:\tlearn: 0.0520512\ttotal: 23m\tremaining: 3m 20s\n",
      "8730:\tlearn: 0.0520512\ttotal: 23m\tremaining: 3m 20s\n",
      "8731:\tlearn: 0.0520512\ttotal: 23m\tremaining: 3m 20s\n",
      "8732:\tlearn: 0.0520512\ttotal: 23m 1s\tremaining: 3m 20s\n",
      "8733:\tlearn: 0.0520512\ttotal: 23m 1s\tremaining: 3m 20s\n",
      "8734:\tlearn: 0.0520512\ttotal: 23m 1s\tremaining: 3m 20s\n",
      "8735:\tlearn: 0.0520512\ttotal: 23m 1s\tremaining: 3m 19s\n",
      "8736:\tlearn: 0.0520512\ttotal: 23m 1s\tremaining: 3m 19s\n",
      "8737:\tlearn: 0.0520512\ttotal: 23m 1s\tremaining: 3m 19s\n",
      "8738:\tlearn: 0.0520512\ttotal: 23m 2s\tremaining: 3m 19s\n",
      "8739:\tlearn: 0.0520512\ttotal: 23m 2s\tremaining: 3m 19s\n",
      "8740:\tlearn: 0.0520512\ttotal: 23m 2s\tremaining: 3m 19s\n",
      "8741:\tlearn: 0.0520512\ttotal: 23m 2s\tremaining: 3m 18s\n",
      "8742:\tlearn: 0.0520512\ttotal: 23m 2s\tremaining: 3m 18s\n",
      "8743:\tlearn: 0.0520512\ttotal: 23m 2s\tremaining: 3m 18s\n",
      "8744:\tlearn: 0.0520512\ttotal: 23m 3s\tremaining: 3m 18s\n",
      "8745:\tlearn: 0.0520512\ttotal: 23m 3s\tremaining: 3m 18s\n",
      "8746:\tlearn: 0.0520512\ttotal: 23m 3s\tremaining: 3m 18s\n",
      "8747:\tlearn: 0.0520512\ttotal: 23m 3s\tremaining: 3m 18s\n",
      "8748:\tlearn: 0.0520512\ttotal: 23m 3s\tremaining: 3m 17s\n",
      "8749:\tlearn: 0.0520512\ttotal: 23m 3s\tremaining: 3m 17s\n",
      "8750:\tlearn: 0.0520512\ttotal: 23m 4s\tremaining: 3m 17s\n",
      "8751:\tlearn: 0.0520512\ttotal: 23m 4s\tremaining: 3m 17s\n",
      "8752:\tlearn: 0.0520512\ttotal: 23m 4s\tremaining: 3m 17s\n",
      "8753:\tlearn: 0.0520512\ttotal: 23m 4s\tremaining: 3m 17s\n",
      "8754:\tlearn: 0.0520512\ttotal: 23m 4s\tremaining: 3m 16s\n",
      "8755:\tlearn: 0.0520512\ttotal: 23m 4s\tremaining: 3m 16s\n",
      "8756:\tlearn: 0.0520512\ttotal: 23m 5s\tremaining: 3m 16s\n",
      "8757:\tlearn: 0.0520512\ttotal: 23m 5s\tremaining: 3m 16s\n",
      "8758:\tlearn: 0.0520512\ttotal: 23m 5s\tremaining: 3m 16s\n",
      "8759:\tlearn: 0.0520512\ttotal: 23m 5s\tremaining: 3m 16s\n",
      "8760:\tlearn: 0.0520512\ttotal: 23m 5s\tremaining: 3m 15s\n",
      "8761:\tlearn: 0.0520512\ttotal: 23m 5s\tremaining: 3m 15s\n",
      "8762:\tlearn: 0.0520512\ttotal: 23m 5s\tremaining: 3m 15s\n",
      "8763:\tlearn: 0.0520512\ttotal: 23m 6s\tremaining: 3m 15s\n",
      "8764:\tlearn: 0.0520512\ttotal: 23m 6s\tremaining: 3m 15s\n",
      "8765:\tlearn: 0.0520512\ttotal: 23m 6s\tremaining: 3m 15s\n",
      "8766:\tlearn: 0.0520512\ttotal: 23m 6s\tremaining: 3m 15s\n",
      "8767:\tlearn: 0.0520512\ttotal: 23m 6s\tremaining: 3m 14s\n",
      "8768:\tlearn: 0.0520512\ttotal: 23m 6s\tremaining: 3m 14s\n",
      "8769:\tlearn: 0.0520512\ttotal: 23m 7s\tremaining: 3m 14s\n",
      "8770:\tlearn: 0.0520512\ttotal: 23m 7s\tremaining: 3m 14s\n",
      "8771:\tlearn: 0.0520512\ttotal: 23m 7s\tremaining: 3m 14s\n",
      "8772:\tlearn: 0.0520512\ttotal: 23m 7s\tremaining: 3m 14s\n",
      "8773:\tlearn: 0.0520512\ttotal: 23m 7s\tremaining: 3m 13s\n",
      "8774:\tlearn: 0.0520512\ttotal: 23m 7s\tremaining: 3m 13s\n",
      "8775:\tlearn: 0.0520512\ttotal: 23m 8s\tremaining: 3m 13s\n",
      "8776:\tlearn: 0.0520512\ttotal: 23m 8s\tremaining: 3m 13s\n",
      "8777:\tlearn: 0.0520512\ttotal: 23m 8s\tremaining: 3m 13s\n",
      "8778:\tlearn: 0.0520512\ttotal: 23m 8s\tremaining: 3m 13s\n",
      "8779:\tlearn: 0.0520512\ttotal: 23m 8s\tremaining: 3m 12s\n",
      "8780:\tlearn: 0.0520512\ttotal: 23m 8s\tremaining: 3m 12s\n",
      "8781:\tlearn: 0.0520512\ttotal: 23m 9s\tremaining: 3m 12s\n",
      "8782:\tlearn: 0.0520512\ttotal: 23m 9s\tremaining: 3m 12s\n",
      "8783:\tlearn: 0.0520512\ttotal: 23m 9s\tremaining: 3m 12s\n",
      "8784:\tlearn: 0.0520512\ttotal: 23m 9s\tremaining: 3m 12s\n",
      "8785:\tlearn: 0.0520512\ttotal: 23m 9s\tremaining: 3m 12s\n",
      "8786:\tlearn: 0.0520512\ttotal: 23m 9s\tremaining: 3m 11s\n",
      "8787:\tlearn: 0.0520512\ttotal: 23m 10s\tremaining: 3m 11s\n",
      "8788:\tlearn: 0.0520512\ttotal: 23m 10s\tremaining: 3m 11s\n",
      "8789:\tlearn: 0.0520512\ttotal: 23m 10s\tremaining: 3m 11s\n",
      "8790:\tlearn: 0.0520512\ttotal: 23m 10s\tremaining: 3m 11s\n",
      "8791:\tlearn: 0.0520512\ttotal: 23m 10s\tremaining: 3m 11s\n",
      "8792:\tlearn: 0.0520512\ttotal: 23m 10s\tremaining: 3m 10s\n",
      "8793:\tlearn: 0.0520512\ttotal: 23m 10s\tremaining: 3m 10s\n",
      "8794:\tlearn: 0.0520512\ttotal: 23m 11s\tremaining: 3m 10s\n",
      "8795:\tlearn: 0.0520512\ttotal: 23m 11s\tremaining: 3m 10s\n",
      "8796:\tlearn: 0.0520512\ttotal: 23m 11s\tremaining: 3m 10s\n",
      "8797:\tlearn: 0.0520512\ttotal: 23m 11s\tremaining: 3m 10s\n",
      "8798:\tlearn: 0.0520512\ttotal: 23m 11s\tremaining: 3m 9s\n",
      "8799:\tlearn: 0.0520512\ttotal: 23m 11s\tremaining: 3m 9s\n",
      "8800:\tlearn: 0.0520512\ttotal: 23m 12s\tremaining: 3m 9s\n",
      "8801:\tlearn: 0.0520512\ttotal: 23m 12s\tremaining: 3m 9s\n",
      "8802:\tlearn: 0.0520512\ttotal: 23m 12s\tremaining: 3m 9s\n",
      "8803:\tlearn: 0.0520512\ttotal: 23m 12s\tremaining: 3m 9s\n",
      "8804:\tlearn: 0.0520512\ttotal: 23m 12s\tremaining: 3m 9s\n",
      "8805:\tlearn: 0.0520512\ttotal: 23m 12s\tremaining: 3m 8s\n",
      "8806:\tlearn: 0.0520512\ttotal: 23m 13s\tremaining: 3m 8s\n",
      "8807:\tlearn: 0.0520512\ttotal: 23m 13s\tremaining: 3m 8s\n",
      "8808:\tlearn: 0.0520512\ttotal: 23m 13s\tremaining: 3m 8s\n",
      "8809:\tlearn: 0.0520512\ttotal: 23m 13s\tremaining: 3m 8s\n",
      "8810:\tlearn: 0.0520512\ttotal: 23m 13s\tremaining: 3m 8s\n",
      "8811:\tlearn: 0.0520512\ttotal: 23m 13s\tremaining: 3m 7s\n",
      "8812:\tlearn: 0.0520512\ttotal: 23m 14s\tremaining: 3m 7s\n",
      "8813:\tlearn: 0.0520512\ttotal: 23m 14s\tremaining: 3m 7s\n",
      "8814:\tlearn: 0.0520512\ttotal: 23m 14s\tremaining: 3m 7s\n",
      "8815:\tlearn: 0.0520512\ttotal: 23m 14s\tremaining: 3m 7s\n",
      "8816:\tlearn: 0.0520512\ttotal: 23m 14s\tremaining: 3m 7s\n",
      "8817:\tlearn: 0.0520512\ttotal: 23m 14s\tremaining: 3m 6s\n",
      "8818:\tlearn: 0.0520512\ttotal: 23m 15s\tremaining: 3m 6s\n",
      "8819:\tlearn: 0.0520512\ttotal: 23m 15s\tremaining: 3m 6s\n",
      "8820:\tlearn: 0.0520512\ttotal: 23m 15s\tremaining: 3m 6s\n",
      "8821:\tlearn: 0.0520512\ttotal: 23m 15s\tremaining: 3m 6s\n",
      "8822:\tlearn: 0.0520512\ttotal: 23m 15s\tremaining: 3m 6s\n",
      "8823:\tlearn: 0.0520512\ttotal: 23m 15s\tremaining: 3m 6s\n",
      "8824:\tlearn: 0.0520512\ttotal: 23m 16s\tremaining: 3m 5s\n",
      "8825:\tlearn: 0.0520512\ttotal: 23m 16s\tremaining: 3m 5s\n",
      "8826:\tlearn: 0.0520512\ttotal: 23m 16s\tremaining: 3m 5s\n",
      "8827:\tlearn: 0.0520512\ttotal: 23m 16s\tremaining: 3m 5s\n",
      "8828:\tlearn: 0.0520512\ttotal: 23m 16s\tremaining: 3m 5s\n",
      "8829:\tlearn: 0.0520512\ttotal: 23m 16s\tremaining: 3m 5s\n",
      "8830:\tlearn: 0.0520512\ttotal: 23m 17s\tremaining: 3m 4s\n",
      "8831:\tlearn: 0.0520512\ttotal: 23m 17s\tremaining: 3m 4s\n",
      "8832:\tlearn: 0.0520512\ttotal: 23m 17s\tremaining: 3m 4s\n",
      "8833:\tlearn: 0.0520512\ttotal: 23m 17s\tremaining: 3m 4s\n",
      "8834:\tlearn: 0.0520512\ttotal: 23m 17s\tremaining: 3m 4s\n",
      "8835:\tlearn: 0.0520512\ttotal: 23m 17s\tremaining: 3m 4s\n",
      "8836:\tlearn: 0.0520512\ttotal: 23m 18s\tremaining: 3m 3s\n",
      "8837:\tlearn: 0.0520512\ttotal: 23m 18s\tremaining: 3m 3s\n",
      "8838:\tlearn: 0.0520512\ttotal: 23m 18s\tremaining: 3m 3s\n",
      "8839:\tlearn: 0.0520512\ttotal: 23m 18s\tremaining: 3m 3s\n",
      "8840:\tlearn: 0.0520512\ttotal: 23m 18s\tremaining: 3m 3s\n",
      "8841:\tlearn: 0.0520512\ttotal: 23m 18s\tremaining: 3m 3s\n",
      "8842:\tlearn: 0.0520512\ttotal: 23m 19s\tremaining: 3m 3s\n",
      "8843:\tlearn: 0.0520512\ttotal: 23m 19s\tremaining: 3m 2s\n",
      "8844:\tlearn: 0.0520512\ttotal: 23m 19s\tremaining: 3m 2s\n",
      "8845:\tlearn: 0.0520512\ttotal: 23m 19s\tremaining: 3m 2s\n",
      "8846:\tlearn: 0.0520512\ttotal: 23m 19s\tremaining: 3m 2s\n",
      "8847:\tlearn: 0.0520512\ttotal: 23m 19s\tremaining: 3m 2s\n",
      "8848:\tlearn: 0.0520512\ttotal: 23m 20s\tremaining: 3m 2s\n",
      "8849:\tlearn: 0.0520512\ttotal: 23m 20s\tremaining: 3m 1s\n",
      "8850:\tlearn: 0.0520512\ttotal: 23m 20s\tremaining: 3m 1s\n",
      "8851:\tlearn: 0.0520512\ttotal: 23m 20s\tremaining: 3m 1s\n",
      "8852:\tlearn: 0.0520512\ttotal: 23m 20s\tremaining: 3m 1s\n",
      "8853:\tlearn: 0.0520512\ttotal: 23m 20s\tremaining: 3m 1s\n",
      "8854:\tlearn: 0.0520512\ttotal: 23m 21s\tremaining: 3m 1s\n",
      "8855:\tlearn: 0.0520512\ttotal: 23m 21s\tremaining: 3m 1s\n",
      "8856:\tlearn: 0.0520512\ttotal: 23m 21s\tremaining: 3m\n",
      "8857:\tlearn: 0.0520512\ttotal: 23m 21s\tremaining: 3m\n",
      "8858:\tlearn: 0.0520512\ttotal: 23m 21s\tremaining: 3m\n",
      "8859:\tlearn: 0.0520512\ttotal: 23m 21s\tremaining: 3m\n",
      "8860:\tlearn: 0.0520512\ttotal: 23m 22s\tremaining: 3m\n",
      "8861:\tlearn: 0.0520512\ttotal: 23m 22s\tremaining: 3m\n",
      "8862:\tlearn: 0.0520512\ttotal: 23m 22s\tremaining: 2m 59s\n",
      "8863:\tlearn: 0.0520512\ttotal: 23m 22s\tremaining: 2m 59s\n",
      "8864:\tlearn: 0.0520512\ttotal: 23m 22s\tremaining: 2m 59s\n",
      "8865:\tlearn: 0.0520512\ttotal: 23m 22s\tremaining: 2m 59s\n",
      "8866:\tlearn: 0.0520512\ttotal: 23m 23s\tremaining: 2m 59s\n",
      "8867:\tlearn: 0.0520512\ttotal: 23m 23s\tremaining: 2m 59s\n",
      "8868:\tlearn: 0.0520512\ttotal: 23m 23s\tremaining: 2m 58s\n",
      "8869:\tlearn: 0.0520512\ttotal: 23m 23s\tremaining: 2m 58s\n",
      "8870:\tlearn: 0.0520512\ttotal: 23m 23s\tremaining: 2m 58s\n",
      "8871:\tlearn: 0.0520512\ttotal: 23m 23s\tremaining: 2m 58s\n",
      "8872:\tlearn: 0.0520512\ttotal: 23m 24s\tremaining: 2m 58s\n",
      "8873:\tlearn: 0.0520512\ttotal: 23m 24s\tremaining: 2m 58s\n",
      "8874:\tlearn: 0.0520512\ttotal: 23m 24s\tremaining: 2m 58s\n",
      "8875:\tlearn: 0.0520512\ttotal: 23m 24s\tremaining: 2m 57s\n",
      "8876:\tlearn: 0.0520512\ttotal: 23m 24s\tremaining: 2m 57s\n",
      "8877:\tlearn: 0.0520512\ttotal: 23m 24s\tremaining: 2m 57s\n",
      "8878:\tlearn: 0.0520512\ttotal: 23m 25s\tremaining: 2m 57s\n",
      "8879:\tlearn: 0.0520512\ttotal: 23m 25s\tremaining: 2m 57s\n",
      "8880:\tlearn: 0.0520512\ttotal: 23m 25s\tremaining: 2m 57s\n",
      "8881:\tlearn: 0.0520512\ttotal: 23m 25s\tremaining: 2m 56s\n",
      "8882:\tlearn: 0.0520512\ttotal: 23m 25s\tremaining: 2m 56s\n",
      "8883:\tlearn: 0.0520512\ttotal: 23m 25s\tremaining: 2m 56s\n",
      "8884:\tlearn: 0.0520512\ttotal: 23m 26s\tremaining: 2m 56s\n",
      "8885:\tlearn: 0.0520512\ttotal: 23m 26s\tremaining: 2m 56s\n",
      "8886:\tlearn: 0.0520512\ttotal: 23m 26s\tremaining: 2m 56s\n",
      "8887:\tlearn: 0.0520512\ttotal: 23m 26s\tremaining: 2m 55s\n",
      "8888:\tlearn: 0.0520512\ttotal: 23m 26s\tremaining: 2m 55s\n",
      "8889:\tlearn: 0.0520512\ttotal: 23m 26s\tremaining: 2m 55s\n",
      "8890:\tlearn: 0.0520512\ttotal: 23m 27s\tremaining: 2m 55s\n",
      "8891:\tlearn: 0.0520512\ttotal: 23m 27s\tremaining: 2m 55s\n",
      "8892:\tlearn: 0.0520512\ttotal: 23m 27s\tremaining: 2m 55s\n",
      "8893:\tlearn: 0.0520512\ttotal: 23m 27s\tremaining: 2m 55s\n",
      "8894:\tlearn: 0.0520512\ttotal: 23m 27s\tremaining: 2m 54s\n",
      "8895:\tlearn: 0.0520512\ttotal: 23m 27s\tremaining: 2m 54s\n",
      "8896:\tlearn: 0.0520512\ttotal: 23m 28s\tremaining: 2m 54s\n",
      "8897:\tlearn: 0.0520512\ttotal: 23m 28s\tremaining: 2m 54s\n",
      "8898:\tlearn: 0.0520512\ttotal: 23m 28s\tremaining: 2m 54s\n",
      "8899:\tlearn: 0.0520512\ttotal: 23m 28s\tremaining: 2m 54s\n",
      "8900:\tlearn: 0.0520512\ttotal: 23m 28s\tremaining: 2m 53s\n",
      "8901:\tlearn: 0.0520512\ttotal: 23m 28s\tremaining: 2m 53s\n",
      "8902:\tlearn: 0.0520512\ttotal: 23m 29s\tremaining: 2m 53s\n",
      "8903:\tlearn: 0.0520512\ttotal: 23m 29s\tremaining: 2m 53s\n",
      "8904:\tlearn: 0.0520512\ttotal: 23m 29s\tremaining: 2m 53s\n",
      "8905:\tlearn: 0.0520512\ttotal: 23m 29s\tremaining: 2m 53s\n",
      "8906:\tlearn: 0.0520512\ttotal: 23m 29s\tremaining: 2m 52s\n",
      "8907:\tlearn: 0.0520512\ttotal: 23m 29s\tremaining: 2m 52s\n",
      "8908:\tlearn: 0.0520512\ttotal: 23m 30s\tremaining: 2m 52s\n",
      "8909:\tlearn: 0.0520512\ttotal: 23m 30s\tremaining: 2m 52s\n",
      "8910:\tlearn: 0.0520512\ttotal: 23m 30s\tremaining: 2m 52s\n",
      "8911:\tlearn: 0.0520512\ttotal: 23m 30s\tremaining: 2m 52s\n",
      "8912:\tlearn: 0.0520512\ttotal: 23m 30s\tremaining: 2m 52s\n",
      "8913:\tlearn: 0.0520512\ttotal: 23m 30s\tremaining: 2m 51s\n",
      "8914:\tlearn: 0.0520512\ttotal: 23m 31s\tremaining: 2m 51s\n",
      "8915:\tlearn: 0.0520512\ttotal: 23m 31s\tremaining: 2m 51s\n",
      "8916:\tlearn: 0.0520512\ttotal: 23m 31s\tremaining: 2m 51s\n",
      "8917:\tlearn: 0.0520512\ttotal: 23m 31s\tremaining: 2m 51s\n",
      "8918:\tlearn: 0.0520512\ttotal: 23m 31s\tremaining: 2m 51s\n",
      "8919:\tlearn: 0.0520512\ttotal: 23m 31s\tremaining: 2m 50s\n",
      "8920:\tlearn: 0.0520512\ttotal: 23m 32s\tremaining: 2m 50s\n",
      "8921:\tlearn: 0.0520512\ttotal: 23m 32s\tremaining: 2m 50s\n",
      "8922:\tlearn: 0.0520512\ttotal: 23m 32s\tremaining: 2m 50s\n",
      "8923:\tlearn: 0.0520512\ttotal: 23m 32s\tremaining: 2m 50s\n",
      "8924:\tlearn: 0.0520512\ttotal: 23m 32s\tremaining: 2m 50s\n",
      "8925:\tlearn: 0.0520512\ttotal: 23m 32s\tremaining: 2m 50s\n",
      "8926:\tlearn: 0.0520512\ttotal: 23m 33s\tremaining: 2m 49s\n",
      "8927:\tlearn: 0.0520512\ttotal: 23m 33s\tremaining: 2m 49s\n",
      "8928:\tlearn: 0.0520512\ttotal: 23m 33s\tremaining: 2m 49s\n",
      "8929:\tlearn: 0.0520512\ttotal: 23m 33s\tremaining: 2m 49s\n",
      "8930:\tlearn: 0.0520512\ttotal: 23m 33s\tremaining: 2m 49s\n",
      "8931:\tlearn: 0.0520512\ttotal: 23m 33s\tremaining: 2m 49s\n",
      "8932:\tlearn: 0.0520512\ttotal: 23m 33s\tremaining: 2m 48s\n",
      "8933:\tlearn: 0.0520512\ttotal: 23m 34s\tremaining: 2m 48s\n",
      "8934:\tlearn: 0.0520512\ttotal: 23m 34s\tremaining: 2m 48s\n",
      "8935:\tlearn: 0.0520512\ttotal: 23m 34s\tremaining: 2m 48s\n",
      "8936:\tlearn: 0.0520512\ttotal: 23m 34s\tremaining: 2m 48s\n",
      "8937:\tlearn: 0.0520512\ttotal: 23m 34s\tremaining: 2m 48s\n",
      "8938:\tlearn: 0.0520512\ttotal: 23m 34s\tremaining: 2m 47s\n",
      "8939:\tlearn: 0.0520512\ttotal: 23m 35s\tremaining: 2m 47s\n",
      "8940:\tlearn: 0.0520512\ttotal: 23m 35s\tremaining: 2m 47s\n",
      "8941:\tlearn: 0.0520512\ttotal: 23m 35s\tremaining: 2m 47s\n",
      "8942:\tlearn: 0.0520512\ttotal: 23m 35s\tremaining: 2m 47s\n",
      "8943:\tlearn: 0.0520512\ttotal: 23m 35s\tremaining: 2m 47s\n",
      "8944:\tlearn: 0.0520512\ttotal: 23m 35s\tremaining: 2m 47s\n",
      "8945:\tlearn: 0.0520512\ttotal: 23m 36s\tremaining: 2m 46s\n",
      "8946:\tlearn: 0.0520512\ttotal: 23m 36s\tremaining: 2m 46s\n",
      "8947:\tlearn: 0.0520512\ttotal: 23m 36s\tremaining: 2m 46s\n",
      "8948:\tlearn: 0.0520512\ttotal: 23m 36s\tremaining: 2m 46s\n",
      "8949:\tlearn: 0.0520512\ttotal: 23m 36s\tremaining: 2m 46s\n",
      "8950:\tlearn: 0.0520512\ttotal: 23m 36s\tremaining: 2m 46s\n",
      "8951:\tlearn: 0.0520512\ttotal: 23m 37s\tremaining: 2m 45s\n",
      "8952:\tlearn: 0.0520512\ttotal: 23m 37s\tremaining: 2m 45s\n",
      "8953:\tlearn: 0.0520512\ttotal: 23m 37s\tremaining: 2m 45s\n",
      "8954:\tlearn: 0.0520512\ttotal: 23m 37s\tremaining: 2m 45s\n",
      "8955:\tlearn: 0.0520512\ttotal: 23m 37s\tremaining: 2m 45s\n",
      "8956:\tlearn: 0.0520512\ttotal: 23m 37s\tremaining: 2m 45s\n",
      "8957:\tlearn: 0.0520512\ttotal: 23m 38s\tremaining: 2m 44s\n",
      "8958:\tlearn: 0.0520512\ttotal: 23m 38s\tremaining: 2m 44s\n",
      "8959:\tlearn: 0.0520512\ttotal: 23m 38s\tremaining: 2m 44s\n",
      "8960:\tlearn: 0.0520512\ttotal: 23m 38s\tremaining: 2m 44s\n",
      "8961:\tlearn: 0.0520512\ttotal: 23m 38s\tremaining: 2m 44s\n",
      "8962:\tlearn: 0.0520512\ttotal: 23m 38s\tremaining: 2m 44s\n",
      "8963:\tlearn: 0.0520512\ttotal: 23m 39s\tremaining: 2m 44s\n",
      "8964:\tlearn: 0.0520512\ttotal: 23m 39s\tremaining: 2m 43s\n",
      "8965:\tlearn: 0.0520512\ttotal: 23m 39s\tremaining: 2m 43s\n",
      "8966:\tlearn: 0.0520512\ttotal: 23m 39s\tremaining: 2m 43s\n",
      "8967:\tlearn: 0.0520512\ttotal: 23m 39s\tremaining: 2m 43s\n",
      "8968:\tlearn: 0.0520512\ttotal: 23m 39s\tremaining: 2m 43s\n",
      "8969:\tlearn: 0.0520512\ttotal: 23m 40s\tremaining: 2m 43s\n",
      "8970:\tlearn: 0.0520512\ttotal: 23m 40s\tremaining: 2m 42s\n",
      "8971:\tlearn: 0.0520512\ttotal: 23m 40s\tremaining: 2m 42s\n",
      "8972:\tlearn: 0.0520512\ttotal: 23m 40s\tremaining: 2m 42s\n",
      "8973:\tlearn: 0.0520512\ttotal: 23m 40s\tremaining: 2m 42s\n",
      "8974:\tlearn: 0.0520512\ttotal: 23m 40s\tremaining: 2m 42s\n",
      "8975:\tlearn: 0.0520512\ttotal: 23m 41s\tremaining: 2m 42s\n",
      "8976:\tlearn: 0.0520512\ttotal: 23m 41s\tremaining: 2m 41s\n",
      "8977:\tlearn: 0.0520512\ttotal: 23m 41s\tremaining: 2m 41s\n",
      "8978:\tlearn: 0.0520512\ttotal: 23m 41s\tremaining: 2m 41s\n",
      "8979:\tlearn: 0.0520512\ttotal: 23m 41s\tremaining: 2m 41s\n",
      "8980:\tlearn: 0.0520512\ttotal: 23m 41s\tremaining: 2m 41s\n",
      "8981:\tlearn: 0.0520512\ttotal: 23m 42s\tremaining: 2m 41s\n",
      "8982:\tlearn: 0.0520512\ttotal: 23m 42s\tremaining: 2m 41s\n",
      "8983:\tlearn: 0.0520512\ttotal: 23m 42s\tremaining: 2m 40s\n",
      "8984:\tlearn: 0.0520512\ttotal: 23m 42s\tremaining: 2m 40s\n",
      "8985:\tlearn: 0.0520512\ttotal: 23m 42s\tremaining: 2m 40s\n",
      "8986:\tlearn: 0.0520512\ttotal: 23m 42s\tremaining: 2m 40s\n",
      "8987:\tlearn: 0.0520512\ttotal: 23m 43s\tremaining: 2m 40s\n",
      "8988:\tlearn: 0.0520512\ttotal: 23m 43s\tremaining: 2m 40s\n",
      "8989:\tlearn: 0.0520512\ttotal: 23m 43s\tremaining: 2m 39s\n",
      "8990:\tlearn: 0.0520512\ttotal: 23m 43s\tremaining: 2m 39s\n",
      "8991:\tlearn: 0.0520512\ttotal: 23m 43s\tremaining: 2m 39s\n",
      "8992:\tlearn: 0.0520512\ttotal: 23m 43s\tremaining: 2m 39s\n",
      "8993:\tlearn: 0.0520512\ttotal: 23m 44s\tremaining: 2m 39s\n",
      "8994:\tlearn: 0.0520512\ttotal: 23m 44s\tremaining: 2m 39s\n",
      "8995:\tlearn: 0.0520512\ttotal: 23m 44s\tremaining: 2m 38s\n",
      "8996:\tlearn: 0.0520512\ttotal: 23m 44s\tremaining: 2m 38s\n",
      "8997:\tlearn: 0.0520512\ttotal: 23m 44s\tremaining: 2m 38s\n",
      "8998:\tlearn: 0.0520512\ttotal: 23m 44s\tremaining: 2m 38s\n",
      "8999:\tlearn: 0.0520512\ttotal: 23m 45s\tremaining: 2m 38s\n",
      "9000:\tlearn: 0.0520512\ttotal: 23m 45s\tremaining: 2m 38s\n",
      "9001:\tlearn: 0.0520512\ttotal: 23m 45s\tremaining: 2m 38s\n",
      "9002:\tlearn: 0.0520512\ttotal: 23m 45s\tremaining: 2m 37s\n",
      "9003:\tlearn: 0.0520512\ttotal: 23m 45s\tremaining: 2m 37s\n",
      "9004:\tlearn: 0.0520512\ttotal: 23m 45s\tremaining: 2m 37s\n",
      "9005:\tlearn: 0.0520512\ttotal: 23m 46s\tremaining: 2m 37s\n",
      "9006:\tlearn: 0.0520512\ttotal: 23m 46s\tremaining: 2m 37s\n",
      "9007:\tlearn: 0.0520512\ttotal: 23m 46s\tremaining: 2m 37s\n",
      "9008:\tlearn: 0.0520512\ttotal: 23m 46s\tremaining: 2m 36s\n",
      "9009:\tlearn: 0.0520512\ttotal: 23m 46s\tremaining: 2m 36s\n",
      "9010:\tlearn: 0.0520512\ttotal: 23m 46s\tremaining: 2m 36s\n",
      "9011:\tlearn: 0.0520512\ttotal: 23m 47s\tremaining: 2m 36s\n",
      "9012:\tlearn: 0.0520512\ttotal: 23m 47s\tremaining: 2m 36s\n",
      "9013:\tlearn: 0.0520512\ttotal: 23m 47s\tremaining: 2m 36s\n",
      "9014:\tlearn: 0.0520512\ttotal: 23m 47s\tremaining: 2m 35s\n",
      "9015:\tlearn: 0.0520512\ttotal: 23m 47s\tremaining: 2m 35s\n",
      "9016:\tlearn: 0.0520512\ttotal: 23m 47s\tremaining: 2m 35s\n",
      "9017:\tlearn: 0.0520512\ttotal: 23m 48s\tremaining: 2m 35s\n",
      "9018:\tlearn: 0.0520512\ttotal: 23m 48s\tremaining: 2m 35s\n",
      "9019:\tlearn: 0.0520512\ttotal: 23m 48s\tremaining: 2m 35s\n",
      "9020:\tlearn: 0.0520512\ttotal: 23m 48s\tremaining: 2m 35s\n",
      "9021:\tlearn: 0.0520512\ttotal: 23m 48s\tremaining: 2m 34s\n",
      "9022:\tlearn: 0.0520512\ttotal: 23m 48s\tremaining: 2m 34s\n",
      "9023:\tlearn: 0.0520512\ttotal: 23m 49s\tremaining: 2m 34s\n",
      "9024:\tlearn: 0.0520512\ttotal: 23m 49s\tremaining: 2m 34s\n",
      "9025:\tlearn: 0.0520512\ttotal: 23m 49s\tremaining: 2m 34s\n",
      "9026:\tlearn: 0.0520512\ttotal: 23m 49s\tremaining: 2m 34s\n",
      "9027:\tlearn: 0.0520512\ttotal: 23m 49s\tremaining: 2m 33s\n",
      "9028:\tlearn: 0.0520512\ttotal: 23m 49s\tremaining: 2m 33s\n",
      "9029:\tlearn: 0.0520512\ttotal: 23m 50s\tremaining: 2m 33s\n",
      "9030:\tlearn: 0.0520512\ttotal: 23m 50s\tremaining: 2m 33s\n",
      "9031:\tlearn: 0.0520512\ttotal: 23m 50s\tremaining: 2m 33s\n",
      "9032:\tlearn: 0.0520512\ttotal: 23m 50s\tremaining: 2m 33s\n",
      "9033:\tlearn: 0.0520512\ttotal: 23m 50s\tremaining: 2m 32s\n",
      "9034:\tlearn: 0.0520512\ttotal: 23m 50s\tremaining: 2m 32s\n",
      "9035:\tlearn: 0.0520512\ttotal: 23m 51s\tremaining: 2m 32s\n",
      "9036:\tlearn: 0.0520512\ttotal: 23m 51s\tremaining: 2m 32s\n",
      "9037:\tlearn: 0.0520512\ttotal: 23m 51s\tremaining: 2m 32s\n",
      "9038:\tlearn: 0.0520512\ttotal: 23m 51s\tremaining: 2m 32s\n",
      "9039:\tlearn: 0.0520512\ttotal: 23m 51s\tremaining: 2m 32s\n",
      "9040:\tlearn: 0.0520512\ttotal: 23m 51s\tremaining: 2m 31s\n",
      "9041:\tlearn: 0.0520512\ttotal: 23m 51s\tremaining: 2m 31s\n",
      "9042:\tlearn: 0.0520512\ttotal: 23m 52s\tremaining: 2m 31s\n",
      "9043:\tlearn: 0.0520512\ttotal: 23m 52s\tremaining: 2m 31s\n",
      "9044:\tlearn: 0.0520512\ttotal: 23m 52s\tremaining: 2m 31s\n",
      "9045:\tlearn: 0.0520512\ttotal: 23m 52s\tremaining: 2m 31s\n",
      "9046:\tlearn: 0.0520512\ttotal: 23m 52s\tremaining: 2m 30s\n",
      "9047:\tlearn: 0.0520512\ttotal: 23m 52s\tremaining: 2m 30s\n",
      "9048:\tlearn: 0.0520512\ttotal: 23m 53s\tremaining: 2m 30s\n",
      "9049:\tlearn: 0.0520512\ttotal: 23m 53s\tremaining: 2m 30s\n",
      "9050:\tlearn: 0.0520512\ttotal: 23m 53s\tremaining: 2m 30s\n",
      "9051:\tlearn: 0.0520512\ttotal: 23m 53s\tremaining: 2m 30s\n",
      "9052:\tlearn: 0.0520512\ttotal: 23m 53s\tremaining: 2m 29s\n",
      "9053:\tlearn: 0.0520512\ttotal: 23m 53s\tremaining: 2m 29s\n",
      "9054:\tlearn: 0.0520512\ttotal: 23m 54s\tremaining: 2m 29s\n",
      "9055:\tlearn: 0.0520512\ttotal: 23m 54s\tremaining: 2m 29s\n",
      "9056:\tlearn: 0.0520512\ttotal: 23m 54s\tremaining: 2m 29s\n",
      "9057:\tlearn: 0.0520512\ttotal: 23m 54s\tremaining: 2m 29s\n",
      "9058:\tlearn: 0.0520512\ttotal: 23m 54s\tremaining: 2m 29s\n",
      "9059:\tlearn: 0.0520512\ttotal: 23m 54s\tremaining: 2m 28s\n",
      "9060:\tlearn: 0.0520512\ttotal: 23m 55s\tremaining: 2m 28s\n",
      "9061:\tlearn: 0.0520512\ttotal: 23m 55s\tremaining: 2m 28s\n",
      "9062:\tlearn: 0.0520512\ttotal: 23m 55s\tremaining: 2m 28s\n",
      "9063:\tlearn: 0.0520512\ttotal: 23m 55s\tremaining: 2m 28s\n",
      "9064:\tlearn: 0.0520512\ttotal: 23m 55s\tremaining: 2m 28s\n",
      "9065:\tlearn: 0.0520512\ttotal: 23m 55s\tremaining: 2m 27s\n",
      "9066:\tlearn: 0.0520512\ttotal: 23m 56s\tremaining: 2m 27s\n",
      "9067:\tlearn: 0.0520512\ttotal: 23m 56s\tremaining: 2m 27s\n",
      "9068:\tlearn: 0.0520512\ttotal: 23m 56s\tremaining: 2m 27s\n",
      "9069:\tlearn: 0.0520512\ttotal: 23m 56s\tremaining: 2m 27s\n",
      "9070:\tlearn: 0.0520512\ttotal: 23m 56s\tremaining: 2m 27s\n",
      "9071:\tlearn: 0.0520512\ttotal: 23m 56s\tremaining: 2m 26s\n",
      "9072:\tlearn: 0.0520512\ttotal: 23m 57s\tremaining: 2m 26s\n",
      "9073:\tlearn: 0.0520512\ttotal: 23m 57s\tremaining: 2m 26s\n",
      "9074:\tlearn: 0.0520512\ttotal: 23m 57s\tremaining: 2m 26s\n",
      "9075:\tlearn: 0.0520512\ttotal: 23m 57s\tremaining: 2m 26s\n",
      "9076:\tlearn: 0.0520512\ttotal: 23m 57s\tremaining: 2m 26s\n",
      "9077:\tlearn: 0.0520512\ttotal: 23m 57s\tremaining: 2m 26s\n",
      "9078:\tlearn: 0.0520512\ttotal: 23m 58s\tremaining: 2m 25s\n",
      "9079:\tlearn: 0.0520512\ttotal: 23m 58s\tremaining: 2m 25s\n",
      "9080:\tlearn: 0.0520512\ttotal: 23m 58s\tremaining: 2m 25s\n",
      "9081:\tlearn: 0.0520512\ttotal: 23m 58s\tremaining: 2m 25s\n",
      "9082:\tlearn: 0.0520512\ttotal: 23m 58s\tremaining: 2m 25s\n",
      "9083:\tlearn: 0.0520512\ttotal: 23m 58s\tremaining: 2m 25s\n",
      "9084:\tlearn: 0.0520512\ttotal: 23m 59s\tremaining: 2m 24s\n",
      "9085:\tlearn: 0.0520512\ttotal: 23m 59s\tremaining: 2m 24s\n",
      "9086:\tlearn: 0.0520512\ttotal: 23m 59s\tremaining: 2m 24s\n",
      "9087:\tlearn: 0.0520512\ttotal: 23m 59s\tremaining: 2m 24s\n",
      "9088:\tlearn: 0.0520512\ttotal: 23m 59s\tremaining: 2m 24s\n",
      "9089:\tlearn: 0.0520512\ttotal: 23m 59s\tremaining: 2m 24s\n",
      "9090:\tlearn: 0.0520512\ttotal: 24m\tremaining: 2m 23s\n",
      "9091:\tlearn: 0.0520512\ttotal: 24m\tremaining: 2m 23s\n",
      "9092:\tlearn: 0.0520512\ttotal: 24m\tremaining: 2m 23s\n",
      "9093:\tlearn: 0.0520512\ttotal: 24m\tremaining: 2m 23s\n",
      "9094:\tlearn: 0.0520512\ttotal: 24m\tremaining: 2m 23s\n",
      "9095:\tlearn: 0.0520512\ttotal: 24m\tremaining: 2m 23s\n",
      "9096:\tlearn: 0.0520512\ttotal: 24m 1s\tremaining: 2m 23s\n",
      "9097:\tlearn: 0.0520512\ttotal: 24m 1s\tremaining: 2m 22s\n",
      "9098:\tlearn: 0.0520512\ttotal: 24m 1s\tremaining: 2m 22s\n",
      "9099:\tlearn: 0.0520512\ttotal: 24m 1s\tremaining: 2m 22s\n",
      "9100:\tlearn: 0.0520512\ttotal: 24m 1s\tremaining: 2m 22s\n",
      "9101:\tlearn: 0.0520512\ttotal: 24m 1s\tremaining: 2m 22s\n",
      "9102:\tlearn: 0.0520512\ttotal: 24m 2s\tremaining: 2m 22s\n",
      "9103:\tlearn: 0.0520512\ttotal: 24m 2s\tremaining: 2m 21s\n",
      "9104:\tlearn: 0.0520512\ttotal: 24m 2s\tremaining: 2m 21s\n",
      "9105:\tlearn: 0.0520512\ttotal: 24m 2s\tremaining: 2m 21s\n",
      "9106:\tlearn: 0.0520512\ttotal: 24m 2s\tremaining: 2m 21s\n",
      "9107:\tlearn: 0.0520512\ttotal: 24m 2s\tremaining: 2m 21s\n",
      "9108:\tlearn: 0.0520512\ttotal: 24m 3s\tremaining: 2m 21s\n",
      "9109:\tlearn: 0.0520512\ttotal: 24m 3s\tremaining: 2m 20s\n",
      "9110:\tlearn: 0.0520512\ttotal: 24m 3s\tremaining: 2m 20s\n",
      "9111:\tlearn: 0.0520512\ttotal: 24m 3s\tremaining: 2m 20s\n",
      "9112:\tlearn: 0.0520512\ttotal: 24m 3s\tremaining: 2m 20s\n",
      "9113:\tlearn: 0.0520512\ttotal: 24m 3s\tremaining: 2m 20s\n",
      "9114:\tlearn: 0.0520512\ttotal: 24m 4s\tremaining: 2m 20s\n",
      "9115:\tlearn: 0.0520512\ttotal: 24m 4s\tremaining: 2m 20s\n",
      "9116:\tlearn: 0.0520512\ttotal: 24m 4s\tremaining: 2m 19s\n",
      "9117:\tlearn: 0.0520512\ttotal: 24m 4s\tremaining: 2m 19s\n",
      "9118:\tlearn: 0.0520512\ttotal: 24m 4s\tremaining: 2m 19s\n",
      "9119:\tlearn: 0.0520512\ttotal: 24m 4s\tremaining: 2m 19s\n",
      "9120:\tlearn: 0.0520512\ttotal: 24m 5s\tremaining: 2m 19s\n",
      "9121:\tlearn: 0.0520512\ttotal: 24m 5s\tremaining: 2m 19s\n",
      "9122:\tlearn: 0.0520512\ttotal: 24m 5s\tremaining: 2m 18s\n",
      "9123:\tlearn: 0.0520512\ttotal: 24m 5s\tremaining: 2m 18s\n",
      "9124:\tlearn: 0.0520512\ttotal: 24m 5s\tremaining: 2m 18s\n",
      "9125:\tlearn: 0.0520512\ttotal: 24m 5s\tremaining: 2m 18s\n",
      "9126:\tlearn: 0.0520512\ttotal: 24m 6s\tremaining: 2m 18s\n",
      "9127:\tlearn: 0.0520512\ttotal: 24m 6s\tremaining: 2m 18s\n",
      "9128:\tlearn: 0.0520512\ttotal: 24m 6s\tremaining: 2m 17s\n",
      "9129:\tlearn: 0.0520512\ttotal: 24m 6s\tremaining: 2m 17s\n",
      "9130:\tlearn: 0.0520512\ttotal: 24m 6s\tremaining: 2m 17s\n",
      "9131:\tlearn: 0.0520512\ttotal: 24m 6s\tremaining: 2m 17s\n",
      "9132:\tlearn: 0.0520512\ttotal: 24m 6s\tremaining: 2m 17s\n",
      "9133:\tlearn: 0.0520512\ttotal: 24m 7s\tremaining: 2m 17s\n",
      "9134:\tlearn: 0.0520512\ttotal: 24m 7s\tremaining: 2m 17s\n",
      "9135:\tlearn: 0.0520512\ttotal: 24m 7s\tremaining: 2m 16s\n",
      "9136:\tlearn: 0.0520512\ttotal: 24m 7s\tremaining: 2m 16s\n",
      "9137:\tlearn: 0.0520512\ttotal: 24m 7s\tremaining: 2m 16s\n",
      "9138:\tlearn: 0.0520512\ttotal: 24m 7s\tremaining: 2m 16s\n",
      "9139:\tlearn: 0.0520512\ttotal: 24m 8s\tremaining: 2m 16s\n",
      "9140:\tlearn: 0.0520512\ttotal: 24m 8s\tremaining: 2m 16s\n",
      "9141:\tlearn: 0.0520512\ttotal: 24m 8s\tremaining: 2m 15s\n",
      "9142:\tlearn: 0.0520512\ttotal: 24m 8s\tremaining: 2m 15s\n",
      "9143:\tlearn: 0.0520512\ttotal: 24m 8s\tremaining: 2m 15s\n",
      "9144:\tlearn: 0.0520512\ttotal: 24m 8s\tremaining: 2m 15s\n",
      "9145:\tlearn: 0.0520512\ttotal: 24m 9s\tremaining: 2m 15s\n",
      "9146:\tlearn: 0.0520512\ttotal: 24m 9s\tremaining: 2m 15s\n",
      "9147:\tlearn: 0.0520512\ttotal: 24m 9s\tremaining: 2m 14s\n",
      "9148:\tlearn: 0.0520512\ttotal: 24m 9s\tremaining: 2m 14s\n",
      "9149:\tlearn: 0.0520512\ttotal: 24m 9s\tremaining: 2m 14s\n",
      "9150:\tlearn: 0.0520512\ttotal: 24m 9s\tremaining: 2m 14s\n",
      "9151:\tlearn: 0.0520512\ttotal: 24m 10s\tremaining: 2m 14s\n",
      "9152:\tlearn: 0.0520512\ttotal: 24m 10s\tremaining: 2m 14s\n",
      "9153:\tlearn: 0.0520512\ttotal: 24m 10s\tremaining: 2m 14s\n",
      "9154:\tlearn: 0.0520512\ttotal: 24m 10s\tremaining: 2m 13s\n",
      "9155:\tlearn: 0.0520512\ttotal: 24m 10s\tremaining: 2m 13s\n",
      "9156:\tlearn: 0.0520512\ttotal: 24m 10s\tremaining: 2m 13s\n",
      "9157:\tlearn: 0.0520512\ttotal: 24m 11s\tremaining: 2m 13s\n",
      "9158:\tlearn: 0.0520512\ttotal: 24m 11s\tremaining: 2m 13s\n",
      "9159:\tlearn: 0.0520512\ttotal: 24m 11s\tremaining: 2m 13s\n",
      "9160:\tlearn: 0.0520512\ttotal: 24m 11s\tremaining: 2m 12s\n",
      "9161:\tlearn: 0.0520512\ttotal: 24m 11s\tremaining: 2m 12s\n",
      "9162:\tlearn: 0.0520512\ttotal: 24m 11s\tremaining: 2m 12s\n",
      "9163:\tlearn: 0.0520512\ttotal: 24m 12s\tremaining: 2m 12s\n",
      "9164:\tlearn: 0.0520512\ttotal: 24m 12s\tremaining: 2m 12s\n",
      "9165:\tlearn: 0.0520512\ttotal: 24m 12s\tremaining: 2m 12s\n",
      "9166:\tlearn: 0.0520512\ttotal: 24m 12s\tremaining: 2m 12s\n",
      "9167:\tlearn: 0.0520512\ttotal: 24m 12s\tremaining: 2m 11s\n",
      "9168:\tlearn: 0.0520512\ttotal: 24m 12s\tremaining: 2m 11s\n",
      "9169:\tlearn: 0.0520512\ttotal: 24m 13s\tremaining: 2m 11s\n",
      "9170:\tlearn: 0.0520512\ttotal: 24m 13s\tremaining: 2m 11s\n",
      "9171:\tlearn: 0.0520512\ttotal: 24m 13s\tremaining: 2m 11s\n",
      "9172:\tlearn: 0.0520512\ttotal: 24m 13s\tremaining: 2m 11s\n",
      "9173:\tlearn: 0.0520512\ttotal: 24m 13s\tremaining: 2m 10s\n",
      "9174:\tlearn: 0.0520512\ttotal: 24m 13s\tremaining: 2m 10s\n",
      "9175:\tlearn: 0.0520512\ttotal: 24m 14s\tremaining: 2m 10s\n",
      "9176:\tlearn: 0.0520512\ttotal: 24m 14s\tremaining: 2m 10s\n",
      "9177:\tlearn: 0.0520512\ttotal: 24m 14s\tremaining: 2m 10s\n",
      "9178:\tlearn: 0.0520512\ttotal: 24m 14s\tremaining: 2m 10s\n",
      "9179:\tlearn: 0.0520512\ttotal: 24m 14s\tremaining: 2m 9s\n",
      "9180:\tlearn: 0.0520512\ttotal: 24m 14s\tremaining: 2m 9s\n",
      "9181:\tlearn: 0.0520512\ttotal: 24m 15s\tremaining: 2m 9s\n",
      "9182:\tlearn: 0.0520512\ttotal: 24m 15s\tremaining: 2m 9s\n",
      "9183:\tlearn: 0.0520512\ttotal: 24m 15s\tremaining: 2m 9s\n",
      "9184:\tlearn: 0.0520512\ttotal: 24m 15s\tremaining: 2m 9s\n",
      "9185:\tlearn: 0.0520512\ttotal: 24m 15s\tremaining: 2m 9s\n",
      "9186:\tlearn: 0.0520512\ttotal: 24m 15s\tremaining: 2m 8s\n",
      "9187:\tlearn: 0.0520512\ttotal: 24m 16s\tremaining: 2m 8s\n",
      "9188:\tlearn: 0.0520512\ttotal: 24m 16s\tremaining: 2m 8s\n",
      "9189:\tlearn: 0.0520512\ttotal: 24m 16s\tremaining: 2m 8s\n",
      "9190:\tlearn: 0.0520512\ttotal: 24m 16s\tremaining: 2m 8s\n",
      "9191:\tlearn: 0.0520512\ttotal: 24m 16s\tremaining: 2m 8s\n",
      "9192:\tlearn: 0.0520512\ttotal: 24m 16s\tremaining: 2m 7s\n",
      "9193:\tlearn: 0.0520512\ttotal: 24m 17s\tremaining: 2m 7s\n",
      "9194:\tlearn: 0.0520512\ttotal: 24m 17s\tremaining: 2m 7s\n",
      "9195:\tlearn: 0.0520512\ttotal: 24m 17s\tremaining: 2m 7s\n",
      "9196:\tlearn: 0.0520512\ttotal: 24m 17s\tremaining: 2m 7s\n",
      "9197:\tlearn: 0.0520512\ttotal: 24m 17s\tremaining: 2m 7s\n",
      "9198:\tlearn: 0.0520512\ttotal: 24m 17s\tremaining: 2m 6s\n",
      "9199:\tlearn: 0.0520512\ttotal: 24m 18s\tremaining: 2m 6s\n",
      "9200:\tlearn: 0.0520512\ttotal: 24m 18s\tremaining: 2m 6s\n",
      "9201:\tlearn: 0.0520512\ttotal: 24m 18s\tremaining: 2m 6s\n",
      "9202:\tlearn: 0.0520512\ttotal: 24m 18s\tremaining: 2m 6s\n",
      "9203:\tlearn: 0.0520512\ttotal: 24m 18s\tremaining: 2m 6s\n",
      "9204:\tlearn: 0.0520512\ttotal: 24m 18s\tremaining: 2m 6s\n",
      "9205:\tlearn: 0.0520512\ttotal: 24m 19s\tremaining: 2m 5s\n",
      "9206:\tlearn: 0.0520512\ttotal: 24m 19s\tremaining: 2m 5s\n",
      "9207:\tlearn: 0.0520512\ttotal: 24m 19s\tremaining: 2m 5s\n",
      "9208:\tlearn: 0.0520512\ttotal: 24m 19s\tremaining: 2m 5s\n",
      "9209:\tlearn: 0.0520512\ttotal: 24m 19s\tremaining: 2m 5s\n",
      "9210:\tlearn: 0.0520512\ttotal: 24m 19s\tremaining: 2m 5s\n",
      "9211:\tlearn: 0.0520512\ttotal: 24m 20s\tremaining: 2m 4s\n",
      "9212:\tlearn: 0.0520512\ttotal: 24m 20s\tremaining: 2m 4s\n",
      "9213:\tlearn: 0.0520512\ttotal: 24m 20s\tremaining: 2m 4s\n",
      "9214:\tlearn: 0.0520512\ttotal: 24m 20s\tremaining: 2m 4s\n",
      "9215:\tlearn: 0.0520512\ttotal: 24m 20s\tremaining: 2m 4s\n",
      "9216:\tlearn: 0.0520512\ttotal: 24m 20s\tremaining: 2m 4s\n",
      "9217:\tlearn: 0.0520512\ttotal: 24m 21s\tremaining: 2m 3s\n",
      "9218:\tlearn: 0.0520512\ttotal: 24m 21s\tremaining: 2m 3s\n",
      "9219:\tlearn: 0.0520512\ttotal: 24m 21s\tremaining: 2m 3s\n",
      "9220:\tlearn: 0.0520512\ttotal: 24m 21s\tremaining: 2m 3s\n",
      "9221:\tlearn: 0.0520512\ttotal: 24m 21s\tremaining: 2m 3s\n",
      "9222:\tlearn: 0.0520512\ttotal: 24m 21s\tremaining: 2m 3s\n",
      "9223:\tlearn: 0.0520512\ttotal: 24m 22s\tremaining: 2m 3s\n",
      "9224:\tlearn: 0.0520512\ttotal: 24m 22s\tremaining: 2m 2s\n",
      "9225:\tlearn: 0.0520512\ttotal: 24m 22s\tremaining: 2m 2s\n",
      "9226:\tlearn: 0.0520512\ttotal: 24m 22s\tremaining: 2m 2s\n",
      "9227:\tlearn: 0.0520512\ttotal: 24m 22s\tremaining: 2m 2s\n",
      "9228:\tlearn: 0.0520512\ttotal: 24m 22s\tremaining: 2m 2s\n",
      "9229:\tlearn: 0.0520512\ttotal: 24m 23s\tremaining: 2m 2s\n",
      "9230:\tlearn: 0.0520512\ttotal: 24m 23s\tremaining: 2m 1s\n",
      "9231:\tlearn: 0.0520512\ttotal: 24m 23s\tremaining: 2m 1s\n",
      "9232:\tlearn: 0.0520512\ttotal: 24m 23s\tremaining: 2m 1s\n",
      "9233:\tlearn: 0.0520512\ttotal: 24m 23s\tremaining: 2m 1s\n",
      "9234:\tlearn: 0.0520512\ttotal: 24m 23s\tremaining: 2m 1s\n",
      "9235:\tlearn: 0.0520512\ttotal: 24m 24s\tremaining: 2m 1s\n",
      "9236:\tlearn: 0.0520512\ttotal: 24m 24s\tremaining: 2m\n",
      "9237:\tlearn: 0.0520512\ttotal: 24m 24s\tremaining: 2m\n",
      "9238:\tlearn: 0.0520512\ttotal: 24m 24s\tremaining: 2m\n",
      "9239:\tlearn: 0.0520512\ttotal: 24m 24s\tremaining: 2m\n",
      "9240:\tlearn: 0.0520512\ttotal: 24m 24s\tremaining: 2m\n",
      "9241:\tlearn: 0.0520512\ttotal: 24m 25s\tremaining: 2m\n",
      "9242:\tlearn: 0.0520512\ttotal: 24m 25s\tremaining: 2m\n",
      "9243:\tlearn: 0.0520512\ttotal: 24m 25s\tremaining: 1m 59s\n",
      "9244:\tlearn: 0.0520512\ttotal: 24m 25s\tremaining: 1m 59s\n",
      "9245:\tlearn: 0.0520512\ttotal: 24m 25s\tremaining: 1m 59s\n",
      "9246:\tlearn: 0.0520512\ttotal: 24m 25s\tremaining: 1m 59s\n",
      "9247:\tlearn: 0.0520512\ttotal: 24m 26s\tremaining: 1m 59s\n",
      "9248:\tlearn: 0.0520512\ttotal: 24m 26s\tremaining: 1m 59s\n",
      "9249:\tlearn: 0.0520512\ttotal: 24m 26s\tremaining: 1m 58s\n",
      "9250:\tlearn: 0.0520512\ttotal: 24m 26s\tremaining: 1m 58s\n",
      "9251:\tlearn: 0.0520512\ttotal: 24m 26s\tremaining: 1m 58s\n",
      "9252:\tlearn: 0.0520512\ttotal: 24m 26s\tremaining: 1m 58s\n",
      "9253:\tlearn: 0.0520512\ttotal: 24m 27s\tremaining: 1m 58s\n",
      "9254:\tlearn: 0.0520512\ttotal: 24m 27s\tremaining: 1m 58s\n",
      "9255:\tlearn: 0.0520512\ttotal: 24m 27s\tremaining: 1m 57s\n",
      "9256:\tlearn: 0.0520512\ttotal: 24m 27s\tremaining: 1m 57s\n",
      "9257:\tlearn: 0.0520512\ttotal: 24m 27s\tremaining: 1m 57s\n",
      "9258:\tlearn: 0.0520512\ttotal: 24m 27s\tremaining: 1m 57s\n",
      "9259:\tlearn: 0.0520512\ttotal: 24m 28s\tremaining: 1m 57s\n",
      "9260:\tlearn: 0.0520512\ttotal: 24m 28s\tremaining: 1m 57s\n",
      "9261:\tlearn: 0.0520512\ttotal: 24m 28s\tremaining: 1m 57s\n",
      "9262:\tlearn: 0.0520512\ttotal: 24m 28s\tremaining: 1m 56s\n",
      "9263:\tlearn: 0.0520512\ttotal: 24m 28s\tremaining: 1m 56s\n",
      "9264:\tlearn: 0.0520512\ttotal: 24m 28s\tremaining: 1m 56s\n",
      "9265:\tlearn: 0.0520512\ttotal: 24m 29s\tremaining: 1m 56s\n",
      "9266:\tlearn: 0.0520512\ttotal: 24m 29s\tremaining: 1m 56s\n",
      "9267:\tlearn: 0.0520512\ttotal: 24m 29s\tremaining: 1m 56s\n",
      "9268:\tlearn: 0.0520512\ttotal: 24m 29s\tremaining: 1m 55s\n",
      "9269:\tlearn: 0.0520512\ttotal: 24m 29s\tremaining: 1m 55s\n",
      "9270:\tlearn: 0.0520512\ttotal: 24m 29s\tremaining: 1m 55s\n",
      "9271:\tlearn: 0.0520512\ttotal: 24m 30s\tremaining: 1m 55s\n",
      "9272:\tlearn: 0.0520512\ttotal: 24m 30s\tremaining: 1m 55s\n",
      "9273:\tlearn: 0.0520512\ttotal: 24m 30s\tremaining: 1m 55s\n",
      "9274:\tlearn: 0.0520512\ttotal: 24m 30s\tremaining: 1m 54s\n",
      "9275:\tlearn: 0.0520512\ttotal: 24m 30s\tremaining: 1m 54s\n",
      "9276:\tlearn: 0.0520512\ttotal: 24m 30s\tremaining: 1m 54s\n",
      "9277:\tlearn: 0.0520512\ttotal: 24m 31s\tremaining: 1m 54s\n",
      "9278:\tlearn: 0.0520512\ttotal: 24m 31s\tremaining: 1m 54s\n",
      "9279:\tlearn: 0.0520512\ttotal: 24m 31s\tremaining: 1m 54s\n",
      "9280:\tlearn: 0.0520512\ttotal: 24m 31s\tremaining: 1m 53s\n",
      "9281:\tlearn: 0.0520512\ttotal: 24m 31s\tremaining: 1m 53s\n",
      "9282:\tlearn: 0.0520512\ttotal: 24m 31s\tremaining: 1m 53s\n",
      "9283:\tlearn: 0.0520512\ttotal: 24m 32s\tremaining: 1m 53s\n",
      "9284:\tlearn: 0.0520512\ttotal: 24m 32s\tremaining: 1m 53s\n",
      "9285:\tlearn: 0.0520512\ttotal: 24m 32s\tremaining: 1m 53s\n",
      "9286:\tlearn: 0.0520512\ttotal: 24m 32s\tremaining: 1m 53s\n",
      "9287:\tlearn: 0.0520512\ttotal: 24m 32s\tremaining: 1m 52s\n",
      "9288:\tlearn: 0.0520512\ttotal: 24m 32s\tremaining: 1m 52s\n",
      "9289:\tlearn: 0.0520512\ttotal: 24m 33s\tremaining: 1m 52s\n",
      "9290:\tlearn: 0.0520512\ttotal: 24m 33s\tremaining: 1m 52s\n",
      "9291:\tlearn: 0.0520512\ttotal: 24m 33s\tremaining: 1m 52s\n",
      "9292:\tlearn: 0.0520512\ttotal: 24m 33s\tremaining: 1m 52s\n",
      "9293:\tlearn: 0.0520512\ttotal: 24m 33s\tremaining: 1m 51s\n",
      "9294:\tlearn: 0.0520512\ttotal: 24m 33s\tremaining: 1m 51s\n",
      "9295:\tlearn: 0.0520512\ttotal: 24m 34s\tremaining: 1m 51s\n",
      "9296:\tlearn: 0.0520512\ttotal: 24m 34s\tremaining: 1m 51s\n",
      "9297:\tlearn: 0.0520512\ttotal: 24m 34s\tremaining: 1m 51s\n",
      "9298:\tlearn: 0.0520512\ttotal: 24m 34s\tremaining: 1m 51s\n",
      "9299:\tlearn: 0.0520512\ttotal: 24m 34s\tremaining: 1m 50s\n",
      "9300:\tlearn: 0.0520512\ttotal: 24m 34s\tremaining: 1m 50s\n",
      "9301:\tlearn: 0.0520512\ttotal: 24m 35s\tremaining: 1m 50s\n",
      "9302:\tlearn: 0.0520512\ttotal: 24m 35s\tremaining: 1m 50s\n",
      "9303:\tlearn: 0.0520512\ttotal: 24m 35s\tremaining: 1m 50s\n",
      "9304:\tlearn: 0.0520512\ttotal: 24m 35s\tremaining: 1m 50s\n",
      "9305:\tlearn: 0.0520512\ttotal: 24m 35s\tremaining: 1m 50s\n",
      "9306:\tlearn: 0.0520512\ttotal: 24m 35s\tremaining: 1m 49s\n",
      "9307:\tlearn: 0.0520512\ttotal: 24m 36s\tremaining: 1m 49s\n",
      "9308:\tlearn: 0.0520512\ttotal: 24m 36s\tremaining: 1m 49s\n",
      "9309:\tlearn: 0.0520512\ttotal: 24m 36s\tremaining: 1m 49s\n",
      "9310:\tlearn: 0.0520512\ttotal: 24m 36s\tremaining: 1m 49s\n",
      "9311:\tlearn: 0.0520512\ttotal: 24m 36s\tremaining: 1m 49s\n",
      "9312:\tlearn: 0.0520512\ttotal: 24m 36s\tremaining: 1m 48s\n",
      "9313:\tlearn: 0.0520512\ttotal: 24m 37s\tremaining: 1m 48s\n",
      "9314:\tlearn: 0.0520512\ttotal: 24m 37s\tremaining: 1m 48s\n",
      "9315:\tlearn: 0.0520512\ttotal: 24m 37s\tremaining: 1m 48s\n",
      "9316:\tlearn: 0.0520512\ttotal: 24m 37s\tremaining: 1m 48s\n",
      "9317:\tlearn: 0.0520512\ttotal: 24m 37s\tremaining: 1m 48s\n",
      "9318:\tlearn: 0.0520512\ttotal: 24m 37s\tremaining: 1m 47s\n",
      "9319:\tlearn: 0.0520512\ttotal: 24m 38s\tremaining: 1m 47s\n",
      "9320:\tlearn: 0.0520512\ttotal: 24m 38s\tremaining: 1m 47s\n",
      "9321:\tlearn: 0.0520512\ttotal: 24m 38s\tremaining: 1m 47s\n",
      "9322:\tlearn: 0.0520512\ttotal: 24m 38s\tremaining: 1m 47s\n",
      "9323:\tlearn: 0.0520512\ttotal: 24m 38s\tremaining: 1m 47s\n",
      "9324:\tlearn: 0.0520512\ttotal: 24m 38s\tremaining: 1m 47s\n",
      "9325:\tlearn: 0.0520512\ttotal: 24m 39s\tremaining: 1m 46s\n",
      "9326:\tlearn: 0.0520512\ttotal: 24m 39s\tremaining: 1m 46s\n",
      "9327:\tlearn: 0.0520512\ttotal: 24m 39s\tremaining: 1m 46s\n",
      "9328:\tlearn: 0.0520512\ttotal: 24m 39s\tremaining: 1m 46s\n",
      "9329:\tlearn: 0.0520512\ttotal: 24m 39s\tremaining: 1m 46s\n",
      "9330:\tlearn: 0.0520512\ttotal: 24m 39s\tremaining: 1m 46s\n",
      "9331:\tlearn: 0.0520512\ttotal: 24m 40s\tremaining: 1m 45s\n",
      "9332:\tlearn: 0.0520512\ttotal: 24m 40s\tremaining: 1m 45s\n",
      "9333:\tlearn: 0.0520512\ttotal: 24m 40s\tremaining: 1m 45s\n",
      "9334:\tlearn: 0.0520512\ttotal: 24m 40s\tremaining: 1m 45s\n",
      "9335:\tlearn: 0.0520512\ttotal: 24m 40s\tremaining: 1m 45s\n",
      "9336:\tlearn: 0.0520512\ttotal: 24m 40s\tremaining: 1m 45s\n",
      "9337:\tlearn: 0.0520512\ttotal: 24m 41s\tremaining: 1m 44s\n",
      "9338:\tlearn: 0.0520512\ttotal: 24m 41s\tremaining: 1m 44s\n",
      "9339:\tlearn: 0.0520512\ttotal: 24m 41s\tremaining: 1m 44s\n",
      "9340:\tlearn: 0.0520512\ttotal: 24m 41s\tremaining: 1m 44s\n",
      "9341:\tlearn: 0.0520512\ttotal: 24m 41s\tremaining: 1m 44s\n",
      "9342:\tlearn: 0.0520512\ttotal: 24m 41s\tremaining: 1m 44s\n",
      "9343:\tlearn: 0.0520512\ttotal: 24m 41s\tremaining: 1m 44s\n",
      "9344:\tlearn: 0.0520512\ttotal: 24m 42s\tremaining: 1m 43s\n",
      "9345:\tlearn: 0.0520512\ttotal: 24m 42s\tremaining: 1m 43s\n",
      "9346:\tlearn: 0.0520512\ttotal: 24m 42s\tremaining: 1m 43s\n",
      "9347:\tlearn: 0.0520512\ttotal: 24m 42s\tremaining: 1m 43s\n",
      "9348:\tlearn: 0.0520512\ttotal: 24m 42s\tremaining: 1m 43s\n",
      "9349:\tlearn: 0.0520512\ttotal: 24m 42s\tremaining: 1m 43s\n",
      "9350:\tlearn: 0.0520512\ttotal: 24m 43s\tremaining: 1m 42s\n",
      "9351:\tlearn: 0.0520512\ttotal: 24m 43s\tremaining: 1m 42s\n",
      "9352:\tlearn: 0.0520512\ttotal: 24m 43s\tremaining: 1m 42s\n",
      "9353:\tlearn: 0.0520512\ttotal: 24m 43s\tremaining: 1m 42s\n",
      "9354:\tlearn: 0.0520512\ttotal: 24m 43s\tremaining: 1m 42s\n",
      "9355:\tlearn: 0.0520512\ttotal: 24m 43s\tremaining: 1m 42s\n",
      "9356:\tlearn: 0.0520512\ttotal: 24m 44s\tremaining: 1m 41s\n",
      "9357:\tlearn: 0.0520512\ttotal: 24m 44s\tremaining: 1m 41s\n",
      "9358:\tlearn: 0.0520512\ttotal: 24m 44s\tremaining: 1m 41s\n",
      "9359:\tlearn: 0.0520512\ttotal: 24m 44s\tremaining: 1m 41s\n",
      "9360:\tlearn: 0.0520512\ttotal: 24m 44s\tremaining: 1m 41s\n",
      "9361:\tlearn: 0.0520512\ttotal: 24m 44s\tremaining: 1m 41s\n",
      "9362:\tlearn: 0.0520512\ttotal: 24m 45s\tremaining: 1m 41s\n",
      "9363:\tlearn: 0.0520512\ttotal: 24m 45s\tremaining: 1m 40s\n",
      "9364:\tlearn: 0.0520512\ttotal: 24m 45s\tremaining: 1m 40s\n",
      "9365:\tlearn: 0.0520512\ttotal: 24m 45s\tremaining: 1m 40s\n",
      "9366:\tlearn: 0.0520512\ttotal: 24m 45s\tremaining: 1m 40s\n",
      "9367:\tlearn: 0.0520512\ttotal: 24m 45s\tremaining: 1m 40s\n",
      "9368:\tlearn: 0.0520512\ttotal: 24m 46s\tremaining: 1m 40s\n",
      "9369:\tlearn: 0.0520512\ttotal: 24m 46s\tremaining: 1m 39s\n",
      "9370:\tlearn: 0.0520512\ttotal: 24m 46s\tremaining: 1m 39s\n",
      "9371:\tlearn: 0.0520512\ttotal: 24m 46s\tremaining: 1m 39s\n",
      "9372:\tlearn: 0.0520512\ttotal: 24m 46s\tremaining: 1m 39s\n",
      "9373:\tlearn: 0.0520512\ttotal: 24m 46s\tremaining: 1m 39s\n",
      "9374:\tlearn: 0.0520512\ttotal: 24m 47s\tremaining: 1m 39s\n",
      "9375:\tlearn: 0.0520512\ttotal: 24m 47s\tremaining: 1m 38s\n",
      "9376:\tlearn: 0.0520512\ttotal: 24m 47s\tremaining: 1m 38s\n",
      "9377:\tlearn: 0.0520512\ttotal: 24m 47s\tremaining: 1m 38s\n",
      "9378:\tlearn: 0.0520512\ttotal: 24m 47s\tremaining: 1m 38s\n",
      "9379:\tlearn: 0.0520512\ttotal: 24m 47s\tremaining: 1m 38s\n",
      "9380:\tlearn: 0.0520512\ttotal: 24m 48s\tremaining: 1m 38s\n",
      "9381:\tlearn: 0.0520512\ttotal: 24m 48s\tremaining: 1m 38s\n",
      "9382:\tlearn: 0.0520512\ttotal: 24m 48s\tremaining: 1m 37s\n",
      "9383:\tlearn: 0.0520512\ttotal: 24m 48s\tremaining: 1m 37s\n",
      "9384:\tlearn: 0.0520512\ttotal: 24m 48s\tremaining: 1m 37s\n",
      "9385:\tlearn: 0.0520512\ttotal: 24m 48s\tremaining: 1m 37s\n",
      "9386:\tlearn: 0.0520512\ttotal: 24m 49s\tremaining: 1m 37s\n",
      "9387:\tlearn: 0.0520512\ttotal: 24m 49s\tremaining: 1m 37s\n",
      "9388:\tlearn: 0.0520512\ttotal: 24m 49s\tremaining: 1m 36s\n",
      "9389:\tlearn: 0.0520512\ttotal: 24m 49s\tremaining: 1m 36s\n",
      "9390:\tlearn: 0.0520512\ttotal: 24m 49s\tremaining: 1m 36s\n",
      "9391:\tlearn: 0.0520512\ttotal: 24m 49s\tremaining: 1m 36s\n",
      "9392:\tlearn: 0.0520512\ttotal: 24m 50s\tremaining: 1m 36s\n",
      "9393:\tlearn: 0.0520512\ttotal: 24m 50s\tremaining: 1m 36s\n",
      "9394:\tlearn: 0.0520512\ttotal: 24m 50s\tremaining: 1m 35s\n",
      "9395:\tlearn: 0.0520512\ttotal: 24m 50s\tremaining: 1m 35s\n",
      "9396:\tlearn: 0.0520512\ttotal: 24m 50s\tremaining: 1m 35s\n",
      "9397:\tlearn: 0.0520512\ttotal: 24m 50s\tremaining: 1m 35s\n",
      "9398:\tlearn: 0.0520512\ttotal: 24m 51s\tremaining: 1m 35s\n",
      "9399:\tlearn: 0.0520512\ttotal: 24m 51s\tremaining: 1m 35s\n",
      "9400:\tlearn: 0.0520512\ttotal: 24m 51s\tremaining: 1m 35s\n",
      "9401:\tlearn: 0.0520512\ttotal: 24m 51s\tremaining: 1m 34s\n",
      "9402:\tlearn: 0.0520512\ttotal: 24m 51s\tremaining: 1m 34s\n",
      "9403:\tlearn: 0.0520512\ttotal: 24m 51s\tremaining: 1m 34s\n",
      "9404:\tlearn: 0.0520512\ttotal: 24m 52s\tremaining: 1m 34s\n",
      "9405:\tlearn: 0.0520512\ttotal: 24m 52s\tremaining: 1m 34s\n",
      "9406:\tlearn: 0.0520512\ttotal: 24m 52s\tremaining: 1m 34s\n",
      "9407:\tlearn: 0.0520512\ttotal: 24m 52s\tremaining: 1m 33s\n",
      "9408:\tlearn: 0.0520512\ttotal: 24m 52s\tremaining: 1m 33s\n",
      "9409:\tlearn: 0.0520512\ttotal: 24m 52s\tremaining: 1m 33s\n",
      "9410:\tlearn: 0.0520512\ttotal: 24m 53s\tremaining: 1m 33s\n",
      "9411:\tlearn: 0.0520512\ttotal: 24m 53s\tremaining: 1m 33s\n",
      "9412:\tlearn: 0.0520512\ttotal: 24m 53s\tremaining: 1m 33s\n",
      "9413:\tlearn: 0.0520512\ttotal: 24m 53s\tremaining: 1m 32s\n",
      "9414:\tlearn: 0.0520512\ttotal: 24m 53s\tremaining: 1m 32s\n",
      "9415:\tlearn: 0.0520512\ttotal: 24m 53s\tremaining: 1m 32s\n",
      "9416:\tlearn: 0.0520512\ttotal: 24m 53s\tremaining: 1m 32s\n",
      "9417:\tlearn: 0.0520512\ttotal: 24m 54s\tremaining: 1m 32s\n",
      "9418:\tlearn: 0.0520512\ttotal: 24m 54s\tremaining: 1m 32s\n",
      "9419:\tlearn: 0.0520512\ttotal: 24m 54s\tremaining: 1m 32s\n",
      "9420:\tlearn: 0.0520512\ttotal: 24m 54s\tremaining: 1m 31s\n",
      "9421:\tlearn: 0.0520512\ttotal: 24m 54s\tremaining: 1m 31s\n",
      "9422:\tlearn: 0.0520512\ttotal: 24m 54s\tremaining: 1m 31s\n",
      "9423:\tlearn: 0.0520512\ttotal: 24m 55s\tremaining: 1m 31s\n",
      "9424:\tlearn: 0.0520512\ttotal: 24m 55s\tremaining: 1m 31s\n",
      "9425:\tlearn: 0.0520512\ttotal: 24m 55s\tremaining: 1m 31s\n",
      "9426:\tlearn: 0.0520512\ttotal: 24m 55s\tremaining: 1m 30s\n",
      "9427:\tlearn: 0.0520512\ttotal: 24m 55s\tremaining: 1m 30s\n",
      "9428:\tlearn: 0.0520512\ttotal: 24m 55s\tremaining: 1m 30s\n",
      "9429:\tlearn: 0.0520512\ttotal: 24m 56s\tremaining: 1m 30s\n",
      "9430:\tlearn: 0.0520512\ttotal: 24m 56s\tremaining: 1m 30s\n",
      "9431:\tlearn: 0.0520512\ttotal: 24m 56s\tremaining: 1m 30s\n",
      "9432:\tlearn: 0.0520512\ttotal: 24m 56s\tremaining: 1m 29s\n",
      "9433:\tlearn: 0.0520512\ttotal: 24m 56s\tremaining: 1m 29s\n",
      "9434:\tlearn: 0.0520512\ttotal: 24m 56s\tremaining: 1m 29s\n",
      "9435:\tlearn: 0.0520512\ttotal: 24m 57s\tremaining: 1m 29s\n",
      "9436:\tlearn: 0.0520512\ttotal: 24m 57s\tremaining: 1m 29s\n",
      "9437:\tlearn: 0.0520512\ttotal: 24m 57s\tremaining: 1m 29s\n",
      "9438:\tlearn: 0.0520512\ttotal: 24m 57s\tremaining: 1m 29s\n",
      "9439:\tlearn: 0.0520512\ttotal: 24m 57s\tremaining: 1m 28s\n",
      "9440:\tlearn: 0.0520512\ttotal: 24m 57s\tremaining: 1m 28s\n",
      "9441:\tlearn: 0.0520512\ttotal: 24m 57s\tremaining: 1m 28s\n",
      "9442:\tlearn: 0.0520512\ttotal: 24m 58s\tremaining: 1m 28s\n",
      "9443:\tlearn: 0.0520512\ttotal: 24m 58s\tremaining: 1m 28s\n",
      "9444:\tlearn: 0.0520512\ttotal: 24m 58s\tremaining: 1m 28s\n",
      "9445:\tlearn: 0.0520512\ttotal: 24m 58s\tremaining: 1m 27s\n",
      "9446:\tlearn: 0.0520512\ttotal: 24m 58s\tremaining: 1m 27s\n",
      "9447:\tlearn: 0.0520512\ttotal: 24m 58s\tremaining: 1m 27s\n",
      "9448:\tlearn: 0.0520512\ttotal: 24m 59s\tremaining: 1m 27s\n",
      "9449:\tlearn: 0.0520512\ttotal: 24m 59s\tremaining: 1m 27s\n",
      "9450:\tlearn: 0.0520512\ttotal: 24m 59s\tremaining: 1m 27s\n",
      "9451:\tlearn: 0.0520512\ttotal: 24m 59s\tremaining: 1m 26s\n",
      "9452:\tlearn: 0.0520512\ttotal: 24m 59s\tremaining: 1m 26s\n",
      "9453:\tlearn: 0.0520512\ttotal: 24m 59s\tremaining: 1m 26s\n",
      "9454:\tlearn: 0.0520512\ttotal: 25m\tremaining: 1m 26s\n",
      "9455:\tlearn: 0.0520512\ttotal: 25m\tremaining: 1m 26s\n",
      "9456:\tlearn: 0.0520512\ttotal: 25m\tremaining: 1m 26s\n",
      "9457:\tlearn: 0.0520512\ttotal: 25m\tremaining: 1m 25s\n",
      "9458:\tlearn: 0.0520512\ttotal: 25m\tremaining: 1m 25s\n",
      "9459:\tlearn: 0.0520512\ttotal: 25m\tremaining: 1m 25s\n",
      "9460:\tlearn: 0.0520512\ttotal: 25m 1s\tremaining: 1m 25s\n",
      "9461:\tlearn: 0.0520512\ttotal: 25m 1s\tremaining: 1m 25s\n",
      "9462:\tlearn: 0.0520512\ttotal: 25m 1s\tremaining: 1m 25s\n",
      "9463:\tlearn: 0.0520512\ttotal: 25m 1s\tremaining: 1m 25s\n",
      "9464:\tlearn: 0.0520512\ttotal: 25m 1s\tremaining: 1m 24s\n",
      "9465:\tlearn: 0.0520512\ttotal: 25m 1s\tremaining: 1m 24s\n",
      "9466:\tlearn: 0.0520512\ttotal: 25m 2s\tremaining: 1m 24s\n",
      "9467:\tlearn: 0.0520512\ttotal: 25m 2s\tremaining: 1m 24s\n",
      "9468:\tlearn: 0.0520512\ttotal: 25m 2s\tremaining: 1m 24s\n",
      "9469:\tlearn: 0.0520512\ttotal: 25m 2s\tremaining: 1m 24s\n",
      "9470:\tlearn: 0.0520512\ttotal: 25m 2s\tremaining: 1m 23s\n",
      "9471:\tlearn: 0.0520512\ttotal: 25m 2s\tremaining: 1m 23s\n",
      "9472:\tlearn: 0.0520512\ttotal: 25m 3s\tremaining: 1m 23s\n",
      "9473:\tlearn: 0.0520512\ttotal: 25m 3s\tremaining: 1m 23s\n",
      "9474:\tlearn: 0.0520512\ttotal: 25m 3s\tremaining: 1m 23s\n",
      "9475:\tlearn: 0.0520512\ttotal: 25m 3s\tremaining: 1m 23s\n",
      "9476:\tlearn: 0.0520512\ttotal: 25m 3s\tremaining: 1m 22s\n",
      "9477:\tlearn: 0.0520512\ttotal: 25m 3s\tremaining: 1m 22s\n",
      "9478:\tlearn: 0.0520512\ttotal: 25m 4s\tremaining: 1m 22s\n",
      "9479:\tlearn: 0.0520512\ttotal: 25m 4s\tremaining: 1m 22s\n",
      "9480:\tlearn: 0.0520512\ttotal: 25m 4s\tremaining: 1m 22s\n",
      "9481:\tlearn: 0.0520512\ttotal: 25m 4s\tremaining: 1m 22s\n",
      "9482:\tlearn: 0.0520512\ttotal: 25m 4s\tremaining: 1m 22s\n",
      "9483:\tlearn: 0.0520512\ttotal: 25m 4s\tremaining: 1m 21s\n",
      "9484:\tlearn: 0.0520512\ttotal: 25m 5s\tremaining: 1m 21s\n",
      "9485:\tlearn: 0.0520512\ttotal: 25m 5s\tremaining: 1m 21s\n",
      "9486:\tlearn: 0.0520512\ttotal: 25m 5s\tremaining: 1m 21s\n",
      "9487:\tlearn: 0.0520512\ttotal: 25m 5s\tremaining: 1m 21s\n",
      "9488:\tlearn: 0.0520512\ttotal: 25m 5s\tremaining: 1m 21s\n",
      "9489:\tlearn: 0.0520512\ttotal: 25m 5s\tremaining: 1m 20s\n",
      "9490:\tlearn: 0.0520512\ttotal: 25m 5s\tremaining: 1m 20s\n",
      "9491:\tlearn: 0.0520512\ttotal: 25m 6s\tremaining: 1m 20s\n",
      "9492:\tlearn: 0.0520512\ttotal: 25m 6s\tremaining: 1m 20s\n",
      "9493:\tlearn: 0.0520512\ttotal: 25m 6s\tremaining: 1m 20s\n",
      "9494:\tlearn: 0.0520512\ttotal: 25m 6s\tremaining: 1m 20s\n",
      "9495:\tlearn: 0.0520512\ttotal: 25m 6s\tremaining: 1m 19s\n",
      "9496:\tlearn: 0.0520512\ttotal: 25m 6s\tremaining: 1m 19s\n",
      "9497:\tlearn: 0.0520512\ttotal: 25m 7s\tremaining: 1m 19s\n",
      "9498:\tlearn: 0.0520512\ttotal: 25m 7s\tremaining: 1m 19s\n",
      "9499:\tlearn: 0.0520512\ttotal: 25m 7s\tremaining: 1m 19s\n",
      "9500:\tlearn: 0.0520512\ttotal: 25m 7s\tremaining: 1m 19s\n",
      "9501:\tlearn: 0.0520512\ttotal: 25m 7s\tremaining: 1m 19s\n",
      "9502:\tlearn: 0.0520512\ttotal: 25m 7s\tremaining: 1m 18s\n",
      "9503:\tlearn: 0.0520512\ttotal: 25m 8s\tremaining: 1m 18s\n",
      "9504:\tlearn: 0.0520512\ttotal: 25m 8s\tremaining: 1m 18s\n",
      "9505:\tlearn: 0.0520512\ttotal: 25m 8s\tremaining: 1m 18s\n",
      "9506:\tlearn: 0.0520512\ttotal: 25m 8s\tremaining: 1m 18s\n",
      "9507:\tlearn: 0.0520512\ttotal: 25m 8s\tremaining: 1m 18s\n",
      "9508:\tlearn: 0.0520512\ttotal: 25m 8s\tremaining: 1m 17s\n",
      "9509:\tlearn: 0.0520512\ttotal: 25m 9s\tremaining: 1m 17s\n",
      "9510:\tlearn: 0.0520512\ttotal: 25m 9s\tremaining: 1m 17s\n",
      "9511:\tlearn: 0.0520512\ttotal: 25m 9s\tremaining: 1m 17s\n",
      "9512:\tlearn: 0.0520512\ttotal: 25m 9s\tremaining: 1m 17s\n",
      "9513:\tlearn: 0.0520512\ttotal: 25m 9s\tremaining: 1m 17s\n",
      "9514:\tlearn: 0.0520512\ttotal: 25m 9s\tremaining: 1m 16s\n",
      "9515:\tlearn: 0.0520512\ttotal: 25m 10s\tremaining: 1m 16s\n",
      "9516:\tlearn: 0.0520512\ttotal: 25m 10s\tremaining: 1m 16s\n",
      "9517:\tlearn: 0.0520512\ttotal: 25m 10s\tremaining: 1m 16s\n",
      "9518:\tlearn: 0.0520512\ttotal: 25m 10s\tremaining: 1m 16s\n",
      "9519:\tlearn: 0.0520512\ttotal: 25m 10s\tremaining: 1m 16s\n",
      "9520:\tlearn: 0.0520512\ttotal: 25m 10s\tremaining: 1m 16s\n",
      "9521:\tlearn: 0.0520512\ttotal: 25m 11s\tremaining: 1m 15s\n",
      "9522:\tlearn: 0.0520512\ttotal: 25m 11s\tremaining: 1m 15s\n",
      "9523:\tlearn: 0.0520512\ttotal: 25m 11s\tremaining: 1m 15s\n",
      "9524:\tlearn: 0.0520512\ttotal: 25m 11s\tremaining: 1m 15s\n",
      "9525:\tlearn: 0.0520512\ttotal: 25m 11s\tremaining: 1m 15s\n",
      "9526:\tlearn: 0.0520512\ttotal: 25m 11s\tremaining: 1m 15s\n",
      "9527:\tlearn: 0.0520512\ttotal: 25m 12s\tremaining: 1m 14s\n",
      "9528:\tlearn: 0.0520512\ttotal: 25m 12s\tremaining: 1m 14s\n",
      "9529:\tlearn: 0.0520512\ttotal: 25m 12s\tremaining: 1m 14s\n",
      "9530:\tlearn: 0.0520512\ttotal: 25m 12s\tremaining: 1m 14s\n",
      "9531:\tlearn: 0.0520512\ttotal: 25m 12s\tremaining: 1m 14s\n",
      "9532:\tlearn: 0.0520512\ttotal: 25m 12s\tremaining: 1m 14s\n",
      "9533:\tlearn: 0.0520512\ttotal: 25m 13s\tremaining: 1m 13s\n",
      "9534:\tlearn: 0.0520512\ttotal: 25m 13s\tremaining: 1m 13s\n",
      "9535:\tlearn: 0.0520512\ttotal: 25m 13s\tremaining: 1m 13s\n",
      "9536:\tlearn: 0.0520512\ttotal: 25m 13s\tremaining: 1m 13s\n",
      "9537:\tlearn: 0.0520512\ttotal: 25m 13s\tremaining: 1m 13s\n",
      "9538:\tlearn: 0.0520512\ttotal: 25m 13s\tremaining: 1m 13s\n",
      "9539:\tlearn: 0.0520512\ttotal: 25m 13s\tremaining: 1m 13s\n",
      "9540:\tlearn: 0.0520512\ttotal: 25m 14s\tremaining: 1m 12s\n",
      "9541:\tlearn: 0.0520512\ttotal: 25m 14s\tremaining: 1m 12s\n",
      "9542:\tlearn: 0.0520512\ttotal: 25m 14s\tremaining: 1m 12s\n",
      "9543:\tlearn: 0.0520512\ttotal: 25m 14s\tremaining: 1m 12s\n",
      "9544:\tlearn: 0.0520512\ttotal: 25m 14s\tremaining: 1m 12s\n",
      "9545:\tlearn: 0.0520512\ttotal: 25m 14s\tremaining: 1m 12s\n",
      "9546:\tlearn: 0.0520512\ttotal: 25m 15s\tremaining: 1m 11s\n",
      "9547:\tlearn: 0.0520512\ttotal: 25m 15s\tremaining: 1m 11s\n",
      "9548:\tlearn: 0.0520512\ttotal: 25m 15s\tremaining: 1m 11s\n",
      "9549:\tlearn: 0.0520512\ttotal: 25m 15s\tremaining: 1m 11s\n",
      "9550:\tlearn: 0.0520512\ttotal: 25m 15s\tremaining: 1m 11s\n",
      "9551:\tlearn: 0.0520512\ttotal: 25m 15s\tremaining: 1m 11s\n",
      "9552:\tlearn: 0.0520512\ttotal: 25m 16s\tremaining: 1m 10s\n",
      "9553:\tlearn: 0.0520512\ttotal: 25m 16s\tremaining: 1m 10s\n",
      "9554:\tlearn: 0.0520512\ttotal: 25m 16s\tremaining: 1m 10s\n",
      "9555:\tlearn: 0.0520512\ttotal: 25m 16s\tremaining: 1m 10s\n",
      "9556:\tlearn: 0.0520512\ttotal: 25m 16s\tremaining: 1m 10s\n",
      "9557:\tlearn: 0.0520512\ttotal: 25m 16s\tremaining: 1m 10s\n",
      "9558:\tlearn: 0.0520512\ttotal: 25m 17s\tremaining: 1m 9s\n",
      "9559:\tlearn: 0.0520512\ttotal: 25m 17s\tremaining: 1m 9s\n",
      "9560:\tlearn: 0.0520512\ttotal: 25m 17s\tremaining: 1m 9s\n",
      "9561:\tlearn: 0.0520512\ttotal: 25m 17s\tremaining: 1m 9s\n",
      "9562:\tlearn: 0.0520512\ttotal: 25m 17s\tremaining: 1m 9s\n",
      "9563:\tlearn: 0.0520512\ttotal: 25m 17s\tremaining: 1m 9s\n",
      "9564:\tlearn: 0.0520512\ttotal: 25m 18s\tremaining: 1m 9s\n",
      "9565:\tlearn: 0.0520512\ttotal: 25m 18s\tremaining: 1m 8s\n",
      "9566:\tlearn: 0.0520512\ttotal: 25m 18s\tremaining: 1m 8s\n",
      "9567:\tlearn: 0.0520512\ttotal: 25m 18s\tremaining: 1m 8s\n",
      "9568:\tlearn: 0.0520512\ttotal: 25m 18s\tremaining: 1m 8s\n",
      "9569:\tlearn: 0.0520512\ttotal: 25m 18s\tremaining: 1m 8s\n",
      "9570:\tlearn: 0.0520512\ttotal: 25m 19s\tremaining: 1m 8s\n",
      "9571:\tlearn: 0.0520512\ttotal: 25m 19s\tremaining: 1m 7s\n",
      "9572:\tlearn: 0.0520512\ttotal: 25m 19s\tremaining: 1m 7s\n",
      "9573:\tlearn: 0.0520512\ttotal: 25m 19s\tremaining: 1m 7s\n",
      "9574:\tlearn: 0.0520512\ttotal: 25m 19s\tremaining: 1m 7s\n",
      "9575:\tlearn: 0.0520512\ttotal: 25m 19s\tremaining: 1m 7s\n",
      "9576:\tlearn: 0.0520512\ttotal: 25m 20s\tremaining: 1m 7s\n",
      "9577:\tlearn: 0.0520512\ttotal: 25m 20s\tremaining: 1m 6s\n",
      "9578:\tlearn: 0.0520512\ttotal: 25m 20s\tremaining: 1m 6s\n",
      "9579:\tlearn: 0.0520512\ttotal: 25m 20s\tremaining: 1m 6s\n",
      "9580:\tlearn: 0.0520512\ttotal: 25m 20s\tremaining: 1m 6s\n",
      "9581:\tlearn: 0.0520512\ttotal: 25m 20s\tremaining: 1m 6s\n",
      "9582:\tlearn: 0.0520512\ttotal: 25m 21s\tremaining: 1m 6s\n",
      "9583:\tlearn: 0.0520512\ttotal: 25m 21s\tremaining: 1m 6s\n",
      "9584:\tlearn: 0.0520512\ttotal: 25m 21s\tremaining: 1m 5s\n",
      "9585:\tlearn: 0.0520512\ttotal: 25m 21s\tremaining: 1m 5s\n",
      "9586:\tlearn: 0.0520512\ttotal: 25m 21s\tremaining: 1m 5s\n",
      "9587:\tlearn: 0.0520512\ttotal: 25m 21s\tremaining: 1m 5s\n",
      "9588:\tlearn: 0.0520512\ttotal: 25m 22s\tremaining: 1m 5s\n",
      "9589:\tlearn: 0.0520512\ttotal: 25m 22s\tremaining: 1m 5s\n",
      "9590:\tlearn: 0.0520512\ttotal: 25m 22s\tremaining: 1m 4s\n",
      "9591:\tlearn: 0.0520512\ttotal: 25m 22s\tremaining: 1m 4s\n",
      "9592:\tlearn: 0.0520512\ttotal: 25m 22s\tremaining: 1m 4s\n",
      "9593:\tlearn: 0.0520512\ttotal: 25m 22s\tremaining: 1m 4s\n",
      "9594:\tlearn: 0.0520512\ttotal: 25m 22s\tremaining: 1m 4s\n",
      "9595:\tlearn: 0.0520512\ttotal: 25m 23s\tremaining: 1m 4s\n",
      "9596:\tlearn: 0.0520512\ttotal: 25m 23s\tremaining: 1m 3s\n",
      "9597:\tlearn: 0.0520512\ttotal: 25m 23s\tremaining: 1m 3s\n",
      "9598:\tlearn: 0.0520512\ttotal: 25m 23s\tremaining: 1m 3s\n",
      "9599:\tlearn: 0.0520512\ttotal: 25m 23s\tremaining: 1m 3s\n",
      "9600:\tlearn: 0.0520512\ttotal: 25m 23s\tremaining: 1m 3s\n",
      "9601:\tlearn: 0.0520512\ttotal: 25m 24s\tremaining: 1m 3s\n",
      "9602:\tlearn: 0.0520512\ttotal: 25m 24s\tremaining: 1m 3s\n",
      "9603:\tlearn: 0.0520512\ttotal: 25m 24s\tremaining: 1m 2s\n",
      "9604:\tlearn: 0.0520512\ttotal: 25m 24s\tremaining: 1m 2s\n",
      "9605:\tlearn: 0.0520512\ttotal: 25m 24s\tremaining: 1m 2s\n",
      "9606:\tlearn: 0.0520512\ttotal: 25m 24s\tremaining: 1m 2s\n",
      "9607:\tlearn: 0.0520512\ttotal: 25m 25s\tremaining: 1m 2s\n",
      "9608:\tlearn: 0.0520512\ttotal: 25m 25s\tremaining: 1m 2s\n",
      "9609:\tlearn: 0.0520512\ttotal: 25m 25s\tremaining: 1m 1s\n",
      "9610:\tlearn: 0.0520512\ttotal: 25m 25s\tremaining: 1m 1s\n",
      "9611:\tlearn: 0.0520512\ttotal: 25m 25s\tremaining: 1m 1s\n",
      "9612:\tlearn: 0.0520512\ttotal: 25m 25s\tremaining: 1m 1s\n",
      "9613:\tlearn: 0.0520512\ttotal: 25m 26s\tremaining: 1m 1s\n",
      "9614:\tlearn: 0.0520512\ttotal: 25m 26s\tremaining: 1m 1s\n",
      "9615:\tlearn: 0.0520512\ttotal: 25m 26s\tremaining: 1m\n",
      "9616:\tlearn: 0.0520512\ttotal: 25m 26s\tremaining: 1m\n",
      "9617:\tlearn: 0.0520512\ttotal: 25m 26s\tremaining: 1m\n",
      "9618:\tlearn: 0.0520512\ttotal: 25m 26s\tremaining: 1m\n",
      "9619:\tlearn: 0.0520512\ttotal: 25m 26s\tremaining: 1m\n",
      "9620:\tlearn: 0.0520512\ttotal: 25m 27s\tremaining: 1m\n",
      "9621:\tlearn: 0.0520512\ttotal: 25m 27s\tremaining: 1m\n",
      "9622:\tlearn: 0.0520512\ttotal: 25m 27s\tremaining: 59.8s\n",
      "9623:\tlearn: 0.0520512\ttotal: 25m 27s\tremaining: 59.7s\n",
      "9624:\tlearn: 0.0520512\ttotal: 25m 27s\tremaining: 59.5s\n",
      "9625:\tlearn: 0.0520512\ttotal: 25m 27s\tremaining: 59.4s\n",
      "9626:\tlearn: 0.0520512\ttotal: 25m 28s\tremaining: 59.2s\n",
      "9627:\tlearn: 0.0520512\ttotal: 25m 28s\tremaining: 59s\n",
      "9628:\tlearn: 0.0520512\ttotal: 25m 28s\tremaining: 58.9s\n",
      "9629:\tlearn: 0.0520512\ttotal: 25m 28s\tremaining: 58.7s\n",
      "9630:\tlearn: 0.0520512\ttotal: 25m 28s\tremaining: 58.6s\n",
      "9631:\tlearn: 0.0520512\ttotal: 25m 28s\tremaining: 58.4s\n",
      "9632:\tlearn: 0.0520512\ttotal: 25m 29s\tremaining: 58.3s\n",
      "9633:\tlearn: 0.0520512\ttotal: 25m 29s\tremaining: 58.1s\n",
      "9634:\tlearn: 0.0520512\ttotal: 25m 29s\tremaining: 57.9s\n",
      "9635:\tlearn: 0.0520512\ttotal: 25m 29s\tremaining: 57.8s\n",
      "9636:\tlearn: 0.0520512\ttotal: 25m 29s\tremaining: 57.6s\n",
      "9637:\tlearn: 0.0520512\ttotal: 25m 29s\tremaining: 57.5s\n",
      "9638:\tlearn: 0.0520512\ttotal: 25m 30s\tremaining: 57.3s\n",
      "9639:\tlearn: 0.0520512\ttotal: 25m 30s\tremaining: 57.1s\n",
      "9640:\tlearn: 0.0520512\ttotal: 25m 30s\tremaining: 57s\n",
      "9641:\tlearn: 0.0520512\ttotal: 25m 30s\tremaining: 56.8s\n",
      "9642:\tlearn: 0.0520512\ttotal: 25m 30s\tremaining: 56.7s\n",
      "9643:\tlearn: 0.0520512\ttotal: 25m 30s\tremaining: 56.5s\n",
      "9644:\tlearn: 0.0520512\ttotal: 25m 30s\tremaining: 56.3s\n",
      "9645:\tlearn: 0.0520512\ttotal: 25m 31s\tremaining: 56.2s\n",
      "9646:\tlearn: 0.0520512\ttotal: 25m 31s\tremaining: 56s\n",
      "9647:\tlearn: 0.0520512\ttotal: 25m 31s\tremaining: 55.9s\n",
      "9648:\tlearn: 0.0520512\ttotal: 25m 31s\tremaining: 55.7s\n",
      "9649:\tlearn: 0.0520512\ttotal: 25m 31s\tremaining: 55.6s\n",
      "9650:\tlearn: 0.0520512\ttotal: 25m 31s\tremaining: 55.4s\n",
      "9651:\tlearn: 0.0520512\ttotal: 25m 32s\tremaining: 55.2s\n",
      "9652:\tlearn: 0.0520512\ttotal: 25m 32s\tremaining: 55.1s\n",
      "9653:\tlearn: 0.0520512\ttotal: 25m 32s\tremaining: 54.9s\n",
      "9654:\tlearn: 0.0520512\ttotal: 25m 32s\tremaining: 54.8s\n",
      "9655:\tlearn: 0.0520512\ttotal: 25m 32s\tremaining: 54.6s\n",
      "9656:\tlearn: 0.0520512\ttotal: 25m 32s\tremaining: 54.4s\n",
      "9657:\tlearn: 0.0520512\ttotal: 25m 33s\tremaining: 54.3s\n",
      "9658:\tlearn: 0.0520512\ttotal: 25m 33s\tremaining: 54.1s\n",
      "9659:\tlearn: 0.0520512\ttotal: 25m 33s\tremaining: 54s\n",
      "9660:\tlearn: 0.0520512\ttotal: 25m 33s\tremaining: 53.8s\n",
      "9661:\tlearn: 0.0520512\ttotal: 25m 33s\tremaining: 53.7s\n",
      "9662:\tlearn: 0.0520512\ttotal: 25m 33s\tremaining: 53.5s\n",
      "9663:\tlearn: 0.0520512\ttotal: 25m 34s\tremaining: 53.3s\n",
      "9664:\tlearn: 0.0520512\ttotal: 25m 34s\tremaining: 53.2s\n",
      "9665:\tlearn: 0.0520512\ttotal: 25m 34s\tremaining: 53s\n",
      "9666:\tlearn: 0.0520512\ttotal: 25m 34s\tremaining: 52.9s\n",
      "9667:\tlearn: 0.0520512\ttotal: 25m 34s\tremaining: 52.7s\n",
      "9668:\tlearn: 0.0520512\ttotal: 25m 34s\tremaining: 52.5s\n",
      "9669:\tlearn: 0.0520512\ttotal: 25m 35s\tremaining: 52.4s\n",
      "9670:\tlearn: 0.0520512\ttotal: 25m 35s\tremaining: 52.2s\n",
      "9671:\tlearn: 0.0520512\ttotal: 25m 35s\tremaining: 52.1s\n",
      "9672:\tlearn: 0.0520512\ttotal: 25m 35s\tremaining: 51.9s\n",
      "9673:\tlearn: 0.0520512\ttotal: 25m 35s\tremaining: 51.8s\n",
      "9674:\tlearn: 0.0520512\ttotal: 25m 35s\tremaining: 51.6s\n",
      "9675:\tlearn: 0.0520512\ttotal: 25m 36s\tremaining: 51.4s\n",
      "9676:\tlearn: 0.0520512\ttotal: 25m 36s\tremaining: 51.3s\n",
      "9677:\tlearn: 0.0520512\ttotal: 25m 36s\tremaining: 51.1s\n",
      "9678:\tlearn: 0.0520512\ttotal: 25m 36s\tremaining: 51s\n",
      "9679:\tlearn: 0.0520512\ttotal: 25m 36s\tremaining: 50.8s\n",
      "9680:\tlearn: 0.0520512\ttotal: 25m 36s\tremaining: 50.6s\n",
      "9681:\tlearn: 0.0520512\ttotal: 25m 37s\tremaining: 50.5s\n",
      "9682:\tlearn: 0.0520512\ttotal: 25m 37s\tremaining: 50.3s\n",
      "9683:\tlearn: 0.0520512\ttotal: 25m 37s\tremaining: 50.2s\n",
      "9684:\tlearn: 0.0520512\ttotal: 25m 37s\tremaining: 50s\n",
      "9685:\tlearn: 0.0520512\ttotal: 25m 37s\tremaining: 49.8s\n",
      "9686:\tlearn: 0.0520512\ttotal: 25m 37s\tremaining: 49.7s\n",
      "9687:\tlearn: 0.0520512\ttotal: 25m 38s\tremaining: 49.5s\n",
      "9688:\tlearn: 0.0520512\ttotal: 25m 38s\tremaining: 49.4s\n",
      "9689:\tlearn: 0.0520512\ttotal: 25m 38s\tremaining: 49.2s\n",
      "9690:\tlearn: 0.0520512\ttotal: 25m 38s\tremaining: 49.1s\n",
      "9691:\tlearn: 0.0520512\ttotal: 25m 38s\tremaining: 48.9s\n",
      "9692:\tlearn: 0.0520512\ttotal: 25m 38s\tremaining: 48.7s\n",
      "9693:\tlearn: 0.0520512\ttotal: 25m 39s\tremaining: 48.6s\n",
      "9694:\tlearn: 0.0520512\ttotal: 25m 39s\tremaining: 48.4s\n",
      "9695:\tlearn: 0.0520512\ttotal: 25m 39s\tremaining: 48.3s\n",
      "9696:\tlearn: 0.0520512\ttotal: 25m 39s\tremaining: 48.1s\n",
      "9697:\tlearn: 0.0520512\ttotal: 25m 39s\tremaining: 47.9s\n",
      "9698:\tlearn: 0.0520512\ttotal: 25m 39s\tremaining: 47.8s\n",
      "9699:\tlearn: 0.0520512\ttotal: 25m 40s\tremaining: 47.6s\n",
      "9700:\tlearn: 0.0520512\ttotal: 25m 40s\tremaining: 47.5s\n",
      "9701:\tlearn: 0.0520512\ttotal: 25m 40s\tremaining: 47.3s\n",
      "9702:\tlearn: 0.0520512\ttotal: 25m 40s\tremaining: 47.2s\n",
      "9703:\tlearn: 0.0520512\ttotal: 25m 40s\tremaining: 47s\n",
      "9704:\tlearn: 0.0520512\ttotal: 25m 40s\tremaining: 46.8s\n",
      "9705:\tlearn: 0.0520512\ttotal: 25m 41s\tremaining: 46.7s\n",
      "9706:\tlearn: 0.0520512\ttotal: 25m 41s\tremaining: 46.5s\n",
      "9707:\tlearn: 0.0520512\ttotal: 25m 41s\tremaining: 46.4s\n",
      "9708:\tlearn: 0.0520512\ttotal: 25m 41s\tremaining: 46.2s\n",
      "9709:\tlearn: 0.0520512\ttotal: 25m 41s\tremaining: 46s\n",
      "9710:\tlearn: 0.0520512\ttotal: 25m 41s\tremaining: 45.9s\n",
      "9711:\tlearn: 0.0520512\ttotal: 25m 42s\tremaining: 45.7s\n",
      "9712:\tlearn: 0.0520512\ttotal: 25m 42s\tremaining: 45.6s\n",
      "9713:\tlearn: 0.0520512\ttotal: 25m 42s\tremaining: 45.4s\n",
      "9714:\tlearn: 0.0520512\ttotal: 25m 42s\tremaining: 45.3s\n",
      "9715:\tlearn: 0.0520512\ttotal: 25m 42s\tremaining: 45.1s\n",
      "9716:\tlearn: 0.0520512\ttotal: 25m 42s\tremaining: 44.9s\n",
      "9717:\tlearn: 0.0520512\ttotal: 25m 43s\tremaining: 44.8s\n",
      "9718:\tlearn: 0.0520512\ttotal: 25m 43s\tremaining: 44.6s\n",
      "9719:\tlearn: 0.0520512\ttotal: 25m 43s\tremaining: 44.5s\n",
      "9720:\tlearn: 0.0520512\ttotal: 25m 43s\tremaining: 44.3s\n",
      "9721:\tlearn: 0.0520512\ttotal: 25m 43s\tremaining: 44.1s\n",
      "9722:\tlearn: 0.0520512\ttotal: 25m 43s\tremaining: 44s\n",
      "9723:\tlearn: 0.0520512\ttotal: 25m 44s\tremaining: 43.8s\n",
      "9724:\tlearn: 0.0520512\ttotal: 25m 44s\tremaining: 43.7s\n",
      "9725:\tlearn: 0.0520512\ttotal: 25m 44s\tremaining: 43.5s\n",
      "9726:\tlearn: 0.0520512\ttotal: 25m 44s\tremaining: 43.3s\n",
      "9727:\tlearn: 0.0520512\ttotal: 25m 44s\tremaining: 43.2s\n",
      "9728:\tlearn: 0.0520512\ttotal: 25m 44s\tremaining: 43s\n",
      "9729:\tlearn: 0.0520512\ttotal: 25m 44s\tremaining: 42.9s\n",
      "9730:\tlearn: 0.0520512\ttotal: 25m 45s\tremaining: 42.7s\n",
      "9731:\tlearn: 0.0520512\ttotal: 25m 45s\tremaining: 42.6s\n",
      "9732:\tlearn: 0.0520512\ttotal: 25m 45s\tremaining: 42.4s\n",
      "9733:\tlearn: 0.0520512\ttotal: 25m 45s\tremaining: 42.2s\n",
      "9734:\tlearn: 0.0520512\ttotal: 25m 45s\tremaining: 42.1s\n",
      "9735:\tlearn: 0.0520512\ttotal: 25m 45s\tremaining: 41.9s\n",
      "9736:\tlearn: 0.0520512\ttotal: 25m 46s\tremaining: 41.8s\n",
      "9737:\tlearn: 0.0520512\ttotal: 25m 46s\tremaining: 41.6s\n",
      "9738:\tlearn: 0.0520512\ttotal: 25m 46s\tremaining: 41.4s\n",
      "9739:\tlearn: 0.0520512\ttotal: 25m 46s\tremaining: 41.3s\n",
      "9740:\tlearn: 0.0520512\ttotal: 25m 46s\tremaining: 41.1s\n",
      "9741:\tlearn: 0.0520512\ttotal: 25m 46s\tremaining: 41s\n",
      "9742:\tlearn: 0.0520512\ttotal: 25m 47s\tremaining: 40.8s\n",
      "9743:\tlearn: 0.0520512\ttotal: 25m 47s\tremaining: 40.6s\n",
      "9744:\tlearn: 0.0520512\ttotal: 25m 47s\tremaining: 40.5s\n",
      "9745:\tlearn: 0.0520512\ttotal: 25m 47s\tremaining: 40.3s\n",
      "9746:\tlearn: 0.0520512\ttotal: 25m 47s\tremaining: 40.2s\n",
      "9747:\tlearn: 0.0520512\ttotal: 25m 47s\tremaining: 40s\n",
      "9748:\tlearn: 0.0520512\ttotal: 25m 48s\tremaining: 39.9s\n",
      "9749:\tlearn: 0.0520512\ttotal: 25m 48s\tremaining: 39.7s\n",
      "9750:\tlearn: 0.0520512\ttotal: 25m 48s\tremaining: 39.5s\n",
      "9751:\tlearn: 0.0520512\ttotal: 25m 48s\tremaining: 39.4s\n",
      "9752:\tlearn: 0.0520512\ttotal: 25m 48s\tremaining: 39.2s\n",
      "9753:\tlearn: 0.0520512\ttotal: 25m 48s\tremaining: 39.1s\n",
      "9754:\tlearn: 0.0520512\ttotal: 25m 49s\tremaining: 38.9s\n",
      "9755:\tlearn: 0.0520512\ttotal: 25m 49s\tremaining: 38.7s\n",
      "9756:\tlearn: 0.0520512\ttotal: 25m 49s\tremaining: 38.6s\n",
      "9757:\tlearn: 0.0520512\ttotal: 25m 49s\tremaining: 38.4s\n",
      "9758:\tlearn: 0.0520512\ttotal: 25m 49s\tremaining: 38.3s\n",
      "9759:\tlearn: 0.0520512\ttotal: 25m 49s\tremaining: 38.1s\n",
      "9760:\tlearn: 0.0520512\ttotal: 25m 50s\tremaining: 38s\n",
      "9761:\tlearn: 0.0520512\ttotal: 25m 50s\tremaining: 37.8s\n",
      "9762:\tlearn: 0.0520512\ttotal: 25m 50s\tremaining: 37.6s\n",
      "9763:\tlearn: 0.0520512\ttotal: 25m 50s\tremaining: 37.5s\n",
      "9764:\tlearn: 0.0520512\ttotal: 25m 50s\tremaining: 37.3s\n",
      "9765:\tlearn: 0.0520512\ttotal: 25m 50s\tremaining: 37.2s\n",
      "9766:\tlearn: 0.0520512\ttotal: 25m 51s\tremaining: 37s\n",
      "9767:\tlearn: 0.0520512\ttotal: 25m 51s\tremaining: 36.8s\n",
      "9768:\tlearn: 0.0520512\ttotal: 25m 51s\tremaining: 36.7s\n",
      "9769:\tlearn: 0.0520512\ttotal: 25m 51s\tremaining: 36.5s\n",
      "9770:\tlearn: 0.0520512\ttotal: 25m 51s\tremaining: 36.4s\n",
      "9771:\tlearn: 0.0520512\ttotal: 25m 51s\tremaining: 36.2s\n",
      "9772:\tlearn: 0.0520512\ttotal: 25m 52s\tremaining: 36s\n",
      "9773:\tlearn: 0.0520512\ttotal: 25m 52s\tremaining: 35.9s\n",
      "9774:\tlearn: 0.0520512\ttotal: 25m 52s\tremaining: 35.7s\n",
      "9775:\tlearn: 0.0520512\ttotal: 25m 52s\tremaining: 35.6s\n",
      "9776:\tlearn: 0.0520512\ttotal: 25m 52s\tremaining: 35.4s\n",
      "9777:\tlearn: 0.0520512\ttotal: 25m 52s\tremaining: 35.3s\n",
      "9778:\tlearn: 0.0520512\ttotal: 25m 53s\tremaining: 35.1s\n",
      "9779:\tlearn: 0.0520512\ttotal: 25m 53s\tremaining: 34.9s\n",
      "9780:\tlearn: 0.0520512\ttotal: 25m 53s\tremaining: 34.8s\n",
      "9781:\tlearn: 0.0520512\ttotal: 25m 53s\tremaining: 34.6s\n",
      "9782:\tlearn: 0.0520512\ttotal: 25m 53s\tremaining: 34.5s\n",
      "9783:\tlearn: 0.0520512\ttotal: 25m 53s\tremaining: 34.3s\n",
      "9784:\tlearn: 0.0520512\ttotal: 25m 53s\tremaining: 34.1s\n",
      "9785:\tlearn: 0.0520512\ttotal: 25m 54s\tremaining: 34s\n",
      "9786:\tlearn: 0.0520512\ttotal: 25m 54s\tremaining: 33.8s\n",
      "9787:\tlearn: 0.0520512\ttotal: 25m 54s\tremaining: 33.7s\n",
      "9788:\tlearn: 0.0520512\ttotal: 25m 54s\tremaining: 33.5s\n",
      "9789:\tlearn: 0.0520512\ttotal: 25m 54s\tremaining: 33.4s\n",
      "9790:\tlearn: 0.0520512\ttotal: 25m 54s\tremaining: 33.2s\n",
      "9791:\tlearn: 0.0520512\ttotal: 25m 55s\tremaining: 33s\n",
      "9792:\tlearn: 0.0520512\ttotal: 25m 55s\tremaining: 32.9s\n",
      "9793:\tlearn: 0.0520512\ttotal: 25m 55s\tremaining: 32.7s\n",
      "9794:\tlearn: 0.0520512\ttotal: 25m 55s\tremaining: 32.6s\n",
      "9795:\tlearn: 0.0520512\ttotal: 25m 55s\tremaining: 32.4s\n",
      "9796:\tlearn: 0.0520512\ttotal: 25m 55s\tremaining: 32.2s\n",
      "9797:\tlearn: 0.0520512\ttotal: 25m 56s\tremaining: 32.1s\n",
      "9798:\tlearn: 0.0520512\ttotal: 25m 56s\tremaining: 31.9s\n",
      "9799:\tlearn: 0.0520512\ttotal: 25m 56s\tremaining: 31.8s\n",
      "9800:\tlearn: 0.0520512\ttotal: 25m 56s\tremaining: 31.6s\n",
      "9801:\tlearn: 0.0520512\ttotal: 25m 56s\tremaining: 31.4s\n",
      "9802:\tlearn: 0.0520512\ttotal: 25m 56s\tremaining: 31.3s\n",
      "9803:\tlearn: 0.0520512\ttotal: 25m 57s\tremaining: 31.1s\n",
      "9804:\tlearn: 0.0520512\ttotal: 25m 57s\tremaining: 31s\n",
      "9805:\tlearn: 0.0520512\ttotal: 25m 57s\tremaining: 30.8s\n",
      "9806:\tlearn: 0.0520512\ttotal: 25m 57s\tremaining: 30.7s\n",
      "9807:\tlearn: 0.0520512\ttotal: 25m 57s\tremaining: 30.5s\n",
      "9808:\tlearn: 0.0520512\ttotal: 25m 57s\tremaining: 30.3s\n",
      "9809:\tlearn: 0.0520512\ttotal: 25m 58s\tremaining: 30.2s\n",
      "9810:\tlearn: 0.0520512\ttotal: 25m 58s\tremaining: 30s\n",
      "9811:\tlearn: 0.0520512\ttotal: 25m 58s\tremaining: 29.9s\n",
      "9812:\tlearn: 0.0520512\ttotal: 25m 58s\tremaining: 29.7s\n",
      "9813:\tlearn: 0.0520512\ttotal: 25m 58s\tremaining: 29.5s\n",
      "9814:\tlearn: 0.0520512\ttotal: 25m 58s\tremaining: 29.4s\n",
      "9815:\tlearn: 0.0520512\ttotal: 25m 59s\tremaining: 29.2s\n",
      "9816:\tlearn: 0.0520512\ttotal: 25m 59s\tremaining: 29.1s\n",
      "9817:\tlearn: 0.0520512\ttotal: 25m 59s\tremaining: 28.9s\n",
      "9818:\tlearn: 0.0520512\ttotal: 25m 59s\tremaining: 28.7s\n",
      "9819:\tlearn: 0.0520512\ttotal: 25m 59s\tremaining: 28.6s\n",
      "9820:\tlearn: 0.0520512\ttotal: 25m 59s\tremaining: 28.4s\n",
      "9821:\tlearn: 0.0520512\ttotal: 26m\tremaining: 28.3s\n",
      "9822:\tlearn: 0.0520512\ttotal: 26m\tremaining: 28.1s\n",
      "9823:\tlearn: 0.0520512\ttotal: 26m\tremaining: 28s\n",
      "9824:\tlearn: 0.0520512\ttotal: 26m\tremaining: 27.8s\n",
      "9825:\tlearn: 0.0520512\ttotal: 26m\tremaining: 27.6s\n",
      "9826:\tlearn: 0.0520512\ttotal: 26m\tremaining: 27.5s\n",
      "9827:\tlearn: 0.0520512\ttotal: 26m 1s\tremaining: 27.3s\n",
      "9828:\tlearn: 0.0520512\ttotal: 26m 1s\tremaining: 27.2s\n",
      "9829:\tlearn: 0.0520512\ttotal: 26m 1s\tremaining: 27s\n",
      "9830:\tlearn: 0.0520512\ttotal: 26m 1s\tremaining: 26.8s\n",
      "9831:\tlearn: 0.0520512\ttotal: 26m 1s\tremaining: 26.7s\n",
      "9832:\tlearn: 0.0520512\ttotal: 26m 1s\tremaining: 26.5s\n",
      "9833:\tlearn: 0.0520512\ttotal: 26m 2s\tremaining: 26.4s\n",
      "9834:\tlearn: 0.0520512\ttotal: 26m 2s\tremaining: 26.2s\n",
      "9835:\tlearn: 0.0520512\ttotal: 26m 2s\tremaining: 26.1s\n",
      "9836:\tlearn: 0.0520512\ttotal: 26m 2s\tremaining: 25.9s\n",
      "9837:\tlearn: 0.0520512\ttotal: 26m 2s\tremaining: 25.7s\n",
      "9838:\tlearn: 0.0520512\ttotal: 26m 2s\tremaining: 25.6s\n",
      "9839:\tlearn: 0.0520512\ttotal: 26m 3s\tremaining: 25.4s\n",
      "9840:\tlearn: 0.0520512\ttotal: 26m 3s\tremaining: 25.3s\n",
      "9841:\tlearn: 0.0520512\ttotal: 26m 3s\tremaining: 25.1s\n",
      "9842:\tlearn: 0.0520512\ttotal: 26m 3s\tremaining: 24.9s\n",
      "9843:\tlearn: 0.0520512\ttotal: 26m 3s\tremaining: 24.8s\n",
      "9844:\tlearn: 0.0520512\ttotal: 26m 3s\tremaining: 24.6s\n",
      "9845:\tlearn: 0.0520512\ttotal: 26m 4s\tremaining: 24.5s\n",
      "9846:\tlearn: 0.0520512\ttotal: 26m 4s\tremaining: 24.3s\n",
      "9847:\tlearn: 0.0520512\ttotal: 26m 4s\tremaining: 24.1s\n",
      "9848:\tlearn: 0.0520512\ttotal: 26m 4s\tremaining: 24s\n",
      "9849:\tlearn: 0.0520512\ttotal: 26m 4s\tremaining: 23.8s\n",
      "9850:\tlearn: 0.0520512\ttotal: 26m 4s\tremaining: 23.7s\n",
      "9851:\tlearn: 0.0520512\ttotal: 26m 5s\tremaining: 23.5s\n",
      "9852:\tlearn: 0.0520512\ttotal: 26m 5s\tremaining: 23.4s\n",
      "9853:\tlearn: 0.0520512\ttotal: 26m 5s\tremaining: 23.2s\n",
      "9854:\tlearn: 0.0520512\ttotal: 26m 5s\tremaining: 23s\n",
      "9855:\tlearn: 0.0520512\ttotal: 26m 5s\tremaining: 22.9s\n",
      "9856:\tlearn: 0.0520512\ttotal: 26m 5s\tremaining: 22.7s\n",
      "9857:\tlearn: 0.0520512\ttotal: 26m 5s\tremaining: 22.6s\n",
      "9858:\tlearn: 0.0520512\ttotal: 26m 6s\tremaining: 22.4s\n",
      "9859:\tlearn: 0.0520512\ttotal: 26m 6s\tremaining: 22.2s\n",
      "9860:\tlearn: 0.0520512\ttotal: 26m 6s\tremaining: 22.1s\n",
      "9861:\tlearn: 0.0520512\ttotal: 26m 6s\tremaining: 21.9s\n",
      "9862:\tlearn: 0.0520512\ttotal: 26m 6s\tremaining: 21.8s\n",
      "9863:\tlearn: 0.0520512\ttotal: 26m 6s\tremaining: 21.6s\n",
      "9864:\tlearn: 0.0520512\ttotal: 26m 7s\tremaining: 21.4s\n",
      "9865:\tlearn: 0.0520512\ttotal: 26m 7s\tremaining: 21.3s\n",
      "9866:\tlearn: 0.0520512\ttotal: 26m 7s\tremaining: 21.1s\n",
      "9867:\tlearn: 0.0520512\ttotal: 26m 7s\tremaining: 21s\n",
      "9868:\tlearn: 0.0520512\ttotal: 26m 7s\tremaining: 20.8s\n",
      "9869:\tlearn: 0.0520512\ttotal: 26m 7s\tremaining: 20.7s\n",
      "9870:\tlearn: 0.0520512\ttotal: 26m 8s\tremaining: 20.5s\n",
      "9871:\tlearn: 0.0520512\ttotal: 26m 8s\tremaining: 20.3s\n",
      "9872:\tlearn: 0.0520512\ttotal: 26m 8s\tremaining: 20.2s\n",
      "9873:\tlearn: 0.0520512\ttotal: 26m 8s\tremaining: 20s\n",
      "9874:\tlearn: 0.0520512\ttotal: 26m 8s\tremaining: 19.9s\n",
      "9875:\tlearn: 0.0520512\ttotal: 26m 8s\tremaining: 19.7s\n",
      "9876:\tlearn: 0.0520512\ttotal: 26m 9s\tremaining: 19.5s\n",
      "9877:\tlearn: 0.0520512\ttotal: 26m 9s\tremaining: 19.4s\n",
      "9878:\tlearn: 0.0520512\ttotal: 26m 9s\tremaining: 19.2s\n",
      "9879:\tlearn: 0.0520512\ttotal: 26m 9s\tremaining: 19.1s\n",
      "9880:\tlearn: 0.0520512\ttotal: 26m 9s\tremaining: 18.9s\n",
      "9881:\tlearn: 0.0520512\ttotal: 26m 9s\tremaining: 18.7s\n",
      "9882:\tlearn: 0.0520512\ttotal: 26m 10s\tremaining: 18.6s\n",
      "9883:\tlearn: 0.0520512\ttotal: 26m 10s\tremaining: 18.4s\n",
      "9884:\tlearn: 0.0520512\ttotal: 26m 10s\tremaining: 18.3s\n",
      "9885:\tlearn: 0.0520512\ttotal: 26m 10s\tremaining: 18.1s\n",
      "9886:\tlearn: 0.0520512\ttotal: 26m 10s\tremaining: 18s\n",
      "9887:\tlearn: 0.0520512\ttotal: 26m 10s\tremaining: 17.8s\n",
      "9888:\tlearn: 0.0520512\ttotal: 26m 11s\tremaining: 17.6s\n",
      "9889:\tlearn: 0.0520512\ttotal: 26m 11s\tremaining: 17.5s\n",
      "9890:\tlearn: 0.0520512\ttotal: 26m 11s\tremaining: 17.3s\n",
      "9891:\tlearn: 0.0520512\ttotal: 26m 11s\tremaining: 17.2s\n",
      "9892:\tlearn: 0.0520512\ttotal: 26m 11s\tremaining: 17s\n",
      "9893:\tlearn: 0.0520512\ttotal: 26m 11s\tremaining: 16.8s\n",
      "9894:\tlearn: 0.0520512\ttotal: 26m 12s\tremaining: 16.7s\n",
      "9895:\tlearn: 0.0520512\ttotal: 26m 12s\tremaining: 16.5s\n",
      "9896:\tlearn: 0.0520512\ttotal: 26m 12s\tremaining: 16.4s\n",
      "9897:\tlearn: 0.0520512\ttotal: 26m 12s\tremaining: 16.2s\n",
      "9898:\tlearn: 0.0520512\ttotal: 26m 12s\tremaining: 16s\n",
      "9899:\tlearn: 0.0520512\ttotal: 26m 12s\tremaining: 15.9s\n",
      "9900:\tlearn: 0.0520512\ttotal: 26m 13s\tremaining: 15.7s\n",
      "9901:\tlearn: 0.0520512\ttotal: 26m 13s\tremaining: 15.6s\n",
      "9902:\tlearn: 0.0520512\ttotal: 26m 13s\tremaining: 15.4s\n",
      "9903:\tlearn: 0.0520512\ttotal: 26m 13s\tremaining: 15.3s\n",
      "9904:\tlearn: 0.0520512\ttotal: 26m 13s\tremaining: 15.1s\n",
      "9905:\tlearn: 0.0520512\ttotal: 26m 13s\tremaining: 14.9s\n",
      "9906:\tlearn: 0.0520512\ttotal: 26m 14s\tremaining: 14.8s\n",
      "9907:\tlearn: 0.0520512\ttotal: 26m 14s\tremaining: 14.6s\n",
      "9908:\tlearn: 0.0520512\ttotal: 26m 14s\tremaining: 14.5s\n",
      "9909:\tlearn: 0.0520512\ttotal: 26m 14s\tremaining: 14.3s\n",
      "9910:\tlearn: 0.0520512\ttotal: 26m 14s\tremaining: 14.1s\n",
      "9911:\tlearn: 0.0520512\ttotal: 26m 14s\tremaining: 14s\n",
      "9912:\tlearn: 0.0520512\ttotal: 26m 15s\tremaining: 13.8s\n",
      "9913:\tlearn: 0.0520512\ttotal: 26m 15s\tremaining: 13.7s\n",
      "9914:\tlearn: 0.0520512\ttotal: 26m 15s\tremaining: 13.5s\n",
      "9915:\tlearn: 0.0520512\ttotal: 26m 15s\tremaining: 13.3s\n",
      "9916:\tlearn: 0.0520512\ttotal: 26m 15s\tremaining: 13.2s\n",
      "9917:\tlearn: 0.0520512\ttotal: 26m 15s\tremaining: 13s\n",
      "9918:\tlearn: 0.0520512\ttotal: 26m 16s\tremaining: 12.9s\n",
      "9919:\tlearn: 0.0520512\ttotal: 26m 16s\tremaining: 12.7s\n",
      "9920:\tlearn: 0.0520512\ttotal: 26m 16s\tremaining: 12.6s\n",
      "9921:\tlearn: 0.0520512\ttotal: 26m 16s\tremaining: 12.4s\n",
      "9922:\tlearn: 0.0520512\ttotal: 26m 16s\tremaining: 12.2s\n",
      "9923:\tlearn: 0.0520512\ttotal: 26m 16s\tremaining: 12.1s\n",
      "9924:\tlearn: 0.0520512\ttotal: 26m 17s\tremaining: 11.9s\n",
      "9925:\tlearn: 0.0520512\ttotal: 26m 17s\tremaining: 11.8s\n",
      "9926:\tlearn: 0.0520512\ttotal: 26m 17s\tremaining: 11.6s\n",
      "9927:\tlearn: 0.0520512\ttotal: 26m 17s\tremaining: 11.4s\n",
      "9928:\tlearn: 0.0520512\ttotal: 26m 17s\tremaining: 11.3s\n",
      "9929:\tlearn: 0.0520512\ttotal: 26m 17s\tremaining: 11.1s\n",
      "9930:\tlearn: 0.0520512\ttotal: 26m 18s\tremaining: 11s\n",
      "9931:\tlearn: 0.0520512\ttotal: 26m 18s\tremaining: 10.8s\n",
      "9932:\tlearn: 0.0520512\ttotal: 26m 18s\tremaining: 10.6s\n",
      "9933:\tlearn: 0.0520512\ttotal: 26m 18s\tremaining: 10.5s\n",
      "9934:\tlearn: 0.0520512\ttotal: 26m 18s\tremaining: 10.3s\n",
      "9935:\tlearn: 0.0520512\ttotal: 26m 18s\tremaining: 10.2s\n",
      "9936:\tlearn: 0.0520512\ttotal: 26m 19s\tremaining: 10s\n",
      "9937:\tlearn: 0.0520512\ttotal: 26m 19s\tremaining: 9.85s\n",
      "9938:\tlearn: 0.0520512\ttotal: 26m 19s\tremaining: 9.69s\n",
      "9939:\tlearn: 0.0520512\ttotal: 26m 19s\tremaining: 9.53s\n",
      "9940:\tlearn: 0.0520512\ttotal: 26m 19s\tremaining: 9.38s\n",
      "9941:\tlearn: 0.0520512\ttotal: 26m 19s\tremaining: 9.22s\n",
      "9942:\tlearn: 0.0520512\ttotal: 26m 20s\tremaining: 9.06s\n",
      "9943:\tlearn: 0.0520512\ttotal: 26m 20s\tremaining: 8.9s\n",
      "9944:\tlearn: 0.0520512\ttotal: 26m 20s\tremaining: 8.74s\n",
      "9945:\tlearn: 0.0520512\ttotal: 26m 20s\tremaining: 8.58s\n",
      "9946:\tlearn: 0.0520512\ttotal: 26m 20s\tremaining: 8.42s\n",
      "9947:\tlearn: 0.0520512\ttotal: 26m 20s\tremaining: 8.26s\n",
      "9948:\tlearn: 0.0520512\ttotal: 26m 21s\tremaining: 8.1s\n",
      "9949:\tlearn: 0.0520512\ttotal: 26m 21s\tremaining: 7.95s\n",
      "9950:\tlearn: 0.0520512\ttotal: 26m 21s\tremaining: 7.79s\n",
      "9951:\tlearn: 0.0520512\ttotal: 26m 21s\tremaining: 7.63s\n",
      "9952:\tlearn: 0.0520512\ttotal: 26m 21s\tremaining: 7.47s\n",
      "9953:\tlearn: 0.0520512\ttotal: 26m 21s\tremaining: 7.31s\n",
      "9954:\tlearn: 0.0520512\ttotal: 26m 21s\tremaining: 7.15s\n",
      "9955:\tlearn: 0.0520512\ttotal: 26m 22s\tremaining: 6.99s\n",
      "9956:\tlearn: 0.0520512\ttotal: 26m 22s\tremaining: 6.83s\n",
      "9957:\tlearn: 0.0520512\ttotal: 26m 22s\tremaining: 6.67s\n",
      "9958:\tlearn: 0.0520512\ttotal: 26m 22s\tremaining: 6.51s\n",
      "9959:\tlearn: 0.0520512\ttotal: 26m 22s\tremaining: 6.36s\n",
      "9960:\tlearn: 0.0520512\ttotal: 26m 23s\tremaining: 6.2s\n",
      "9961:\tlearn: 0.0520512\ttotal: 26m 23s\tremaining: 6.04s\n",
      "9962:\tlearn: 0.0520512\ttotal: 26m 23s\tremaining: 5.88s\n",
      "9963:\tlearn: 0.0520512\ttotal: 26m 23s\tremaining: 5.72s\n",
      "9964:\tlearn: 0.0520512\ttotal: 26m 23s\tremaining: 5.56s\n",
      "9965:\tlearn: 0.0520512\ttotal: 26m 23s\tremaining: 5.4s\n",
      "9966:\tlearn: 0.0520512\ttotal: 26m 23s\tremaining: 5.24s\n",
      "9967:\tlearn: 0.0520512\ttotal: 26m 24s\tremaining: 5.08s\n",
      "9968:\tlearn: 0.0520512\ttotal: 26m 24s\tremaining: 4.93s\n",
      "9969:\tlearn: 0.0520512\ttotal: 26m 24s\tremaining: 4.77s\n",
      "9970:\tlearn: 0.0520512\ttotal: 26m 24s\tremaining: 4.61s\n",
      "9971:\tlearn: 0.0520512\ttotal: 26m 24s\tremaining: 4.45s\n",
      "9972:\tlearn: 0.0520512\ttotal: 26m 25s\tremaining: 4.29s\n",
      "9973:\tlearn: 0.0520512\ttotal: 26m 25s\tremaining: 4.13s\n",
      "9974:\tlearn: 0.0520512\ttotal: 26m 25s\tremaining: 3.97s\n",
      "9975:\tlearn: 0.0520512\ttotal: 26m 25s\tremaining: 3.81s\n",
      "9976:\tlearn: 0.0520512\ttotal: 26m 25s\tremaining: 3.65s\n",
      "9977:\tlearn: 0.0520512\ttotal: 26m 25s\tremaining: 3.5s\n",
      "9978:\tlearn: 0.0520512\ttotal: 26m 26s\tremaining: 3.34s\n",
      "9979:\tlearn: 0.0520512\ttotal: 26m 26s\tremaining: 3.18s\n",
      "9980:\tlearn: 0.0520512\ttotal: 26m 26s\tremaining: 3.02s\n",
      "9981:\tlearn: 0.0520512\ttotal: 26m 26s\tremaining: 2.86s\n",
      "9982:\tlearn: 0.0520512\ttotal: 26m 26s\tremaining: 2.7s\n",
      "9983:\tlearn: 0.0520512\ttotal: 26m 26s\tremaining: 2.54s\n",
      "9984:\tlearn: 0.0520512\ttotal: 26m 27s\tremaining: 2.38s\n",
      "9985:\tlearn: 0.0520512\ttotal: 26m 27s\tremaining: 2.23s\n",
      "9986:\tlearn: 0.0520512\ttotal: 26m 27s\tremaining: 2.07s\n",
      "9987:\tlearn: 0.0520512\ttotal: 26m 27s\tremaining: 1.91s\n",
      "9988:\tlearn: 0.0520512\ttotal: 26m 27s\tremaining: 1.75s\n",
      "9989:\tlearn: 0.0520512\ttotal: 26m 27s\tremaining: 1.59s\n",
      "9990:\tlearn: 0.0520512\ttotal: 26m 28s\tremaining: 1.43s\n",
      "9991:\tlearn: 0.0520512\ttotal: 26m 28s\tremaining: 1.27s\n",
      "9992:\tlearn: 0.0520512\ttotal: 26m 28s\tremaining: 1.11s\n",
      "9993:\tlearn: 0.0520512\ttotal: 26m 28s\tremaining: 954ms\n",
      "9994:\tlearn: 0.0520512\ttotal: 26m 28s\tremaining: 795ms\n",
      "9995:\tlearn: 0.0520512\ttotal: 26m 28s\tremaining: 636ms\n",
      "9996:\tlearn: 0.0520512\ttotal: 26m 29s\tremaining: 477ms\n",
      "9997:\tlearn: 0.0520512\ttotal: 26m 29s\tremaining: 318ms\n",
      "9998:\tlearn: 0.0520512\ttotal: 26m 29s\tremaining: 159ms\n",
      "9999:\tlearn: 0.0520512\ttotal: 26m 29s\tremaining: 0us\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving ./auto_gl/exp-iot23-oversample/deploy-exp/STTACKING2_layer1_search/models/CatBoost_BAG_L1/hpo/model.pkl\n",
      "Loading: ./auto_gl/exp-iot23-oversample/deploy-exp/STTACKING2_layer1_search/models/CatBoost_BAG_L1/hpo/model.pkl\n",
      "Saving ./auto_gl/exp-iot23-oversample/deploy-exp/STTACKING2_layer1_search/models/CatBoost_BAG_L1/T1/utils/model_template.pkl\n",
      "Saving ./auto_gl/exp-iot23-oversample/deploy-exp/STTACKING2_layer1_search/models/CatBoost_BAG_L1/T1/utils/oof.pkl\n",
      "Saving ./auto_gl/exp-iot23-oversample/deploy-exp/STTACKING2_layer1_search/models/CatBoost_BAG_L1/T1/model.pkl\n",
      "Loading: ./auto_gl/exp-iot23-oversample/deploy-exp/STTACKING2_layer1_search/models/CatBoost_BAG_L1/T1/model.pkl\n",
      "Fitted model: CatBoost_BAG_L1/T1 ...\n",
      "\t0.9953\t = Validation score   (roc_auc)\n",
      "\t1610.2s\t = Training   runtime\n",
      "\t1.19s\t = Validation runtime\n",
      "Saving ./auto_gl/exp-iot23-oversample/deploy-exp/STTACKING2_layer1_search/models/trainer.pkl\n",
      "Loading: ./auto_gl/exp-iot23-oversample/deploy-exp/STTACKING2_layer1_search/models/LightGBM_BAG_L1/T1/model.pkl\n",
      "Fitting model: LightGBM_BAG_L1/T1 ... Training model for up to 34331.7s of the 34331.7s of remaining time.\n",
      "Loading: ./auto_gl/exp-iot23-oversample/deploy-exp/STTACKING2_layer1_search/models/LightGBM_BAG_L1/T1/utils/model_template.pkl\n",
      "Loading: ./auto_gl/exp-iot23-oversample/deploy-exp/STTACKING2_layer1_search/models/LightGBM_BAG_L1/T1/utils/oof.pkl\n",
      "Loading: ./auto_gl/exp-iot23-oversample/deploy-exp/STTACKING2_layer1_search/models/LightGBM_BAG_L1/T1/utils/model_template.pkl\n",
      "\tDropped 0 of 30 features.\n",
      "\tMemory not enough to fit LGBModel folds in parallel. Will do sequential fitting instead. \tConsider decreasing folds trained in parallel by passing num_folds_parallel to ag_args_ensemble when calling predictor.fit\n",
      "\tFitting 4 child models (S1F2 - S1F5) | Fitting with SequentialLocalFoldFittingStrategy\n",
      "\tDropped 0 of 30 features.\n",
      "\tFitting S1F2 with 'num_gpus': 0, 'num_cpus': 8\n",
      "\tWarning: Potentially not enough memory to safely train model, roughly requires: 4.463 GB, but only 5.858 GB is available...\n",
      "\tFitting 100 rounds... Hyperparameters: {'learning_rate': 0.103335706015396, 'num_leaves': 62, 'feature_fraction': 0.842181292665241, 'min_data_in_leaf': 2}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1]\tvalid_set's binary_logloss: 0.603945\n",
      "[2]\tvalid_set's binary_logloss: 0.527612\n",
      "[3]\tvalid_set's binary_logloss: 0.464426\n",
      "[4]\tvalid_set's binary_logloss: 0.411394\n",
      "[5]\tvalid_set's binary_logloss: 0.368622\n",
      "[6]\tvalid_set's binary_logloss: 0.32977\n",
      "[7]\tvalid_set's binary_logloss: 0.298438\n",
      "[8]\tvalid_set's binary_logloss: 0.269152\n",
      "[9]\tvalid_set's binary_logloss: 0.243704\n",
      "[10]\tvalid_set's binary_logloss: 0.221505\n",
      "[11]\tvalid_set's binary_logloss: 0.202078\n",
      "[12]\tvalid_set's binary_logloss: 0.185042\n",
      "[13]\tvalid_set's binary_logloss: 0.170046\n",
      "[14]\tvalid_set's binary_logloss: 0.156833\n",
      "[15]\tvalid_set's binary_logloss: 0.14517\n",
      "[16]\tvalid_set's binary_logloss: 0.134863\n",
      "[17]\tvalid_set's binary_logloss: 0.125744\n",
      "[18]\tvalid_set's binary_logloss: 0.117666\n",
      "[19]\tvalid_set's binary_logloss: 0.110503\n",
      "[20]\tvalid_set's binary_logloss: 0.10415\n",
      "[21]\tvalid_set's binary_logloss: 0.0985102\n",
      "[22]\tvalid_set's binary_logloss: 0.0934961\n",
      "[23]\tvalid_set's binary_logloss: 0.0892791\n",
      "[24]\tvalid_set's binary_logloss: 0.085283\n",
      "[25]\tvalid_set's binary_logloss: 0.081731\n",
      "[26]\tvalid_set's binary_logloss: 0.0785705\n",
      "[27]\tvalid_set's binary_logloss: 0.0759147\n",
      "[28]\tvalid_set's binary_logloss: 0.0734484\n",
      "[29]\tvalid_set's binary_logloss: 0.0711894\n",
      "[30]\tvalid_set's binary_logloss: 0.0691794\n",
      "[31]\tvalid_set's binary_logloss: 0.0673882\n",
      "[32]\tvalid_set's binary_logloss: 0.0657917\n",
      "[33]\tvalid_set's binary_logloss: 0.0643684\n",
      "[34]\tvalid_set's binary_logloss: 0.0630992\n",
      "[35]\tvalid_set's binary_logloss: 0.0619665\n",
      "[36]\tvalid_set's binary_logloss: 0.0609547\n",
      "[37]\tvalid_set's binary_logloss: 0.0600519\n",
      "[38]\tvalid_set's binary_logloss: 0.0592434\n",
      "[39]\tvalid_set's binary_logloss: 0.0585445\n",
      "[40]\tvalid_set's binary_logloss: 0.0578943\n",
      "[41]\tvalid_set's binary_logloss: 0.0573132\n",
      "[42]\tvalid_set's binary_logloss: 0.0567927\n",
      "[43]\tvalid_set's binary_logloss: 0.0563405\n",
      "[44]\tvalid_set's binary_logloss: 0.0559208\n",
      "[45]\tvalid_set's binary_logloss: 0.0555364\n",
      "[46]\tvalid_set's binary_logloss: 0.0551988\n",
      "[47]\tvalid_set's binary_logloss: 0.0548964\n",
      "[48]\tvalid_set's binary_logloss: 0.0546291\n",
      "[49]\tvalid_set's binary_logloss: 0.0543852\n",
      "[50]\tvalid_set's binary_logloss: 0.0541638\n",
      "[51]\tvalid_set's binary_logloss: 0.0539659\n",
      "[52]\tvalid_set's binary_logloss: 0.0537886\n",
      "[53]\tvalid_set's binary_logloss: 0.0536296\n",
      "[54]\tvalid_set's binary_logloss: 0.0534858\n",
      "[55]\tvalid_set's binary_logloss: 0.0533566\n",
      "[56]\tvalid_set's binary_logloss: 0.0532399\n",
      "[57]\tvalid_set's binary_logloss: 0.0531356\n",
      "[58]\tvalid_set's binary_logloss: 0.0530425\n",
      "[59]\tvalid_set's binary_logloss: 0.0529583\n",
      "[60]\tvalid_set's binary_logloss: 0.0528827\n",
      "[61]\tvalid_set's binary_logloss: 0.0528144\n",
      "[62]\tvalid_set's binary_logloss: 0.0527533\n",
      "[63]\tvalid_set's binary_logloss: 0.0526984\n",
      "[64]\tvalid_set's binary_logloss: 0.0526491\n",
      "[65]\tvalid_set's binary_logloss: 0.0526045\n",
      "[66]\tvalid_set's binary_logloss: 0.0525649\n",
      "[67]\tvalid_set's binary_logloss: 0.0525289\n",
      "[68]\tvalid_set's binary_logloss: 0.0524969\n",
      "[69]\tvalid_set's binary_logloss: 0.0524678\n",
      "[70]\tvalid_set's binary_logloss: 0.0524419\n",
      "[71]\tvalid_set's binary_logloss: 0.0524186\n",
      "[72]\tvalid_set's binary_logloss: 0.0523976\n",
      "[73]\tvalid_set's binary_logloss: 0.0523841\n",
      "[74]\tvalid_set's binary_logloss: 0.0523669\n",
      "[75]\tvalid_set's binary_logloss: 0.0523512\n",
      "[76]\tvalid_set's binary_logloss: 0.0523372\n",
      "[77]\tvalid_set's binary_logloss: 0.0523241\n",
      "[78]\tvalid_set's binary_logloss: 0.0523126\n",
      "[79]\tvalid_set's binary_logloss: 0.0523026\n",
      "[80]\tvalid_set's binary_logloss: 0.0522936\n",
      "[81]\tvalid_set's binary_logloss: 0.0522848\n",
      "[82]\tvalid_set's binary_logloss: 0.0522776\n",
      "[83]\tvalid_set's binary_logloss: 0.0522714\n",
      "[84]\tvalid_set's binary_logloss: 0.0522659\n",
      "[85]\tvalid_set's binary_logloss: 0.0522601\n",
      "[86]\tvalid_set's binary_logloss: 0.0522555\n",
      "[87]\tvalid_set's binary_logloss: 0.0522513\n",
      "[88]\tvalid_set's binary_logloss: 0.0522471\n",
      "[89]\tvalid_set's binary_logloss: 0.0522434\n",
      "[90]\tvalid_set's binary_logloss: 0.0522404\n",
      "[91]\tvalid_set's binary_logloss: 0.0522374\n",
      "[92]\tvalid_set's binary_logloss: 0.0522351\n",
      "[93]\tvalid_set's binary_logloss: 0.0522333\n",
      "[94]\tvalid_set's binary_logloss: 0.0522311\n",
      "[95]\tvalid_set's binary_logloss: 0.0522292\n",
      "[96]\tvalid_set's binary_logloss: 0.0522284\n",
      "[97]\tvalid_set's binary_logloss: 0.0522272\n",
      "[98]\tvalid_set's binary_logloss: 0.0522267\n",
      "[99]\tvalid_set's binary_logloss: 0.0522266\n",
      "[100]\tvalid_set's binary_logloss: 0.0522255\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\tDropped 0 of 30 features.\n",
      "\tFitting S1F3 with 'num_gpus': 0, 'num_cpus': 8\n",
      "\tWarning: Potentially not enough memory to safely train model, roughly requires: 4.463 GB, but only 5.699 GB is available...\n",
      "\tFitting 100 rounds... Hyperparameters: {'learning_rate': 0.103335706015396, 'num_leaves': 62, 'feature_fraction': 0.842181292665241, 'min_data_in_leaf': 2}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1]\tvalid_set's binary_logloss: 0.600155\n",
      "[2]\tvalid_set's binary_logloss: 0.524537\n",
      "[3]\tvalid_set's binary_logloss: 0.464493\n",
      "[4]\tvalid_set's binary_logloss: 0.411441\n",
      "[5]\tvalid_set's binary_logloss: 0.366434\n",
      "[6]\tvalid_set's binary_logloss: 0.327933\n",
      "[7]\tvalid_set's binary_logloss: 0.294773\n",
      "[8]\tvalid_set's binary_logloss: 0.266057\n",
      "[9]\tvalid_set's binary_logloss: 0.241079\n",
      "[10]\tvalid_set's binary_logloss: 0.21927\n",
      "[11]\tvalid_set's binary_logloss: 0.200165\n",
      "[12]\tvalid_set's binary_logloss: 0.1834\n",
      "[13]\tvalid_set's binary_logloss: 0.168632\n",
      "[14]\tvalid_set's binary_logloss: 0.15561\n",
      "[15]\tvalid_set's binary_logloss: 0.144106\n",
      "[16]\tvalid_set's binary_logloss: 0.133933\n",
      "[17]\tvalid_set's binary_logloss: 0.124927\n",
      "[18]\tvalid_set's binary_logloss: 0.116944\n",
      "[19]\tvalid_set's binary_logloss: 0.109863\n",
      "[20]\tvalid_set's binary_logloss: 0.103849\n",
      "[21]\tvalid_set's binary_logloss: 0.0982252\n",
      "[22]\tvalid_set's binary_logloss: 0.0934861\n",
      "[23]\tvalid_set's binary_logloss: 0.0890041\n",
      "[24]\tvalid_set's binary_logloss: 0.0850188\n",
      "[25]\tvalid_set's binary_logloss: 0.0814741\n",
      "[26]\tvalid_set's binary_logloss: 0.0783204\n",
      "[27]\tvalid_set's binary_logloss: 0.0755145\n",
      "[28]\tvalid_set's binary_logloss: 0.07301\n",
      "[29]\tvalid_set's binary_logloss: 0.070783\n",
      "[30]\tvalid_set's binary_logloss: 0.0687989\n",
      "[31]\tvalid_set's binary_logloss: 0.0670294\n",
      "[32]\tvalid_set's binary_logloss: 0.0654508\n",
      "[33]\tvalid_set's binary_logloss: 0.0640417\n",
      "[34]\tvalid_set's binary_logloss: 0.062784\n",
      "[35]\tvalid_set's binary_logloss: 0.0616605\n",
      "[36]\tvalid_set's binary_logloss: 0.0606765\n",
      "[37]\tvalid_set's binary_logloss: 0.0597765\n",
      "[38]\tvalid_set's binary_logloss: 0.0589705\n",
      "[39]\tvalid_set's binary_logloss: 0.0582686\n",
      "[40]\tvalid_set's binary_logloss: 0.0576199\n",
      "[41]\tvalid_set's binary_logloss: 0.0570389\n",
      "[42]\tvalid_set's binary_logloss: 0.0565189\n",
      "[43]\tvalid_set's binary_logloss: 0.0560632\n",
      "[44]\tvalid_set's binary_logloss: 0.0556432\n",
      "[45]\tvalid_set's binary_logloss: 0.0552645\n",
      "[46]\tvalid_set's binary_logloss: 0.0549264\n",
      "[47]\tvalid_set's binary_logloss: 0.0546222\n",
      "[48]\tvalid_set's binary_logloss: 0.05435\n",
      "[49]\tvalid_set's binary_logloss: 0.0541052\n",
      "[50]\tvalid_set's binary_logloss: 0.0538849\n",
      "[51]\tvalid_set's binary_logloss: 0.0536898\n",
      "[52]\tvalid_set's binary_logloss: 0.053514\n",
      "[53]\tvalid_set's binary_logloss: 0.0533539\n",
      "[54]\tvalid_set's binary_logloss: 0.0532095\n",
      "[55]\tvalid_set's binary_logloss: 0.0530798\n",
      "[56]\tvalid_set's binary_logloss: 0.0529633\n",
      "[57]\tvalid_set's binary_logloss: 0.0528601\n",
      "[58]\tvalid_set's binary_logloss: 0.0527657\n",
      "[59]\tvalid_set's binary_logloss: 0.052681\n",
      "[60]\tvalid_set's binary_logloss: 0.0526053\n",
      "[61]\tvalid_set's binary_logloss: 0.0525362\n",
      "[62]\tvalid_set's binary_logloss: 0.0524741\n",
      "[63]\tvalid_set's binary_logloss: 0.052419\n",
      "[64]\tvalid_set's binary_logloss: 0.0523686\n",
      "[65]\tvalid_set's binary_logloss: 0.0523236\n",
      "[66]\tvalid_set's binary_logloss: 0.0522832\n",
      "[67]\tvalid_set's binary_logloss: 0.0522467\n",
      "[68]\tvalid_set's binary_logloss: 0.0522136\n",
      "[69]\tvalid_set's binary_logloss: 0.0521842\n",
      "[70]\tvalid_set's binary_logloss: 0.0521577\n",
      "[71]\tvalid_set's binary_logloss: 0.0521336\n",
      "[72]\tvalid_set's binary_logloss: 0.0521119\n",
      "[73]\tvalid_set's binary_logloss: 0.0520926\n",
      "[74]\tvalid_set's binary_logloss: 0.052075\n",
      "[75]\tvalid_set's binary_logloss: 0.0520595\n",
      "[76]\tvalid_set's binary_logloss: 0.0520454\n",
      "[77]\tvalid_set's binary_logloss: 0.0520328\n",
      "[78]\tvalid_set's binary_logloss: 0.0520214\n",
      "[79]\tvalid_set's binary_logloss: 0.0520111\n",
      "[80]\tvalid_set's binary_logloss: 0.0520017\n",
      "[81]\tvalid_set's binary_logloss: 0.0519935\n",
      "[82]\tvalid_set's binary_logloss: 0.0519861\n",
      "[83]\tvalid_set's binary_logloss: 0.0519795\n",
      "[84]\tvalid_set's binary_logloss: 0.0519731\n",
      "[85]\tvalid_set's binary_logloss: 0.0519675\n",
      "[86]\tvalid_set's binary_logloss: 0.0519623\n",
      "[87]\tvalid_set's binary_logloss: 0.0519577\n",
      "[88]\tvalid_set's binary_logloss: 0.051954\n",
      "[89]\tvalid_set's binary_logloss: 0.0519506\n",
      "[90]\tvalid_set's binary_logloss: 0.0519476\n",
      "[91]\tvalid_set's binary_logloss: 0.0519447\n",
      "[92]\tvalid_set's binary_logloss: 0.0519421\n",
      "[93]\tvalid_set's binary_logloss: 0.0519398\n",
      "[94]\tvalid_set's binary_logloss: 0.0519379\n",
      "[95]\tvalid_set's binary_logloss: 0.0519366\n",
      "[96]\tvalid_set's binary_logloss: 0.0519357\n",
      "[97]\tvalid_set's binary_logloss: 0.0519346\n",
      "[98]\tvalid_set's binary_logloss: 0.051933\n",
      "[99]\tvalid_set's binary_logloss: 0.0519327\n",
      "[100]\tvalid_set's binary_logloss: 0.0519318\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\tDropped 0 of 30 features.\n",
      "\tFitting S1F4 with 'num_gpus': 0, 'num_cpus': 8\n",
      "\tWarning: Potentially not enough memory to safely train model, roughly requires: 4.463 GB, but only 5.639 GB is available...\n",
      "\tFitting 100 rounds... Hyperparameters: {'learning_rate': 0.103335706015396, 'num_leaves': 62, 'feature_fraction': 0.842181292665241, 'min_data_in_leaf': 2}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1]\tvalid_set's binary_logloss: 0.600138\n",
      "[2]\tvalid_set's binary_logloss: 0.524501\n",
      "[3]\tvalid_set's binary_logloss: 0.464429\n",
      "[4]\tvalid_set's binary_logloss: 0.411362\n",
      "[5]\tvalid_set's binary_logloss: 0.366341\n",
      "[6]\tvalid_set's binary_logloss: 0.327826\n",
      "[7]\tvalid_set's binary_logloss: 0.294653\n",
      "[8]\tvalid_set's binary_logloss: 0.265928\n",
      "[9]\tvalid_set's binary_logloss: 0.240938\n",
      "[10]\tvalid_set's binary_logloss: 0.219118\n",
      "[11]\tvalid_set's binary_logloss: 0.199999\n",
      "[12]\tvalid_set's binary_logloss: 0.183217\n",
      "[13]\tvalid_set's binary_logloss: 0.16844\n",
      "[14]\tvalid_set's binary_logloss: 0.155408\n",
      "[15]\tvalid_set's binary_logloss: 0.143899\n",
      "[16]\tvalid_set's binary_logloss: 0.133716\n",
      "[17]\tvalid_set's binary_logloss: 0.1247\n",
      "[18]\tvalid_set's binary_logloss: 0.116709\n",
      "[19]\tvalid_set's binary_logloss: 0.109615\n",
      "[20]\tvalid_set's binary_logloss: 0.103605\n",
      "[21]\tvalid_set's binary_logloss: 0.0979707\n",
      "[22]\tvalid_set's binary_logloss: 0.0932306\n",
      "[23]\tvalid_set's binary_logloss: 0.0887394\n",
      "[24]\tvalid_set's binary_logloss: 0.0847461\n",
      "[25]\tvalid_set's binary_logloss: 0.081196\n",
      "[26]\tvalid_set's binary_logloss: 0.0780371\n",
      "[27]\tvalid_set's binary_logloss: 0.0752244\n",
      "[28]\tvalid_set's binary_logloss: 0.0727151\n",
      "[29]\tvalid_set's binary_logloss: 0.0704823\n",
      "[30]\tvalid_set's binary_logloss: 0.0684933\n",
      "[31]\tvalid_set's binary_logloss: 0.0667197\n",
      "[32]\tvalid_set's binary_logloss: 0.0651371\n",
      "[33]\tvalid_set's binary_logloss: 0.0637244\n",
      "[34]\tvalid_set's binary_logloss: 0.062464\n",
      "[35]\tvalid_set's binary_logloss: 0.0613372\n",
      "[36]\tvalid_set's binary_logloss: 0.0603509\n",
      "[37]\tvalid_set's binary_logloss: 0.059449\n",
      "[38]\tvalid_set's binary_logloss: 0.0586416\n",
      "[39]\tvalid_set's binary_logloss: 0.0579409\n",
      "[40]\tvalid_set's binary_logloss: 0.0572897\n",
      "[41]\tvalid_set's binary_logloss: 0.0567075\n",
      "[42]\tvalid_set's binary_logloss: 0.0561862\n",
      "[43]\tvalid_set's binary_logloss: 0.0557322\n",
      "[44]\tvalid_set's binary_logloss: 0.0553111\n",
      "[45]\tvalid_set's binary_logloss: 0.054932\n",
      "[46]\tvalid_set's binary_logloss: 0.0545928\n",
      "[47]\tvalid_set's binary_logloss: 0.054288\n",
      "[48]\tvalid_set's binary_logloss: 0.0540142\n",
      "[49]\tvalid_set's binary_logloss: 0.0537692\n",
      "[50]\tvalid_set's binary_logloss: 0.0535492\n",
      "[51]\tvalid_set's binary_logloss: 0.0533556\n",
      "[52]\tvalid_set's binary_logloss: 0.0531815\n",
      "[53]\tvalid_set's binary_logloss: 0.0530205\n",
      "[54]\tvalid_set's binary_logloss: 0.0528757\n",
      "[55]\tvalid_set's binary_logloss: 0.0527463\n",
      "[56]\tvalid_set's binary_logloss: 0.0526292\n",
      "[57]\tvalid_set's binary_logloss: 0.0525263\n",
      "[58]\tvalid_set's binary_logloss: 0.0524319\n",
      "[59]\tvalid_set's binary_logloss: 0.0523473\n",
      "[60]\tvalid_set's binary_logloss: 0.0522725\n",
      "[61]\tvalid_set's binary_logloss: 0.0522043\n",
      "[62]\tvalid_set's binary_logloss: 0.0521428\n",
      "[63]\tvalid_set's binary_logloss: 0.0520881\n",
      "[64]\tvalid_set's binary_logloss: 0.0520382\n",
      "[65]\tvalid_set's binary_logloss: 0.0519933\n",
      "[66]\tvalid_set's binary_logloss: 0.051953\n",
      "[67]\tvalid_set's binary_logloss: 0.0519169\n",
      "[68]\tvalid_set's binary_logloss: 0.0518846\n",
      "[69]\tvalid_set's binary_logloss: 0.051855\n",
      "[70]\tvalid_set's binary_logloss: 0.0518284\n",
      "[71]\tvalid_set's binary_logloss: 0.051805\n",
      "[72]\tvalid_set's binary_logloss: 0.051784\n",
      "[73]\tvalid_set's binary_logloss: 0.0517646\n",
      "[74]\tvalid_set's binary_logloss: 0.0517474\n",
      "[75]\tvalid_set's binary_logloss: 0.0517324\n",
      "[76]\tvalid_set's binary_logloss: 0.0517187\n",
      "[77]\tvalid_set's binary_logloss: 0.0517064\n",
      "[78]\tvalid_set's binary_logloss: 0.0516956\n",
      "[79]\tvalid_set's binary_logloss: 0.0516855\n",
      "[80]\tvalid_set's binary_logloss: 0.051677\n",
      "[81]\tvalid_set's binary_logloss: 0.0516687\n",
      "[82]\tvalid_set's binary_logloss: 0.0516615\n",
      "[83]\tvalid_set's binary_logloss: 0.0516554\n",
      "[84]\tvalid_set's binary_logloss: 0.0516495\n",
      "[85]\tvalid_set's binary_logloss: 0.0516445\n",
      "[86]\tvalid_set's binary_logloss: 0.0516407\n",
      "[87]\tvalid_set's binary_logloss: 0.0516367\n",
      "[88]\tvalid_set's binary_logloss: 0.0516334\n",
      "[89]\tvalid_set's binary_logloss: 0.0516301\n",
      "[90]\tvalid_set's binary_logloss: 0.0516267\n",
      "[91]\tvalid_set's binary_logloss: 0.0516242\n",
      "[92]\tvalid_set's binary_logloss: 0.0516217\n",
      "[93]\tvalid_set's binary_logloss: 0.0516196\n",
      "[94]\tvalid_set's binary_logloss: 0.0516176\n",
      "[95]\tvalid_set's binary_logloss: 0.0516166\n",
      "[96]\tvalid_set's binary_logloss: 0.0516154\n",
      "[97]\tvalid_set's binary_logloss: 0.0516145\n",
      "[98]\tvalid_set's binary_logloss: 0.0516137\n",
      "[99]\tvalid_set's binary_logloss: 0.0516126\n",
      "[100]\tvalid_set's binary_logloss: 0.0516123\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\tDropped 0 of 30 features.\n",
      "\tFitting S1F5 with 'num_gpus': 0, 'num_cpus': 8\n",
      "\tWarning: Potentially not enough memory to safely train model, roughly requires: 4.463 GB, but only 5.538 GB is available...\n",
      "\tFitting 100 rounds... Hyperparameters: {'learning_rate': 0.103335706015396, 'num_leaves': 62, 'feature_fraction': 0.842181292665241, 'min_data_in_leaf': 2}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1]\tvalid_set's binary_logloss: 0.603518\n",
      "[2]\tvalid_set's binary_logloss: 0.527258\n",
      "[3]\tvalid_set's binary_logloss: 0.46414\n",
      "[4]\tvalid_set's binary_logloss: 0.411158\n",
      "[5]\tvalid_set's binary_logloss: 0.36621\n",
      "[6]\tvalid_set's binary_logloss: 0.327756\n",
      "[7]\tvalid_set's binary_logloss: 0.294633\n",
      "[8]\tvalid_set's binary_logloss: 0.265948\n",
      "[9]\tvalid_set's binary_logloss: 0.241008\n",
      "[10]\tvalid_set's binary_logloss: 0.219209\n",
      "[11]\tvalid_set's binary_logloss: 0.200115\n",
      "[12]\tvalid_set's binary_logloss: 0.184036\n",
      "[13]\tvalid_set's binary_logloss: 0.16996\n",
      "[14]\tvalid_set's binary_logloss: 0.156747\n",
      "[15]\tvalid_set's binary_logloss: 0.145071\n",
      "[16]\tvalid_set's binary_logloss: 0.134751\n",
      "[17]\tvalid_set's binary_logloss: 0.125614\n",
      "[18]\tvalid_set's binary_logloss: 0.117519\n",
      "[19]\tvalid_set's binary_logloss: 0.110339\n",
      "[20]\tvalid_set's binary_logloss: 0.103969\n",
      "[21]\tvalid_set's binary_logloss: 0.0986165\n",
      "[22]\tvalid_set's binary_logloss: 0.0938688\n",
      "[23]\tvalid_set's binary_logloss: 0.089654\n",
      "[24]\tvalid_set's binary_logloss: 0.08591\n",
      "[25]\tvalid_set's binary_logloss: 0.0825815\n",
      "[26]\tvalid_set's binary_logloss: 0.0796214\n",
      "[27]\tvalid_set's binary_logloss: 0.0765885\n",
      "[28]\tvalid_set's binary_logloss: 0.0738943\n",
      "[29]\tvalid_set's binary_logloss: 0.0717881\n",
      "[30]\tvalid_set's binary_logloss: 0.0699109\n",
      "[31]\tvalid_set's binary_logloss: 0.0679371\n",
      "[32]\tvalid_set's binary_logloss: 0.0664362\n",
      "[33]\tvalid_set's binary_logloss: 0.0648414\n",
      "[34]\tvalid_set's binary_logloss: 0.0636402\n",
      "[35]\tvalid_set's binary_logloss: 0.0623489\n",
      "[36]\tvalid_set's binary_logloss: 0.0612043\n",
      "[37]\tvalid_set's binary_logloss: 0.0603399\n",
      "[38]\tvalid_set's binary_logloss: 0.0594116\n",
      "[39]\tvalid_set's binary_logloss: 0.0585881\n",
      "[40]\tvalid_set's binary_logloss: 0.0578581\n",
      "[41]\tvalid_set's binary_logloss: 0.0572087\n",
      "[42]\tvalid_set's binary_logloss: 0.0566313\n",
      "[43]\tvalid_set's binary_logloss: 0.0561175\n",
      "[44]\tvalid_set's binary_logloss: 0.0556602\n",
      "[45]\tvalid_set's binary_logloss: 0.0552522\n",
      "[46]\tvalid_set's binary_logloss: 0.0548882\n",
      "[47]\tvalid_set's binary_logloss: 0.0545929\n",
      "[48]\tvalid_set's binary_logloss: 0.0542978\n",
      "[49]\tvalid_set's binary_logloss: 0.0540342\n",
      "[50]\tvalid_set's binary_logloss: 0.0537987\n",
      "[51]\tvalid_set's binary_logloss: 0.053588\n",
      "[52]\tvalid_set's binary_logloss: 0.0533996\n",
      "[53]\tvalid_set's binary_logloss: 0.0532312\n",
      "[54]\tvalid_set's binary_logloss: 0.0530832\n",
      "[55]\tvalid_set's binary_logloss: 0.0529481\n",
      "[56]\tvalid_set's binary_logloss: 0.0528263\n",
      "[57]\tvalid_set's binary_logloss: 0.0527177\n",
      "[58]\tvalid_set's binary_logloss: 0.0526197\n",
      "[59]\tvalid_set's binary_logloss: 0.0525318\n",
      "[60]\tvalid_set's binary_logloss: 0.0524528\n",
      "[61]\tvalid_set's binary_logloss: 0.0523824\n",
      "[62]\tvalid_set's binary_logloss: 0.0523217\n",
      "[63]\tvalid_set's binary_logloss: 0.052267\n",
      "[64]\tvalid_set's binary_logloss: 0.052215\n",
      "[65]\tvalid_set's binary_logloss: 0.0521684\n",
      "[66]\tvalid_set's binary_logloss: 0.0521264\n",
      "[67]\tvalid_set's binary_logloss: 0.0520896\n",
      "[68]\tvalid_set's binary_logloss: 0.0520557\n",
      "[69]\tvalid_set's binary_logloss: 0.0520255\n",
      "[70]\tvalid_set's binary_logloss: 0.0519982\n",
      "[71]\tvalid_set's binary_logloss: 0.0519738\n",
      "[72]\tvalid_set's binary_logloss: 0.0519519\n",
      "[73]\tvalid_set's binary_logloss: 0.051932\n",
      "[74]\tvalid_set's binary_logloss: 0.0519146\n",
      "[75]\tvalid_set's binary_logloss: 0.0518986\n",
      "[76]\tvalid_set's binary_logloss: 0.0518841\n",
      "[77]\tvalid_set's binary_logloss: 0.0518714\n",
      "[78]\tvalid_set's binary_logloss: 0.0518594\n",
      "[79]\tvalid_set's binary_logloss: 0.0518489\n",
      "[80]\tvalid_set's binary_logloss: 0.0518394\n",
      "[81]\tvalid_set's binary_logloss: 0.0518311\n",
      "[82]\tvalid_set's binary_logloss: 0.0518235\n",
      "[83]\tvalid_set's binary_logloss: 0.0518167\n",
      "[84]\tvalid_set's binary_logloss: 0.0518106\n",
      "[85]\tvalid_set's binary_logloss: 0.051805\n",
      "[86]\tvalid_set's binary_logloss: 0.0518001\n",
      "[87]\tvalid_set's binary_logloss: 0.0517956\n",
      "[88]\tvalid_set's binary_logloss: 0.0517916\n",
      "[89]\tvalid_set's binary_logloss: 0.0517881\n",
      "[90]\tvalid_set's binary_logloss: 0.0517848\n",
      "[91]\tvalid_set's binary_logloss: 0.0517819\n",
      "[92]\tvalid_set's binary_logloss: 0.0517793\n",
      "[93]\tvalid_set's binary_logloss: 0.0517767\n",
      "[94]\tvalid_set's binary_logloss: 0.0517753\n",
      "[95]\tvalid_set's binary_logloss: 0.0517737\n",
      "[96]\tvalid_set's binary_logloss: 0.0517718\n",
      "[97]\tvalid_set's binary_logloss: 0.0517702\n",
      "[98]\tvalid_set's binary_logloss: 0.0517692\n",
      "[99]\tvalid_set's binary_logloss: 0.051768\n",
      "[100]\tvalid_set's binary_logloss: 0.0517673\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving ./auto_gl/exp-iot23-oversample/deploy-exp/STTACKING2_layer1_search/models/LightGBM_BAG_L1/T1/utils/oof.pkl\n",
      "Saving ./auto_gl/exp-iot23-oversample/deploy-exp/STTACKING2_layer1_search/models/LightGBM_BAG_L1/T1/model.pkl\n",
      "\t0.9953\t = Validation score   (roc_auc)\n",
      "\t67.28s\t = Training   runtime\n",
      "\t3.65s\t = Validation runtime\n",
      "Saving ./auto_gl/exp-iot23-oversample/deploy-exp/STTACKING2_layer1_search/models/trainer.pkl\n",
      "Loading: ./auto_gl/exp-iot23-oversample/deploy-exp/STTACKING2_layer1_search/models/CatBoost_BAG_L1/T1/model.pkl\n",
      "Fitting model: CatBoost_BAG_L1/T1 ... Training model for up to 34274.87s of the 34274.87s of remaining time.\n",
      "Loading: ./auto_gl/exp-iot23-oversample/deploy-exp/STTACKING2_layer1_search/models/CatBoost_BAG_L1/T1/utils/model_template.pkl\n",
      "Loading: ./auto_gl/exp-iot23-oversample/deploy-exp/STTACKING2_layer1_search/models/CatBoost_BAG_L1/T1/utils/oof.pkl\n",
      "Loading: ./auto_gl/exp-iot23-oversample/deploy-exp/STTACKING2_layer1_search/models/CatBoost_BAG_L1/T1/utils/model_template.pkl\n",
      "\tDropped 0 of 30 features.\n",
      "\tMemory not enough to fit CatBoostModel folds in parallel. Will do sequential fitting instead. \tConsider decreasing folds trained in parallel by passing num_folds_parallel to ag_args_ensemble when calling predictor.fit\n",
      "\tFitting 4 child models (S1F2 - S1F5) | Fitting with SequentialLocalFoldFittingStrategy\n",
      "\tDropped 0 of 30 features.\n",
      "\tFitting S1F2 with 'num_gpus': 0, 'num_cpus': 8\n",
      "\tWarning: Potentially not enough memory to safely train CatBoost model, roughly requires: 4.463 GB, but only 5.718 GB is available...\n",
      "\tCatboost model hyperparameters: {'iterations': 10000, 'learning_rate': 0.02057151708150835, 'random_seed': 0, 'allow_writing_files': False, 'eval_metric': 'Logloss', 'depth': 5, 'l2_leaf_reg': 4.854651042004117, 'thread_count': 8}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:\tlearn: 0.6171911\ttest: 0.6172217\tbest: 0.6172217 (0)\ttotal: 237ms\tremaining: 39m 30s\n",
      "1:\tlearn: 0.5530527\ttest: 0.5531669\tbest: 0.5531669 (1)\ttotal: 472ms\tremaining: 39m 20s\n",
      "2:\tlearn: 0.4942809\ttest: 0.4938331\tbest: 0.4938331 (2)\ttotal: 697ms\tremaining: 38m 44s\n",
      "3:\tlearn: 0.4419593\ttest: 0.4419323\tbest: 0.4419323 (3)\ttotal: 937ms\tremaining: 39m 1s\n",
      "4:\tlearn: 0.3967868\ttest: 0.3967015\tbest: 0.3967015 (4)\ttotal: 1.19s\tremaining: 39m 29s\n",
      "5:\tlearn: 0.3576096\ttest: 0.3574176\tbest: 0.3574176 (5)\ttotal: 1.44s\tremaining: 40m 5s\n",
      "6:\tlearn: 0.3234787\ttest: 0.3231815\tbest: 0.3231815 (6)\ttotal: 1.69s\tremaining: 40m 19s\n",
      "7:\tlearn: 0.2937145\ttest: 0.2934680\tbest: 0.2934680 (7)\ttotal: 1.95s\tremaining: 40m 34s\n",
      "8:\tlearn: 0.2676240\ttest: 0.2676801\tbest: 0.2676801 (8)\ttotal: 2.2s\tremaining: 40m 39s\n",
      "9:\tlearn: 0.2483117\ttest: 0.2482562\tbest: 0.2482562 (9)\ttotal: 2.44s\tremaining: 40m 34s\n",
      "10:\tlearn: 0.2282950\ttest: 0.2282811\tbest: 0.2282811 (10)\ttotal: 2.69s\tremaining: 40m 39s\n",
      "11:\tlearn: 0.2109451\ttest: 0.2108979\tbest: 0.2108979 (11)\ttotal: 2.93s\tremaining: 40m 42s\n",
      "12:\tlearn: 0.1957630\ttest: 0.1957405\tbest: 0.1957405 (12)\ttotal: 3.18s\tremaining: 40m 45s\n",
      "13:\tlearn: 0.1825319\ttest: 0.1824933\tbest: 0.1824933 (13)\ttotal: 3.42s\tremaining: 40m 41s\n",
      "14:\tlearn: 0.1710369\ttest: 0.1708743\tbest: 0.1708743 (14)\ttotal: 3.67s\tremaining: 40m 44s\n",
      "15:\tlearn: 0.1607709\ttest: 0.1606522\tbest: 0.1606522 (15)\ttotal: 3.92s\tremaining: 40m 46s\n",
      "16:\tlearn: 0.1515766\ttest: 0.1516284\tbest: 0.1516284 (16)\ttotal: 4.17s\tremaining: 40m 46s\n",
      "17:\tlearn: 0.1436614\ttest: 0.1436319\tbest: 0.1436319 (17)\ttotal: 4.42s\tremaining: 40m 49s\n",
      "18:\tlearn: 0.1371845\ttest: 0.1372413\tbest: 0.1372413 (18)\ttotal: 4.64s\tremaining: 40m 38s\n",
      "19:\tlearn: 0.1314391\ttest: 0.1313939\tbest: 0.1313939 (19)\ttotal: 4.87s\tremaining: 40m 30s\n",
      "20:\tlearn: 0.1262092\ttest: 0.1260399\tbest: 0.1260399 (20)\ttotal: 5.09s\tremaining: 40m 21s\n",
      "21:\tlearn: 0.1201703\ttest: 0.1201430\tbest: 0.1201430 (21)\ttotal: 5.35s\tremaining: 40m 26s\n",
      "22:\tlearn: 0.1150041\ttest: 0.1149808\tbest: 0.1149808 (22)\ttotal: 5.58s\tremaining: 40m 21s\n",
      "23:\tlearn: 0.1100112\ttest: 0.1100557\tbest: 0.1100557 (23)\ttotal: 5.82s\tremaining: 40m 18s\n",
      "24:\tlearn: 0.1061963\ttest: 0.1061994\tbest: 0.1061994 (24)\ttotal: 6.06s\tremaining: 40m 19s\n",
      "25:\tlearn: 0.1023426\ttest: 0.1023621\tbest: 0.1023621 (25)\ttotal: 6.3s\tremaining: 40m 19s\n",
      "26:\tlearn: 0.0987121\ttest: 0.0986412\tbest: 0.0986412 (26)\ttotal: 6.55s\tremaining: 40m 20s\n",
      "27:\tlearn: 0.0956620\ttest: 0.0956454\tbest: 0.0956454 (27)\ttotal: 6.78s\tremaining: 40m 15s\n",
      "28:\tlearn: 0.0930414\ttest: 0.0929820\tbest: 0.0929820 (28)\ttotal: 7.01s\tremaining: 40m 12s\n",
      "29:\tlearn: 0.0905610\ttest: 0.0905884\tbest: 0.0905884 (29)\ttotal: 7.26s\tremaining: 40m 13s\n",
      "30:\tlearn: 0.0884192\ttest: 0.0883599\tbest: 0.0883599 (30)\ttotal: 7.51s\tremaining: 40m 14s\n",
      "31:\tlearn: 0.0858747\ttest: 0.0859589\tbest: 0.0859589 (31)\ttotal: 7.75s\tremaining: 40m 15s\n",
      "32:\tlearn: 0.0844942\ttest: 0.0844797\tbest: 0.0844797 (32)\ttotal: 7.98s\tremaining: 40m 10s\n",
      "33:\tlearn: 0.0830861\ttest: 0.0831264\tbest: 0.0831264 (33)\ttotal: 8.22s\tremaining: 40m 10s\n",
      "34:\tlearn: 0.0811762\ttest: 0.0811703\tbest: 0.0811703 (34)\ttotal: 8.46s\tremaining: 40m 9s\n",
      "35:\tlearn: 0.0795257\ttest: 0.0795685\tbest: 0.0795685 (35)\ttotal: 8.69s\tremaining: 40m 4s\n",
      "36:\tlearn: 0.0783830\ttest: 0.0784244\tbest: 0.0784244 (36)\ttotal: 8.91s\tremaining: 40m\n",
      "37:\tlearn: 0.0769166\ttest: 0.0769823\tbest: 0.0769823 (37)\ttotal: 9.15s\tremaining: 39m 57s\n",
      "38:\tlearn: 0.0756652\ttest: 0.0756911\tbest: 0.0756911 (38)\ttotal: 9.39s\tremaining: 39m 58s\n",
      "39:\tlearn: 0.0745626\ttest: 0.0745816\tbest: 0.0745816 (39)\ttotal: 9.61s\tremaining: 39m 53s\n",
      "40:\tlearn: 0.0734669\ttest: 0.0735984\tbest: 0.0735984 (40)\ttotal: 9.86s\tremaining: 39m 54s\n",
      "41:\tlearn: 0.0726967\ttest: 0.0727560\tbest: 0.0727560 (41)\ttotal: 10.1s\tremaining: 39m 47s\n",
      "42:\tlearn: 0.0716765\ttest: 0.0717836\tbest: 0.0717836 (42)\ttotal: 10.3s\tremaining: 39m 40s\n",
      "43:\tlearn: 0.0708539\ttest: 0.0709351\tbest: 0.0709351 (43)\ttotal: 10.5s\tremaining: 39m 39s\n",
      "44:\tlearn: 0.0700738\ttest: 0.0701719\tbest: 0.0701719 (44)\ttotal: 10.7s\tremaining: 39m 34s\n",
      "45:\tlearn: 0.0693044\ttest: 0.0694190\tbest: 0.0694190 (45)\ttotal: 11s\tremaining: 39m 30s\n",
      "46:\tlearn: 0.0684654\ttest: 0.0684680\tbest: 0.0684680 (46)\ttotal: 11.2s\tremaining: 39m 29s\n",
      "47:\tlearn: 0.0675015\ttest: 0.0676002\tbest: 0.0676002 (47)\ttotal: 11.4s\tremaining: 39m 28s\n",
      "48:\tlearn: 0.0669027\ttest: 0.0669735\tbest: 0.0669735 (48)\ttotal: 11.6s\tremaining: 39m 22s\n",
      "49:\tlearn: 0.0661570\ttest: 0.0662402\tbest: 0.0662402 (49)\ttotal: 11.9s\tremaining: 39m 21s\n",
      "50:\tlearn: 0.0655552\ttest: 0.0656244\tbest: 0.0656244 (50)\ttotal: 12.1s\tremaining: 39m 18s\n",
      "51:\tlearn: 0.0650096\ttest: 0.0650575\tbest: 0.0650575 (51)\ttotal: 12.3s\tremaining: 39m 19s\n",
      "52:\tlearn: 0.0644414\ttest: 0.0645442\tbest: 0.0645442 (52)\ttotal: 12.6s\tremaining: 39m 18s\n",
      "53:\tlearn: 0.0638401\ttest: 0.0639497\tbest: 0.0639497 (53)\ttotal: 12.8s\tremaining: 39m 17s\n",
      "54:\tlearn: 0.0633498\ttest: 0.0634787\tbest: 0.0634787 (54)\ttotal: 13s\tremaining: 39m 18s\n",
      "55:\tlearn: 0.0629129\ttest: 0.0630668\tbest: 0.0630668 (55)\ttotal: 13.3s\tremaining: 39m 13s\n",
      "56:\tlearn: 0.0625148\ttest: 0.0625884\tbest: 0.0625884 (56)\ttotal: 13.5s\tremaining: 39m 11s\n",
      "57:\tlearn: 0.0620665\ttest: 0.0621794\tbest: 0.0621794 (57)\ttotal: 13.7s\tremaining: 39m 8s\n",
      "58:\tlearn: 0.0617099\ttest: 0.0617825\tbest: 0.0617825 (58)\ttotal: 13.9s\tremaining: 39m 6s\n",
      "59:\tlearn: 0.0613035\ttest: 0.0614163\tbest: 0.0614163 (59)\ttotal: 14.1s\tremaining: 39m 3s\n",
      "60:\tlearn: 0.0610001\ttest: 0.0610786\tbest: 0.0610786 (60)\ttotal: 14.4s\tremaining: 39m 2s\n",
      "61:\tlearn: 0.0606031\ttest: 0.0607041\tbest: 0.0607041 (61)\ttotal: 14.6s\tremaining: 39m\n",
      "62:\tlearn: 0.0602898\ttest: 0.0603848\tbest: 0.0603848 (62)\ttotal: 14.8s\tremaining: 38m 57s\n",
      "63:\tlearn: 0.0599715\ttest: 0.0600813\tbest: 0.0600813 (63)\ttotal: 15s\tremaining: 38m 54s\n",
      "64:\tlearn: 0.0595965\ttest: 0.0597834\tbest: 0.0597834 (64)\ttotal: 15.3s\tremaining: 38m 51s\n",
      "65:\tlearn: 0.0593655\ttest: 0.0595122\tbest: 0.0595122 (65)\ttotal: 15.5s\tremaining: 38m 52s\n",
      "66:\tlearn: 0.0590964\ttest: 0.0592656\tbest: 0.0592656 (66)\ttotal: 15.7s\tremaining: 38m 49s\n",
      "67:\tlearn: 0.0588931\ttest: 0.0590357\tbest: 0.0590357 (67)\ttotal: 15.9s\tremaining: 38m 48s\n",
      "68:\tlearn: 0.0586533\ttest: 0.0588205\tbest: 0.0588205 (68)\ttotal: 16.1s\tremaining: 38m 44s\n",
      "69:\tlearn: 0.0584436\ttest: 0.0586071\tbest: 0.0586071 (69)\ttotal: 16.4s\tremaining: 38m 42s\n",
      "70:\tlearn: 0.0582702\ttest: 0.0584088\tbest: 0.0584088 (70)\ttotal: 16.6s\tremaining: 38m 38s\n",
      "71:\tlearn: 0.0581081\ttest: 0.0582361\tbest: 0.0582361 (71)\ttotal: 16.8s\tremaining: 38m 37s\n",
      "72:\tlearn: 0.0579289\ttest: 0.0580472\tbest: 0.0580472 (72)\ttotal: 17s\tremaining: 38m 37s\n",
      "73:\tlearn: 0.0577452\ttest: 0.0578624\tbest: 0.0578624 (73)\ttotal: 17.3s\tremaining: 38m 38s\n",
      "74:\tlearn: 0.0575305\ttest: 0.0576802\tbest: 0.0576802 (74)\ttotal: 17.5s\tremaining: 38m 35s\n",
      "75:\tlearn: 0.0573668\ttest: 0.0575354\tbest: 0.0575354 (75)\ttotal: 17.7s\tremaining: 38m 33s\n",
      "76:\tlearn: 0.0571835\ttest: 0.0573711\tbest: 0.0573711 (76)\ttotal: 17.9s\tremaining: 38m 31s\n",
      "77:\tlearn: 0.0570272\ttest: 0.0572395\tbest: 0.0572395 (77)\ttotal: 18.2s\tremaining: 38m 30s\n",
      "78:\tlearn: 0.0569125\ttest: 0.0570954\tbest: 0.0570954 (78)\ttotal: 18.4s\tremaining: 38m 27s\n",
      "79:\tlearn: 0.0567633\ttest: 0.0569583\tbest: 0.0569583 (79)\ttotal: 18.6s\tremaining: 38m 26s\n",
      "80:\tlearn: 0.0566237\ttest: 0.0568432\tbest: 0.0568432 (80)\ttotal: 18.8s\tremaining: 38m 23s\n",
      "81:\tlearn: 0.0565431\ttest: 0.0567335\tbest: 0.0567335 (81)\ttotal: 19s\tremaining: 38m 22s\n",
      "82:\tlearn: 0.0564130\ttest: 0.0566304\tbest: 0.0566304 (82)\ttotal: 19.2s\tremaining: 38m 18s\n",
      "83:\tlearn: 0.0563305\ttest: 0.0565315\tbest: 0.0565315 (83)\ttotal: 19.5s\tremaining: 38m 17s\n",
      "84:\tlearn: 0.0562000\ttest: 0.0564370\tbest: 0.0564370 (84)\ttotal: 19.7s\tremaining: 38m 15s\n",
      "85:\tlearn: 0.0560925\ttest: 0.0563112\tbest: 0.0563112 (85)\ttotal: 19.9s\tremaining: 38m 16s\n",
      "86:\tlearn: 0.0560144\ttest: 0.0562071\tbest: 0.0562071 (86)\ttotal: 20.1s\tremaining: 38m 15s\n",
      "87:\tlearn: 0.0559343\ttest: 0.0561244\tbest: 0.0561244 (87)\ttotal: 20.4s\tremaining: 38m 15s\n",
      "88:\tlearn: 0.0558232\ttest: 0.0560486\tbest: 0.0560486 (88)\ttotal: 20.6s\tremaining: 38m 14s\n",
      "89:\tlearn: 0.0557122\ttest: 0.0559404\tbest: 0.0559404 (89)\ttotal: 20.8s\tremaining: 38m 14s\n",
      "90:\tlearn: 0.0556546\ttest: 0.0558678\tbest: 0.0558678 (90)\ttotal: 21.1s\tremaining: 38m 12s\n",
      "91:\tlearn: 0.0555732\ttest: 0.0557716\tbest: 0.0557716 (91)\ttotal: 21.3s\tremaining: 38m 13s\n",
      "92:\tlearn: 0.0555098\ttest: 0.0557048\tbest: 0.0557048 (92)\ttotal: 21.5s\tremaining: 38m 12s\n",
      "93:\tlearn: 0.0554184\ttest: 0.0556264\tbest: 0.0556264 (93)\ttotal: 21.7s\tremaining: 38m 11s\n",
      "94:\tlearn: 0.0553620\ttest: 0.0555657\tbest: 0.0555657 (94)\ttotal: 22s\tremaining: 38m 10s\n",
      "95:\tlearn: 0.0553004\ttest: 0.0555076\tbest: 0.0555076 (95)\ttotal: 22.2s\tremaining: 38m 5s\n",
      "96:\tlearn: 0.0552365\ttest: 0.0554395\tbest: 0.0554395 (96)\ttotal: 22.4s\tremaining: 38m 3s\n",
      "97:\tlearn: 0.0551525\ttest: 0.0553635\tbest: 0.0553635 (97)\ttotal: 22.6s\tremaining: 38m 3s\n",
      "98:\tlearn: 0.0550839\ttest: 0.0552990\tbest: 0.0552990 (98)\ttotal: 22.8s\tremaining: 38m\n",
      "99:\tlearn: 0.0550006\ttest: 0.0552299\tbest: 0.0552299 (99)\ttotal: 23s\tremaining: 38m\n",
      "100:\tlearn: 0.0549449\ttest: 0.0551825\tbest: 0.0551825 (100)\ttotal: 23.3s\tremaining: 37m 59s\n",
      "101:\tlearn: 0.0548825\ttest: 0.0551253\tbest: 0.0551253 (101)\ttotal: 23.5s\tremaining: 37m 57s\n",
      "102:\tlearn: 0.0548771\ttest: 0.0550897\tbest: 0.0550897 (102)\ttotal: 23.6s\tremaining: 37m 52s\n",
      "103:\tlearn: 0.0548104\ttest: 0.0550370\tbest: 0.0550370 (103)\ttotal: 23.8s\tremaining: 37m 46s\n",
      "104:\tlearn: 0.0547541\ttest: 0.0550054\tbest: 0.0550054 (104)\ttotal: 24s\tremaining: 37m 41s\n",
      "105:\tlearn: 0.0547563\ttest: 0.0549737\tbest: 0.0549737 (105)\ttotal: 24.2s\tremaining: 37m 37s\n",
      "106:\tlearn: 0.0546932\ttest: 0.0549190\tbest: 0.0549190 (106)\ttotal: 24.4s\tremaining: 37m 37s\n",
      "107:\tlearn: 0.0546320\ttest: 0.0548895\tbest: 0.0548895 (107)\ttotal: 24.6s\tremaining: 37m 33s\n",
      "108:\tlearn: 0.0545812\ttest: 0.0548487\tbest: 0.0548487 (108)\ttotal: 24.8s\tremaining: 37m 28s\n",
      "109:\tlearn: 0.0545903\ttest: 0.0548222\tbest: 0.0548222 (109)\ttotal: 25s\tremaining: 37m 24s\n",
      "110:\tlearn: 0.0545139\ttest: 0.0547756\tbest: 0.0547756 (110)\ttotal: 25.2s\tremaining: 37m 24s\n",
      "111:\tlearn: 0.0545202\ttest: 0.0547503\tbest: 0.0547503 (111)\ttotal: 25.4s\tremaining: 37m 20s\n",
      "112:\tlearn: 0.0544658\ttest: 0.0547234\tbest: 0.0547234 (112)\ttotal: 25.5s\tremaining: 37m 14s\n",
      "113:\tlearn: 0.0544702\ttest: 0.0546985\tbest: 0.0546985 (113)\ttotal: 25.7s\tremaining: 37m 11s\n",
      "114:\tlearn: 0.0544186\ttest: 0.0546728\tbest: 0.0546728 (114)\ttotal: 25.9s\tremaining: 37m 7s\n",
      "115:\tlearn: 0.0543639\ttest: 0.0546368\tbest: 0.0546368 (115)\ttotal: 26.1s\tremaining: 37m 3s\n",
      "116:\tlearn: 0.0543663\ttest: 0.0546132\tbest: 0.0546132 (116)\ttotal: 26.3s\tremaining: 36m 58s\n",
      "117:\tlearn: 0.0543103\ttest: 0.0545904\tbest: 0.0545904 (117)\ttotal: 26.4s\tremaining: 36m 52s\n",
      "118:\tlearn: 0.0543080\ttest: 0.0545561\tbest: 0.0545561 (118)\ttotal: 26.6s\tremaining: 36m 51s\n",
      "119:\tlearn: 0.0542479\ttest: 0.0545212\tbest: 0.0545212 (119)\ttotal: 26.8s\tremaining: 36m 49s\n",
      "120:\tlearn: 0.0542474\ttest: 0.0544998\tbest: 0.0544998 (120)\ttotal: 27s\tremaining: 36m 46s\n",
      "121:\tlearn: 0.0541975\ttest: 0.0544823\tbest: 0.0544823 (121)\ttotal: 27.2s\tremaining: 36m 43s\n",
      "122:\tlearn: 0.0541967\ttest: 0.0544620\tbest: 0.0544620 (122)\ttotal: 27.4s\tremaining: 36m 39s\n",
      "123:\tlearn: 0.0541899\ttest: 0.0544328\tbest: 0.0544328 (123)\ttotal: 27.6s\tremaining: 36m 39s\n",
      "124:\tlearn: 0.0541306\ttest: 0.0544040\tbest: 0.0544040 (124)\ttotal: 27.8s\tremaining: 36m 36s\n",
      "125:\tlearn: 0.0541336\ttest: 0.0543814\tbest: 0.0543814 (125)\ttotal: 28s\tremaining: 36m 35s\n",
      "126:\tlearn: 0.0540776\ttest: 0.0543607\tbest: 0.0543607 (126)\ttotal: 28.2s\tremaining: 36m 34s\n",
      "127:\tlearn: 0.0540818\ttest: 0.0543400\tbest: 0.0543400 (127)\ttotal: 28.5s\tremaining: 36m 35s\n",
      "128:\tlearn: 0.0540358\ttest: 0.0543143\tbest: 0.0543143 (128)\ttotal: 28.7s\tremaining: 36m 34s\n",
      "129:\tlearn: 0.0540328\ttest: 0.0542905\tbest: 0.0542905 (129)\ttotal: 28.9s\tremaining: 36m 31s\n",
      "130:\tlearn: 0.0539739\ttest: 0.0542713\tbest: 0.0542713 (130)\ttotal: 29s\tremaining: 36m 27s\n",
      "131:\tlearn: 0.0539650\ttest: 0.0542499\tbest: 0.0542499 (131)\ttotal: 29.2s\tremaining: 36m 24s\n",
      "132:\tlearn: 0.0539680\ttest: 0.0542332\tbest: 0.0542332 (132)\ttotal: 29.5s\tremaining: 36m 25s\n",
      "133:\tlearn: 0.0539232\ttest: 0.0542108\tbest: 0.0542108 (133)\ttotal: 29.7s\tremaining: 36m 24s\n",
      "134:\tlearn: 0.0539234\ttest: 0.0541922\tbest: 0.0541922 (134)\ttotal: 29.9s\tremaining: 36m 23s\n",
      "135:\tlearn: 0.0539132\ttest: 0.0541731\tbest: 0.0541731 (135)\ttotal: 30.1s\tremaining: 36m 23s\n",
      "136:\tlearn: 0.0538769\ttest: 0.0541587\tbest: 0.0541587 (136)\ttotal: 30.3s\tremaining: 36m 23s\n",
      "137:\tlearn: 0.0538736\ttest: 0.0541472\tbest: 0.0541472 (137)\ttotal: 30.6s\tremaining: 36m 23s\n",
      "138:\tlearn: 0.0538696\ttest: 0.0541343\tbest: 0.0541343 (138)\ttotal: 30.8s\tremaining: 36m 24s\n",
      "139:\tlearn: 0.0538289\ttest: 0.0541187\tbest: 0.0541187 (139)\ttotal: 31s\tremaining: 36m 23s\n",
      "140:\tlearn: 0.0538279\ttest: 0.0541052\tbest: 0.0541052 (140)\ttotal: 31.2s\tremaining: 36m 23s\n",
      "141:\tlearn: 0.0538191\ttest: 0.0540881\tbest: 0.0540881 (141)\ttotal: 31.5s\tremaining: 36m 23s\n",
      "142:\tlearn: 0.0537655\ttest: 0.0540660\tbest: 0.0540660 (142)\ttotal: 31.7s\tremaining: 36m 23s\n",
      "143:\tlearn: 0.0537515\ttest: 0.0540427\tbest: 0.0540427 (143)\ttotal: 31.9s\tremaining: 36m 23s\n",
      "144:\tlearn: 0.0537657\ttest: 0.0540312\tbest: 0.0540312 (144)\ttotal: 32.1s\tremaining: 36m 24s\n",
      "145:\tlearn: 0.0537647\ttest: 0.0540197\tbest: 0.0540197 (145)\ttotal: 32.4s\tremaining: 36m 25s\n",
      "146:\tlearn: 0.0537058\ttest: 0.0540078\tbest: 0.0540078 (146)\ttotal: 32.6s\tremaining: 36m 25s\n",
      "147:\tlearn: 0.0537178\ttest: 0.0539979\tbest: 0.0539979 (147)\ttotal: 32.8s\tremaining: 36m 23s\n",
      "148:\tlearn: 0.0537086\ttest: 0.0539782\tbest: 0.0539782 (148)\ttotal: 33s\tremaining: 36m 21s\n",
      "149:\tlearn: 0.0536639\ttest: 0.0539667\tbest: 0.0539667 (149)\ttotal: 33.2s\tremaining: 36m 22s\n",
      "150:\tlearn: 0.0536589\ttest: 0.0539576\tbest: 0.0539576 (150)\ttotal: 33.5s\tremaining: 36m 22s\n",
      "151:\tlearn: 0.0536608\ttest: 0.0539391\tbest: 0.0539391 (151)\ttotal: 33.7s\tremaining: 36m 22s\n",
      "152:\tlearn: 0.0536706\ttest: 0.0539321\tbest: 0.0539321 (152)\ttotal: 33.9s\tremaining: 36m 22s\n",
      "153:\tlearn: 0.0536607\ttest: 0.0539224\tbest: 0.0539224 (153)\ttotal: 34.1s\tremaining: 36m 19s\n",
      "154:\tlearn: 0.0536146\ttest: 0.0539097\tbest: 0.0539097 (154)\ttotal: 34.3s\tremaining: 36m 20s\n",
      "155:\tlearn: 0.0536085\ttest: 0.0538999\tbest: 0.0538999 (155)\ttotal: 34.5s\tremaining: 36m 19s\n",
      "156:\tlearn: 0.0536209\ttest: 0.0538903\tbest: 0.0538903 (156)\ttotal: 34.7s\tremaining: 36m 18s\n",
      "157:\tlearn: 0.0536144\ttest: 0.0538825\tbest: 0.0538825 (157)\ttotal: 35s\tremaining: 36m 19s\n",
      "158:\tlearn: 0.0535689\ttest: 0.0538753\tbest: 0.0538753 (158)\ttotal: 35.2s\tremaining: 36m 19s\n",
      "159:\tlearn: 0.0535663\ttest: 0.0538597\tbest: 0.0538597 (159)\ttotal: 35.5s\tremaining: 36m 20s\n",
      "160:\tlearn: 0.0535549\ttest: 0.0538440\tbest: 0.0538440 (160)\ttotal: 35.7s\tremaining: 36m 20s\n",
      "161:\tlearn: 0.0535653\ttest: 0.0538367\tbest: 0.0538367 (161)\ttotal: 35.9s\tremaining: 36m 20s\n",
      "162:\tlearn: 0.0535716\ttest: 0.0538272\tbest: 0.0538272 (162)\ttotal: 36.1s\tremaining: 36m 18s\n",
      "163:\tlearn: 0.0535604\ttest: 0.0538186\tbest: 0.0538186 (163)\ttotal: 36.3s\tremaining: 36m 18s\n",
      "164:\tlearn: 0.0535168\ttest: 0.0538106\tbest: 0.0538106 (164)\ttotal: 36.5s\tremaining: 36m 17s\n",
      "165:\tlearn: 0.0535050\ttest: 0.0538044\tbest: 0.0538044 (165)\ttotal: 36.8s\tremaining: 36m 18s\n",
      "166:\tlearn: 0.0535164\ttest: 0.0537988\tbest: 0.0537988 (166)\ttotal: 37s\tremaining: 36m 19s\n",
      "167:\tlearn: 0.0535235\ttest: 0.0537923\tbest: 0.0537923 (167)\ttotal: 37.2s\tremaining: 36m 16s\n",
      "168:\tlearn: 0.0535159\ttest: 0.0537874\tbest: 0.0537874 (168)\ttotal: 37.4s\tremaining: 36m 16s\n",
      "169:\tlearn: 0.0535161\ttest: 0.0537793\tbest: 0.0537793 (169)\ttotal: 37.6s\tremaining: 36m 13s\n",
      "170:\tlearn: 0.0534757\ttest: 0.0537744\tbest: 0.0537744 (170)\ttotal: 37.8s\tremaining: 36m 12s\n",
      "171:\tlearn: 0.0534765\ttest: 0.0537658\tbest: 0.0537658 (171)\ttotal: 38s\tremaining: 36m 12s\n",
      "172:\tlearn: 0.0534660\ttest: 0.0537579\tbest: 0.0537579 (172)\ttotal: 38.2s\tremaining: 36m 11s\n",
      "173:\tlearn: 0.0534781\ttest: 0.0537519\tbest: 0.0537519 (173)\ttotal: 38.4s\tremaining: 36m 10s\n",
      "174:\tlearn: 0.0534676\ttest: 0.0537379\tbest: 0.0537379 (174)\ttotal: 38.6s\tremaining: 36m 9s\n",
      "175:\tlearn: 0.0534590\ttest: 0.0537320\tbest: 0.0537320 (175)\ttotal: 38.9s\tremaining: 36m 9s\n",
      "176:\tlearn: 0.0534539\ttest: 0.0537193\tbest: 0.0537193 (176)\ttotal: 39.1s\tremaining: 36m 9s\n",
      "177:\tlearn: 0.0534100\ttest: 0.0537137\tbest: 0.0537137 (177)\ttotal: 39.3s\tremaining: 36m 9s\n",
      "178:\tlearn: 0.0534022\ttest: 0.0536996\tbest: 0.0536996 (178)\ttotal: 39.5s\tremaining: 36m 8s\n",
      "179:\tlearn: 0.0533973\ttest: 0.0536609\tbest: 0.0536609 (179)\ttotal: 39.8s\tremaining: 36m 9s\n",
      "180:\tlearn: 0.0533811\ttest: 0.0536507\tbest: 0.0536507 (180)\ttotal: 40s\tremaining: 36m 9s\n",
      "181:\tlearn: 0.0533811\ttest: 0.0536424\tbest: 0.0536424 (181)\ttotal: 40.2s\tremaining: 36m 8s\n",
      "182:\tlearn: 0.0533706\ttest: 0.0536083\tbest: 0.0536083 (182)\ttotal: 40.4s\tremaining: 36m 8s\n",
      "183:\tlearn: 0.0533704\ttest: 0.0536022\tbest: 0.0536022 (183)\ttotal: 40.6s\tremaining: 36m 8s\n",
      "184:\tlearn: 0.0533551\ttest: 0.0535849\tbest: 0.0535849 (184)\ttotal: 40.9s\tremaining: 36m 7s\n",
      "185:\tlearn: 0.0533575\ttest: 0.0535787\tbest: 0.0535787 (185)\ttotal: 41.1s\tremaining: 36m 6s\n",
      "186:\tlearn: 0.0533504\ttest: 0.0535668\tbest: 0.0535668 (186)\ttotal: 41.3s\tremaining: 36m 6s\n",
      "187:\tlearn: 0.0533007\ttest: 0.0535621\tbest: 0.0535621 (187)\ttotal: 41.5s\tremaining: 36m 6s\n",
      "188:\tlearn: 0.0533022\ttest: 0.0535566\tbest: 0.0535566 (188)\ttotal: 41.7s\tremaining: 36m 5s\n",
      "189:\tlearn: 0.0532989\ttest: 0.0535505\tbest: 0.0535505 (189)\ttotal: 41.9s\tremaining: 36m 4s\n",
      "190:\tlearn: 0.0532942\ttest: 0.0535472\tbest: 0.0535472 (190)\ttotal: 42.1s\tremaining: 36m 3s\n",
      "191:\tlearn: 0.0532966\ttest: 0.0535427\tbest: 0.0535427 (191)\ttotal: 42.3s\tremaining: 36m 2s\n",
      "192:\tlearn: 0.0532851\ttest: 0.0535361\tbest: 0.0535361 (192)\ttotal: 42.6s\tremaining: 36m 2s\n",
      "193:\tlearn: 0.0532833\ttest: 0.0535313\tbest: 0.0535313 (193)\ttotal: 42.7s\tremaining: 36m\n",
      "194:\tlearn: 0.0532797\ttest: 0.0535278\tbest: 0.0535278 (194)\ttotal: 42.9s\tremaining: 35m 56s\n",
      "195:\tlearn: 0.0532621\ttest: 0.0535051\tbest: 0.0535051 (195)\ttotal: 43.1s\tremaining: 35m 55s\n",
      "196:\tlearn: 0.0532357\ttest: 0.0534808\tbest: 0.0534808 (196)\ttotal: 43.3s\tremaining: 35m 55s\n",
      "197:\tlearn: 0.0532370\ttest: 0.0534750\tbest: 0.0534750 (197)\ttotal: 43.5s\tremaining: 35m 55s\n",
      "198:\tlearn: 0.0532419\ttest: 0.0534724\tbest: 0.0534724 (198)\ttotal: 43.7s\tremaining: 35m 53s\n",
      "199:\tlearn: 0.0532409\ttest: 0.0534680\tbest: 0.0534680 (199)\ttotal: 43.9s\tremaining: 35m 51s\n",
      "200:\tlearn: 0.0532286\ttest: 0.0534627\tbest: 0.0534627 (200)\ttotal: 44.1s\tremaining: 35m 51s\n",
      "201:\tlearn: 0.0532247\ttest: 0.0534576\tbest: 0.0534576 (201)\ttotal: 44.3s\tremaining: 35m 50s\n",
      "202:\tlearn: 0.0532250\ttest: 0.0534524\tbest: 0.0534524 (202)\ttotal: 44.5s\tremaining: 35m 49s\n",
      "203:\tlearn: 0.0532127\ttest: 0.0534293\tbest: 0.0534293 (203)\ttotal: 44.8s\tremaining: 35m 49s\n",
      "204:\tlearn: 0.0532132\ttest: 0.0534262\tbest: 0.0534262 (204)\ttotal: 44.9s\tremaining: 35m 46s\n",
      "205:\tlearn: 0.0531659\ttest: 0.0534237\tbest: 0.0534237 (205)\ttotal: 45.2s\tremaining: 35m 47s\n",
      "206:\tlearn: 0.0531670\ttest: 0.0534212\tbest: 0.0534212 (206)\ttotal: 45.4s\tremaining: 35m 45s\n",
      "207:\tlearn: 0.0531644\ttest: 0.0534171\tbest: 0.0534171 (207)\ttotal: 45.6s\tremaining: 35m 44s\n",
      "208:\tlearn: 0.0531654\ttest: 0.0534137\tbest: 0.0534137 (208)\ttotal: 45.8s\tremaining: 35m 43s\n",
      "209:\tlearn: 0.0531635\ttest: 0.0534097\tbest: 0.0534097 (209)\ttotal: 46s\tremaining: 35m 42s\n",
      "210:\tlearn: 0.0531491\ttest: 0.0534064\tbest: 0.0534064 (210)\ttotal: 46.2s\tremaining: 35m 43s\n",
      "211:\tlearn: 0.0531509\ttest: 0.0534045\tbest: 0.0534045 (211)\ttotal: 46.4s\tremaining: 35m 41s\n",
      "212:\tlearn: 0.0531530\ttest: 0.0534002\tbest: 0.0534002 (212)\ttotal: 46.6s\tremaining: 35m 41s\n",
      "213:\tlearn: 0.0531470\ttest: 0.0533971\tbest: 0.0533971 (213)\ttotal: 46.8s\tremaining: 35m 40s\n",
      "214:\tlearn: 0.0531456\ttest: 0.0533921\tbest: 0.0533921 (214)\ttotal: 47s\tremaining: 35m 39s\n",
      "215:\tlearn: 0.0531017\ttest: 0.0533744\tbest: 0.0533744 (215)\ttotal: 47.2s\tremaining: 35m 39s\n",
      "216:\tlearn: 0.0531032\ttest: 0.0533710\tbest: 0.0533710 (216)\ttotal: 47.4s\tremaining: 35m 37s\n",
      "217:\tlearn: 0.0530306\ttest: 0.0533561\tbest: 0.0533561 (217)\ttotal: 47.6s\tremaining: 35m 37s\n",
      "218:\tlearn: 0.0530310\ttest: 0.0533532\tbest: 0.0533532 (218)\ttotal: 47.8s\tremaining: 35m 36s\n",
      "219:\tlearn: 0.0530255\ttest: 0.0533492\tbest: 0.0533492 (219)\ttotal: 48s\tremaining: 35m 36s\n",
      "220:\tlearn: 0.0530262\ttest: 0.0533459\tbest: 0.0533459 (220)\ttotal: 48.3s\tremaining: 35m 35s\n",
      "221:\tlearn: 0.0530299\ttest: 0.0533447\tbest: 0.0533447 (221)\ttotal: 48.4s\tremaining: 35m 31s\n",
      "222:\tlearn: 0.0530127\ttest: 0.0533418\tbest: 0.0533418 (222)\ttotal: 48.6s\tremaining: 35m 30s\n",
      "223:\tlearn: 0.0530107\ttest: 0.0533383\tbest: 0.0533383 (223)\ttotal: 48.8s\tremaining: 35m 29s\n",
      "224:\tlearn: 0.0530081\ttest: 0.0533345\tbest: 0.0533345 (224)\ttotal: 49s\tremaining: 35m 29s\n",
      "225:\tlearn: 0.0530153\ttest: 0.0533328\tbest: 0.0533328 (225)\ttotal: 49.2s\tremaining: 35m 29s\n",
      "226:\tlearn: 0.0530107\ttest: 0.0533311\tbest: 0.0533311 (226)\ttotal: 49.4s\tremaining: 35m 28s\n",
      "227:\tlearn: 0.0530107\ttest: 0.0533276\tbest: 0.0533276 (227)\ttotal: 49.6s\tremaining: 35m 27s\n",
      "228:\tlearn: 0.0530135\ttest: 0.0533259\tbest: 0.0533259 (228)\ttotal: 49.9s\tremaining: 35m 27s\n",
      "229:\tlearn: 0.0530109\ttest: 0.0533238\tbest: 0.0533238 (229)\ttotal: 50.1s\tremaining: 35m 26s\n",
      "230:\tlearn: 0.0529624\ttest: 0.0533224\tbest: 0.0533224 (230)\ttotal: 50.3s\tremaining: 35m 26s\n",
      "231:\tlearn: 0.0529635\ttest: 0.0533209\tbest: 0.0533209 (231)\ttotal: 50.5s\tremaining: 35m 25s\n",
      "232:\tlearn: 0.0529582\ttest: 0.0533146\tbest: 0.0533146 (232)\ttotal: 50.7s\tremaining: 35m 25s\n",
      "233:\tlearn: 0.0529591\ttest: 0.0533132\tbest: 0.0533132 (233)\ttotal: 50.9s\tremaining: 35m 23s\n",
      "234:\tlearn: 0.0529497\ttest: 0.0532992\tbest: 0.0532992 (234)\ttotal: 51.1s\tremaining: 35m 22s\n",
      "235:\tlearn: 0.0529494\ttest: 0.0532962\tbest: 0.0532962 (235)\ttotal: 51.2s\tremaining: 35m 20s\n",
      "236:\tlearn: 0.0529394\ttest: 0.0532893\tbest: 0.0532893 (236)\ttotal: 51.4s\tremaining: 35m 19s\n",
      "237:\tlearn: 0.0529426\ttest: 0.0532877\tbest: 0.0532877 (237)\ttotal: 51.7s\tremaining: 35m 19s\n",
      "238:\tlearn: 0.0529469\ttest: 0.0532865\tbest: 0.0532865 (238)\ttotal: 51.9s\tremaining: 35m 19s\n",
      "239:\tlearn: 0.0529224\ttest: 0.0532573\tbest: 0.0532573 (239)\ttotal: 52.1s\tremaining: 35m 18s\n",
      "240:\tlearn: 0.0529218\ttest: 0.0532554\tbest: 0.0532554 (240)\ttotal: 52.3s\tremaining: 35m 17s\n",
      "241:\tlearn: 0.0529057\ttest: 0.0532536\tbest: 0.0532536 (241)\ttotal: 52.5s\tremaining: 35m 16s\n",
      "242:\tlearn: 0.0529059\ttest: 0.0532516\tbest: 0.0532516 (242)\ttotal: 52.7s\tremaining: 35m 16s\n",
      "243:\tlearn: 0.0529074\ttest: 0.0532503\tbest: 0.0532503 (243)\ttotal: 52.9s\tremaining: 35m 15s\n",
      "244:\tlearn: 0.0529003\ttest: 0.0532344\tbest: 0.0532344 (244)\ttotal: 53.1s\tremaining: 35m 15s\n",
      "245:\tlearn: 0.0529042\ttest: 0.0532328\tbest: 0.0532328 (245)\ttotal: 53.4s\tremaining: 35m 15s\n",
      "246:\tlearn: 0.0529021\ttest: 0.0532313\tbest: 0.0532313 (246)\ttotal: 53.6s\tremaining: 35m 15s\n",
      "247:\tlearn: 0.0529018\ttest: 0.0532302\tbest: 0.0532302 (247)\ttotal: 53.8s\tremaining: 35m 14s\n",
      "248:\tlearn: 0.0529006\ttest: 0.0532282\tbest: 0.0532282 (248)\ttotal: 54s\tremaining: 35m 13s\n",
      "249:\tlearn: 0.0528940\ttest: 0.0532220\tbest: 0.0532220 (249)\ttotal: 54.2s\tremaining: 35m 13s\n",
      "250:\tlearn: 0.0528891\ttest: 0.0532204\tbest: 0.0532204 (250)\ttotal: 54.4s\tremaining: 35m 12s\n",
      "251:\tlearn: 0.0528876\ttest: 0.0532159\tbest: 0.0532159 (251)\ttotal: 54.6s\tremaining: 35m 10s\n",
      "252:\tlearn: 0.0528858\ttest: 0.0532150\tbest: 0.0532150 (252)\ttotal: 54.8s\tremaining: 35m 10s\n",
      "253:\tlearn: 0.0528868\ttest: 0.0532120\tbest: 0.0532120 (253)\ttotal: 55s\tremaining: 35m 9s\n",
      "254:\tlearn: 0.0528876\ttest: 0.0531988\tbest: 0.0531988 (254)\ttotal: 55.2s\tremaining: 35m 10s\n",
      "255:\tlearn: 0.0528787\ttest: 0.0531868\tbest: 0.0531868 (255)\ttotal: 55.4s\tremaining: 35m 9s\n",
      "256:\tlearn: 0.0528818\ttest: 0.0531851\tbest: 0.0531851 (256)\ttotal: 55.6s\tremaining: 35m 7s\n",
      "257:\tlearn: 0.0528731\ttest: 0.0531751\tbest: 0.0531751 (257)\ttotal: 55.8s\tremaining: 35m 7s\n",
      "258:\tlearn: 0.0528743\ttest: 0.0531730\tbest: 0.0531730 (258)\ttotal: 56s\tremaining: 35m 5s\n",
      "259:\tlearn: 0.0528690\ttest: 0.0531713\tbest: 0.0531713 (259)\ttotal: 56.1s\tremaining: 35m 3s\n",
      "260:\tlearn: 0.0528710\ttest: 0.0531701\tbest: 0.0531701 (260)\ttotal: 56.3s\tremaining: 35m 2s\n",
      "261:\tlearn: 0.0528706\ttest: 0.0531688\tbest: 0.0531688 (261)\ttotal: 56.5s\tremaining: 35m\n",
      "262:\tlearn: 0.0528715\ttest: 0.0531677\tbest: 0.0531677 (262)\ttotal: 56.7s\tremaining: 35m\n",
      "263:\tlearn: 0.0528732\ttest: 0.0531666\tbest: 0.0531666 (263)\ttotal: 57s\tremaining: 35m\n",
      "264:\tlearn: 0.0528710\ttest: 0.0531619\tbest: 0.0531619 (264)\ttotal: 57.2s\tremaining: 35m\n",
      "265:\tlearn: 0.0528562\ttest: 0.0531610\tbest: 0.0531610 (265)\ttotal: 57.4s\tremaining: 35m\n",
      "266:\tlearn: 0.0528541\ttest: 0.0531590\tbest: 0.0531590 (266)\ttotal: 57.6s\tremaining: 34m 58s\n",
      "267:\tlearn: 0.0528555\ttest: 0.0531572\tbest: 0.0531572 (267)\ttotal: 57.7s\tremaining: 34m 56s\n",
      "268:\tlearn: 0.0528530\ttest: 0.0531542\tbest: 0.0531542 (268)\ttotal: 57.9s\tremaining: 34m 56s\n",
      "269:\tlearn: 0.0528472\ttest: 0.0531451\tbest: 0.0531451 (269)\ttotal: 58.1s\tremaining: 34m 54s\n",
      "270:\tlearn: 0.0528464\ttest: 0.0531438\tbest: 0.0531438 (270)\ttotal: 58.3s\tremaining: 34m 53s\n",
      "271:\tlearn: 0.0528454\ttest: 0.0531425\tbest: 0.0531425 (271)\ttotal: 58.5s\tremaining: 34m 53s\n",
      "272:\tlearn: 0.0528435\ttest: 0.0531398\tbest: 0.0531398 (272)\ttotal: 58.7s\tremaining: 34m 52s\n",
      "273:\tlearn: 0.0528457\ttest: 0.0531385\tbest: 0.0531385 (273)\ttotal: 58.9s\tremaining: 34m 52s\n",
      "274:\tlearn: 0.0528444\ttest: 0.0531368\tbest: 0.0531368 (274)\ttotal: 59.1s\tremaining: 34m 51s\n",
      "275:\tlearn: 0.0528432\ttest: 0.0531354\tbest: 0.0531354 (275)\ttotal: 59.3s\tremaining: 34m 50s\n",
      "276:\tlearn: 0.0528428\ttest: 0.0531348\tbest: 0.0531348 (276)\ttotal: 59.5s\tremaining: 34m 47s\n",
      "277:\tlearn: 0.0528425\ttest: 0.0531336\tbest: 0.0531336 (277)\ttotal: 59.7s\tremaining: 34m 46s\n",
      "278:\tlearn: 0.0528403\ttest: 0.0531318\tbest: 0.0531318 (278)\ttotal: 59.8s\tremaining: 34m 45s\n",
      "279:\tlearn: 0.0528401\ttest: 0.0531307\tbest: 0.0531307 (279)\ttotal: 1m\tremaining: 34m 44s\n",
      "280:\tlearn: 0.0528400\ttest: 0.0531285\tbest: 0.0531285 (280)\ttotal: 1m\tremaining: 34m 43s\n",
      "281:\tlearn: 0.0528394\ttest: 0.0531276\tbest: 0.0531276 (281)\ttotal: 1m\tremaining: 34m 42s\n",
      "282:\tlearn: 0.0528376\ttest: 0.0531256\tbest: 0.0531256 (282)\ttotal: 1m\tremaining: 34m 41s\n",
      "283:\tlearn: 0.0528199\ttest: 0.0531134\tbest: 0.0531134 (283)\ttotal: 1m\tremaining: 34m 40s\n",
      "284:\tlearn: 0.0528097\ttest: 0.0530926\tbest: 0.0530926 (284)\ttotal: 1m 1s\tremaining: 34m 39s\n",
      "285:\tlearn: 0.0528040\ttest: 0.0530866\tbest: 0.0530866 (285)\ttotal: 1m 1s\tremaining: 34m 38s\n",
      "286:\tlearn: 0.0527474\ttest: 0.0530669\tbest: 0.0530669 (286)\ttotal: 1m 1s\tremaining: 34m 37s\n",
      "287:\tlearn: 0.0527449\ttest: 0.0530641\tbest: 0.0530641 (287)\ttotal: 1m 1s\tremaining: 34m 36s\n",
      "288:\tlearn: 0.0527442\ttest: 0.0530627\tbest: 0.0530627 (288)\ttotal: 1m 1s\tremaining: 34m 35s\n",
      "289:\tlearn: 0.0527442\ttest: 0.0530611\tbest: 0.0530611 (289)\ttotal: 1m 1s\tremaining: 34m 35s\n",
      "290:\tlearn: 0.0527432\ttest: 0.0530596\tbest: 0.0530596 (290)\ttotal: 1m 2s\tremaining: 34m 35s\n",
      "291:\tlearn: 0.0527422\ttest: 0.0530586\tbest: 0.0530586 (291)\ttotal: 1m 2s\tremaining: 34m 34s\n",
      "292:\tlearn: 0.0527398\ttest: 0.0530567\tbest: 0.0530567 (292)\ttotal: 1m 2s\tremaining: 34m 33s\n",
      "293:\tlearn: 0.0527418\ttest: 0.0530522\tbest: 0.0530522 (293)\ttotal: 1m 2s\tremaining: 34m 33s\n",
      "294:\tlearn: 0.0527386\ttest: 0.0530430\tbest: 0.0530430 (294)\ttotal: 1m 3s\tremaining: 34m 33s\n",
      "295:\tlearn: 0.0526854\ttest: 0.0530386\tbest: 0.0530386 (295)\ttotal: 1m 3s\tremaining: 34m 33s\n",
      "296:\tlearn: 0.0526851\ttest: 0.0530383\tbest: 0.0530383 (296)\ttotal: 1m 3s\tremaining: 34m 31s\n",
      "297:\tlearn: 0.0526860\ttest: 0.0530378\tbest: 0.0530378 (297)\ttotal: 1m 3s\tremaining: 34m 31s\n",
      "298:\tlearn: 0.0526825\ttest: 0.0530322\tbest: 0.0530322 (298)\ttotal: 1m 3s\tremaining: 34m 30s\n",
      "299:\tlearn: 0.0526819\ttest: 0.0530304\tbest: 0.0530304 (299)\ttotal: 1m 4s\tremaining: 34m 29s\n",
      "300:\tlearn: 0.0526779\ttest: 0.0530279\tbest: 0.0530279 (300)\ttotal: 1m 4s\tremaining: 34m 28s\n",
      "301:\tlearn: 0.0526625\ttest: 0.0530151\tbest: 0.0530151 (301)\ttotal: 1m 4s\tremaining: 34m 27s\n",
      "302:\tlearn: 0.0526614\ttest: 0.0530142\tbest: 0.0530142 (302)\ttotal: 1m 4s\tremaining: 34m 26s\n",
      "303:\tlearn: 0.0526607\ttest: 0.0530104\tbest: 0.0530104 (303)\ttotal: 1m 4s\tremaining: 34m 25s\n",
      "304:\tlearn: 0.0526560\ttest: 0.0530066\tbest: 0.0530066 (304)\ttotal: 1m 4s\tremaining: 34m 25s\n",
      "305:\tlearn: 0.0526544\ttest: 0.0530019\tbest: 0.0530019 (305)\ttotal: 1m 5s\tremaining: 34m 24s\n",
      "306:\tlearn: 0.0526506\ttest: 0.0529987\tbest: 0.0529987 (306)\ttotal: 1m 5s\tremaining: 34m 23s\n",
      "307:\tlearn: 0.0526499\ttest: 0.0529971\tbest: 0.0529971 (307)\ttotal: 1m 5s\tremaining: 34m 23s\n",
      "308:\tlearn: 0.0526529\ttest: 0.0529938\tbest: 0.0529938 (308)\ttotal: 1m 5s\tremaining: 34m 22s\n",
      "309:\tlearn: 0.0526531\ttest: 0.0529912\tbest: 0.0529912 (309)\ttotal: 1m 5s\tremaining: 34m 22s\n",
      "310:\tlearn: 0.0526508\ttest: 0.0529829\tbest: 0.0529829 (310)\ttotal: 1m 6s\tremaining: 34m 23s\n",
      "311:\tlearn: 0.0526493\ttest: 0.0529810\tbest: 0.0529810 (311)\ttotal: 1m 6s\tremaining: 34m 22s\n",
      "312:\tlearn: 0.0526321\ttest: 0.0529803\tbest: 0.0529803 (312)\ttotal: 1m 6s\tremaining: 34m 23s\n",
      "313:\tlearn: 0.0526301\ttest: 0.0529783\tbest: 0.0529783 (313)\ttotal: 1m 6s\tremaining: 34m 22s\n",
      "314:\tlearn: 0.0526067\ttest: 0.0529722\tbest: 0.0529722 (314)\ttotal: 1m 7s\tremaining: 34m 21s\n",
      "315:\tlearn: 0.0526061\ttest: 0.0529716\tbest: 0.0529716 (315)\ttotal: 1m 7s\tremaining: 34m 21s\n",
      "316:\tlearn: 0.0526133\ttest: 0.0529553\tbest: 0.0529553 (316)\ttotal: 1m 7s\tremaining: 34m 20s\n",
      "317:\tlearn: 0.0525935\ttest: 0.0529531\tbest: 0.0529531 (317)\ttotal: 1m 7s\tremaining: 34m 19s\n",
      "318:\tlearn: 0.0525949\ttest: 0.0529525\tbest: 0.0529525 (318)\ttotal: 1m 7s\tremaining: 34m 18s\n",
      "319:\tlearn: 0.0525949\ttest: 0.0529517\tbest: 0.0529517 (319)\ttotal: 1m 8s\tremaining: 34m 18s\n",
      "320:\tlearn: 0.0525937\ttest: 0.0529507\tbest: 0.0529507 (320)\ttotal: 1m 8s\tremaining: 34m 18s\n",
      "321:\tlearn: 0.0525931\ttest: 0.0529500\tbest: 0.0529500 (321)\ttotal: 1m 8s\tremaining: 34m 17s\n",
      "322:\tlearn: 0.0525920\ttest: 0.0529485\tbest: 0.0529485 (322)\ttotal: 1m 8s\tremaining: 34m 15s\n",
      "323:\tlearn: 0.0525905\ttest: 0.0529480\tbest: 0.0529480 (323)\ttotal: 1m 8s\tremaining: 34m 15s\n",
      "324:\tlearn: 0.0525879\ttest: 0.0529405\tbest: 0.0529405 (324)\ttotal: 1m 9s\tremaining: 34m 14s\n",
      "325:\tlearn: 0.0525791\ttest: 0.0529315\tbest: 0.0529315 (325)\ttotal: 1m 9s\tremaining: 34m 13s\n",
      "326:\tlearn: 0.0525922\ttest: 0.0529275\tbest: 0.0529275 (326)\ttotal: 1m 9s\tremaining: 34m 12s\n",
      "327:\tlearn: 0.0525762\ttest: 0.0529248\tbest: 0.0529248 (327)\ttotal: 1m 9s\tremaining: 34m 11s\n",
      "328:\tlearn: 0.0525754\ttest: 0.0529190\tbest: 0.0529190 (328)\ttotal: 1m 9s\tremaining: 34m 10s\n",
      "329:\tlearn: 0.0525742\ttest: 0.0529176\tbest: 0.0529176 (329)\ttotal: 1m 9s\tremaining: 34m 9s\n",
      "330:\tlearn: 0.0525729\ttest: 0.0529166\tbest: 0.0529166 (330)\ttotal: 1m 10s\tremaining: 34m 8s\n",
      "331:\tlearn: 0.0525722\ttest: 0.0529158\tbest: 0.0529158 (331)\ttotal: 1m 10s\tremaining: 34m 7s\n",
      "332:\tlearn: 0.0525692\ttest: 0.0529094\tbest: 0.0529094 (332)\ttotal: 1m 10s\tremaining: 34m 7s\n",
      "333:\tlearn: 0.0525676\ttest: 0.0529076\tbest: 0.0529076 (333)\ttotal: 1m 10s\tremaining: 34m 7s\n",
      "334:\tlearn: 0.0525702\ttest: 0.0529047\tbest: 0.0529047 (334)\ttotal: 1m 10s\tremaining: 34m 7s\n",
      "335:\tlearn: 0.0525665\ttest: 0.0528967\tbest: 0.0528967 (335)\ttotal: 1m 11s\tremaining: 34m 6s\n",
      "336:\tlearn: 0.0525548\ttest: 0.0528940\tbest: 0.0528940 (336)\ttotal: 1m 11s\tremaining: 34m 6s\n",
      "337:\tlearn: 0.0525540\ttest: 0.0528917\tbest: 0.0528917 (337)\ttotal: 1m 11s\tremaining: 34m 6s\n",
      "338:\tlearn: 0.0525514\ttest: 0.0528866\tbest: 0.0528866 (338)\ttotal: 1m 11s\tremaining: 34m 6s\n",
      "339:\tlearn: 0.0525513\ttest: 0.0528866\tbest: 0.0528866 (339)\ttotal: 1m 11s\tremaining: 34m 4s\n",
      "340:\tlearn: 0.0525509\ttest: 0.0528859\tbest: 0.0528859 (340)\ttotal: 1m 12s\tremaining: 34m 4s\n",
      "341:\tlearn: 0.0525492\ttest: 0.0528815\tbest: 0.0528815 (341)\ttotal: 1m 12s\tremaining: 34m 4s\n",
      "342:\tlearn: 0.0525485\ttest: 0.0528810\tbest: 0.0528810 (342)\ttotal: 1m 12s\tremaining: 34m 3s\n",
      "343:\tlearn: 0.0525405\ttest: 0.0528771\tbest: 0.0528771 (343)\ttotal: 1m 12s\tremaining: 34m 3s\n",
      "344:\tlearn: 0.0525402\ttest: 0.0528765\tbest: 0.0528765 (344)\ttotal: 1m 12s\tremaining: 34m 1s\n",
      "345:\tlearn: 0.0525394\ttest: 0.0528755\tbest: 0.0528755 (345)\ttotal: 1m 13s\tremaining: 34m 1s\n",
      "346:\tlearn: 0.0525380\ttest: 0.0528741\tbest: 0.0528741 (346)\ttotal: 1m 13s\tremaining: 34m\n",
      "347:\tlearn: 0.0525368\ttest: 0.0528731\tbest: 0.0528731 (347)\ttotal: 1m 13s\tremaining: 34m\n",
      "348:\tlearn: 0.0525349\ttest: 0.0528694\tbest: 0.0528694 (348)\ttotal: 1m 13s\tremaining: 33m 59s\n",
      "349:\tlearn: 0.0525346\ttest: 0.0528686\tbest: 0.0528686 (349)\ttotal: 1m 13s\tremaining: 33m 58s\n",
      "350:\tlearn: 0.0525334\ttest: 0.0528659\tbest: 0.0528659 (350)\ttotal: 1m 14s\tremaining: 33m 58s\n",
      "351:\tlearn: 0.0525317\ttest: 0.0528609\tbest: 0.0528609 (351)\ttotal: 1m 14s\tremaining: 33m 58s\n",
      "352:\tlearn: 0.0525288\ttest: 0.0528561\tbest: 0.0528561 (352)\ttotal: 1m 14s\tremaining: 33m 57s\n",
      "353:\tlearn: 0.0525222\ttest: 0.0528519\tbest: 0.0528519 (353)\ttotal: 1m 14s\tremaining: 33m 57s\n",
      "354:\tlearn: 0.0525216\ttest: 0.0528512\tbest: 0.0528512 (354)\ttotal: 1m 14s\tremaining: 33m 57s\n",
      "355:\tlearn: 0.0525203\ttest: 0.0528504\tbest: 0.0528504 (355)\ttotal: 1m 15s\tremaining: 33m 56s\n",
      "356:\tlearn: 0.0525198\ttest: 0.0528497\tbest: 0.0528497 (356)\ttotal: 1m 15s\tremaining: 33m 56s\n",
      "357:\tlearn: 0.0525128\ttest: 0.0528395\tbest: 0.0528395 (357)\ttotal: 1m 15s\tremaining: 33m 55s\n",
      "358:\tlearn: 0.0525146\ttest: 0.0528374\tbest: 0.0528374 (358)\ttotal: 1m 15s\tremaining: 33m 55s\n",
      "359:\tlearn: 0.0525092\ttest: 0.0528311\tbest: 0.0528311 (359)\ttotal: 1m 15s\tremaining: 33m 55s\n",
      "360:\tlearn: 0.0525119\ttest: 0.0528299\tbest: 0.0528299 (360)\ttotal: 1m 16s\tremaining: 33m 53s\n",
      "361:\tlearn: 0.0525112\ttest: 0.0528271\tbest: 0.0528271 (361)\ttotal: 1m 16s\tremaining: 33m 53s\n",
      "362:\tlearn: 0.0525090\ttest: 0.0528258\tbest: 0.0528258 (362)\ttotal: 1m 16s\tremaining: 33m 53s\n",
      "363:\tlearn: 0.0525072\ttest: 0.0528241\tbest: 0.0528241 (363)\ttotal: 1m 16s\tremaining: 33m 52s\n",
      "364:\tlearn: 0.0525071\ttest: 0.0528237\tbest: 0.0528237 (364)\ttotal: 1m 16s\tremaining: 33m 52s\n",
      "365:\tlearn: 0.0525051\ttest: 0.0528204\tbest: 0.0528204 (365)\ttotal: 1m 17s\tremaining: 33m 51s\n",
      "366:\tlearn: 0.0525047\ttest: 0.0528201\tbest: 0.0528201 (366)\ttotal: 1m 17s\tremaining: 33m 51s\n",
      "367:\tlearn: 0.0525043\ttest: 0.0528171\tbest: 0.0528171 (367)\ttotal: 1m 17s\tremaining: 33m 50s\n",
      "368:\tlearn: 0.0525041\ttest: 0.0528166\tbest: 0.0528166 (368)\ttotal: 1m 17s\tremaining: 33m 50s\n",
      "369:\tlearn: 0.0525036\ttest: 0.0528159\tbest: 0.0528159 (369)\ttotal: 1m 17s\tremaining: 33m 49s\n",
      "370:\tlearn: 0.0525034\ttest: 0.0528154\tbest: 0.0528154 (370)\ttotal: 1m 18s\tremaining: 33m 49s\n",
      "371:\tlearn: 0.0525028\ttest: 0.0528147\tbest: 0.0528147 (371)\ttotal: 1m 18s\tremaining: 33m 49s\n",
      "372:\tlearn: 0.0525032\ttest: 0.0528135\tbest: 0.0528135 (372)\ttotal: 1m 18s\tremaining: 33m 49s\n",
      "373:\tlearn: 0.0525017\ttest: 0.0528129\tbest: 0.0528129 (373)\ttotal: 1m 18s\tremaining: 33m 48s\n",
      "374:\tlearn: 0.0524997\ttest: 0.0528116\tbest: 0.0528116 (374)\ttotal: 1m 19s\tremaining: 33m 48s\n",
      "375:\tlearn: 0.0525004\ttest: 0.0528116\tbest: 0.0528116 (375)\ttotal: 1m 19s\tremaining: 33m 47s\n",
      "376:\tlearn: 0.0525001\ttest: 0.0528112\tbest: 0.0528112 (376)\ttotal: 1m 19s\tremaining: 33m 47s\n",
      "377:\tlearn: 0.0524993\ttest: 0.0528102\tbest: 0.0528102 (377)\ttotal: 1m 19s\tremaining: 33m 46s\n",
      "378:\tlearn: 0.0524981\ttest: 0.0528068\tbest: 0.0528068 (378)\ttotal: 1m 19s\tremaining: 33m 46s\n",
      "379:\tlearn: 0.0524974\ttest: 0.0528060\tbest: 0.0528060 (379)\ttotal: 1m 20s\tremaining: 33m 46s\n",
      "380:\tlearn: 0.0524965\ttest: 0.0528048\tbest: 0.0528048 (380)\ttotal: 1m 20s\tremaining: 33m 44s\n",
      "381:\tlearn: 0.0524941\ttest: 0.0528034\tbest: 0.0528034 (381)\ttotal: 1m 20s\tremaining: 33m 44s\n",
      "382:\tlearn: 0.0524937\ttest: 0.0528030\tbest: 0.0528030 (382)\ttotal: 1m 20s\tremaining: 33m 43s\n",
      "383:\tlearn: 0.0524904\ttest: 0.0527973\tbest: 0.0527973 (383)\ttotal: 1m 20s\tremaining: 33m 42s\n",
      "384:\tlearn: 0.0524904\ttest: 0.0527970\tbest: 0.0527970 (384)\ttotal: 1m 20s\tremaining: 33m 42s\n",
      "385:\tlearn: 0.0524757\ttest: 0.0527955\tbest: 0.0527955 (385)\ttotal: 1m 21s\tremaining: 33m 42s\n",
      "386:\tlearn: 0.0524541\ttest: 0.0527931\tbest: 0.0527931 (386)\ttotal: 1m 21s\tremaining: 33m 41s\n",
      "387:\tlearn: 0.0524739\ttest: 0.0527915\tbest: 0.0527915 (387)\ttotal: 1m 21s\tremaining: 33m 40s\n",
      "388:\tlearn: 0.0524508\ttest: 0.0527899\tbest: 0.0527899 (388)\ttotal: 1m 21s\tremaining: 33m 40s\n",
      "389:\tlearn: 0.0524491\ttest: 0.0527876\tbest: 0.0527876 (389)\ttotal: 1m 21s\tremaining: 33m 39s\n",
      "390:\tlearn: 0.0524498\ttest: 0.0527863\tbest: 0.0527863 (390)\ttotal: 1m 22s\tremaining: 33m 39s\n",
      "391:\tlearn: 0.0524457\ttest: 0.0527818\tbest: 0.0527818 (391)\ttotal: 1m 22s\tremaining: 33m 39s\n",
      "392:\tlearn: 0.0524416\ttest: 0.0527716\tbest: 0.0527716 (392)\ttotal: 1m 22s\tremaining: 33m 39s\n",
      "393:\tlearn: 0.0524408\ttest: 0.0527709\tbest: 0.0527709 (393)\ttotal: 1m 22s\tremaining: 33m 38s\n",
      "394:\tlearn: 0.0524411\ttest: 0.0527697\tbest: 0.0527697 (394)\ttotal: 1m 22s\tremaining: 33m 37s\n",
      "395:\tlearn: 0.0524401\ttest: 0.0527682\tbest: 0.0527682 (395)\ttotal: 1m 23s\tremaining: 33m 36s\n",
      "396:\tlearn: 0.0524392\ttest: 0.0527657\tbest: 0.0527657 (396)\ttotal: 1m 23s\tremaining: 33m 36s\n",
      "397:\tlearn: 0.0524415\ttest: 0.0527645\tbest: 0.0527645 (397)\ttotal: 1m 23s\tremaining: 33m 35s\n",
      "398:\tlearn: 0.0524401\ttest: 0.0527633\tbest: 0.0527633 (398)\ttotal: 1m 23s\tremaining: 33m 36s\n",
      "399:\tlearn: 0.0524195\ttest: 0.0527586\tbest: 0.0527586 (399)\ttotal: 1m 23s\tremaining: 33m 35s\n",
      "400:\tlearn: 0.0524356\ttest: 0.0527575\tbest: 0.0527575 (400)\ttotal: 1m 24s\tremaining: 33m 35s\n",
      "401:\tlearn: 0.0524135\ttest: 0.0527557\tbest: 0.0527557 (401)\ttotal: 1m 24s\tremaining: 33m 36s\n",
      "402:\tlearn: 0.0524116\ttest: 0.0527545\tbest: 0.0527545 (402)\ttotal: 1m 24s\tremaining: 33m 35s\n",
      "403:\tlearn: 0.0524111\ttest: 0.0527540\tbest: 0.0527540 (403)\ttotal: 1m 24s\tremaining: 33m 35s\n",
      "404:\tlearn: 0.0524129\ttest: 0.0527525\tbest: 0.0527525 (404)\ttotal: 1m 25s\tremaining: 33m 34s\n",
      "405:\tlearn: 0.0524119\ttest: 0.0527512\tbest: 0.0527512 (405)\ttotal: 1m 25s\tremaining: 33m 34s\n",
      "406:\tlearn: 0.0524154\ttest: 0.0527489\tbest: 0.0527489 (406)\ttotal: 1m 25s\tremaining: 33m 33s\n",
      "407:\tlearn: 0.0524111\ttest: 0.0527467\tbest: 0.0527467 (407)\ttotal: 1m 25s\tremaining: 33m 33s\n",
      "408:\tlearn: 0.0524103\ttest: 0.0527463\tbest: 0.0527463 (408)\ttotal: 1m 25s\tremaining: 33m 33s\n",
      "409:\tlearn: 0.0524088\ttest: 0.0527435\tbest: 0.0527435 (409)\ttotal: 1m 26s\tremaining: 33m 33s\n",
      "410:\tlearn: 0.0524090\ttest: 0.0527431\tbest: 0.0527431 (410)\ttotal: 1m 26s\tremaining: 33m 33s\n",
      "411:\tlearn: 0.0524080\ttest: 0.0527415\tbest: 0.0527415 (411)\ttotal: 1m 26s\tremaining: 33m 33s\n",
      "412:\tlearn: 0.0524089\ttest: 0.0527390\tbest: 0.0527390 (412)\ttotal: 1m 26s\tremaining: 33m 33s\n",
      "413:\tlearn: 0.0524050\ttest: 0.0527376\tbest: 0.0527376 (413)\ttotal: 1m 26s\tremaining: 33m 33s\n",
      "414:\tlearn: 0.0524047\ttest: 0.0527374\tbest: 0.0527374 (414)\ttotal: 1m 27s\tremaining: 33m 32s\n",
      "415:\tlearn: 0.0524075\ttest: 0.0527344\tbest: 0.0527344 (415)\ttotal: 1m 27s\tremaining: 33m 32s\n",
      "416:\tlearn: 0.0523890\ttest: 0.0527263\tbest: 0.0527263 (416)\ttotal: 1m 27s\tremaining: 33m 32s\n",
      "417:\tlearn: 0.0523872\ttest: 0.0527231\tbest: 0.0527231 (417)\ttotal: 1m 27s\tremaining: 33m 32s\n",
      "418:\tlearn: 0.0523866\ttest: 0.0527225\tbest: 0.0527225 (418)\ttotal: 1m 27s\tremaining: 33m 31s\n",
      "419:\tlearn: 0.0523863\ttest: 0.0527219\tbest: 0.0527219 (419)\ttotal: 1m 28s\tremaining: 33m 31s\n",
      "420:\tlearn: 0.0523874\ttest: 0.0527208\tbest: 0.0527208 (420)\ttotal: 1m 28s\tremaining: 33m 30s\n",
      "421:\tlearn: 0.0523866\ttest: 0.0527187\tbest: 0.0527187 (421)\ttotal: 1m 28s\tremaining: 33m 30s\n",
      "422:\tlearn: 0.0523899\ttest: 0.0527164\tbest: 0.0527164 (422)\ttotal: 1m 28s\tremaining: 33m 30s\n",
      "423:\tlearn: 0.0523876\ttest: 0.0527142\tbest: 0.0527142 (423)\ttotal: 1m 29s\tremaining: 33m 30s\n",
      "424:\tlearn: 0.0523850\ttest: 0.0527122\tbest: 0.0527122 (424)\ttotal: 1m 29s\tremaining: 33m 31s\n",
      "425:\tlearn: 0.0523853\ttest: 0.0527121\tbest: 0.0527121 (425)\ttotal: 1m 29s\tremaining: 33m 30s\n",
      "426:\tlearn: 0.0523851\ttest: 0.0527119\tbest: 0.0527119 (426)\ttotal: 1m 29s\tremaining: 33m 30s\n",
      "427:\tlearn: 0.0523859\ttest: 0.0527111\tbest: 0.0527111 (427)\ttotal: 1m 29s\tremaining: 33m 29s\n",
      "428:\tlearn: 0.0523864\ttest: 0.0527081\tbest: 0.0527081 (428)\ttotal: 1m 30s\tremaining: 33m 29s\n",
      "429:\tlearn: 0.0523851\ttest: 0.0527061\tbest: 0.0527061 (429)\ttotal: 1m 30s\tremaining: 33m 29s\n",
      "430:\tlearn: 0.0523837\ttest: 0.0527046\tbest: 0.0527046 (430)\ttotal: 1m 30s\tremaining: 33m 29s\n",
      "431:\tlearn: 0.0523836\ttest: 0.0527044\tbest: 0.0527044 (431)\ttotal: 1m 30s\tremaining: 33m 27s\n",
      "432:\tlearn: 0.0523843\ttest: 0.0527043\tbest: 0.0527043 (432)\ttotal: 1m 30s\tremaining: 33m 26s\n",
      "433:\tlearn: 0.0523816\ttest: 0.0527021\tbest: 0.0527021 (433)\ttotal: 1m 31s\tremaining: 33m 26s\n",
      "434:\tlearn: 0.0523810\ttest: 0.0527002\tbest: 0.0527002 (434)\ttotal: 1m 31s\tremaining: 33m 26s\n",
      "435:\tlearn: 0.0523805\ttest: 0.0526992\tbest: 0.0526992 (435)\ttotal: 1m 31s\tremaining: 33m 26s\n",
      "436:\tlearn: 0.0523790\ttest: 0.0526979\tbest: 0.0526979 (436)\ttotal: 1m 31s\tremaining: 33m 25s\n",
      "437:\tlearn: 0.0523248\ttest: 0.0526956\tbest: 0.0526956 (437)\ttotal: 1m 31s\tremaining: 33m 25s\n",
      "438:\tlearn: 0.0523261\ttest: 0.0526939\tbest: 0.0526939 (438)\ttotal: 1m 32s\tremaining: 33m 26s\n",
      "439:\tlearn: 0.0523257\ttest: 0.0526937\tbest: 0.0526937 (439)\ttotal: 1m 32s\tremaining: 33m 25s\n",
      "440:\tlearn: 0.0523255\ttest: 0.0526934\tbest: 0.0526934 (440)\ttotal: 1m 32s\tremaining: 33m 25s\n",
      "441:\tlearn: 0.0523246\ttest: 0.0526918\tbest: 0.0526918 (441)\ttotal: 1m 32s\tremaining: 33m 25s\n",
      "442:\tlearn: 0.0523238\ttest: 0.0526908\tbest: 0.0526908 (442)\ttotal: 1m 32s\tremaining: 33m 25s\n",
      "443:\tlearn: 0.0523262\ttest: 0.0526902\tbest: 0.0526902 (443)\ttotal: 1m 33s\tremaining: 33m 25s\n",
      "444:\tlearn: 0.0523257\ttest: 0.0526897\tbest: 0.0526897 (444)\ttotal: 1m 33s\tremaining: 33m 25s\n",
      "445:\tlearn: 0.0523234\ttest: 0.0526877\tbest: 0.0526877 (445)\ttotal: 1m 33s\tremaining: 33m 24s\n",
      "446:\tlearn: 0.0523225\ttest: 0.0526868\tbest: 0.0526868 (446)\ttotal: 1m 33s\tremaining: 33m 24s\n",
      "447:\tlearn: 0.0523203\ttest: 0.0526844\tbest: 0.0526844 (447)\ttotal: 1m 34s\tremaining: 33m 25s\n",
      "448:\tlearn: 0.0523163\ttest: 0.0526806\tbest: 0.0526806 (448)\ttotal: 1m 34s\tremaining: 33m 25s\n",
      "449:\tlearn: 0.0523159\ttest: 0.0526785\tbest: 0.0526785 (449)\ttotal: 1m 34s\tremaining: 33m 24s\n",
      "450:\tlearn: 0.0523151\ttest: 0.0526775\tbest: 0.0526775 (450)\ttotal: 1m 34s\tremaining: 33m 24s\n",
      "451:\tlearn: 0.0523141\ttest: 0.0526765\tbest: 0.0526765 (451)\ttotal: 1m 34s\tremaining: 33m 23s\n",
      "452:\tlearn: 0.0523106\ttest: 0.0526731\tbest: 0.0526731 (452)\ttotal: 1m 35s\tremaining: 33m 22s\n",
      "453:\tlearn: 0.0523112\ttest: 0.0526731\tbest: 0.0526731 (453)\ttotal: 1m 35s\tremaining: 33m 21s\n",
      "454:\tlearn: 0.0523095\ttest: 0.0526725\tbest: 0.0526725 (454)\ttotal: 1m 35s\tremaining: 33m 20s\n",
      "455:\tlearn: 0.0523131\ttest: 0.0526712\tbest: 0.0526712 (455)\ttotal: 1m 35s\tremaining: 33m 20s\n",
      "456:\tlearn: 0.0523132\ttest: 0.0526708\tbest: 0.0526708 (456)\ttotal: 1m 35s\tremaining: 33m 19s\n",
      "457:\tlearn: 0.0523131\ttest: 0.0526703\tbest: 0.0526703 (457)\ttotal: 1m 35s\tremaining: 33m 19s\n",
      "458:\tlearn: 0.0523108\ttest: 0.0526694\tbest: 0.0526694 (458)\ttotal: 1m 36s\tremaining: 33m 18s\n",
      "459:\tlearn: 0.0523080\ttest: 0.0526671\tbest: 0.0526671 (459)\ttotal: 1m 36s\tremaining: 33m 19s\n",
      "460:\tlearn: 0.0523082\ttest: 0.0526664\tbest: 0.0526664 (460)\ttotal: 1m 36s\tremaining: 33m 18s\n",
      "461:\tlearn: 0.0523078\ttest: 0.0526663\tbest: 0.0526663 (461)\ttotal: 1m 36s\tremaining: 33m 17s\n",
      "462:\tlearn: 0.0523107\ttest: 0.0526649\tbest: 0.0526649 (462)\ttotal: 1m 36s\tremaining: 33m 17s\n",
      "463:\tlearn: 0.0523094\ttest: 0.0526641\tbest: 0.0526641 (463)\ttotal: 1m 37s\tremaining: 33m 17s\n",
      "464:\tlearn: 0.0523092\ttest: 0.0526636\tbest: 0.0526636 (464)\ttotal: 1m 37s\tremaining: 33m 17s\n",
      "465:\tlearn: 0.0523082\ttest: 0.0526627\tbest: 0.0526627 (465)\ttotal: 1m 37s\tremaining: 33m 16s\n",
      "466:\tlearn: 0.0523083\ttest: 0.0526627\tbest: 0.0526627 (466)\ttotal: 1m 37s\tremaining: 33m 15s\n",
      "467:\tlearn: 0.0523081\ttest: 0.0526623\tbest: 0.0526623 (467)\ttotal: 1m 37s\tremaining: 33m 15s\n",
      "468:\tlearn: 0.0523085\ttest: 0.0526621\tbest: 0.0526621 (468)\ttotal: 1m 38s\tremaining: 33m 14s\n",
      "469:\tlearn: 0.0523083\ttest: 0.0526613\tbest: 0.0526613 (469)\ttotal: 1m 38s\tremaining: 33m 14s\n",
      "470:\tlearn: 0.0523083\ttest: 0.0526613\tbest: 0.0526613 (470)\ttotal: 1m 38s\tremaining: 33m 12s\n",
      "471:\tlearn: 0.0523030\ttest: 0.0526601\tbest: 0.0526601 (471)\ttotal: 1m 38s\tremaining: 33m 12s\n",
      "472:\tlearn: 0.0523030\ttest: 0.0526601\tbest: 0.0526601 (471)\ttotal: 1m 38s\tremaining: 33m 11s\n",
      "473:\tlearn: 0.0523042\ttest: 0.0526592\tbest: 0.0526592 (473)\ttotal: 1m 39s\tremaining: 33m 11s\n",
      "474:\tlearn: 0.0523069\ttest: 0.0526579\tbest: 0.0526579 (474)\ttotal: 1m 39s\tremaining: 33m 11s\n",
      "475:\tlearn: 0.0523060\ttest: 0.0526566\tbest: 0.0526566 (475)\ttotal: 1m 39s\tremaining: 33m 10s\n",
      "476:\tlearn: 0.0522980\ttest: 0.0526550\tbest: 0.0526550 (476)\ttotal: 1m 39s\tremaining: 33m 10s\n",
      "477:\tlearn: 0.0522945\ttest: 0.0526478\tbest: 0.0526478 (477)\ttotal: 1m 39s\tremaining: 33m 10s\n",
      "478:\tlearn: 0.0522931\ttest: 0.0526462\tbest: 0.0526462 (478)\ttotal: 1m 40s\tremaining: 33m 10s\n",
      "479:\tlearn: 0.0522927\ttest: 0.0526454\tbest: 0.0526454 (479)\ttotal: 1m 40s\tremaining: 33m 10s\n",
      "480:\tlearn: 0.0522912\ttest: 0.0526441\tbest: 0.0526441 (480)\ttotal: 1m 40s\tremaining: 33m 8s\n",
      "481:\tlearn: 0.0522946\ttest: 0.0526432\tbest: 0.0526432 (481)\ttotal: 1m 40s\tremaining: 33m 8s\n",
      "482:\tlearn: 0.0522931\ttest: 0.0526429\tbest: 0.0526429 (482)\ttotal: 1m 40s\tremaining: 33m 8s\n",
      "483:\tlearn: 0.0522917\ttest: 0.0526419\tbest: 0.0526419 (483)\ttotal: 1m 41s\tremaining: 33m 7s\n",
      "484:\tlearn: 0.0522904\ttest: 0.0526392\tbest: 0.0526392 (484)\ttotal: 1m 41s\tremaining: 33m 7s\n",
      "485:\tlearn: 0.0522895\ttest: 0.0526375\tbest: 0.0526375 (485)\ttotal: 1m 41s\tremaining: 33m 6s\n",
      "486:\tlearn: 0.0522886\ttest: 0.0526367\tbest: 0.0526367 (486)\ttotal: 1m 41s\tremaining: 33m 6s\n",
      "487:\tlearn: 0.0522892\ttest: 0.0526366\tbest: 0.0526366 (487)\ttotal: 1m 41s\tremaining: 33m 5s\n",
      "488:\tlearn: 0.0522891\ttest: 0.0526365\tbest: 0.0526365 (488)\ttotal: 1m 42s\tremaining: 33m 4s\n",
      "489:\tlearn: 0.0522878\ttest: 0.0526353\tbest: 0.0526353 (489)\ttotal: 1m 42s\tremaining: 33m 3s\n",
      "490:\tlearn: 0.0522876\ttest: 0.0526350\tbest: 0.0526350 (490)\ttotal: 1m 42s\tremaining: 33m 3s\n",
      "491:\tlearn: 0.0522870\ttest: 0.0526341\tbest: 0.0526341 (491)\ttotal: 1m 42s\tremaining: 33m 3s\n",
      "492:\tlearn: 0.0522870\ttest: 0.0526341\tbest: 0.0526341 (492)\ttotal: 1m 42s\tremaining: 33m 2s\n",
      "493:\tlearn: 0.0522858\ttest: 0.0526330\tbest: 0.0526330 (493)\ttotal: 1m 43s\tremaining: 33m 2s\n",
      "494:\tlearn: 0.0522851\ttest: 0.0526325\tbest: 0.0526325 (494)\ttotal: 1m 43s\tremaining: 33m 1s\n",
      "495:\tlearn: 0.0522870\ttest: 0.0526313\tbest: 0.0526313 (495)\ttotal: 1m 43s\tremaining: 33m 1s\n",
      "496:\tlearn: 0.0522863\ttest: 0.0526306\tbest: 0.0526306 (496)\ttotal: 1m 43s\tremaining: 33m 1s\n",
      "497:\tlearn: 0.0522857\ttest: 0.0526302\tbest: 0.0526302 (497)\ttotal: 1m 43s\tremaining: 33m 1s\n",
      "498:\tlearn: 0.0522850\ttest: 0.0526295\tbest: 0.0526295 (498)\ttotal: 1m 44s\tremaining: 33m 1s\n",
      "499:\tlearn: 0.0522843\ttest: 0.0526279\tbest: 0.0526279 (499)\ttotal: 1m 44s\tremaining: 33m 1s\n",
      "500:\tlearn: 0.0522831\ttest: 0.0526268\tbest: 0.0526268 (500)\ttotal: 1m 44s\tremaining: 33m 1s\n",
      "501:\tlearn: 0.0522828\ttest: 0.0526262\tbest: 0.0526262 (501)\ttotal: 1m 44s\tremaining: 33m 1s\n",
      "502:\tlearn: 0.0522809\ttest: 0.0526250\tbest: 0.0526250 (502)\ttotal: 1m 44s\tremaining: 33m\n",
      "503:\tlearn: 0.0522822\ttest: 0.0526239\tbest: 0.0526239 (503)\ttotal: 1m 45s\tremaining: 33m\n",
      "504:\tlearn: 0.0522837\ttest: 0.0526231\tbest: 0.0526231 (504)\ttotal: 1m 45s\tremaining: 33m\n",
      "505:\tlearn: 0.0522832\ttest: 0.0526225\tbest: 0.0526225 (505)\ttotal: 1m 45s\tremaining: 32m 59s\n",
      "506:\tlearn: 0.0522822\ttest: 0.0526219\tbest: 0.0526219 (506)\ttotal: 1m 45s\tremaining: 32m 59s\n",
      "507:\tlearn: 0.0522810\ttest: 0.0526205\tbest: 0.0526205 (507)\ttotal: 1m 45s\tremaining: 32m 59s\n",
      "508:\tlearn: 0.0522797\ttest: 0.0526192\tbest: 0.0526192 (508)\ttotal: 1m 46s\tremaining: 32m 58s\n",
      "509:\tlearn: 0.0522785\ttest: 0.0526180\tbest: 0.0526180 (509)\ttotal: 1m 46s\tremaining: 32m 58s\n",
      "510:\tlearn: 0.0522779\ttest: 0.0526173\tbest: 0.0526173 (510)\ttotal: 1m 46s\tremaining: 32m 58s\n",
      "511:\tlearn: 0.0522772\ttest: 0.0526168\tbest: 0.0526168 (511)\ttotal: 1m 46s\tremaining: 32m 57s\n",
      "512:\tlearn: 0.0522768\ttest: 0.0526159\tbest: 0.0526159 (512)\ttotal: 1m 46s\tremaining: 32m 57s\n",
      "513:\tlearn: 0.0522768\ttest: 0.0526155\tbest: 0.0526155 (513)\ttotal: 1m 47s\tremaining: 32m 57s\n",
      "514:\tlearn: 0.0522557\ttest: 0.0526123\tbest: 0.0526123 (514)\ttotal: 1m 47s\tremaining: 32m 57s\n",
      "515:\tlearn: 0.0522551\ttest: 0.0526117\tbest: 0.0526117 (515)\ttotal: 1m 47s\tremaining: 32m 57s\n",
      "516:\tlearn: 0.0522559\ttest: 0.0526107\tbest: 0.0526107 (516)\ttotal: 1m 47s\tremaining: 32m 57s\n",
      "517:\tlearn: 0.0522559\ttest: 0.0526104\tbest: 0.0526104 (517)\ttotal: 1m 47s\tremaining: 32m 56s\n",
      "518:\tlearn: 0.0522555\ttest: 0.0526097\tbest: 0.0526097 (518)\ttotal: 1m 48s\tremaining: 32m 55s\n",
      "519:\tlearn: 0.0522554\ttest: 0.0526093\tbest: 0.0526093 (519)\ttotal: 1m 48s\tremaining: 32m 55s\n",
      "520:\tlearn: 0.0522545\ttest: 0.0526086\tbest: 0.0526086 (520)\ttotal: 1m 48s\tremaining: 32m 54s\n",
      "521:\tlearn: 0.0522536\ttest: 0.0526081\tbest: 0.0526081 (521)\ttotal: 1m 48s\tremaining: 32m 54s\n",
      "522:\tlearn: 0.0522535\ttest: 0.0526076\tbest: 0.0526076 (522)\ttotal: 1m 48s\tremaining: 32m 53s\n",
      "523:\tlearn: 0.0522548\ttest: 0.0526066\tbest: 0.0526066 (523)\ttotal: 1m 49s\tremaining: 32m 53s\n",
      "524:\tlearn: 0.0522545\ttest: 0.0526064\tbest: 0.0526064 (524)\ttotal: 1m 49s\tremaining: 32m 52s\n",
      "525:\tlearn: 0.0522544\ttest: 0.0526064\tbest: 0.0526064 (525)\ttotal: 1m 49s\tremaining: 32m 51s\n",
      "526:\tlearn: 0.0522541\ttest: 0.0526058\tbest: 0.0526058 (526)\ttotal: 1m 49s\tremaining: 32m 51s\n",
      "527:\tlearn: 0.0522523\ttest: 0.0526048\tbest: 0.0526048 (527)\ttotal: 1m 49s\tremaining: 32m 51s\n",
      "528:\tlearn: 0.0522521\ttest: 0.0526043\tbest: 0.0526043 (528)\ttotal: 1m 50s\tremaining: 32m 51s\n",
      "529:\tlearn: 0.0522514\ttest: 0.0526034\tbest: 0.0526034 (529)\ttotal: 1m 50s\tremaining: 32m 50s\n",
      "530:\tlearn: 0.0522514\ttest: 0.0526016\tbest: 0.0526016 (530)\ttotal: 1m 50s\tremaining: 32m 50s\n",
      "531:\tlearn: 0.0522503\ttest: 0.0526014\tbest: 0.0526014 (531)\ttotal: 1m 50s\tremaining: 32m 49s\n",
      "532:\tlearn: 0.0522498\ttest: 0.0526009\tbest: 0.0526009 (532)\ttotal: 1m 50s\tremaining: 32m 48s\n",
      "533:\tlearn: 0.0522501\ttest: 0.0526005\tbest: 0.0526005 (533)\ttotal: 1m 51s\tremaining: 32m 48s\n",
      "534:\tlearn: 0.0522491\ttest: 0.0525999\tbest: 0.0525999 (534)\ttotal: 1m 51s\tremaining: 32m 48s\n",
      "535:\tlearn: 0.0522492\ttest: 0.0525998\tbest: 0.0525998 (535)\ttotal: 1m 51s\tremaining: 32m 47s\n",
      "536:\tlearn: 0.0522487\ttest: 0.0525985\tbest: 0.0525985 (536)\ttotal: 1m 51s\tremaining: 32m 47s\n",
      "537:\tlearn: 0.0522483\ttest: 0.0525979\tbest: 0.0525979 (537)\ttotal: 1m 51s\tremaining: 32m 47s\n",
      "538:\tlearn: 0.0522483\ttest: 0.0525979\tbest: 0.0525979 (538)\ttotal: 1m 52s\tremaining: 32m 46s\n",
      "539:\tlearn: 0.0522483\ttest: 0.0525976\tbest: 0.0525976 (539)\ttotal: 1m 52s\tremaining: 32m 45s\n",
      "540:\tlearn: 0.0522483\ttest: 0.0525976\tbest: 0.0525976 (540)\ttotal: 1m 52s\tremaining: 32m 45s\n",
      "541:\tlearn: 0.0522478\ttest: 0.0525973\tbest: 0.0525973 (541)\ttotal: 1m 52s\tremaining: 32m 45s\n",
      "542:\tlearn: 0.0522470\ttest: 0.0525972\tbest: 0.0525972 (542)\ttotal: 1m 52s\tremaining: 32m 44s\n",
      "543:\tlearn: 0.0522472\ttest: 0.0525969\tbest: 0.0525969 (543)\ttotal: 1m 52s\tremaining: 32m 43s\n",
      "544:\tlearn: 0.0522470\ttest: 0.0525966\tbest: 0.0525966 (544)\ttotal: 1m 53s\tremaining: 32m 43s\n",
      "545:\tlearn: 0.0522461\ttest: 0.0525962\tbest: 0.0525962 (545)\ttotal: 1m 53s\tremaining: 32m 42s\n",
      "546:\tlearn: 0.0522463\ttest: 0.0525960\tbest: 0.0525960 (546)\ttotal: 1m 53s\tremaining: 32m 42s\n",
      "547:\tlearn: 0.0522484\ttest: 0.0525943\tbest: 0.0525943 (547)\ttotal: 1m 53s\tremaining: 32m 42s\n",
      "548:\tlearn: 0.0522480\ttest: 0.0525930\tbest: 0.0525930 (548)\ttotal: 1m 53s\tremaining: 32m 41s\n",
      "549:\tlearn: 0.0522475\ttest: 0.0525921\tbest: 0.0525921 (549)\ttotal: 1m 54s\tremaining: 32m 42s\n",
      "550:\tlearn: 0.0522461\ttest: 0.0525906\tbest: 0.0525906 (550)\ttotal: 1m 54s\tremaining: 32m 41s\n",
      "551:\tlearn: 0.0522436\ttest: 0.0525891\tbest: 0.0525891 (551)\ttotal: 1m 54s\tremaining: 32m 41s\n",
      "552:\tlearn: 0.0522435\ttest: 0.0525886\tbest: 0.0525886 (552)\ttotal: 1m 54s\tremaining: 32m 40s\n",
      "553:\tlearn: 0.0522432\ttest: 0.0525881\tbest: 0.0525881 (553)\ttotal: 1m 54s\tremaining: 32m 40s\n",
      "554:\tlearn: 0.0522428\ttest: 0.0525872\tbest: 0.0525872 (554)\ttotal: 1m 55s\tremaining: 32m 39s\n",
      "555:\tlearn: 0.0522422\ttest: 0.0525866\tbest: 0.0525866 (555)\ttotal: 1m 55s\tremaining: 32m 39s\n",
      "556:\tlearn: 0.0522420\ttest: 0.0525864\tbest: 0.0525864 (556)\ttotal: 1m 55s\tremaining: 32m 39s\n",
      "557:\tlearn: 0.0522415\ttest: 0.0525861\tbest: 0.0525861 (557)\ttotal: 1m 55s\tremaining: 32m 38s\n",
      "558:\tlearn: 0.0522416\ttest: 0.0525861\tbest: 0.0525861 (558)\ttotal: 1m 55s\tremaining: 32m 38s\n",
      "559:\tlearn: 0.0522411\ttest: 0.0525847\tbest: 0.0525847 (559)\ttotal: 1m 56s\tremaining: 32m 37s\n",
      "560:\tlearn: 0.0522428\ttest: 0.0525847\tbest: 0.0525847 (560)\ttotal: 1m 56s\tremaining: 32m 37s\n",
      "561:\tlearn: 0.0522424\ttest: 0.0525844\tbest: 0.0525844 (561)\ttotal: 1m 56s\tremaining: 32m 36s\n",
      "562:\tlearn: 0.0522421\ttest: 0.0525839\tbest: 0.0525839 (562)\ttotal: 1m 56s\tremaining: 32m 36s\n",
      "563:\tlearn: 0.0522421\ttest: 0.0525839\tbest: 0.0525839 (562)\ttotal: 1m 56s\tremaining: 32m 35s\n",
      "564:\tlearn: 0.0522412\ttest: 0.0525829\tbest: 0.0525829 (564)\ttotal: 1m 57s\tremaining: 32m 35s\n",
      "565:\tlearn: 0.0522412\ttest: 0.0525829\tbest: 0.0525829 (565)\ttotal: 1m 57s\tremaining: 32m 34s\n",
      "566:\tlearn: 0.0522372\ttest: 0.0525823\tbest: 0.0525823 (566)\ttotal: 1m 57s\tremaining: 32m 34s\n",
      "567:\tlearn: 0.0522366\ttest: 0.0525813\tbest: 0.0525813 (567)\ttotal: 1m 57s\tremaining: 32m 34s\n",
      "568:\tlearn: 0.0522373\ttest: 0.0525810\tbest: 0.0525810 (568)\ttotal: 1m 57s\tremaining: 32m 33s\n",
      "569:\tlearn: 0.0522367\ttest: 0.0525807\tbest: 0.0525807 (569)\ttotal: 1m 58s\tremaining: 32m 32s\n",
      "570:\tlearn: 0.0522376\ttest: 0.0525802\tbest: 0.0525802 (570)\ttotal: 1m 58s\tremaining: 32m 31s\n",
      "571:\tlearn: 0.0522356\ttest: 0.0525800\tbest: 0.0525800 (571)\ttotal: 1m 58s\tremaining: 32m 31s\n",
      "572:\tlearn: 0.0522351\ttest: 0.0525788\tbest: 0.0525788 (572)\ttotal: 1m 58s\tremaining: 32m 31s\n",
      "573:\tlearn: 0.0522349\ttest: 0.0525785\tbest: 0.0525785 (573)\ttotal: 1m 58s\tremaining: 32m 31s\n",
      "574:\tlearn: 0.0522374\ttest: 0.0525778\tbest: 0.0525778 (574)\ttotal: 1m 58s\tremaining: 32m 30s\n",
      "575:\tlearn: 0.0522379\ttest: 0.0525770\tbest: 0.0525770 (575)\ttotal: 1m 59s\tremaining: 32m 30s\n",
      "576:\tlearn: 0.0522351\ttest: 0.0525741\tbest: 0.0525741 (576)\ttotal: 1m 59s\tremaining: 32m 29s\n",
      "577:\tlearn: 0.0522344\ttest: 0.0525732\tbest: 0.0525732 (577)\ttotal: 1m 59s\tremaining: 32m 29s\n",
      "578:\tlearn: 0.0522343\ttest: 0.0525732\tbest: 0.0525732 (578)\ttotal: 1m 59s\tremaining: 32m 29s\n",
      "579:\tlearn: 0.0522341\ttest: 0.0525729\tbest: 0.0525729 (579)\ttotal: 1m 59s\tremaining: 32m 28s\n",
      "580:\tlearn: 0.0522340\ttest: 0.0525719\tbest: 0.0525719 (580)\ttotal: 2m\tremaining: 32m 28s\n",
      "581:\tlearn: 0.0522325\ttest: 0.0525711\tbest: 0.0525711 (581)\ttotal: 2m\tremaining: 32m 28s\n",
      "582:\tlearn: 0.0522305\ttest: 0.0525691\tbest: 0.0525691 (582)\ttotal: 2m\tremaining: 32m 28s\n",
      "583:\tlearn: 0.0522297\ttest: 0.0525686\tbest: 0.0525686 (583)\ttotal: 2m\tremaining: 32m 27s\n",
      "584:\tlearn: 0.0522298\ttest: 0.0525679\tbest: 0.0525679 (584)\ttotal: 2m\tremaining: 32m 27s\n",
      "585:\tlearn: 0.0522275\ttest: 0.0525677\tbest: 0.0525677 (585)\ttotal: 2m 1s\tremaining: 32m 26s\n",
      "586:\tlearn: 0.0522274\ttest: 0.0525667\tbest: 0.0525667 (586)\ttotal: 2m 1s\tremaining: 32m 26s\n",
      "587:\tlearn: 0.0522266\ttest: 0.0525661\tbest: 0.0525661 (587)\ttotal: 2m 1s\tremaining: 32m 26s\n",
      "588:\tlearn: 0.0522250\ttest: 0.0525650\tbest: 0.0525650 (588)\ttotal: 2m 1s\tremaining: 32m 25s\n",
      "589:\tlearn: 0.0522247\ttest: 0.0525642\tbest: 0.0525642 (589)\ttotal: 2m 1s\tremaining: 32m 25s\n",
      "590:\tlearn: 0.0522259\ttest: 0.0525638\tbest: 0.0525638 (590)\ttotal: 2m 2s\tremaining: 32m 25s\n",
      "591:\tlearn: 0.0522256\ttest: 0.0525633\tbest: 0.0525633 (591)\ttotal: 2m 2s\tremaining: 32m 25s\n",
      "592:\tlearn: 0.0522270\ttest: 0.0525628\tbest: 0.0525628 (592)\ttotal: 2m 2s\tremaining: 32m 24s\n",
      "593:\tlearn: 0.0522248\ttest: 0.0525625\tbest: 0.0525625 (593)\ttotal: 2m 2s\tremaining: 32m 24s\n",
      "594:\tlearn: 0.0522259\ttest: 0.0525618\tbest: 0.0525618 (594)\ttotal: 2m 3s\tremaining: 32m 24s\n",
      "595:\tlearn: 0.0522238\ttest: 0.0525605\tbest: 0.0525605 (595)\ttotal: 2m 3s\tremaining: 32m 23s\n",
      "596:\tlearn: 0.0522272\ttest: 0.0525597\tbest: 0.0525597 (596)\ttotal: 2m 3s\tremaining: 32m 23s\n",
      "597:\tlearn: 0.0522265\ttest: 0.0525589\tbest: 0.0525589 (597)\ttotal: 2m 3s\tremaining: 32m 23s\n",
      "598:\tlearn: 0.0522261\ttest: 0.0525582\tbest: 0.0525582 (598)\ttotal: 2m 3s\tremaining: 32m 23s\n",
      "599:\tlearn: 0.0522259\ttest: 0.0525582\tbest: 0.0525582 (599)\ttotal: 2m 3s\tremaining: 32m 22s\n",
      "600:\tlearn: 0.0522250\ttest: 0.0525573\tbest: 0.0525573 (600)\ttotal: 2m 4s\tremaining: 32m 22s\n",
      "601:\tlearn: 0.0522238\ttest: 0.0525565\tbest: 0.0525565 (601)\ttotal: 2m 4s\tremaining: 32m 21s\n",
      "602:\tlearn: 0.0522228\ttest: 0.0525554\tbest: 0.0525554 (602)\ttotal: 2m 4s\tremaining: 32m 21s\n",
      "603:\tlearn: 0.0522226\ttest: 0.0525551\tbest: 0.0525551 (603)\ttotal: 2m 4s\tremaining: 32m 21s\n",
      "604:\tlearn: 0.0522224\ttest: 0.0525550\tbest: 0.0525550 (604)\ttotal: 2m 5s\tremaining: 32m 21s\n",
      "605:\tlearn: 0.0522238\ttest: 0.0525540\tbest: 0.0525540 (605)\ttotal: 2m 5s\tremaining: 32m 20s\n",
      "606:\tlearn: 0.0522234\ttest: 0.0525533\tbest: 0.0525533 (606)\ttotal: 2m 5s\tremaining: 32m 20s\n",
      "607:\tlearn: 0.0522229\ttest: 0.0525529\tbest: 0.0525529 (607)\ttotal: 2m 5s\tremaining: 32m 20s\n",
      "608:\tlearn: 0.0522225\ttest: 0.0525527\tbest: 0.0525527 (608)\ttotal: 2m 5s\tremaining: 32m 19s\n",
      "609:\tlearn: 0.0522214\ttest: 0.0525518\tbest: 0.0525518 (609)\ttotal: 2m 6s\tremaining: 32m 19s\n",
      "610:\tlearn: 0.0522209\ttest: 0.0525513\tbest: 0.0525513 (610)\ttotal: 2m 6s\tremaining: 32m 19s\n",
      "611:\tlearn: 0.0522193\ttest: 0.0525506\tbest: 0.0525506 (611)\ttotal: 2m 6s\tremaining: 32m 18s\n",
      "612:\tlearn: 0.0522183\ttest: 0.0525501\tbest: 0.0525501 (612)\ttotal: 2m 6s\tremaining: 32m 17s\n",
      "613:\tlearn: 0.0522176\ttest: 0.0525494\tbest: 0.0525494 (613)\ttotal: 2m 6s\tremaining: 32m 17s\n",
      "614:\tlearn: 0.0522175\ttest: 0.0525493\tbest: 0.0525493 (614)\ttotal: 2m 6s\tremaining: 32m 16s\n",
      "615:\tlearn: 0.0522168\ttest: 0.0525485\tbest: 0.0525485 (615)\ttotal: 2m 7s\tremaining: 32m 16s\n",
      "616:\tlearn: 0.0522165\ttest: 0.0525479\tbest: 0.0525479 (616)\ttotal: 2m 7s\tremaining: 32m 16s\n",
      "617:\tlearn: 0.0522187\ttest: 0.0525470\tbest: 0.0525470 (617)\ttotal: 2m 7s\tremaining: 32m 16s\n",
      "618:\tlearn: 0.0522186\ttest: 0.0525467\tbest: 0.0525467 (618)\ttotal: 2m 7s\tremaining: 32m 16s\n",
      "619:\tlearn: 0.0522183\ttest: 0.0525467\tbest: 0.0525467 (619)\ttotal: 2m 7s\tremaining: 32m 14s\n",
      "620:\tlearn: 0.0522182\ttest: 0.0525463\tbest: 0.0525463 (620)\ttotal: 2m 8s\tremaining: 32m 14s\n",
      "621:\tlearn: 0.0522054\ttest: 0.0525450\tbest: 0.0525450 (621)\ttotal: 2m 8s\tremaining: 32m 14s\n",
      "622:\tlearn: 0.0522051\ttest: 0.0525448\tbest: 0.0525448 (622)\ttotal: 2m 8s\tremaining: 32m 13s\n",
      "623:\tlearn: 0.0522048\ttest: 0.0525444\tbest: 0.0525444 (623)\ttotal: 2m 8s\tremaining: 32m 13s\n",
      "624:\tlearn: 0.0522040\ttest: 0.0525426\tbest: 0.0525426 (624)\ttotal: 2m 8s\tremaining: 32m 12s\n",
      "625:\tlearn: 0.0522034\ttest: 0.0525425\tbest: 0.0525425 (625)\ttotal: 2m 9s\tremaining: 32m 12s\n",
      "626:\tlearn: 0.0522054\ttest: 0.0525416\tbest: 0.0525416 (626)\ttotal: 2m 9s\tremaining: 32m 11s\n",
      "627:\tlearn: 0.0522054\ttest: 0.0525414\tbest: 0.0525414 (627)\ttotal: 2m 9s\tremaining: 32m 11s\n",
      "628:\tlearn: 0.0522003\ttest: 0.0525403\tbest: 0.0525403 (628)\ttotal: 2m 9s\tremaining: 32m 10s\n",
      "629:\tlearn: 0.0521996\ttest: 0.0525398\tbest: 0.0525398 (629)\ttotal: 2m 9s\tremaining: 32m 10s\n",
      "630:\tlearn: 0.0521991\ttest: 0.0525394\tbest: 0.0525394 (630)\ttotal: 2m 10s\tremaining: 32m 10s\n",
      "631:\tlearn: 0.0521931\ttest: 0.0525391\tbest: 0.0525391 (631)\ttotal: 2m 10s\tremaining: 32m 9s\n",
      "632:\tlearn: 0.0521928\ttest: 0.0525384\tbest: 0.0525384 (632)\ttotal: 2m 10s\tremaining: 32m 9s\n",
      "633:\tlearn: 0.0521927\ttest: 0.0525383\tbest: 0.0525383 (633)\ttotal: 2m 10s\tremaining: 32m 8s\n",
      "634:\tlearn: 0.0521921\ttest: 0.0525379\tbest: 0.0525379 (634)\ttotal: 2m 10s\tremaining: 32m 8s\n",
      "635:\tlearn: 0.0521916\ttest: 0.0525375\tbest: 0.0525375 (635)\ttotal: 2m 10s\tremaining: 32m 7s\n",
      "636:\tlearn: 0.0521916\ttest: 0.0525372\tbest: 0.0525372 (636)\ttotal: 2m 11s\tremaining: 32m 7s\n",
      "637:\tlearn: 0.0521910\ttest: 0.0525366\tbest: 0.0525366 (637)\ttotal: 2m 11s\tremaining: 32m 6s\n",
      "638:\tlearn: 0.0521913\ttest: 0.0525357\tbest: 0.0525357 (638)\ttotal: 2m 11s\tremaining: 32m 6s\n",
      "639:\tlearn: 0.0521910\ttest: 0.0525352\tbest: 0.0525352 (639)\ttotal: 2m 11s\tremaining: 32m 5s\n",
      "640:\tlearn: 0.0521920\ttest: 0.0525348\tbest: 0.0525348 (640)\ttotal: 2m 11s\tremaining: 32m 5s\n",
      "641:\tlearn: 0.0521906\ttest: 0.0525335\tbest: 0.0525335 (641)\ttotal: 2m 12s\tremaining: 32m 5s\n",
      "642:\tlearn: 0.0521908\ttest: 0.0525330\tbest: 0.0525330 (642)\ttotal: 2m 12s\tremaining: 32m 5s\n",
      "643:\tlearn: 0.0521905\ttest: 0.0525328\tbest: 0.0525328 (643)\ttotal: 2m 12s\tremaining: 32m 4s\n",
      "644:\tlearn: 0.0521904\ttest: 0.0525321\tbest: 0.0525321 (644)\ttotal: 2m 12s\tremaining: 32m 4s\n",
      "645:\tlearn: 0.0521903\ttest: 0.0525320\tbest: 0.0525320 (645)\ttotal: 2m 12s\tremaining: 32m 4s\n",
      "646:\tlearn: 0.0521924\ttest: 0.0525314\tbest: 0.0525314 (646)\ttotal: 2m 13s\tremaining: 32m 3s\n",
      "647:\tlearn: 0.0521922\ttest: 0.0525312\tbest: 0.0525312 (647)\ttotal: 2m 13s\tremaining: 32m 3s\n",
      "648:\tlearn: 0.0521918\ttest: 0.0525308\tbest: 0.0525308 (648)\ttotal: 2m 13s\tremaining: 32m 3s\n",
      "649:\tlearn: 0.0521912\ttest: 0.0525303\tbest: 0.0525303 (649)\ttotal: 2m 13s\tremaining: 32m 2s\n",
      "650:\tlearn: 0.0521911\ttest: 0.0525303\tbest: 0.0525303 (650)\ttotal: 2m 13s\tremaining: 32m 1s\n",
      "651:\tlearn: 0.0521905\ttest: 0.0525297\tbest: 0.0525297 (651)\ttotal: 2m 14s\tremaining: 32m 1s\n",
      "652:\tlearn: 0.0521901\ttest: 0.0525293\tbest: 0.0525293 (652)\ttotal: 2m 14s\tremaining: 32m\n",
      "653:\tlearn: 0.0521890\ttest: 0.0525283\tbest: 0.0525283 (653)\ttotal: 2m 14s\tremaining: 32m\n",
      "654:\tlearn: 0.0521880\ttest: 0.0525275\tbest: 0.0525275 (654)\ttotal: 2m 14s\tremaining: 32m\n",
      "655:\tlearn: 0.0521878\ttest: 0.0525270\tbest: 0.0525270 (655)\ttotal: 2m 14s\tremaining: 32m\n",
      "656:\tlearn: 0.0521877\ttest: 0.0525268\tbest: 0.0525268 (656)\ttotal: 2m 14s\tremaining: 31m 59s\n",
      "657:\tlearn: 0.0521870\ttest: 0.0525263\tbest: 0.0525263 (657)\ttotal: 2m 15s\tremaining: 31m 59s\n",
      "658:\tlearn: 0.0521865\ttest: 0.0525259\tbest: 0.0525259 (658)\ttotal: 2m 15s\tremaining: 31m 59s\n",
      "659:\tlearn: 0.0521879\ttest: 0.0525256\tbest: 0.0525256 (659)\ttotal: 2m 15s\tremaining: 31m 58s\n",
      "660:\tlearn: 0.0521862\ttest: 0.0525253\tbest: 0.0525253 (660)\ttotal: 2m 15s\tremaining: 31m 57s\n",
      "661:\tlearn: 0.0521867\ttest: 0.0525246\tbest: 0.0525246 (661)\ttotal: 2m 15s\tremaining: 31m 57s\n",
      "662:\tlearn: 0.0521865\ttest: 0.0525242\tbest: 0.0525242 (662)\ttotal: 2m 16s\tremaining: 31m 56s\n",
      "663:\tlearn: 0.0521859\ttest: 0.0525237\tbest: 0.0525237 (663)\ttotal: 2m 16s\tremaining: 31m 56s\n",
      "664:\tlearn: 0.0521855\ttest: 0.0525235\tbest: 0.0525235 (664)\ttotal: 2m 16s\tremaining: 31m 56s\n",
      "665:\tlearn: 0.0521853\ttest: 0.0525231\tbest: 0.0525231 (665)\ttotal: 2m 16s\tremaining: 31m 55s\n",
      "666:\tlearn: 0.0521863\ttest: 0.0525224\tbest: 0.0525224 (666)\ttotal: 2m 16s\tremaining: 31m 55s\n",
      "667:\tlearn: 0.0521863\ttest: 0.0525220\tbest: 0.0525220 (667)\ttotal: 2m 17s\tremaining: 31m 54s\n",
      "668:\tlearn: 0.0521856\ttest: 0.0525213\tbest: 0.0525213 (668)\ttotal: 2m 17s\tremaining: 31m 54s\n",
      "669:\tlearn: 0.0521851\ttest: 0.0525212\tbest: 0.0525212 (669)\ttotal: 2m 17s\tremaining: 31m 53s\n",
      "670:\tlearn: 0.0521851\ttest: 0.0525212\tbest: 0.0525212 (669)\ttotal: 2m 17s\tremaining: 31m 52s\n",
      "671:\tlearn: 0.0521849\ttest: 0.0525209\tbest: 0.0525209 (671)\ttotal: 2m 17s\tremaining: 31m 52s\n",
      "672:\tlearn: 0.0521822\ttest: 0.0525200\tbest: 0.0525200 (672)\ttotal: 2m 17s\tremaining: 31m 52s\n",
      "673:\tlearn: 0.0521822\ttest: 0.0525199\tbest: 0.0525199 (673)\ttotal: 2m 18s\tremaining: 31m 51s\n",
      "674:\tlearn: 0.0521820\ttest: 0.0525196\tbest: 0.0525196 (674)\ttotal: 2m 18s\tremaining: 31m 51s\n",
      "675:\tlearn: 0.0521813\ttest: 0.0525188\tbest: 0.0525188 (675)\ttotal: 2m 18s\tremaining: 31m 51s\n",
      "676:\tlearn: 0.0521808\ttest: 0.0525184\tbest: 0.0525184 (676)\ttotal: 2m 18s\tremaining: 31m 50s\n",
      "677:\tlearn: 0.0521815\ttest: 0.0525184\tbest: 0.0525184 (677)\ttotal: 2m 18s\tremaining: 31m 49s\n",
      "678:\tlearn: 0.0521804\ttest: 0.0525172\tbest: 0.0525172 (678)\ttotal: 2m 19s\tremaining: 31m 49s\n",
      "679:\tlearn: 0.0521810\ttest: 0.0525172\tbest: 0.0525172 (679)\ttotal: 2m 19s\tremaining: 31m 48s\n",
      "680:\tlearn: 0.0521792\ttest: 0.0525159\tbest: 0.0525159 (680)\ttotal: 2m 19s\tremaining: 31m 48s\n",
      "681:\tlearn: 0.0521785\ttest: 0.0525152\tbest: 0.0525152 (681)\ttotal: 2m 19s\tremaining: 31m 47s\n",
      "682:\tlearn: 0.0521804\ttest: 0.0525144\tbest: 0.0525144 (682)\ttotal: 2m 19s\tremaining: 31m 47s\n",
      "683:\tlearn: 0.0521813\ttest: 0.0525136\tbest: 0.0525136 (683)\ttotal: 2m 20s\tremaining: 31m 47s\n",
      "684:\tlearn: 0.0521820\ttest: 0.0525135\tbest: 0.0525135 (684)\ttotal: 2m 20s\tremaining: 31m 46s\n",
      "685:\tlearn: 0.0521810\ttest: 0.0525126\tbest: 0.0525126 (685)\ttotal: 2m 20s\tremaining: 31m 46s\n",
      "686:\tlearn: 0.0521825\ttest: 0.0525119\tbest: 0.0525119 (686)\ttotal: 2m 20s\tremaining: 31m 45s\n",
      "687:\tlearn: 0.0521811\ttest: 0.0525114\tbest: 0.0525114 (687)\ttotal: 2m 20s\tremaining: 31m 45s\n",
      "688:\tlearn: 0.0521809\ttest: 0.0525113\tbest: 0.0525113 (688)\ttotal: 2m 20s\tremaining: 31m 44s\n",
      "689:\tlearn: 0.0521794\ttest: 0.0525112\tbest: 0.0525112 (689)\ttotal: 2m 21s\tremaining: 31m 44s\n",
      "690:\tlearn: 0.0521790\ttest: 0.0525103\tbest: 0.0525103 (690)\ttotal: 2m 21s\tremaining: 31m 44s\n",
      "691:\tlearn: 0.0521782\ttest: 0.0525097\tbest: 0.0525097 (691)\ttotal: 2m 21s\tremaining: 31m 43s\n",
      "692:\tlearn: 0.0521772\ttest: 0.0525093\tbest: 0.0525093 (692)\ttotal: 2m 21s\tremaining: 31m 43s\n",
      "693:\tlearn: 0.0521772\ttest: 0.0525093\tbest: 0.0525093 (692)\ttotal: 2m 21s\tremaining: 31m 42s\n",
      "694:\tlearn: 0.0521778\ttest: 0.0525088\tbest: 0.0525088 (694)\ttotal: 2m 22s\tremaining: 31m 42s\n",
      "695:\tlearn: 0.0521769\ttest: 0.0525087\tbest: 0.0525087 (695)\ttotal: 2m 22s\tremaining: 31m 41s\n",
      "696:\tlearn: 0.0521766\ttest: 0.0525083\tbest: 0.0525083 (696)\ttotal: 2m 22s\tremaining: 31m 41s\n",
      "697:\tlearn: 0.0521760\ttest: 0.0525079\tbest: 0.0525079 (697)\ttotal: 2m 22s\tremaining: 31m 41s\n",
      "698:\tlearn: 0.0521762\ttest: 0.0525075\tbest: 0.0525075 (698)\ttotal: 2m 22s\tremaining: 31m 41s\n",
      "699:\tlearn: 0.0521778\ttest: 0.0525070\tbest: 0.0525070 (699)\ttotal: 2m 23s\tremaining: 31m 41s\n",
      "700:\tlearn: 0.0521777\ttest: 0.0525069\tbest: 0.0525069 (700)\ttotal: 2m 23s\tremaining: 31m 40s\n",
      "701:\tlearn: 0.0521797\ttest: 0.0525067\tbest: 0.0525067 (701)\ttotal: 2m 23s\tremaining: 31m 39s\n",
      "702:\tlearn: 0.0521773\ttest: 0.0525059\tbest: 0.0525059 (702)\ttotal: 2m 23s\tremaining: 31m 39s\n",
      "703:\tlearn: 0.0521769\ttest: 0.0525056\tbest: 0.0525056 (703)\ttotal: 2m 23s\tremaining: 31m 38s\n",
      "704:\tlearn: 0.0521765\ttest: 0.0525047\tbest: 0.0525047 (704)\ttotal: 2m 23s\tremaining: 31m 38s\n",
      "705:\tlearn: 0.0521775\ttest: 0.0525044\tbest: 0.0525044 (705)\ttotal: 2m 24s\tremaining: 31m 37s\n",
      "706:\tlearn: 0.0521746\ttest: 0.0525041\tbest: 0.0525041 (706)\ttotal: 2m 24s\tremaining: 31m 36s\n",
      "707:\tlearn: 0.0521743\ttest: 0.0525035\tbest: 0.0525035 (707)\ttotal: 2m 24s\tremaining: 31m 36s\n",
      "708:\tlearn: 0.0521748\ttest: 0.0525034\tbest: 0.0525034 (708)\ttotal: 2m 24s\tremaining: 31m 35s\n",
      "709:\tlearn: 0.0521745\ttest: 0.0525030\tbest: 0.0525030 (709)\ttotal: 2m 24s\tremaining: 31m 35s\n",
      "710:\tlearn: 0.0521731\ttest: 0.0525024\tbest: 0.0525024 (710)\ttotal: 2m 25s\tremaining: 31m 34s\n",
      "711:\tlearn: 0.0521743\ttest: 0.0525022\tbest: 0.0525022 (711)\ttotal: 2m 25s\tremaining: 31m 34s\n",
      "712:\tlearn: 0.0521729\ttest: 0.0525018\tbest: 0.0525018 (712)\ttotal: 2m 25s\tremaining: 31m 33s\n",
      "713:\tlearn: 0.0521738\ttest: 0.0525015\tbest: 0.0525015 (713)\ttotal: 2m 25s\tremaining: 31m 33s\n",
      "714:\tlearn: 0.0521738\ttest: 0.0525013\tbest: 0.0525013 (714)\ttotal: 2m 25s\tremaining: 31m 32s\n",
      "715:\tlearn: 0.0521736\ttest: 0.0525013\tbest: 0.0525013 (715)\ttotal: 2m 25s\tremaining: 31m 32s\n",
      "716:\tlearn: 0.0521736\ttest: 0.0525013\tbest: 0.0525013 (716)\ttotal: 2m 26s\tremaining: 31m 31s\n",
      "717:\tlearn: 0.0521733\ttest: 0.0525003\tbest: 0.0525003 (717)\ttotal: 2m 26s\tremaining: 31m 31s\n",
      "718:\tlearn: 0.0521713\ttest: 0.0524996\tbest: 0.0524996 (718)\ttotal: 2m 26s\tremaining: 31m 30s\n",
      "719:\tlearn: 0.0521713\ttest: 0.0524996\tbest: 0.0524996 (719)\ttotal: 2m 26s\tremaining: 31m 30s\n",
      "720:\tlearn: 0.0521713\ttest: 0.0524995\tbest: 0.0524995 (720)\ttotal: 2m 26s\tremaining: 31m 29s\n",
      "721:\tlearn: 0.0521713\ttest: 0.0524995\tbest: 0.0524995 (721)\ttotal: 2m 26s\tremaining: 31m 28s\n",
      "722:\tlearn: 0.0521707\ttest: 0.0524988\tbest: 0.0524988 (722)\ttotal: 2m 27s\tremaining: 31m 28s\n",
      "723:\tlearn: 0.0521697\ttest: 0.0524980\tbest: 0.0524980 (723)\ttotal: 2m 27s\tremaining: 31m 28s\n",
      "724:\tlearn: 0.0521697\ttest: 0.0524978\tbest: 0.0524978 (724)\ttotal: 2m 27s\tremaining: 31m 27s\n",
      "725:\tlearn: 0.0521685\ttest: 0.0524975\tbest: 0.0524975 (725)\ttotal: 2m 27s\tremaining: 31m 27s\n",
      "726:\tlearn: 0.0521683\ttest: 0.0524965\tbest: 0.0524965 (726)\ttotal: 2m 27s\tremaining: 31m 27s\n",
      "727:\tlearn: 0.0521681\ttest: 0.0524963\tbest: 0.0524963 (727)\ttotal: 2m 28s\tremaining: 31m 26s\n",
      "728:\tlearn: 0.0521681\ttest: 0.0524963\tbest: 0.0524963 (728)\ttotal: 2m 28s\tremaining: 31m 26s\n",
      "729:\tlearn: 0.0521679\ttest: 0.0524962\tbest: 0.0524962 (729)\ttotal: 2m 28s\tremaining: 31m 25s\n",
      "730:\tlearn: 0.0521678\ttest: 0.0524959\tbest: 0.0524959 (730)\ttotal: 2m 28s\tremaining: 31m 25s\n",
      "731:\tlearn: 0.0521678\ttest: 0.0524958\tbest: 0.0524958 (731)\ttotal: 2m 28s\tremaining: 31m 24s\n",
      "732:\tlearn: 0.0521675\ttest: 0.0524958\tbest: 0.0524958 (732)\ttotal: 2m 29s\tremaining: 31m 23s\n",
      "733:\tlearn: 0.0521695\ttest: 0.0524955\tbest: 0.0524955 (733)\ttotal: 2m 29s\tremaining: 31m 23s\n",
      "734:\tlearn: 0.0521690\ttest: 0.0524952\tbest: 0.0524952 (734)\ttotal: 2m 29s\tremaining: 31m 22s\n",
      "735:\tlearn: 0.0521690\ttest: 0.0524951\tbest: 0.0524951 (735)\ttotal: 2m 29s\tremaining: 31m 22s\n",
      "736:\tlearn: 0.0521690\ttest: 0.0524951\tbest: 0.0524951 (736)\ttotal: 2m 29s\tremaining: 31m 21s\n",
      "737:\tlearn: 0.0521689\ttest: 0.0524950\tbest: 0.0524950 (737)\ttotal: 2m 29s\tremaining: 31m 21s\n",
      "738:\tlearn: 0.0521683\ttest: 0.0524947\tbest: 0.0524947 (738)\ttotal: 2m 30s\tremaining: 31m 20s\n",
      "739:\tlearn: 0.0521685\ttest: 0.0524947\tbest: 0.0524947 (739)\ttotal: 2m 30s\tremaining: 31m 20s\n",
      "740:\tlearn: 0.0521687\ttest: 0.0524945\tbest: 0.0524945 (740)\ttotal: 2m 30s\tremaining: 31m 19s\n",
      "741:\tlearn: 0.0521687\ttest: 0.0524944\tbest: 0.0524944 (741)\ttotal: 2m 30s\tremaining: 31m 19s\n",
      "742:\tlearn: 0.0521699\ttest: 0.0524933\tbest: 0.0524933 (742)\ttotal: 2m 30s\tremaining: 31m 19s\n",
      "743:\tlearn: 0.0521696\ttest: 0.0524928\tbest: 0.0524928 (743)\ttotal: 2m 31s\tremaining: 31m 19s\n",
      "744:\tlearn: 0.0521693\ttest: 0.0524925\tbest: 0.0524925 (744)\ttotal: 2m 31s\tremaining: 31m 18s\n",
      "745:\tlearn: 0.0521690\ttest: 0.0524923\tbest: 0.0524923 (745)\ttotal: 2m 31s\tremaining: 31m 18s\n",
      "746:\tlearn: 0.0521690\ttest: 0.0524923\tbest: 0.0524923 (746)\ttotal: 2m 31s\tremaining: 31m 17s\n",
      "747:\tlearn: 0.0521690\ttest: 0.0524923\tbest: 0.0524923 (747)\ttotal: 2m 31s\tremaining: 31m 17s\n",
      "748:\tlearn: 0.0521689\ttest: 0.0524920\tbest: 0.0524920 (748)\ttotal: 2m 31s\tremaining: 31m 17s\n",
      "749:\tlearn: 0.0521686\ttest: 0.0524916\tbest: 0.0524916 (749)\ttotal: 2m 32s\tremaining: 31m 16s\n",
      "750:\tlearn: 0.0521683\ttest: 0.0524914\tbest: 0.0524914 (750)\ttotal: 2m 32s\tremaining: 31m 15s\n",
      "751:\tlearn: 0.0521675\ttest: 0.0524909\tbest: 0.0524909 (751)\ttotal: 2m 32s\tremaining: 31m 15s\n",
      "752:\tlearn: 0.0521670\ttest: 0.0524902\tbest: 0.0524902 (752)\ttotal: 2m 32s\tremaining: 31m 15s\n",
      "753:\tlearn: 0.0521669\ttest: 0.0524901\tbest: 0.0524901 (753)\ttotal: 2m 32s\tremaining: 31m 15s\n",
      "754:\tlearn: 0.0521670\ttest: 0.0524900\tbest: 0.0524900 (754)\ttotal: 2m 33s\tremaining: 31m 14s\n",
      "755:\tlearn: 0.0521662\ttest: 0.0524898\tbest: 0.0524898 (755)\ttotal: 2m 33s\tremaining: 31m 14s\n",
      "756:\tlearn: 0.0521657\ttest: 0.0524895\tbest: 0.0524895 (756)\ttotal: 2m 33s\tremaining: 31m 14s\n",
      "757:\tlearn: 0.0521657\ttest: 0.0524892\tbest: 0.0524892 (757)\ttotal: 2m 33s\tremaining: 31m 14s\n",
      "758:\tlearn: 0.0521663\ttest: 0.0524890\tbest: 0.0524890 (758)\ttotal: 2m 33s\tremaining: 31m 13s\n",
      "759:\tlearn: 0.0521661\ttest: 0.0524888\tbest: 0.0524888 (759)\ttotal: 2m 34s\tremaining: 31m 13s\n",
      "760:\tlearn: 0.0521661\ttest: 0.0524888\tbest: 0.0524888 (760)\ttotal: 2m 34s\tremaining: 31m 13s\n",
      "761:\tlearn: 0.0521661\ttest: 0.0524888\tbest: 0.0524888 (761)\ttotal: 2m 34s\tremaining: 31m 12s\n",
      "762:\tlearn: 0.0521663\ttest: 0.0524887\tbest: 0.0524887 (762)\ttotal: 2m 34s\tremaining: 31m 11s\n",
      "763:\tlearn: 0.0521658\ttest: 0.0524882\tbest: 0.0524882 (763)\ttotal: 2m 34s\tremaining: 31m 11s\n",
      "764:\tlearn: 0.0521659\ttest: 0.0524882\tbest: 0.0524882 (764)\ttotal: 2m 34s\tremaining: 31m 10s\n",
      "765:\tlearn: 0.0521659\ttest: 0.0524881\tbest: 0.0524881 (765)\ttotal: 2m 35s\tremaining: 31m 10s\n",
      "766:\tlearn: 0.0521658\ttest: 0.0524881\tbest: 0.0524881 (766)\ttotal: 2m 35s\tremaining: 31m 9s\n",
      "767:\tlearn: 0.0521674\ttest: 0.0524875\tbest: 0.0524875 (767)\ttotal: 2m 35s\tremaining: 31m 9s\n",
      "768:\tlearn: 0.0521673\ttest: 0.0524870\tbest: 0.0524870 (768)\ttotal: 2m 35s\tremaining: 31m 8s\n",
      "769:\tlearn: 0.0521669\ttest: 0.0524864\tbest: 0.0524864 (769)\ttotal: 2m 35s\tremaining: 31m 8s\n",
      "770:\tlearn: 0.0521669\ttest: 0.0524864\tbest: 0.0524864 (770)\ttotal: 2m 36s\tremaining: 31m 7s\n",
      "771:\tlearn: 0.0521666\ttest: 0.0524862\tbest: 0.0524862 (771)\ttotal: 2m 36s\tremaining: 31m 7s\n",
      "772:\tlearn: 0.0521664\ttest: 0.0524862\tbest: 0.0524862 (772)\ttotal: 2m 36s\tremaining: 31m 7s\n",
      "773:\tlearn: 0.0521663\ttest: 0.0524861\tbest: 0.0524861 (773)\ttotal: 2m 36s\tremaining: 31m 6s\n",
      "774:\tlearn: 0.0521665\ttest: 0.0524860\tbest: 0.0524860 (774)\ttotal: 2m 36s\tremaining: 31m 5s\n",
      "775:\tlearn: 0.0521662\ttest: 0.0524854\tbest: 0.0524854 (775)\ttotal: 2m 36s\tremaining: 31m 5s\n",
      "776:\tlearn: 0.0521662\ttest: 0.0524854\tbest: 0.0524854 (776)\ttotal: 2m 37s\tremaining: 31m 5s\n",
      "777:\tlearn: 0.0521654\ttest: 0.0524849\tbest: 0.0524849 (777)\ttotal: 2m 37s\tremaining: 31m 4s\n",
      "778:\tlearn: 0.0521654\ttest: 0.0524849\tbest: 0.0524849 (777)\ttotal: 2m 37s\tremaining: 31m 4s\n",
      "779:\tlearn: 0.0521654\ttest: 0.0524849\tbest: 0.0524849 (779)\ttotal: 2m 37s\tremaining: 31m 3s\n",
      "780:\tlearn: 0.0521651\ttest: 0.0524847\tbest: 0.0524847 (780)\ttotal: 2m 37s\tremaining: 31m 3s\n",
      "781:\tlearn: 0.0521650\ttest: 0.0524841\tbest: 0.0524841 (781)\ttotal: 2m 38s\tremaining: 31m 3s\n",
      "782:\tlearn: 0.0521650\ttest: 0.0524841\tbest: 0.0524841 (781)\ttotal: 2m 38s\tremaining: 31m 2s\n",
      "783:\tlearn: 0.0521638\ttest: 0.0524840\tbest: 0.0524840 (783)\ttotal: 2m 38s\tremaining: 31m 2s\n",
      "784:\tlearn: 0.0521650\ttest: 0.0524840\tbest: 0.0524840 (784)\ttotal: 2m 38s\tremaining: 31m 1s\n",
      "785:\tlearn: 0.0521649\ttest: 0.0524840\tbest: 0.0524840 (785)\ttotal: 2m 38s\tremaining: 31m 1s\n",
      "786:\tlearn: 0.0521646\ttest: 0.0524840\tbest: 0.0524840 (786)\ttotal: 2m 38s\tremaining: 31m\n",
      "787:\tlearn: 0.0521649\ttest: 0.0524839\tbest: 0.0524839 (787)\ttotal: 2m 39s\tremaining: 30m 59s\n",
      "788:\tlearn: 0.0521642\ttest: 0.0524836\tbest: 0.0524836 (788)\ttotal: 2m 39s\tremaining: 30m 59s\n",
      "789:\tlearn: 0.0521642\ttest: 0.0524836\tbest: 0.0524836 (789)\ttotal: 2m 39s\tremaining: 30m 59s\n",
      "790:\tlearn: 0.0521642\ttest: 0.0524836\tbest: 0.0524836 (789)\ttotal: 2m 39s\tremaining: 30m 58s\n",
      "791:\tlearn: 0.0521642\ttest: 0.0524836\tbest: 0.0524836 (789)\ttotal: 2m 39s\tremaining: 30m 57s\n",
      "792:\tlearn: 0.0521642\ttest: 0.0524836\tbest: 0.0524836 (789)\ttotal: 2m 39s\tremaining: 30m 57s\n",
      "793:\tlearn: 0.0521645\ttest: 0.0524834\tbest: 0.0524834 (793)\ttotal: 2m 40s\tremaining: 30m 56s\n",
      "794:\tlearn: 0.0521622\ttest: 0.0524833\tbest: 0.0524833 (794)\ttotal: 2m 40s\tremaining: 30m 56s\n",
      "795:\tlearn: 0.0521620\ttest: 0.0524832\tbest: 0.0524832 (795)\ttotal: 2m 40s\tremaining: 30m 56s\n",
      "796:\tlearn: 0.0521620\ttest: 0.0524827\tbest: 0.0524827 (796)\ttotal: 2m 40s\tremaining: 30m 56s\n",
      "797:\tlearn: 0.0521619\ttest: 0.0524821\tbest: 0.0524821 (797)\ttotal: 2m 40s\tremaining: 30m 56s\n",
      "798:\tlearn: 0.0521612\ttest: 0.0524817\tbest: 0.0524817 (798)\ttotal: 2m 41s\tremaining: 30m 55s\n",
      "799:\tlearn: 0.0521607\ttest: 0.0524813\tbest: 0.0524813 (799)\ttotal: 2m 41s\tremaining: 30m 54s\n",
      "800:\tlearn: 0.0521602\ttest: 0.0524809\tbest: 0.0524809 (800)\ttotal: 2m 41s\tremaining: 30m 54s\n",
      "801:\tlearn: 0.0521600\ttest: 0.0524806\tbest: 0.0524806 (801)\ttotal: 2m 41s\tremaining: 30m 54s\n",
      "802:\tlearn: 0.0521598\ttest: 0.0524804\tbest: 0.0524804 (802)\ttotal: 2m 41s\tremaining: 30m 54s\n",
      "803:\tlearn: 0.0521599\ttest: 0.0524804\tbest: 0.0524804 (803)\ttotal: 2m 42s\tremaining: 30m 53s\n",
      "804:\tlearn: 0.0521602\ttest: 0.0524801\tbest: 0.0524801 (804)\ttotal: 2m 42s\tremaining: 30m 53s\n",
      "805:\tlearn: 0.0521602\ttest: 0.0524801\tbest: 0.0524801 (805)\ttotal: 2m 42s\tremaining: 30m 52s\n",
      "806:\tlearn: 0.0521595\ttest: 0.0524798\tbest: 0.0524798 (806)\ttotal: 2m 42s\tremaining: 30m 52s\n",
      "807:\tlearn: 0.0521595\ttest: 0.0524797\tbest: 0.0524797 (807)\ttotal: 2m 42s\tremaining: 30m 51s\n",
      "808:\tlearn: 0.0521593\ttest: 0.0524796\tbest: 0.0524796 (808)\ttotal: 2m 42s\tremaining: 30m 51s\n",
      "809:\tlearn: 0.0521593\ttest: 0.0524795\tbest: 0.0524795 (809)\ttotal: 2m 43s\tremaining: 30m 51s\n",
      "810:\tlearn: 0.0521592\ttest: 0.0524794\tbest: 0.0524794 (810)\ttotal: 2m 43s\tremaining: 30m 50s\n",
      "811:\tlearn: 0.0521592\ttest: 0.0524794\tbest: 0.0524794 (811)\ttotal: 2m 43s\tremaining: 30m 49s\n",
      "812:\tlearn: 0.0521592\ttest: 0.0524793\tbest: 0.0524793 (812)\ttotal: 2m 43s\tremaining: 30m 49s\n",
      "813:\tlearn: 0.0521591\ttest: 0.0524792\tbest: 0.0524792 (813)\ttotal: 2m 43s\tremaining: 30m 48s\n",
      "814:\tlearn: 0.0521591\ttest: 0.0524792\tbest: 0.0524792 (813)\ttotal: 2m 44s\tremaining: 30m 48s\n",
      "815:\tlearn: 0.0521589\ttest: 0.0524790\tbest: 0.0524790 (815)\ttotal: 2m 44s\tremaining: 30m 48s\n",
      "816:\tlearn: 0.0521585\ttest: 0.0524787\tbest: 0.0524787 (816)\ttotal: 2m 44s\tremaining: 30m 47s\n",
      "817:\tlearn: 0.0521585\ttest: 0.0524787\tbest: 0.0524787 (817)\ttotal: 2m 44s\tremaining: 30m 47s\n",
      "818:\tlearn: 0.0521585\ttest: 0.0524787\tbest: 0.0524787 (818)\ttotal: 2m 44s\tremaining: 30m 46s\n",
      "819:\tlearn: 0.0521585\ttest: 0.0524787\tbest: 0.0524787 (819)\ttotal: 2m 44s\tremaining: 30m 46s\n",
      "820:\tlearn: 0.0521589\ttest: 0.0524786\tbest: 0.0524786 (820)\ttotal: 2m 45s\tremaining: 30m 45s\n",
      "821:\tlearn: 0.0521589\ttest: 0.0524785\tbest: 0.0524785 (821)\ttotal: 2m 45s\tremaining: 30m 45s\n",
      "822:\tlearn: 0.0521585\ttest: 0.0524780\tbest: 0.0524780 (822)\ttotal: 2m 45s\tremaining: 30m 45s\n",
      "823:\tlearn: 0.0521585\ttest: 0.0524780\tbest: 0.0524780 (822)\ttotal: 2m 45s\tremaining: 30m 44s\n",
      "824:\tlearn: 0.0521585\ttest: 0.0524780\tbest: 0.0524780 (822)\ttotal: 2m 45s\tremaining: 30m 43s\n",
      "825:\tlearn: 0.0521585\ttest: 0.0524780\tbest: 0.0524780 (822)\ttotal: 2m 45s\tremaining: 30m 43s\n",
      "826:\tlearn: 0.0521585\ttest: 0.0524780\tbest: 0.0524780 (822)\ttotal: 2m 46s\tremaining: 30m 42s\n",
      "827:\tlearn: 0.0521584\ttest: 0.0524778\tbest: 0.0524778 (827)\ttotal: 2m 46s\tremaining: 30m 42s\n",
      "828:\tlearn: 0.0521582\ttest: 0.0524776\tbest: 0.0524776 (828)\ttotal: 2m 46s\tremaining: 30m 42s\n",
      "829:\tlearn: 0.0521582\ttest: 0.0524776\tbest: 0.0524776 (829)\ttotal: 2m 46s\tremaining: 30m 41s\n",
      "830:\tlearn: 0.0521582\ttest: 0.0524776\tbest: 0.0524776 (830)\ttotal: 2m 46s\tremaining: 30m 40s\n",
      "831:\tlearn: 0.0521599\ttest: 0.0524774\tbest: 0.0524774 (831)\ttotal: 2m 47s\tremaining: 30m 40s\n",
      "832:\tlearn: 0.0521599\ttest: 0.0524774\tbest: 0.0524774 (832)\ttotal: 2m 47s\tremaining: 30m 39s\n",
      "833:\tlearn: 0.0521600\ttest: 0.0524773\tbest: 0.0524773 (833)\ttotal: 2m 47s\tremaining: 30m 39s\n",
      "834:\tlearn: 0.0521600\ttest: 0.0524772\tbest: 0.0524772 (834)\ttotal: 2m 47s\tremaining: 30m 39s\n",
      "835:\tlearn: 0.0521596\ttest: 0.0524771\tbest: 0.0524771 (835)\ttotal: 2m 47s\tremaining: 30m 38s\n",
      "836:\tlearn: 0.0521597\ttest: 0.0524769\tbest: 0.0524769 (836)\ttotal: 2m 47s\tremaining: 30m 38s\n",
      "837:\tlearn: 0.0521596\ttest: 0.0524769\tbest: 0.0524769 (837)\ttotal: 2m 48s\tremaining: 30m 38s\n",
      "838:\tlearn: 0.0521595\ttest: 0.0524768\tbest: 0.0524768 (838)\ttotal: 2m 48s\tremaining: 30m 37s\n",
      "839:\tlearn: 0.0521591\ttest: 0.0524764\tbest: 0.0524764 (839)\ttotal: 2m 48s\tremaining: 30m 37s\n",
      "840:\tlearn: 0.0521591\ttest: 0.0524764\tbest: 0.0524764 (840)\ttotal: 2m 48s\tremaining: 30m 36s\n",
      "841:\tlearn: 0.0521590\ttest: 0.0524760\tbest: 0.0524760 (841)\ttotal: 2m 48s\tremaining: 30m 36s\n",
      "842:\tlearn: 0.0521588\ttest: 0.0524757\tbest: 0.0524757 (842)\ttotal: 2m 49s\tremaining: 30m 36s\n",
      "843:\tlearn: 0.0521593\ttest: 0.0524756\tbest: 0.0524756 (843)\ttotal: 2m 49s\tremaining: 30m 35s\n",
      "844:\tlearn: 0.0521593\ttest: 0.0524756\tbest: 0.0524756 (844)\ttotal: 2m 49s\tremaining: 30m 34s\n",
      "845:\tlearn: 0.0521593\ttest: 0.0524756\tbest: 0.0524756 (845)\ttotal: 2m 49s\tremaining: 30m 33s\n",
      "846:\tlearn: 0.0521586\ttest: 0.0524756\tbest: 0.0524756 (846)\ttotal: 2m 49s\tremaining: 30m 33s\n",
      "847:\tlearn: 0.0521587\ttest: 0.0524755\tbest: 0.0524755 (847)\ttotal: 2m 49s\tremaining: 30m 32s\n",
      "848:\tlearn: 0.0521592\ttest: 0.0524753\tbest: 0.0524753 (848)\ttotal: 2m 50s\tremaining: 30m 32s\n",
      "849:\tlearn: 0.0521579\ttest: 0.0524746\tbest: 0.0524746 (849)\ttotal: 2m 50s\tremaining: 30m 32s\n",
      "850:\tlearn: 0.0521580\ttest: 0.0524744\tbest: 0.0524744 (850)\ttotal: 2m 50s\tremaining: 30m 32s\n",
      "851:\tlearn: 0.0521580\ttest: 0.0524744\tbest: 0.0524744 (851)\ttotal: 2m 50s\tremaining: 30m 31s\n",
      "852:\tlearn: 0.0521582\ttest: 0.0524743\tbest: 0.0524743 (852)\ttotal: 2m 50s\tremaining: 30m 31s\n",
      "853:\tlearn: 0.0521594\ttest: 0.0524737\tbest: 0.0524737 (853)\ttotal: 2m 50s\tremaining: 30m 31s\n",
      "854:\tlearn: 0.0521594\ttest: 0.0524737\tbest: 0.0524737 (853)\ttotal: 2m 51s\tremaining: 30m 30s\n",
      "855:\tlearn: 0.0521592\ttest: 0.0524734\tbest: 0.0524734 (855)\ttotal: 2m 51s\tremaining: 30m 30s\n",
      "856:\tlearn: 0.0521591\ttest: 0.0524734\tbest: 0.0524734 (856)\ttotal: 2m 51s\tremaining: 30m 29s\n",
      "857:\tlearn: 0.0521587\ttest: 0.0524733\tbest: 0.0524733 (857)\ttotal: 2m 51s\tremaining: 30m 29s\n",
      "858:\tlearn: 0.0521588\ttest: 0.0524732\tbest: 0.0524732 (858)\ttotal: 2m 51s\tremaining: 30m 28s\n",
      "859:\tlearn: 0.0521584\ttest: 0.0524730\tbest: 0.0524730 (859)\ttotal: 2m 52s\tremaining: 30m 28s\n",
      "860:\tlearn: 0.0521585\ttest: 0.0524727\tbest: 0.0524727 (860)\ttotal: 2m 52s\tremaining: 30m 28s\n",
      "861:\tlearn: 0.0521581\ttest: 0.0524723\tbest: 0.0524723 (861)\ttotal: 2m 52s\tremaining: 30m 28s\n",
      "862:\tlearn: 0.0521581\ttest: 0.0524723\tbest: 0.0524723 (861)\ttotal: 2m 52s\tremaining: 30m 27s\n",
      "863:\tlearn: 0.0521581\ttest: 0.0524723\tbest: 0.0524723 (863)\ttotal: 2m 52s\tremaining: 30m 26s\n",
      "864:\tlearn: 0.0521575\ttest: 0.0524717\tbest: 0.0524717 (864)\ttotal: 2m 52s\tremaining: 30m 26s\n",
      "865:\tlearn: 0.0521573\ttest: 0.0524715\tbest: 0.0524715 (865)\ttotal: 2m 53s\tremaining: 30m 26s\n",
      "866:\tlearn: 0.0521572\ttest: 0.0524713\tbest: 0.0524713 (866)\ttotal: 2m 53s\tremaining: 30m 26s\n",
      "867:\tlearn: 0.0521569\ttest: 0.0524711\tbest: 0.0524711 (867)\ttotal: 2m 53s\tremaining: 30m 25s\n",
      "868:\tlearn: 0.0521569\ttest: 0.0524711\tbest: 0.0524711 (868)\ttotal: 2m 53s\tremaining: 30m 25s\n",
      "869:\tlearn: 0.0521568\ttest: 0.0524711\tbest: 0.0524711 (869)\ttotal: 2m 53s\tremaining: 30m 24s\n",
      "870:\tlearn: 0.0521569\ttest: 0.0524711\tbest: 0.0524711 (870)\ttotal: 2m 54s\tremaining: 30m 23s\n",
      "871:\tlearn: 0.0521567\ttest: 0.0524708\tbest: 0.0524708 (871)\ttotal: 2m 54s\tremaining: 30m 23s\n",
      "872:\tlearn: 0.0521568\ttest: 0.0524706\tbest: 0.0524706 (872)\ttotal: 2m 54s\tremaining: 30m 23s\n",
      "873:\tlearn: 0.0521565\ttest: 0.0524704\tbest: 0.0524704 (873)\ttotal: 2m 54s\tremaining: 30m 23s\n",
      "874:\tlearn: 0.0521564\ttest: 0.0524703\tbest: 0.0524703 (874)\ttotal: 2m 54s\tremaining: 30m 22s\n",
      "875:\tlearn: 0.0521564\ttest: 0.0524697\tbest: 0.0524697 (875)\ttotal: 2m 54s\tremaining: 30m 22s\n",
      "876:\tlearn: 0.0521565\ttest: 0.0524697\tbest: 0.0524697 (876)\ttotal: 2m 55s\tremaining: 30m 21s\n",
      "877:\tlearn: 0.0521568\ttest: 0.0524695\tbest: 0.0524695 (877)\ttotal: 2m 55s\tremaining: 30m 21s\n",
      "878:\tlearn: 0.0521566\ttest: 0.0524692\tbest: 0.0524692 (878)\ttotal: 2m 55s\tremaining: 30m 21s\n",
      "879:\tlearn: 0.0521567\ttest: 0.0524685\tbest: 0.0524685 (879)\ttotal: 2m 55s\tremaining: 30m 20s\n",
      "880:\tlearn: 0.0521551\ttest: 0.0524680\tbest: 0.0524680 (880)\ttotal: 2m 55s\tremaining: 30m 20s\n",
      "881:\tlearn: 0.0521557\ttest: 0.0524678\tbest: 0.0524678 (881)\ttotal: 2m 56s\tremaining: 30m 20s\n",
      "882:\tlearn: 0.0521560\ttest: 0.0524676\tbest: 0.0524676 (882)\ttotal: 2m 56s\tremaining: 30m 19s\n",
      "883:\tlearn: 0.0521560\ttest: 0.0524676\tbest: 0.0524676 (883)\ttotal: 2m 56s\tremaining: 30m 19s\n",
      "884:\tlearn: 0.0521555\ttest: 0.0524676\tbest: 0.0524676 (884)\ttotal: 2m 56s\tremaining: 30m 18s\n",
      "885:\tlearn: 0.0521558\ttest: 0.0524675\tbest: 0.0524675 (885)\ttotal: 2m 56s\tremaining: 30m 17s\n",
      "886:\tlearn: 0.0521554\ttest: 0.0524675\tbest: 0.0524675 (886)\ttotal: 2m 56s\tremaining: 30m 17s\n",
      "887:\tlearn: 0.0521554\ttest: 0.0524675\tbest: 0.0524675 (887)\ttotal: 2m 57s\tremaining: 30m 16s\n",
      "888:\tlearn: 0.0521554\ttest: 0.0524675\tbest: 0.0524675 (888)\ttotal: 2m 57s\tremaining: 30m 15s\n",
      "889:\tlearn: 0.0521553\ttest: 0.0524674\tbest: 0.0524674 (889)\ttotal: 2m 57s\tremaining: 30m 15s\n",
      "890:\tlearn: 0.0521552\ttest: 0.0524667\tbest: 0.0524667 (890)\ttotal: 2m 57s\tremaining: 30m 14s\n",
      "891:\tlearn: 0.0521552\ttest: 0.0524667\tbest: 0.0524667 (891)\ttotal: 2m 57s\tremaining: 30m 14s\n",
      "892:\tlearn: 0.0521544\ttest: 0.0524665\tbest: 0.0524665 (892)\ttotal: 2m 57s\tremaining: 30m 13s\n",
      "893:\tlearn: 0.0521543\ttest: 0.0524663\tbest: 0.0524663 (893)\ttotal: 2m 58s\tremaining: 30m 13s\n",
      "894:\tlearn: 0.0521544\ttest: 0.0524656\tbest: 0.0524656 (894)\ttotal: 2m 58s\tremaining: 30m 12s\n",
      "895:\tlearn: 0.0521544\ttest: 0.0524656\tbest: 0.0524656 (895)\ttotal: 2m 58s\tremaining: 30m 12s\n",
      "896:\tlearn: 0.0521544\ttest: 0.0524656\tbest: 0.0524656 (896)\ttotal: 2m 58s\tremaining: 30m 11s\n",
      "897:\tlearn: 0.0521544\ttest: 0.0524656\tbest: 0.0524656 (897)\ttotal: 2m 58s\tremaining: 30m 10s\n",
      "898:\tlearn: 0.0521498\ttest: 0.0524655\tbest: 0.0524655 (898)\ttotal: 2m 58s\tremaining: 30m 10s\n",
      "899:\tlearn: 0.0521496\ttest: 0.0524652\tbest: 0.0524652 (899)\ttotal: 2m 59s\tremaining: 30m 10s\n",
      "900:\tlearn: 0.0521496\ttest: 0.0524652\tbest: 0.0524652 (900)\ttotal: 2m 59s\tremaining: 30m 9s\n",
      "901:\tlearn: 0.0521496\ttest: 0.0524651\tbest: 0.0524651 (901)\ttotal: 2m 59s\tremaining: 30m 8s\n",
      "902:\tlearn: 0.0521496\ttest: 0.0524651\tbest: 0.0524651 (902)\ttotal: 2m 59s\tremaining: 30m 8s\n",
      "903:\tlearn: 0.0521497\ttest: 0.0524650\tbest: 0.0524650 (903)\ttotal: 2m 59s\tremaining: 30m 7s\n",
      "904:\tlearn: 0.0521496\ttest: 0.0524650\tbest: 0.0524650 (904)\ttotal: 2m 59s\tremaining: 30m 7s\n",
      "905:\tlearn: 0.0521502\ttest: 0.0524649\tbest: 0.0524649 (905)\ttotal: 2m 59s\tremaining: 30m 6s\n",
      "906:\tlearn: 0.0521502\ttest: 0.0524649\tbest: 0.0524649 (906)\ttotal: 3m\tremaining: 30m 5s\n",
      "907:\tlearn: 0.0521502\ttest: 0.0524649\tbest: 0.0524649 (907)\ttotal: 3m\tremaining: 30m 5s\n",
      "908:\tlearn: 0.0521502\ttest: 0.0524649\tbest: 0.0524649 (908)\ttotal: 3m\tremaining: 30m 4s\n",
      "909:\tlearn: 0.0521502\ttest: 0.0524649\tbest: 0.0524649 (909)\ttotal: 3m\tremaining: 30m 3s\n",
      "910:\tlearn: 0.0521502\ttest: 0.0524649\tbest: 0.0524649 (910)\ttotal: 3m\tremaining: 30m 2s\n",
      "911:\tlearn: 0.0521502\ttest: 0.0524649\tbest: 0.0524649 (911)\ttotal: 3m\tremaining: 30m 2s\n",
      "912:\tlearn: 0.0521492\ttest: 0.0524643\tbest: 0.0524643 (912)\ttotal: 3m 1s\tremaining: 30m 2s\n",
      "913:\tlearn: 0.0521492\ttest: 0.0524643\tbest: 0.0524643 (913)\ttotal: 3m 1s\tremaining: 30m 1s\n",
      "914:\tlearn: 0.0521492\ttest: 0.0524643\tbest: 0.0524643 (914)\ttotal: 3m 1s\tremaining: 30m\n",
      "915:\tlearn: 0.0521492\ttest: 0.0524643\tbest: 0.0524643 (915)\ttotal: 3m 1s\tremaining: 29m 59s\n",
      "916:\tlearn: 0.0521497\ttest: 0.0524641\tbest: 0.0524641 (916)\ttotal: 3m 1s\tremaining: 29m 59s\n",
      "917:\tlearn: 0.0521496\ttest: 0.0524639\tbest: 0.0524639 (917)\ttotal: 3m 1s\tremaining: 29m 59s\n",
      "918:\tlearn: 0.0521495\ttest: 0.0524639\tbest: 0.0524639 (918)\ttotal: 3m 2s\tremaining: 29m 58s\n",
      "919:\tlearn: 0.0521494\ttest: 0.0524639\tbest: 0.0524639 (919)\ttotal: 3m 2s\tremaining: 29m 58s\n",
      "920:\tlearn: 0.0521489\ttest: 0.0524637\tbest: 0.0524637 (920)\ttotal: 3m 2s\tremaining: 29m 58s\n",
      "921:\tlearn: 0.0521494\ttest: 0.0524632\tbest: 0.0524632 (921)\ttotal: 3m 2s\tremaining: 29m 58s\n",
      "922:\tlearn: 0.0521493\ttest: 0.0524630\tbest: 0.0524630 (922)\ttotal: 3m 2s\tremaining: 29m 57s\n",
      "923:\tlearn: 0.0521491\ttest: 0.0524628\tbest: 0.0524628 (923)\ttotal: 3m 3s\tremaining: 29m 57s\n",
      "924:\tlearn: 0.0521491\ttest: 0.0524627\tbest: 0.0524627 (924)\ttotal: 3m 3s\tremaining: 29m 56s\n",
      "925:\tlearn: 0.0521481\ttest: 0.0524621\tbest: 0.0524621 (925)\ttotal: 3m 3s\tremaining: 29m 56s\n",
      "926:\tlearn: 0.0521483\ttest: 0.0524621\tbest: 0.0524621 (926)\ttotal: 3m 3s\tremaining: 29m 56s\n",
      "927:\tlearn: 0.0521481\ttest: 0.0524620\tbest: 0.0524620 (927)\ttotal: 3m 3s\tremaining: 29m 55s\n",
      "928:\tlearn: 0.0521482\ttest: 0.0524620\tbest: 0.0524620 (928)\ttotal: 3m 3s\tremaining: 29m 54s\n",
      "929:\tlearn: 0.0521478\ttest: 0.0524614\tbest: 0.0524614 (929)\ttotal: 3m 4s\tremaining: 29m 54s\n",
      "930:\tlearn: 0.0521478\ttest: 0.0524614\tbest: 0.0524614 (930)\ttotal: 3m 4s\tremaining: 29m 53s\n",
      "931:\tlearn: 0.0521478\ttest: 0.0524614\tbest: 0.0524614 (931)\ttotal: 3m 4s\tremaining: 29m 53s\n",
      "932:\tlearn: 0.0521478\ttest: 0.0524614\tbest: 0.0524614 (931)\ttotal: 3m 4s\tremaining: 29m 53s\n",
      "933:\tlearn: 0.0521478\ttest: 0.0524614\tbest: 0.0524614 (933)\ttotal: 3m 4s\tremaining: 29m 52s\n",
      "934:\tlearn: 0.0521467\ttest: 0.0524607\tbest: 0.0524607 (934)\ttotal: 3m 4s\tremaining: 29m 52s\n",
      "935:\tlearn: 0.0521466\ttest: 0.0524606\tbest: 0.0524606 (935)\ttotal: 3m 5s\tremaining: 29m 52s\n",
      "936:\tlearn: 0.0521466\ttest: 0.0524600\tbest: 0.0524600 (936)\ttotal: 3m 5s\tremaining: 29m 51s\n",
      "937:\tlearn: 0.0521465\ttest: 0.0524599\tbest: 0.0524599 (937)\ttotal: 3m 5s\tremaining: 29m 51s\n",
      "938:\tlearn: 0.0521464\ttest: 0.0524597\tbest: 0.0524597 (938)\ttotal: 3m 5s\tremaining: 29m 51s\n",
      "939:\tlearn: 0.0521461\ttest: 0.0524595\tbest: 0.0524595 (939)\ttotal: 3m 5s\tremaining: 29m 51s\n",
      "940:\tlearn: 0.0521457\ttest: 0.0524591\tbest: 0.0524591 (940)\ttotal: 3m 6s\tremaining: 29m 50s\n",
      "941:\tlearn: 0.0521455\ttest: 0.0524589\tbest: 0.0524589 (941)\ttotal: 3m 6s\tremaining: 29m 50s\n",
      "942:\tlearn: 0.0521455\ttest: 0.0524589\tbest: 0.0524589 (942)\ttotal: 3m 6s\tremaining: 29m 49s\n",
      "943:\tlearn: 0.0521454\ttest: 0.0524588\tbest: 0.0524588 (943)\ttotal: 3m 6s\tremaining: 29m 48s\n",
      "944:\tlearn: 0.0521454\ttest: 0.0524588\tbest: 0.0524588 (944)\ttotal: 3m 6s\tremaining: 29m 48s\n",
      "945:\tlearn: 0.0521453\ttest: 0.0524586\tbest: 0.0524586 (945)\ttotal: 3m 6s\tremaining: 29m 47s\n",
      "946:\tlearn: 0.0521452\ttest: 0.0524585\tbest: 0.0524585 (946)\ttotal: 3m 7s\tremaining: 29m 47s\n",
      "947:\tlearn: 0.0521451\ttest: 0.0524583\tbest: 0.0524583 (947)\ttotal: 3m 7s\tremaining: 29m 47s\n",
      "948:\tlearn: 0.0521452\ttest: 0.0524582\tbest: 0.0524582 (948)\ttotal: 3m 7s\tremaining: 29m 46s\n",
      "949:\tlearn: 0.0521446\ttest: 0.0524576\tbest: 0.0524576 (949)\ttotal: 3m 7s\tremaining: 29m 46s\n",
      "950:\tlearn: 0.0521446\ttest: 0.0524576\tbest: 0.0524576 (950)\ttotal: 3m 7s\tremaining: 29m 46s\n",
      "951:\tlearn: 0.0521446\ttest: 0.0524576\tbest: 0.0524576 (951)\ttotal: 3m 7s\tremaining: 29m 45s\n",
      "952:\tlearn: 0.0521446\ttest: 0.0524576\tbest: 0.0524576 (952)\ttotal: 3m 7s\tremaining: 29m 44s\n",
      "953:\tlearn: 0.0521446\ttest: 0.0524576\tbest: 0.0524576 (953)\ttotal: 3m 8s\tremaining: 29m 43s\n",
      "954:\tlearn: 0.0521446\ttest: 0.0524576\tbest: 0.0524576 (954)\ttotal: 3m 8s\tremaining: 29m 43s\n",
      "955:\tlearn: 0.0521440\ttest: 0.0524574\tbest: 0.0524574 (955)\ttotal: 3m 8s\tremaining: 29m 43s\n",
      "956:\tlearn: 0.0521436\ttest: 0.0524568\tbest: 0.0524568 (956)\ttotal: 3m 8s\tremaining: 29m 42s\n",
      "957:\tlearn: 0.0521436\ttest: 0.0524568\tbest: 0.0524568 (957)\ttotal: 3m 8s\tremaining: 29m 42s\n",
      "958:\tlearn: 0.0521436\ttest: 0.0524568\tbest: 0.0524568 (958)\ttotal: 3m 8s\tremaining: 29m 41s\n",
      "959:\tlearn: 0.0521435\ttest: 0.0524568\tbest: 0.0524568 (959)\ttotal: 3m 9s\tremaining: 29m 40s\n",
      "960:\tlearn: 0.0521438\ttest: 0.0524568\tbest: 0.0524568 (960)\ttotal: 3m 9s\tremaining: 29m 40s\n",
      "961:\tlearn: 0.0521438\ttest: 0.0524568\tbest: 0.0524568 (961)\ttotal: 3m 9s\tremaining: 29m 39s\n",
      "962:\tlearn: 0.0521435\ttest: 0.0524568\tbest: 0.0524568 (962)\ttotal: 3m 9s\tremaining: 29m 38s\n",
      "963:\tlearn: 0.0521438\ttest: 0.0524568\tbest: 0.0524568 (963)\ttotal: 3m 9s\tremaining: 29m 38s\n",
      "964:\tlearn: 0.0521435\ttest: 0.0524568\tbest: 0.0524568 (964)\ttotal: 3m 9s\tremaining: 29m 37s\n",
      "965:\tlearn: 0.0521435\ttest: 0.0524568\tbest: 0.0524568 (965)\ttotal: 3m 10s\tremaining: 29m 37s\n",
      "966:\tlearn: 0.0521435\ttest: 0.0524568\tbest: 0.0524568 (966)\ttotal: 3m 10s\tremaining: 29m 36s\n",
      "967:\tlearn: 0.0521435\ttest: 0.0524568\tbest: 0.0524568 (967)\ttotal: 3m 10s\tremaining: 29m 35s\n",
      "968:\tlearn: 0.0521435\ttest: 0.0524568\tbest: 0.0524568 (968)\ttotal: 3m 10s\tremaining: 29m 35s\n",
      "969:\tlearn: 0.0521435\ttest: 0.0524568\tbest: 0.0524568 (969)\ttotal: 3m 10s\tremaining: 29m 34s\n",
      "970:\tlearn: 0.0521435\ttest: 0.0524568\tbest: 0.0524568 (970)\ttotal: 3m 10s\tremaining: 29m 33s\n",
      "971:\tlearn: 0.0521435\ttest: 0.0524568\tbest: 0.0524568 (971)\ttotal: 3m 10s\tremaining: 29m 33s\n",
      "972:\tlearn: 0.0521435\ttest: 0.0524568\tbest: 0.0524568 (972)\ttotal: 3m 11s\tremaining: 29m 32s\n",
      "973:\tlearn: 0.0521435\ttest: 0.0524568\tbest: 0.0524568 (973)\ttotal: 3m 11s\tremaining: 29m 32s\n",
      "974:\tlearn: 0.0521435\ttest: 0.0524568\tbest: 0.0524568 (974)\ttotal: 3m 11s\tremaining: 29m 31s\n",
      "975:\tlearn: 0.0521435\ttest: 0.0524568\tbest: 0.0524568 (975)\ttotal: 3m 11s\tremaining: 29m 30s\n",
      "976:\tlearn: 0.0521435\ttest: 0.0524568\tbest: 0.0524568 (976)\ttotal: 3m 11s\tremaining: 29m 30s\n",
      "977:\tlearn: 0.0521435\ttest: 0.0524568\tbest: 0.0524568 (977)\ttotal: 3m 11s\tremaining: 29m 29s\n",
      "978:\tlearn: 0.0521435\ttest: 0.0524568\tbest: 0.0524568 (978)\ttotal: 3m 11s\tremaining: 29m 28s\n",
      "979:\tlearn: 0.0521435\ttest: 0.0524568\tbest: 0.0524568 (979)\ttotal: 3m 12s\tremaining: 29m 28s\n",
      "980:\tlearn: 0.0521435\ttest: 0.0524568\tbest: 0.0524568 (980)\ttotal: 3m 12s\tremaining: 29m 27s\n",
      "981:\tlearn: 0.0521435\ttest: 0.0524568\tbest: 0.0524568 (981)\ttotal: 3m 12s\tremaining: 29m 27s\n",
      "982:\tlearn: 0.0521435\ttest: 0.0524568\tbest: 0.0524568 (982)\ttotal: 3m 12s\tremaining: 29m 26s\n",
      "983:\tlearn: 0.0521435\ttest: 0.0524568\tbest: 0.0524568 (983)\ttotal: 3m 12s\tremaining: 29m 26s\n",
      "984:\tlearn: 0.0521435\ttest: 0.0524568\tbest: 0.0524568 (984)\ttotal: 3m 12s\tremaining: 29m 25s\n",
      "985:\tlearn: 0.0521435\ttest: 0.0524568\tbest: 0.0524568 (985)\ttotal: 3m 13s\tremaining: 29m 24s\n",
      "986:\tlearn: 0.0521435\ttest: 0.0524568\tbest: 0.0524568 (986)\ttotal: 3m 13s\tremaining: 29m 23s\n",
      "987:\tlearn: 0.0521435\ttest: 0.0524568\tbest: 0.0524568 (987)\ttotal: 3m 13s\tremaining: 29m 23s\n",
      "988:\tlearn: 0.0521435\ttest: 0.0524568\tbest: 0.0524568 (987)\ttotal: 3m 13s\tremaining: 29m 22s\n",
      "989:\tlearn: 0.0521435\ttest: 0.0524568\tbest: 0.0524568 (989)\ttotal: 3m 13s\tremaining: 29m 22s\n",
      "990:\tlearn: 0.0521435\ttest: 0.0524568\tbest: 0.0524568 (990)\ttotal: 3m 13s\tremaining: 29m 21s\n",
      "991:\tlearn: 0.0521435\ttest: 0.0524568\tbest: 0.0524568 (991)\ttotal: 3m 13s\tremaining: 29m 20s\n",
      "992:\tlearn: 0.0521435\ttest: 0.0524568\tbest: 0.0524568 (992)\ttotal: 3m 14s\tremaining: 29m 20s\n",
      "993:\tlearn: 0.0521435\ttest: 0.0524568\tbest: 0.0524568 (992)\ttotal: 3m 14s\tremaining: 29m 19s\n",
      "994:\tlearn: 0.0521435\ttest: 0.0524568\tbest: 0.0524568 (994)\ttotal: 3m 14s\tremaining: 29m 18s\n",
      "995:\tlearn: 0.0521438\ttest: 0.0524568\tbest: 0.0524568 (995)\ttotal: 3m 14s\tremaining: 29m 18s\n",
      "996:\tlearn: 0.0521435\ttest: 0.0524568\tbest: 0.0524568 (996)\ttotal: 3m 14s\tremaining: 29m 17s\n",
      "997:\tlearn: 0.0521435\ttest: 0.0524568\tbest: 0.0524568 (997)\ttotal: 3m 14s\tremaining: 29m 17s\n",
      "998:\tlearn: 0.0521435\ttest: 0.0524568\tbest: 0.0524568 (998)\ttotal: 3m 14s\tremaining: 29m 16s\n",
      "999:\tlearn: 0.0521434\ttest: 0.0524568\tbest: 0.0524568 (999)\ttotal: 3m 15s\tremaining: 29m 15s\n",
      "1000:\tlearn: 0.0521434\ttest: 0.0524568\tbest: 0.0524568 (1000)\ttotal: 3m 15s\tremaining: 29m 15s\n",
      "1001:\tlearn: 0.0521435\ttest: 0.0524568\tbest: 0.0524568 (1001)\ttotal: 3m 15s\tremaining: 29m 14s\n",
      "1002:\tlearn: 0.0521435\ttest: 0.0524568\tbest: 0.0524568 (1002)\ttotal: 3m 15s\tremaining: 29m 13s\n",
      "1003:\tlearn: 0.0521437\ttest: 0.0524568\tbest: 0.0524568 (1003)\ttotal: 3m 15s\tremaining: 29m 13s\n",
      "1004:\tlearn: 0.0521437\ttest: 0.0524568\tbest: 0.0524568 (1004)\ttotal: 3m 15s\tremaining: 29m 12s\n",
      "1005:\tlearn: 0.0521437\ttest: 0.0524568\tbest: 0.0524568 (1005)\ttotal: 3m 15s\tremaining: 29m 12s\n",
      "1006:\tlearn: 0.0521437\ttest: 0.0524568\tbest: 0.0524568 (1006)\ttotal: 3m 16s\tremaining: 29m 11s\n",
      "1007:\tlearn: 0.0521437\ttest: 0.0524568\tbest: 0.0524568 (1007)\ttotal: 3m 16s\tremaining: 29m 11s\n",
      "1008:\tlearn: 0.0521437\ttest: 0.0524568\tbest: 0.0524568 (1008)\ttotal: 3m 16s\tremaining: 29m 10s\n",
      "1009:\tlearn: 0.0521437\ttest: 0.0524568\tbest: 0.0524568 (1009)\ttotal: 3m 16s\tremaining: 29m 9s\n",
      "1010:\tlearn: 0.0521437\ttest: 0.0524568\tbest: 0.0524568 (1010)\ttotal: 3m 16s\tremaining: 29m 9s\n",
      "1011:\tlearn: 0.0521437\ttest: 0.0524568\tbest: 0.0524568 (1011)\ttotal: 3m 16s\tremaining: 29m 8s\n",
      "1012:\tlearn: 0.0521437\ttest: 0.0524568\tbest: 0.0524568 (1012)\ttotal: 3m 17s\tremaining: 29m 8s\n",
      "1013:\tlearn: 0.0521437\ttest: 0.0524568\tbest: 0.0524568 (1013)\ttotal: 3m 17s\tremaining: 29m 7s\n",
      "1014:\tlearn: 0.0521437\ttest: 0.0524568\tbest: 0.0524568 (1013)\ttotal: 3m 17s\tremaining: 29m 6s\n",
      "1015:\tlearn: 0.0521437\ttest: 0.0524568\tbest: 0.0524568 (1013)\ttotal: 3m 17s\tremaining: 29m 6s\n",
      "1016:\tlearn: 0.0521437\ttest: 0.0524568\tbest: 0.0524568 (1013)\ttotal: 3m 17s\tremaining: 29m 5s\n",
      "1017:\tlearn: 0.0521437\ttest: 0.0524568\tbest: 0.0524568 (1013)\ttotal: 3m 17s\tremaining: 29m 4s\n",
      "1018:\tlearn: 0.0521437\ttest: 0.0524568\tbest: 0.0524568 (1013)\ttotal: 3m 17s\tremaining: 29m 3s\n",
      "1019:\tlearn: 0.0521437\ttest: 0.0524568\tbest: 0.0524568 (1013)\ttotal: 3m 17s\tremaining: 29m 3s\n",
      "1020:\tlearn: 0.0521437\ttest: 0.0524568\tbest: 0.0524568 (1013)\ttotal: 3m 18s\tremaining: 29m 2s\n",
      "1021:\tlearn: 0.0521437\ttest: 0.0524568\tbest: 0.0524568 (1013)\ttotal: 3m 18s\tremaining: 29m 1s\n",
      "1022:\tlearn: 0.0521437\ttest: 0.0524568\tbest: 0.0524568 (1013)\ttotal: 3m 18s\tremaining: 29m\n",
      "1023:\tlearn: 0.0521437\ttest: 0.0524568\tbest: 0.0524568 (1013)\ttotal: 3m 18s\tremaining: 29m\n",
      "1024:\tlearn: 0.0521437\ttest: 0.0524568\tbest: 0.0524568 (1013)\ttotal: 3m 18s\tremaining: 28m 59s\n",
      "1025:\tlearn: 0.0521437\ttest: 0.0524568\tbest: 0.0524568 (1013)\ttotal: 3m 18s\tremaining: 28m 59s\n",
      "1026:\tlearn: 0.0521437\ttest: 0.0524568\tbest: 0.0524568 (1013)\ttotal: 3m 18s\tremaining: 28m 58s\n",
      "1027:\tlearn: 0.0521437\ttest: 0.0524568\tbest: 0.0524568 (1013)\ttotal: 3m 19s\tremaining: 28m 57s\n",
      "1028:\tlearn: 0.0521437\ttest: 0.0524568\tbest: 0.0524568 (1013)\ttotal: 3m 19s\tremaining: 28m 57s\n",
      "1029:\tlearn: 0.0521437\ttest: 0.0524568\tbest: 0.0524568 (1013)\ttotal: 3m 19s\tremaining: 28m 56s\n",
      "1030:\tlearn: 0.0521437\ttest: 0.0524568\tbest: 0.0524568 (1013)\ttotal: 3m 19s\tremaining: 28m 56s\n",
      "1031:\tlearn: 0.0521437\ttest: 0.0524568\tbest: 0.0524568 (1013)\ttotal: 3m 19s\tremaining: 28m 55s\n",
      "1032:\tlearn: 0.0521437\ttest: 0.0524568\tbest: 0.0524568 (1013)\ttotal: 3m 19s\tremaining: 28m 54s\n",
      "1033:\tlearn: 0.0521437\ttest: 0.0524568\tbest: 0.0524568 (1013)\ttotal: 3m 19s\tremaining: 28m 54s\n",
      "1034:\tlearn: 0.0521437\ttest: 0.0524568\tbest: 0.0524568 (1013)\ttotal: 3m 20s\tremaining: 28m 53s\n",
      "1035:\tlearn: 0.0521437\ttest: 0.0524568\tbest: 0.0524568 (1013)\ttotal: 3m 20s\tremaining: 28m 52s\n",
      "1036:\tlearn: 0.0521437\ttest: 0.0524568\tbest: 0.0524568 (1013)\ttotal: 3m 20s\tremaining: 28m 52s\n",
      "1037:\tlearn: 0.0521437\ttest: 0.0524568\tbest: 0.0524568 (1013)\ttotal: 3m 20s\tremaining: 28m 51s\n",
      "1038:\tlearn: 0.0521437\ttest: 0.0524568\tbest: 0.0524568 (1013)\ttotal: 3m 20s\tremaining: 28m 50s\n",
      "1039:\tlearn: 0.0521437\ttest: 0.0524568\tbest: 0.0524568 (1013)\ttotal: 3m 20s\tremaining: 28m 50s\n",
      "1040:\tlearn: 0.0521437\ttest: 0.0524568\tbest: 0.0524568 (1013)\ttotal: 3m 20s\tremaining: 28m 49s\n",
      "1041:\tlearn: 0.0521437\ttest: 0.0524568\tbest: 0.0524568 (1013)\ttotal: 3m 21s\tremaining: 28m 48s\n",
      "1042:\tlearn: 0.0521437\ttest: 0.0524568\tbest: 0.0524568 (1013)\ttotal: 3m 21s\tremaining: 28m 48s\n",
      "1043:\tlearn: 0.0521437\ttest: 0.0524568\tbest: 0.0524568 (1013)\ttotal: 3m 21s\tremaining: 28m 47s\n",
      "1044:\tlearn: 0.0521437\ttest: 0.0524568\tbest: 0.0524568 (1013)\ttotal: 3m 21s\tremaining: 28m 47s\n",
      "1045:\tlearn: 0.0521437\ttest: 0.0524568\tbest: 0.0524568 (1013)\ttotal: 3m 21s\tremaining: 28m 46s\n",
      "1046:\tlearn: 0.0521437\ttest: 0.0524568\tbest: 0.0524568 (1013)\ttotal: 3m 21s\tremaining: 28m 46s\n",
      "1047:\tlearn: 0.0521437\ttest: 0.0524568\tbest: 0.0524568 (1013)\ttotal: 3m 21s\tremaining: 28m 45s\n",
      "1048:\tlearn: 0.0521437\ttest: 0.0524568\tbest: 0.0524568 (1013)\ttotal: 3m 22s\tremaining: 28m 44s\n",
      "1049:\tlearn: 0.0521437\ttest: 0.0524568\tbest: 0.0524568 (1013)\ttotal: 3m 22s\tremaining: 28m 44s\n",
      "1050:\tlearn: 0.0521437\ttest: 0.0524568\tbest: 0.0524568 (1013)\ttotal: 3m 22s\tremaining: 28m 43s\n",
      "1051:\tlearn: 0.0521437\ttest: 0.0524568\tbest: 0.0524568 (1013)\ttotal: 3m 22s\tremaining: 28m 43s\n",
      "1052:\tlearn: 0.0521437\ttest: 0.0524568\tbest: 0.0524568 (1013)\ttotal: 3m 22s\tremaining: 28m 42s\n",
      "1053:\tlearn: 0.0521437\ttest: 0.0524568\tbest: 0.0524568 (1013)\ttotal: 3m 22s\tremaining: 28m 41s\n",
      "1054:\tlearn: 0.0521437\ttest: 0.0524568\tbest: 0.0524568 (1013)\ttotal: 3m 22s\tremaining: 28m 41s\n",
      "1055:\tlearn: 0.0521437\ttest: 0.0524568\tbest: 0.0524568 (1013)\ttotal: 3m 23s\tremaining: 28m 40s\n",
      "1056:\tlearn: 0.0521437\ttest: 0.0524568\tbest: 0.0524568 (1013)\ttotal: 3m 23s\tremaining: 28m 39s\n",
      "1057:\tlearn: 0.0521437\ttest: 0.0524568\tbest: 0.0524568 (1013)\ttotal: 3m 23s\tremaining: 28m 39s\n",
      "1058:\tlearn: 0.0521437\ttest: 0.0524568\tbest: 0.0524568 (1013)\ttotal: 3m 23s\tremaining: 28m 38s\n",
      "1059:\tlearn: 0.0521437\ttest: 0.0524568\tbest: 0.0524568 (1013)\ttotal: 3m 23s\tremaining: 28m 38s\n",
      "1060:\tlearn: 0.0521437\ttest: 0.0524568\tbest: 0.0524568 (1013)\ttotal: 3m 23s\tremaining: 28m 37s\n",
      "1061:\tlearn: 0.0521437\ttest: 0.0524568\tbest: 0.0524568 (1013)\ttotal: 3m 23s\tremaining: 28m 36s\n",
      "1062:\tlearn: 0.0521437\ttest: 0.0524568\tbest: 0.0524568 (1013)\ttotal: 3m 24s\tremaining: 28m 36s\n",
      "1063:\tlearn: 0.0521437\ttest: 0.0524568\tbest: 0.0524568 (1013)\ttotal: 3m 24s\tremaining: 28m 35s\n",
      "1064:\tlearn: 0.0521437\ttest: 0.0524568\tbest: 0.0524568 (1013)\ttotal: 3m 24s\tremaining: 28m 35s\n",
      "1065:\tlearn: 0.0521437\ttest: 0.0524568\tbest: 0.0524568 (1013)\ttotal: 3m 24s\tremaining: 28m 34s\n",
      "1066:\tlearn: 0.0521437\ttest: 0.0524568\tbest: 0.0524568 (1013)\ttotal: 3m 24s\tremaining: 28m 33s\n",
      "1067:\tlearn: 0.0521437\ttest: 0.0524568\tbest: 0.0524568 (1013)\ttotal: 3m 24s\tremaining: 28m 33s\n",
      "1068:\tlearn: 0.0521437\ttest: 0.0524568\tbest: 0.0524568 (1013)\ttotal: 3m 25s\tremaining: 28m 32s\n",
      "1069:\tlearn: 0.0521437\ttest: 0.0524568\tbest: 0.0524568 (1013)\ttotal: 3m 25s\tremaining: 28m 32s\n",
      "1070:\tlearn: 0.0521437\ttest: 0.0524568\tbest: 0.0524568 (1013)\ttotal: 3m 25s\tremaining: 28m 31s\n",
      "1071:\tlearn: 0.0521437\ttest: 0.0524568\tbest: 0.0524568 (1013)\ttotal: 3m 25s\tremaining: 28m 30s\n",
      "1072:\tlearn: 0.0521437\ttest: 0.0524568\tbest: 0.0524568 (1013)\ttotal: 3m 25s\tremaining: 28m 30s\n",
      "1073:\tlearn: 0.0521437\ttest: 0.0524568\tbest: 0.0524568 (1013)\ttotal: 3m 25s\tremaining: 28m 29s\n",
      "1074:\tlearn: 0.0521437\ttest: 0.0524568\tbest: 0.0524568 (1013)\ttotal: 3m 25s\tremaining: 28m 29s\n",
      "1075:\tlearn: 0.0521437\ttest: 0.0524568\tbest: 0.0524568 (1013)\ttotal: 3m 25s\tremaining: 28m 28s\n",
      "1076:\tlearn: 0.0521437\ttest: 0.0524568\tbest: 0.0524568 (1013)\ttotal: 3m 26s\tremaining: 28m 27s\n",
      "1077:\tlearn: 0.0521437\ttest: 0.0524568\tbest: 0.0524568 (1013)\ttotal: 3m 26s\tremaining: 28m 27s\n",
      "1078:\tlearn: 0.0521437\ttest: 0.0524568\tbest: 0.0524568 (1013)\ttotal: 3m 26s\tremaining: 28m 26s\n",
      "1079:\tlearn: 0.0521437\ttest: 0.0524568\tbest: 0.0524568 (1013)\ttotal: 3m 26s\tremaining: 28m 26s\n",
      "1080:\tlearn: 0.0521437\ttest: 0.0524568\tbest: 0.0524568 (1013)\ttotal: 3m 26s\tremaining: 28m 25s\n",
      "1081:\tlearn: 0.0521437\ttest: 0.0524568\tbest: 0.0524568 (1013)\ttotal: 3m 26s\tremaining: 28m 25s\n",
      "1082:\tlearn: 0.0521437\ttest: 0.0524568\tbest: 0.0524568 (1013)\ttotal: 3m 27s\tremaining: 28m 24s\n",
      "1083:\tlearn: 0.0521437\ttest: 0.0524568\tbest: 0.0524568 (1013)\ttotal: 3m 27s\tremaining: 28m 24s\n",
      "1084:\tlearn: 0.0521437\ttest: 0.0524568\tbest: 0.0524568 (1013)\ttotal: 3m 27s\tremaining: 28m 23s\n",
      "1085:\tlearn: 0.0521437\ttest: 0.0524568\tbest: 0.0524568 (1013)\ttotal: 3m 27s\tremaining: 28m 22s\n",
      "1086:\tlearn: 0.0521437\ttest: 0.0524568\tbest: 0.0524568 (1013)\ttotal: 3m 27s\tremaining: 28m 22s\n",
      "1087:\tlearn: 0.0521437\ttest: 0.0524568\tbest: 0.0524568 (1013)\ttotal: 3m 27s\tremaining: 28m 21s\n",
      "1088:\tlearn: 0.0521437\ttest: 0.0524568\tbest: 0.0524568 (1013)\ttotal: 3m 27s\tremaining: 28m 21s\n",
      "1089:\tlearn: 0.0521437\ttest: 0.0524568\tbest: 0.0524568 (1013)\ttotal: 3m 28s\tremaining: 28m 20s\n",
      "1090:\tlearn: 0.0521437\ttest: 0.0524568\tbest: 0.0524568 (1013)\ttotal: 3m 28s\tremaining: 28m 20s\n",
      "1091:\tlearn: 0.0521437\ttest: 0.0524568\tbest: 0.0524568 (1013)\ttotal: 3m 28s\tremaining: 28m 19s\n",
      "1092:\tlearn: 0.0521437\ttest: 0.0524568\tbest: 0.0524568 (1013)\ttotal: 3m 28s\tremaining: 28m 18s\n",
      "1093:\tlearn: 0.0521437\ttest: 0.0524568\tbest: 0.0524568 (1013)\ttotal: 3m 28s\tremaining: 28m 18s\n",
      "1094:\tlearn: 0.0521437\ttest: 0.0524568\tbest: 0.0524568 (1013)\ttotal: 3m 28s\tremaining: 28m 17s\n",
      "1095:\tlearn: 0.0521437\ttest: 0.0524568\tbest: 0.0524568 (1013)\ttotal: 3m 28s\tremaining: 28m 17s\n",
      "1096:\tlearn: 0.0521437\ttest: 0.0524568\tbest: 0.0524568 (1013)\ttotal: 3m 29s\tremaining: 28m 16s\n",
      "1097:\tlearn: 0.0521437\ttest: 0.0524568\tbest: 0.0524568 (1013)\ttotal: 3m 29s\tremaining: 28m 16s\n",
      "1098:\tlearn: 0.0521437\ttest: 0.0524568\tbest: 0.0524568 (1013)\ttotal: 3m 29s\tremaining: 28m 15s\n",
      "1099:\tlearn: 0.0521437\ttest: 0.0524568\tbest: 0.0524568 (1013)\ttotal: 3m 29s\tremaining: 28m 15s\n",
      "1100:\tlearn: 0.0521437\ttest: 0.0524568\tbest: 0.0524568 (1013)\ttotal: 3m 29s\tremaining: 28m 14s\n",
      "1101:\tlearn: 0.0521437\ttest: 0.0524568\tbest: 0.0524568 (1013)\ttotal: 3m 29s\tremaining: 28m 13s\n",
      "1102:\tlearn: 0.0521437\ttest: 0.0524568\tbest: 0.0524568 (1013)\ttotal: 3m 29s\tremaining: 28m 13s\n",
      "1103:\tlearn: 0.0521437\ttest: 0.0524568\tbest: 0.0524568 (1013)\ttotal: 3m 30s\tremaining: 28m 12s\n",
      "1104:\tlearn: 0.0521437\ttest: 0.0524568\tbest: 0.0524568 (1013)\ttotal: 3m 30s\tremaining: 28m 12s\n",
      "1105:\tlearn: 0.0521437\ttest: 0.0524568\tbest: 0.0524568 (1013)\ttotal: 3m 30s\tremaining: 28m 11s\n",
      "1106:\tlearn: 0.0521437\ttest: 0.0524568\tbest: 0.0524568 (1013)\ttotal: 3m 30s\tremaining: 28m 11s\n",
      "1107:\tlearn: 0.0521437\ttest: 0.0524568\tbest: 0.0524568 (1013)\ttotal: 3m 30s\tremaining: 28m 10s\n",
      "1108:\tlearn: 0.0521437\ttest: 0.0524568\tbest: 0.0524568 (1013)\ttotal: 3m 30s\tremaining: 28m 10s\n",
      "1109:\tlearn: 0.0521437\ttest: 0.0524568\tbest: 0.0524568 (1013)\ttotal: 3m 30s\tremaining: 28m 9s\n",
      "1110:\tlearn: 0.0521437\ttest: 0.0524568\tbest: 0.0524568 (1013)\ttotal: 3m 31s\tremaining: 28m 9s\n",
      "1111:\tlearn: 0.0521437\ttest: 0.0524568\tbest: 0.0524568 (1013)\ttotal: 3m 31s\tremaining: 28m 8s\n",
      "1112:\tlearn: 0.0521437\ttest: 0.0524568\tbest: 0.0524568 (1013)\ttotal: 3m 31s\tremaining: 28m 7s\n",
      "1113:\tlearn: 0.0521437\ttest: 0.0524568\tbest: 0.0524568 (1013)\ttotal: 3m 31s\tremaining: 28m 7s\n",
      "1114:\tlearn: 0.0521437\ttest: 0.0524568\tbest: 0.0524568 (1013)\ttotal: 3m 31s\tremaining: 28m 6s\n",
      "1115:\tlearn: 0.0521437\ttest: 0.0524568\tbest: 0.0524568 (1013)\ttotal: 3m 31s\tremaining: 28m 6s\n",
      "1116:\tlearn: 0.0521437\ttest: 0.0524568\tbest: 0.0524568 (1013)\ttotal: 3m 31s\tremaining: 28m 5s\n",
      "1117:\tlearn: 0.0521437\ttest: 0.0524568\tbest: 0.0524568 (1013)\ttotal: 3m 32s\tremaining: 28m 5s\n",
      "1118:\tlearn: 0.0521437\ttest: 0.0524568\tbest: 0.0524568 (1013)\ttotal: 3m 32s\tremaining: 28m 4s\n",
      "1119:\tlearn: 0.0521437\ttest: 0.0524568\tbest: 0.0524568 (1013)\ttotal: 3m 32s\tremaining: 28m 3s\n",
      "1120:\tlearn: 0.0521437\ttest: 0.0524568\tbest: 0.0524568 (1013)\ttotal: 3m 32s\tremaining: 28m 3s\n",
      "1121:\tlearn: 0.0521437\ttest: 0.0524568\tbest: 0.0524568 (1013)\ttotal: 3m 32s\tremaining: 28m 2s\n",
      "1122:\tlearn: 0.0521437\ttest: 0.0524568\tbest: 0.0524568 (1013)\ttotal: 3m 32s\tremaining: 28m 2s\n",
      "1123:\tlearn: 0.0521437\ttest: 0.0524568\tbest: 0.0524568 (1013)\ttotal: 3m 32s\tremaining: 28m 1s\n",
      "1124:\tlearn: 0.0521437\ttest: 0.0524568\tbest: 0.0524568 (1013)\ttotal: 3m 33s\tremaining: 28m 1s\n",
      "1125:\tlearn: 0.0521437\ttest: 0.0524568\tbest: 0.0524568 (1013)\ttotal: 3m 33s\tremaining: 28m\n",
      "1126:\tlearn: 0.0521437\ttest: 0.0524568\tbest: 0.0524568 (1013)\ttotal: 3m 33s\tremaining: 28m\n",
      "1127:\tlearn: 0.0521437\ttest: 0.0524568\tbest: 0.0524568 (1013)\ttotal: 3m 33s\tremaining: 27m 59s\n",
      "1128:\tlearn: 0.0521437\ttest: 0.0524568\tbest: 0.0524568 (1013)\ttotal: 3m 33s\tremaining: 27m 59s\n",
      "1129:\tlearn: 0.0521437\ttest: 0.0524568\tbest: 0.0524568 (1013)\ttotal: 3m 33s\tremaining: 27m 58s\n",
      "1130:\tlearn: 0.0521437\ttest: 0.0524568\tbest: 0.0524568 (1013)\ttotal: 3m 34s\tremaining: 27m 58s\n",
      "1131:\tlearn: 0.0521437\ttest: 0.0524568\tbest: 0.0524568 (1013)\ttotal: 3m 34s\tremaining: 27m 57s\n",
      "1132:\tlearn: 0.0521437\ttest: 0.0524568\tbest: 0.0524568 (1013)\ttotal: 3m 34s\tremaining: 27m 57s\n",
      "1133:\tlearn: 0.0521437\ttest: 0.0524568\tbest: 0.0524568 (1013)\ttotal: 3m 34s\tremaining: 27m 56s\n",
      "1134:\tlearn: 0.0521437\ttest: 0.0524568\tbest: 0.0524568 (1013)\ttotal: 3m 34s\tremaining: 27m 56s\n",
      "1135:\tlearn: 0.0521437\ttest: 0.0524568\tbest: 0.0524568 (1013)\ttotal: 3m 34s\tremaining: 27m 55s\n",
      "1136:\tlearn: 0.0521437\ttest: 0.0524568\tbest: 0.0524568 (1013)\ttotal: 3m 34s\tremaining: 27m 55s\n",
      "1137:\tlearn: 0.0521437\ttest: 0.0524568\tbest: 0.0524568 (1013)\ttotal: 3m 35s\tremaining: 27m 54s\n",
      "1138:\tlearn: 0.0521437\ttest: 0.0524568\tbest: 0.0524568 (1013)\ttotal: 3m 35s\tremaining: 27m 54s\n",
      "1139:\tlearn: 0.0521437\ttest: 0.0524568\tbest: 0.0524568 (1013)\ttotal: 3m 35s\tremaining: 27m 53s\n",
      "1140:\tlearn: 0.0521437\ttest: 0.0524568\tbest: 0.0524568 (1013)\ttotal: 3m 35s\tremaining: 27m 52s\n",
      "1141:\tlearn: 0.0521437\ttest: 0.0524568\tbest: 0.0524568 (1013)\ttotal: 3m 35s\tremaining: 27m 52s\n",
      "1142:\tlearn: 0.0521437\ttest: 0.0524568\tbest: 0.0524568 (1013)\ttotal: 3m 35s\tremaining: 27m 51s\n",
      "1143:\tlearn: 0.0521437\ttest: 0.0524568\tbest: 0.0524568 (1013)\ttotal: 3m 35s\tremaining: 27m 51s\n",
      "1144:\tlearn: 0.0521437\ttest: 0.0524568\tbest: 0.0524568 (1013)\ttotal: 3m 36s\tremaining: 27m 50s\n",
      "1145:\tlearn: 0.0521437\ttest: 0.0524568\tbest: 0.0524568 (1013)\ttotal: 3m 36s\tremaining: 27m 50s\n",
      "1146:\tlearn: 0.0521437\ttest: 0.0524568\tbest: 0.0524568 (1013)\ttotal: 3m 36s\tremaining: 27m 49s\n",
      "1147:\tlearn: 0.0521437\ttest: 0.0524568\tbest: 0.0524568 (1013)\ttotal: 3m 36s\tremaining: 27m 49s\n",
      "1148:\tlearn: 0.0521437\ttest: 0.0524568\tbest: 0.0524568 (1013)\ttotal: 3m 36s\tremaining: 27m 48s\n",
      "1149:\tlearn: 0.0521437\ttest: 0.0524568\tbest: 0.0524568 (1013)\ttotal: 3m 36s\tremaining: 27m 48s\n",
      "1150:\tlearn: 0.0521437\ttest: 0.0524568\tbest: 0.0524568 (1013)\ttotal: 3m 36s\tremaining: 27m 47s\n",
      "1151:\tlearn: 0.0521437\ttest: 0.0524568\tbest: 0.0524568 (1013)\ttotal: 3m 37s\tremaining: 27m 47s\n",
      "1152:\tlearn: 0.0521437\ttest: 0.0524568\tbest: 0.0524568 (1013)\ttotal: 3m 37s\tremaining: 27m 46s\n",
      "1153:\tlearn: 0.0521437\ttest: 0.0524568\tbest: 0.0524568 (1013)\ttotal: 3m 37s\tremaining: 27m 46s\n",
      "1154:\tlearn: 0.0521437\ttest: 0.0524568\tbest: 0.0524568 (1013)\ttotal: 3m 37s\tremaining: 27m 45s\n",
      "1155:\tlearn: 0.0521437\ttest: 0.0524568\tbest: 0.0524568 (1013)\ttotal: 3m 37s\tremaining: 27m 45s\n",
      "1156:\tlearn: 0.0521437\ttest: 0.0524568\tbest: 0.0524568 (1013)\ttotal: 3m 37s\tremaining: 27m 44s\n",
      "1157:\tlearn: 0.0521437\ttest: 0.0524568\tbest: 0.0524568 (1013)\ttotal: 3m 37s\tremaining: 27m 44s\n",
      "1158:\tlearn: 0.0521437\ttest: 0.0524568\tbest: 0.0524568 (1013)\ttotal: 3m 38s\tremaining: 27m 43s\n",
      "1159:\tlearn: 0.0521437\ttest: 0.0524568\tbest: 0.0524568 (1013)\ttotal: 3m 38s\tremaining: 27m 43s\n",
      "1160:\tlearn: 0.0521437\ttest: 0.0524568\tbest: 0.0524568 (1013)\ttotal: 3m 38s\tremaining: 27m 42s\n",
      "1161:\tlearn: 0.0521437\ttest: 0.0524568\tbest: 0.0524568 (1013)\ttotal: 3m 38s\tremaining: 27m 42s\n",
      "1162:\tlearn: 0.0521437\ttest: 0.0524568\tbest: 0.0524568 (1013)\ttotal: 3m 38s\tremaining: 27m 41s\n",
      "1163:\tlearn: 0.0521437\ttest: 0.0524568\tbest: 0.0524568 (1013)\ttotal: 3m 38s\tremaining: 27m 41s\n",
      "1164:\tlearn: 0.0521437\ttest: 0.0524568\tbest: 0.0524568 (1013)\ttotal: 3m 38s\tremaining: 27m 40s\n",
      "1165:\tlearn: 0.0521437\ttest: 0.0524568\tbest: 0.0524568 (1013)\ttotal: 3m 39s\tremaining: 27m 40s\n",
      "1166:\tlearn: 0.0521437\ttest: 0.0524568\tbest: 0.0524568 (1013)\ttotal: 3m 39s\tremaining: 27m 39s\n",
      "1167:\tlearn: 0.0521437\ttest: 0.0524568\tbest: 0.0524568 (1013)\ttotal: 3m 39s\tremaining: 27m 39s\n",
      "1168:\tlearn: 0.0521437\ttest: 0.0524568\tbest: 0.0524568 (1013)\ttotal: 3m 39s\tremaining: 27m 38s\n",
      "1169:\tlearn: 0.0521437\ttest: 0.0524568\tbest: 0.0524568 (1013)\ttotal: 3m 39s\tremaining: 27m 38s\n",
      "1170:\tlearn: 0.0521437\ttest: 0.0524568\tbest: 0.0524568 (1013)\ttotal: 3m 39s\tremaining: 27m 37s\n",
      "1171:\tlearn: 0.0521437\ttest: 0.0524568\tbest: 0.0524568 (1013)\ttotal: 3m 40s\tremaining: 27m 37s\n",
      "1172:\tlearn: 0.0521437\ttest: 0.0524568\tbest: 0.0524568 (1013)\ttotal: 3m 40s\tremaining: 27m 36s\n",
      "1173:\tlearn: 0.0521437\ttest: 0.0524568\tbest: 0.0524568 (1013)\ttotal: 3m 40s\tremaining: 27m 36s\n",
      "1174:\tlearn: 0.0521437\ttest: 0.0524568\tbest: 0.0524568 (1013)\ttotal: 3m 40s\tremaining: 27m 35s\n",
      "1175:\tlearn: 0.0521437\ttest: 0.0524568\tbest: 0.0524568 (1013)\ttotal: 3m 40s\tremaining: 27m 34s\n",
      "1176:\tlearn: 0.0521437\ttest: 0.0524568\tbest: 0.0524568 (1013)\ttotal: 3m 40s\tremaining: 27m 34s\n",
      "1177:\tlearn: 0.0521437\ttest: 0.0524568\tbest: 0.0524568 (1013)\ttotal: 3m 40s\tremaining: 27m 33s\n",
      "1178:\tlearn: 0.0521437\ttest: 0.0524568\tbest: 0.0524568 (1013)\ttotal: 3m 40s\tremaining: 27m 33s\n",
      "1179:\tlearn: 0.0521437\ttest: 0.0524568\tbest: 0.0524568 (1013)\ttotal: 3m 41s\tremaining: 27m 32s\n",
      "1180:\tlearn: 0.0521437\ttest: 0.0524568\tbest: 0.0524568 (1013)\ttotal: 3m 41s\tremaining: 27m 32s\n",
      "1181:\tlearn: 0.0521437\ttest: 0.0524568\tbest: 0.0524568 (1013)\ttotal: 3m 41s\tremaining: 27m 32s\n",
      "1182:\tlearn: 0.0521437\ttest: 0.0524568\tbest: 0.0524568 (1013)\ttotal: 3m 41s\tremaining: 27m 31s\n",
      "1183:\tlearn: 0.0521437\ttest: 0.0524568\tbest: 0.0524568 (1013)\ttotal: 3m 41s\tremaining: 27m 31s\n",
      "1184:\tlearn: 0.0521437\ttest: 0.0524568\tbest: 0.0524568 (1013)\ttotal: 3m 41s\tremaining: 27m 30s\n",
      "1185:\tlearn: 0.0521437\ttest: 0.0524568\tbest: 0.0524568 (1013)\ttotal: 3m 42s\tremaining: 27m 30s\n",
      "1186:\tlearn: 0.0521437\ttest: 0.0524568\tbest: 0.0524568 (1013)\ttotal: 3m 42s\tremaining: 27m 29s\n",
      "1187:\tlearn: 0.0521437\ttest: 0.0524568\tbest: 0.0524568 (1013)\ttotal: 3m 42s\tremaining: 27m 29s\n",
      "1188:\tlearn: 0.0521437\ttest: 0.0524568\tbest: 0.0524568 (1013)\ttotal: 3m 42s\tremaining: 27m 28s\n",
      "1189:\tlearn: 0.0521437\ttest: 0.0524568\tbest: 0.0524568 (1013)\ttotal: 3m 42s\tremaining: 27m 27s\n",
      "1190:\tlearn: 0.0521437\ttest: 0.0524568\tbest: 0.0524568 (1013)\ttotal: 3m 42s\tremaining: 27m 27s\n",
      "1191:\tlearn: 0.0521437\ttest: 0.0524568\tbest: 0.0524568 (1013)\ttotal: 3m 42s\tremaining: 27m 26s\n",
      "1192:\tlearn: 0.0521437\ttest: 0.0524568\tbest: 0.0524568 (1013)\ttotal: 3m 43s\tremaining: 27m 26s\n",
      "1193:\tlearn: 0.0521437\ttest: 0.0524568\tbest: 0.0524568 (1013)\ttotal: 3m 43s\tremaining: 27m 25s\n",
      "1194:\tlearn: 0.0521437\ttest: 0.0524568\tbest: 0.0524568 (1013)\ttotal: 3m 43s\tremaining: 27m 25s\n",
      "1195:\tlearn: 0.0521437\ttest: 0.0524568\tbest: 0.0524568 (1013)\ttotal: 3m 43s\tremaining: 27m 25s\n",
      "1196:\tlearn: 0.0521437\ttest: 0.0524568\tbest: 0.0524568 (1013)\ttotal: 3m 43s\tremaining: 27m 24s\n",
      "1197:\tlearn: 0.0521437\ttest: 0.0524568\tbest: 0.0524568 (1013)\ttotal: 3m 43s\tremaining: 27m 24s\n",
      "1198:\tlearn: 0.0521437\ttest: 0.0524568\tbest: 0.0524568 (1013)\ttotal: 3m 43s\tremaining: 27m 23s\n",
      "1199:\tlearn: 0.0521437\ttest: 0.0524568\tbest: 0.0524568 (1013)\ttotal: 3m 44s\tremaining: 27m 23s\n",
      "1200:\tlearn: 0.0521437\ttest: 0.0524568\tbest: 0.0524568 (1013)\ttotal: 3m 44s\tremaining: 27m 22s\n",
      "1201:\tlearn: 0.0521437\ttest: 0.0524568\tbest: 0.0524568 (1013)\ttotal: 3m 44s\tremaining: 27m 22s\n",
      "1202:\tlearn: 0.0521437\ttest: 0.0524568\tbest: 0.0524568 (1013)\ttotal: 3m 44s\tremaining: 27m 21s\n",
      "1203:\tlearn: 0.0521437\ttest: 0.0524568\tbest: 0.0524568 (1013)\ttotal: 3m 44s\tremaining: 27m 21s\n",
      "1204:\tlearn: 0.0521437\ttest: 0.0524568\tbest: 0.0524568 (1013)\ttotal: 3m 44s\tremaining: 27m 20s\n",
      "1205:\tlearn: 0.0521437\ttest: 0.0524568\tbest: 0.0524568 (1013)\ttotal: 3m 44s\tremaining: 27m 20s\n",
      "1206:\tlearn: 0.0521437\ttest: 0.0524568\tbest: 0.0524568 (1013)\ttotal: 3m 45s\tremaining: 27m 19s\n",
      "1207:\tlearn: 0.0521437\ttest: 0.0524568\tbest: 0.0524568 (1013)\ttotal: 3m 45s\tremaining: 27m 19s\n",
      "1208:\tlearn: 0.0521437\ttest: 0.0524568\tbest: 0.0524568 (1013)\ttotal: 3m 45s\tremaining: 27m 18s\n",
      "1209:\tlearn: 0.0521437\ttest: 0.0524568\tbest: 0.0524568 (1013)\ttotal: 3m 45s\tremaining: 27m 18s\n",
      "1210:\tlearn: 0.0521437\ttest: 0.0524568\tbest: 0.0524568 (1013)\ttotal: 3m 45s\tremaining: 27m 17s\n",
      "1211:\tlearn: 0.0521437\ttest: 0.0524568\tbest: 0.0524568 (1013)\ttotal: 3m 45s\tremaining: 27m 17s\n",
      "1212:\tlearn: 0.0521437\ttest: 0.0524568\tbest: 0.0524568 (1013)\ttotal: 3m 45s\tremaining: 27m 16s\n",
      "1213:\tlearn: 0.0521437\ttest: 0.0524568\tbest: 0.0524568 (1013)\ttotal: 3m 46s\tremaining: 27m 16s\n",
      "1214:\tlearn: 0.0521437\ttest: 0.0524568\tbest: 0.0524568 (1013)\ttotal: 3m 46s\tremaining: 27m 15s\n",
      "1215:\tlearn: 0.0521437\ttest: 0.0524568\tbest: 0.0524568 (1013)\ttotal: 3m 46s\tremaining: 27m 15s\n",
      "1216:\tlearn: 0.0521437\ttest: 0.0524568\tbest: 0.0524568 (1013)\ttotal: 3m 46s\tremaining: 27m 14s\n",
      "1217:\tlearn: 0.0521437\ttest: 0.0524568\tbest: 0.0524568 (1013)\ttotal: 3m 46s\tremaining: 27m 14s\n",
      "1218:\tlearn: 0.0521437\ttest: 0.0524568\tbest: 0.0524568 (1013)\ttotal: 3m 46s\tremaining: 27m 13s\n",
      "1219:\tlearn: 0.0521437\ttest: 0.0524568\tbest: 0.0524568 (1013)\ttotal: 3m 46s\tremaining: 27m 13s\n",
      "1220:\tlearn: 0.0521437\ttest: 0.0524568\tbest: 0.0524568 (1013)\ttotal: 3m 47s\tremaining: 27m 12s\n",
      "1221:\tlearn: 0.0521437\ttest: 0.0524568\tbest: 0.0524568 (1013)\ttotal: 3m 47s\tremaining: 27m 12s\n",
      "1222:\tlearn: 0.0521437\ttest: 0.0524568\tbest: 0.0524568 (1013)\ttotal: 3m 47s\tremaining: 27m 11s\n",
      "1223:\tlearn: 0.0521437\ttest: 0.0524568\tbest: 0.0524568 (1013)\ttotal: 3m 47s\tremaining: 27m 11s\n",
      "1224:\tlearn: 0.0521437\ttest: 0.0524568\tbest: 0.0524568 (1013)\ttotal: 3m 47s\tremaining: 27m 10s\n",
      "1225:\tlearn: 0.0521437\ttest: 0.0524568\tbest: 0.0524568 (1013)\ttotal: 3m 47s\tremaining: 27m 10s\n",
      "1226:\tlearn: 0.0521437\ttest: 0.0524568\tbest: 0.0524568 (1013)\ttotal: 3m 47s\tremaining: 27m 9s\n",
      "1227:\tlearn: 0.0521437\ttest: 0.0524568\tbest: 0.0524568 (1013)\ttotal: 3m 48s\tremaining: 27m 9s\n",
      "1228:\tlearn: 0.0521437\ttest: 0.0524568\tbest: 0.0524568 (1013)\ttotal: 3m 48s\tremaining: 27m 8s\n",
      "1229:\tlearn: 0.0521437\ttest: 0.0524568\tbest: 0.0524568 (1013)\ttotal: 3m 48s\tremaining: 27m 8s\n",
      "1230:\tlearn: 0.0521437\ttest: 0.0524568\tbest: 0.0524568 (1013)\ttotal: 3m 48s\tremaining: 27m 8s\n",
      "1231:\tlearn: 0.0521437\ttest: 0.0524568\tbest: 0.0524568 (1013)\ttotal: 3m 48s\tremaining: 27m 7s\n",
      "1232:\tlearn: 0.0521437\ttest: 0.0524568\tbest: 0.0524568 (1013)\ttotal: 3m 48s\tremaining: 27m 7s\n",
      "1233:\tlearn: 0.0521437\ttest: 0.0524568\tbest: 0.0524568 (1013)\ttotal: 3m 48s\tremaining: 27m 6s\n",
      "1234:\tlearn: 0.0521437\ttest: 0.0524568\tbest: 0.0524568 (1013)\ttotal: 3m 49s\tremaining: 27m 6s\n",
      "1235:\tlearn: 0.0521437\ttest: 0.0524568\tbest: 0.0524568 (1013)\ttotal: 3m 49s\tremaining: 27m 5s\n",
      "1236:\tlearn: 0.0521437\ttest: 0.0524568\tbest: 0.0524568 (1013)\ttotal: 3m 49s\tremaining: 27m 5s\n",
      "1237:\tlearn: 0.0521437\ttest: 0.0524568\tbest: 0.0524568 (1013)\ttotal: 3m 49s\tremaining: 27m 4s\n",
      "1238:\tlearn: 0.0521437\ttest: 0.0524568\tbest: 0.0524568 (1013)\ttotal: 3m 49s\tremaining: 27m 4s\n",
      "1239:\tlearn: 0.0521437\ttest: 0.0524568\tbest: 0.0524568 (1013)\ttotal: 3m 49s\tremaining: 27m 4s\n",
      "1240:\tlearn: 0.0521437\ttest: 0.0524568\tbest: 0.0524568 (1013)\ttotal: 3m 50s\tremaining: 27m 3s\n",
      "1241:\tlearn: 0.0521437\ttest: 0.0524568\tbest: 0.0524568 (1013)\ttotal: 3m 50s\tremaining: 27m 3s\n",
      "1242:\tlearn: 0.0521437\ttest: 0.0524568\tbest: 0.0524568 (1013)\ttotal: 3m 50s\tremaining: 27m 2s\n",
      "1243:\tlearn: 0.0521437\ttest: 0.0524568\tbest: 0.0524568 (1013)\ttotal: 3m 50s\tremaining: 27m 2s\n",
      "1244:\tlearn: 0.0521437\ttest: 0.0524568\tbest: 0.0524568 (1013)\ttotal: 3m 50s\tremaining: 27m 1s\n",
      "1245:\tlearn: 0.0521437\ttest: 0.0524568\tbest: 0.0524568 (1013)\ttotal: 3m 50s\tremaining: 27m 1s\n",
      "1246:\tlearn: 0.0521437\ttest: 0.0524568\tbest: 0.0524568 (1013)\ttotal: 3m 50s\tremaining: 27m\n",
      "1247:\tlearn: 0.0521437\ttest: 0.0524568\tbest: 0.0524568 (1013)\ttotal: 3m 51s\tremaining: 27m\n",
      "1248:\tlearn: 0.0521437\ttest: 0.0524568\tbest: 0.0524568 (1013)\ttotal: 3m 51s\tremaining: 26m 59s\n",
      "1249:\tlearn: 0.0521437\ttest: 0.0524568\tbest: 0.0524568 (1013)\ttotal: 3m 51s\tremaining: 26m 59s\n",
      "1250:\tlearn: 0.0521437\ttest: 0.0524568\tbest: 0.0524568 (1013)\ttotal: 3m 51s\tremaining: 26m 59s\n",
      "1251:\tlearn: 0.0521437\ttest: 0.0524568\tbest: 0.0524568 (1013)\ttotal: 3m 51s\tremaining: 26m 58s\n",
      "1252:\tlearn: 0.0521437\ttest: 0.0524568\tbest: 0.0524568 (1013)\ttotal: 3m 51s\tremaining: 26m 58s\n",
      "1253:\tlearn: 0.0521437\ttest: 0.0524568\tbest: 0.0524568 (1013)\ttotal: 3m 51s\tremaining: 26m 57s\n",
      "1254:\tlearn: 0.0521437\ttest: 0.0524568\tbest: 0.0524568 (1013)\ttotal: 3m 52s\tremaining: 26m 56s\n",
      "1255:\tlearn: 0.0521437\ttest: 0.0524568\tbest: 0.0524568 (1013)\ttotal: 3m 52s\tremaining: 26m 56s\n",
      "1256:\tlearn: 0.0521437\ttest: 0.0524568\tbest: 0.0524568 (1013)\ttotal: 3m 52s\tremaining: 26m 56s\n",
      "1257:\tlearn: 0.0521437\ttest: 0.0524568\tbest: 0.0524568 (1013)\ttotal: 3m 52s\tremaining: 26m 55s\n",
      "1258:\tlearn: 0.0521437\ttest: 0.0524568\tbest: 0.0524568 (1013)\ttotal: 3m 52s\tremaining: 26m 55s\n",
      "1259:\tlearn: 0.0521437\ttest: 0.0524568\tbest: 0.0524568 (1013)\ttotal: 3m 52s\tremaining: 26m 54s\n",
      "1260:\tlearn: 0.0521437\ttest: 0.0524568\tbest: 0.0524568 (1013)\ttotal: 3m 52s\tremaining: 26m 54s\n",
      "1261:\tlearn: 0.0521437\ttest: 0.0524568\tbest: 0.0524568 (1013)\ttotal: 3m 53s\tremaining: 26m 53s\n",
      "1262:\tlearn: 0.0521437\ttest: 0.0524568\tbest: 0.0524568 (1013)\ttotal: 3m 53s\tremaining: 26m 53s\n",
      "1263:\tlearn: 0.0521437\ttest: 0.0524568\tbest: 0.0524568 (1013)\ttotal: 3m 53s\tremaining: 26m 53s\n",
      "1264:\tlearn: 0.0521437\ttest: 0.0524568\tbest: 0.0524568 (1013)\ttotal: 3m 53s\tremaining: 26m 52s\n",
      "1265:\tlearn: 0.0521437\ttest: 0.0524568\tbest: 0.0524568 (1013)\ttotal: 3m 53s\tremaining: 26m 52s\n",
      "1266:\tlearn: 0.0521437\ttest: 0.0524568\tbest: 0.0524568 (1013)\ttotal: 3m 53s\tremaining: 26m 51s\n",
      "1267:\tlearn: 0.0521437\ttest: 0.0524568\tbest: 0.0524568 (1013)\ttotal: 3m 53s\tremaining: 26m 51s\n",
      "1268:\tlearn: 0.0521437\ttest: 0.0524568\tbest: 0.0524568 (1013)\ttotal: 3m 54s\tremaining: 26m 50s\n",
      "1269:\tlearn: 0.0521437\ttest: 0.0524568\tbest: 0.0524568 (1013)\ttotal: 3m 54s\tremaining: 26m 50s\n",
      "1270:\tlearn: 0.0521437\ttest: 0.0524568\tbest: 0.0524568 (1013)\ttotal: 3m 54s\tremaining: 26m 49s\n",
      "1271:\tlearn: 0.0521437\ttest: 0.0524568\tbest: 0.0524568 (1013)\ttotal: 3m 54s\tremaining: 26m 49s\n",
      "1272:\tlearn: 0.0521437\ttest: 0.0524568\tbest: 0.0524568 (1013)\ttotal: 3m 54s\tremaining: 26m 48s\n",
      "1273:\tlearn: 0.0521437\ttest: 0.0524568\tbest: 0.0524568 (1013)\ttotal: 3m 54s\tremaining: 26m 48s\n",
      "1274:\tlearn: 0.0521437\ttest: 0.0524568\tbest: 0.0524568 (1013)\ttotal: 3m 54s\tremaining: 26m 48s\n",
      "1275:\tlearn: 0.0521437\ttest: 0.0524568\tbest: 0.0524568 (1013)\ttotal: 3m 55s\tremaining: 26m 47s\n",
      "1276:\tlearn: 0.0521437\ttest: 0.0524568\tbest: 0.0524568 (1013)\ttotal: 3m 55s\tremaining: 26m 47s\n",
      "1277:\tlearn: 0.0521437\ttest: 0.0524568\tbest: 0.0524568 (1013)\ttotal: 3m 55s\tremaining: 26m 46s\n",
      "1278:\tlearn: 0.0521437\ttest: 0.0524568\tbest: 0.0524568 (1013)\ttotal: 3m 55s\tremaining: 26m 46s\n",
      "1279:\tlearn: 0.0521437\ttest: 0.0524568\tbest: 0.0524568 (1013)\ttotal: 3m 55s\tremaining: 26m 45s\n",
      "1280:\tlearn: 0.0521437\ttest: 0.0524568\tbest: 0.0524568 (1013)\ttotal: 3m 55s\tremaining: 26m 45s\n",
      "1281:\tlearn: 0.0521437\ttest: 0.0524568\tbest: 0.0524568 (1013)\ttotal: 3m 56s\tremaining: 26m 44s\n",
      "1282:\tlearn: 0.0521437\ttest: 0.0524568\tbest: 0.0524568 (1013)\ttotal: 3m 56s\tremaining: 26m 44s\n",
      "1283:\tlearn: 0.0521437\ttest: 0.0524568\tbest: 0.0524568 (1013)\ttotal: 3m 56s\tremaining: 26m 44s\n",
      "1284:\tlearn: 0.0521437\ttest: 0.0524568\tbest: 0.0524568 (1013)\ttotal: 3m 56s\tremaining: 26m 43s\n",
      "1285:\tlearn: 0.0521437\ttest: 0.0524568\tbest: 0.0524568 (1013)\ttotal: 3m 56s\tremaining: 26m 43s\n",
      "1286:\tlearn: 0.0521437\ttest: 0.0524568\tbest: 0.0524568 (1013)\ttotal: 3m 56s\tremaining: 26m 42s\n",
      "1287:\tlearn: 0.0521437\ttest: 0.0524568\tbest: 0.0524568 (1013)\ttotal: 3m 56s\tremaining: 26m 42s\n",
      "1288:\tlearn: 0.0521437\ttest: 0.0524568\tbest: 0.0524568 (1013)\ttotal: 3m 57s\tremaining: 26m 41s\n",
      "1289:\tlearn: 0.0521437\ttest: 0.0524568\tbest: 0.0524568 (1013)\ttotal: 3m 57s\tremaining: 26m 41s\n",
      "1290:\tlearn: 0.0521437\ttest: 0.0524568\tbest: 0.0524568 (1013)\ttotal: 3m 57s\tremaining: 26m 40s\n",
      "1291:\tlearn: 0.0521437\ttest: 0.0524568\tbest: 0.0524568 (1013)\ttotal: 3m 57s\tremaining: 26m 40s\n",
      "1292:\tlearn: 0.0521437\ttest: 0.0524568\tbest: 0.0524568 (1013)\ttotal: 3m 57s\tremaining: 26m 40s\n",
      "1293:\tlearn: 0.0521437\ttest: 0.0524568\tbest: 0.0524568 (1013)\ttotal: 3m 57s\tremaining: 26m 39s\n",
      "1294:\tlearn: 0.0521437\ttest: 0.0524568\tbest: 0.0524568 (1013)\ttotal: 3m 57s\tremaining: 26m 39s\n",
      "1295:\tlearn: 0.0521437\ttest: 0.0524568\tbest: 0.0524568 (1013)\ttotal: 3m 58s\tremaining: 26m 38s\n",
      "1296:\tlearn: 0.0521437\ttest: 0.0524568\tbest: 0.0524568 (1013)\ttotal: 3m 58s\tremaining: 26m 38s\n",
      "1297:\tlearn: 0.0521437\ttest: 0.0524568\tbest: 0.0524568 (1013)\ttotal: 3m 58s\tremaining: 26m 38s\n",
      "1298:\tlearn: 0.0521437\ttest: 0.0524568\tbest: 0.0524568 (1013)\ttotal: 3m 58s\tremaining: 26m 37s\n",
      "1299:\tlearn: 0.0521437\ttest: 0.0524568\tbest: 0.0524568 (1013)\ttotal: 3m 58s\tremaining: 26m 37s\n",
      "1300:\tlearn: 0.0521437\ttest: 0.0524568\tbest: 0.0524568 (1013)\ttotal: 3m 58s\tremaining: 26m 36s\n",
      "1301:\tlearn: 0.0521437\ttest: 0.0524568\tbest: 0.0524568 (1013)\ttotal: 3m 58s\tremaining: 26m 36s\n",
      "1302:\tlearn: 0.0521437\ttest: 0.0524568\tbest: 0.0524568 (1013)\ttotal: 3m 59s\tremaining: 26m 35s\n",
      "1303:\tlearn: 0.0521437\ttest: 0.0524568\tbest: 0.0524568 (1013)\ttotal: 3m 59s\tremaining: 26m 35s\n",
      "1304:\tlearn: 0.0521437\ttest: 0.0524568\tbest: 0.0524568 (1013)\ttotal: 3m 59s\tremaining: 26m 35s\n",
      "1305:\tlearn: 0.0521437\ttest: 0.0524568\tbest: 0.0524568 (1013)\ttotal: 3m 59s\tremaining: 26m 34s\n",
      "1306:\tlearn: 0.0521437\ttest: 0.0524568\tbest: 0.0524568 (1013)\ttotal: 3m 59s\tremaining: 26m 34s\n",
      "1307:\tlearn: 0.0521437\ttest: 0.0524568\tbest: 0.0524568 (1013)\ttotal: 3m 59s\tremaining: 26m 33s\n",
      "1308:\tlearn: 0.0521437\ttest: 0.0524568\tbest: 0.0524568 (1013)\ttotal: 4m\tremaining: 26m 33s\n",
      "1309:\tlearn: 0.0521437\ttest: 0.0524568\tbest: 0.0524568 (1013)\ttotal: 4m\tremaining: 26m 32s\n",
      "1310:\tlearn: 0.0521437\ttest: 0.0524568\tbest: 0.0524568 (1013)\ttotal: 4m\tremaining: 26m 32s\n",
      "1311:\tlearn: 0.0521437\ttest: 0.0524568\tbest: 0.0524568 (1013)\ttotal: 4m\tremaining: 26m 32s\n",
      "1312:\tlearn: 0.0521437\ttest: 0.0524568\tbest: 0.0524568 (1013)\ttotal: 4m\tremaining: 26m 31s\n",
      "1313:\tlearn: 0.0521437\ttest: 0.0524568\tbest: 0.0524568 (1013)\ttotal: 4m\tremaining: 26m 31s\n",
      "1314:\tlearn: 0.0521437\ttest: 0.0524568\tbest: 0.0524568 (1013)\ttotal: 4m\tremaining: 26m 30s\n",
      "1315:\tlearn: 0.0521437\ttest: 0.0524568\tbest: 0.0524568 (1013)\ttotal: 4m 1s\tremaining: 26m 30s\n",
      "1316:\tlearn: 0.0521437\ttest: 0.0524568\tbest: 0.0524568 (1013)\ttotal: 4m 1s\tremaining: 26m 29s\n",
      "1317:\tlearn: 0.0521437\ttest: 0.0524568\tbest: 0.0524568 (1013)\ttotal: 4m 1s\tremaining: 26m 29s\n",
      "1318:\tlearn: 0.0521437\ttest: 0.0524568\tbest: 0.0524568 (1013)\ttotal: 4m 1s\tremaining: 26m 29s\n",
      "1319:\tlearn: 0.0521437\ttest: 0.0524568\tbest: 0.0524568 (1013)\ttotal: 4m 1s\tremaining: 26m 28s\n",
      "1320:\tlearn: 0.0521437\ttest: 0.0524568\tbest: 0.0524568 (1013)\ttotal: 4m 1s\tremaining: 26m 28s\n",
      "1321:\tlearn: 0.0521437\ttest: 0.0524568\tbest: 0.0524568 (1013)\ttotal: 4m 1s\tremaining: 26m 27s\n",
      "1322:\tlearn: 0.0521437\ttest: 0.0524568\tbest: 0.0524568 (1013)\ttotal: 4m 2s\tremaining: 26m 27s\n",
      "1323:\tlearn: 0.0521437\ttest: 0.0524568\tbest: 0.0524568 (1013)\ttotal: 4m 2s\tremaining: 26m 26s\n",
      "1324:\tlearn: 0.0521437\ttest: 0.0524568\tbest: 0.0524568 (1013)\ttotal: 4m 2s\tremaining: 26m 26s\n",
      "1325:\tlearn: 0.0521437\ttest: 0.0524568\tbest: 0.0524568 (1013)\ttotal: 4m 2s\tremaining: 26m 26s\n",
      "1326:\tlearn: 0.0521437\ttest: 0.0524568\tbest: 0.0524568 (1013)\ttotal: 4m 2s\tremaining: 26m 25s\n",
      "1327:\tlearn: 0.0521437\ttest: 0.0524568\tbest: 0.0524568 (1013)\ttotal: 4m 2s\tremaining: 26m 25s\n",
      "1328:\tlearn: 0.0521437\ttest: 0.0524568\tbest: 0.0524568 (1013)\ttotal: 4m 2s\tremaining: 26m 24s\n",
      "1329:\tlearn: 0.0521437\ttest: 0.0524568\tbest: 0.0524568 (1013)\ttotal: 4m 3s\tremaining: 26m 24s\n",
      "1330:\tlearn: 0.0521437\ttest: 0.0524568\tbest: 0.0524568 (1013)\ttotal: 4m 3s\tremaining: 26m 24s\n",
      "1331:\tlearn: 0.0521437\ttest: 0.0524568\tbest: 0.0524568 (1013)\ttotal: 4m 3s\tremaining: 26m 23s\n",
      "1332:\tlearn: 0.0521437\ttest: 0.0524568\tbest: 0.0524568 (1013)\ttotal: 4m 3s\tremaining: 26m 23s\n",
      "1333:\tlearn: 0.0521437\ttest: 0.0524568\tbest: 0.0524568 (1013)\ttotal: 4m 3s\tremaining: 26m 22s\n",
      "1334:\tlearn: 0.0521437\ttest: 0.0524568\tbest: 0.0524568 (1013)\ttotal: 4m 3s\tremaining: 26m 22s\n",
      "1335:\tlearn: 0.0521437\ttest: 0.0524568\tbest: 0.0524568 (1013)\ttotal: 4m 3s\tremaining: 26m 22s\n",
      "1336:\tlearn: 0.0521437\ttest: 0.0524568\tbest: 0.0524568 (1013)\ttotal: 4m 4s\tremaining: 26m 21s\n",
      "1337:\tlearn: 0.0521437\ttest: 0.0524568\tbest: 0.0524568 (1013)\ttotal: 4m 4s\tremaining: 26m 21s\n",
      "\n",
      "bestTest = 0.05245679119\n",
      "bestIteration = 1013\n",
      "\n",
      "Shrink model to first 1014 iterations.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\tDropped 0 of 30 features.\n",
      "\tFitting S1F3 with 'num_gpus': 0, 'num_cpus': 8\n",
      "\tWarning: Potentially not enough memory to safely train CatBoost model, roughly requires: 4.463 GB, but only 5.359 GB is available...\n",
      "\tCatboost model hyperparameters: {'iterations': 10000, 'learning_rate': 0.02057151708150835, 'random_seed': 0, 'allow_writing_files': False, 'eval_metric': 'Logloss', 'depth': 5, 'l2_leaf_reg': 4.854651042004117, 'thread_count': 8}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:\tlearn: 0.6171549\ttest: 0.6172170\tbest: 0.6172170 (0)\ttotal: 246ms\tremaining: 41m\n",
      "1:\tlearn: 0.5529759\ttest: 0.5531428\tbest: 0.5531428 (1)\ttotal: 488ms\tremaining: 40m 41s\n",
      "2:\tlearn: 0.4941657\ttest: 0.4938130\tbest: 0.4938130 (2)\ttotal: 729ms\tremaining: 40m 30s\n",
      "3:\tlearn: 0.4415297\ttest: 0.4419223\tbest: 0.4419223 (3)\ttotal: 972ms\tremaining: 40m 29s\n",
      "4:\tlearn: 0.3965566\ttest: 0.3966992\tbest: 0.3966992 (4)\ttotal: 1.22s\tremaining: 40m 47s\n",
      "5:\tlearn: 0.3572659\ttest: 0.3574229\tbest: 0.3574229 (5)\ttotal: 1.48s\tremaining: 40m 58s\n",
      "6:\tlearn: 0.3233632\ttest: 0.3231974\tbest: 0.3231974 (6)\ttotal: 1.73s\tremaining: 41m 3s\n",
      "7:\tlearn: 0.2936037\ttest: 0.2934947\tbest: 0.2934947 (7)\ttotal: 1.97s\tremaining: 41m 1s\n",
      "8:\tlearn: 0.2673787\ttest: 0.2677169\tbest: 0.2677169 (8)\ttotal: 2.21s\tremaining: 40m 51s\n",
      "9:\tlearn: 0.2484265\ttest: 0.2483059\tbest: 0.2483059 (9)\ttotal: 2.45s\tremaining: 40m 43s\n",
      "10:\tlearn: 0.2280958\ttest: 0.2283372\tbest: 0.2283372 (10)\ttotal: 2.69s\tremaining: 40m 44s\n",
      "11:\tlearn: 0.2109339\ttest: 0.2109601\tbest: 0.2109601 (11)\ttotal: 2.93s\tremaining: 40m 42s\n",
      "12:\tlearn: 0.1957033\ttest: 0.1958081\tbest: 0.1958081 (12)\ttotal: 3.18s\tremaining: 40m 45s\n",
      "13:\tlearn: 0.1824733\ttest: 0.1825707\tbest: 0.1825707 (13)\ttotal: 3.43s\tremaining: 40m 47s\n",
      "14:\tlearn: 0.1709729\ttest: 0.1709555\tbest: 0.1709555 (14)\ttotal: 3.67s\tremaining: 40m 45s\n",
      "15:\tlearn: 0.1606511\ttest: 0.1607363\tbest: 0.1607363 (15)\ttotal: 3.91s\tremaining: 40m 38s\n",
      "16:\tlearn: 0.1516145\ttest: 0.1517148\tbest: 0.1517148 (16)\ttotal: 4.15s\tremaining: 40m 35s\n",
      "17:\tlearn: 0.1437088\ttest: 0.1437195\tbest: 0.1437195 (17)\ttotal: 4.4s\tremaining: 40m 38s\n",
      "18:\tlearn: 0.1372150\ttest: 0.1373305\tbest: 0.1373305 (18)\ttotal: 4.62s\tremaining: 40m 28s\n",
      "19:\tlearn: 0.1315495\ttest: 0.1314840\tbest: 0.1314840 (19)\ttotal: 4.85s\tremaining: 40m 20s\n",
      "20:\tlearn: 0.1261013\ttest: 0.1261297\tbest: 0.1261297 (20)\ttotal: 5.08s\tremaining: 40m 13s\n",
      "21:\tlearn: 0.1201330\ttest: 0.1202346\tbest: 0.1202346 (21)\ttotal: 5.33s\tremaining: 40m 17s\n",
      "22:\tlearn: 0.1149756\ttest: 0.1149485\tbest: 0.1149485 (22)\ttotal: 5.57s\tremaining: 40m 18s\n",
      "23:\tlearn: 0.1098346\ttest: 0.1099282\tbest: 0.1099282 (23)\ttotal: 5.82s\tremaining: 40m 17s\n",
      "24:\tlearn: 0.1060243\ttest: 0.1060977\tbest: 0.1060977 (24)\ttotal: 6.06s\tremaining: 40m 18s\n",
      "25:\tlearn: 0.1022371\ttest: 0.1022484\tbest: 0.1022484 (25)\ttotal: 6.29s\tremaining: 40m 14s\n",
      "26:\tlearn: 0.0991172\ttest: 0.0990524\tbest: 0.0990524 (26)\ttotal: 6.55s\tremaining: 40m 18s\n",
      "27:\tlearn: 0.0964051\ttest: 0.0963714\tbest: 0.0963714 (27)\ttotal: 6.77s\tremaining: 40m 11s\n",
      "28:\tlearn: 0.0938203\ttest: 0.0938703\tbest: 0.0938703 (28)\ttotal: 6.99s\tremaining: 40m 3s\n",
      "29:\tlearn: 0.0910449\ttest: 0.0909945\tbest: 0.0909945 (29)\ttotal: 7.23s\tremaining: 40m 2s\n",
      "30:\tlearn: 0.0887068\ttest: 0.0887354\tbest: 0.0887354 (30)\ttotal: 7.48s\tremaining: 40m 6s\n",
      "31:\tlearn: 0.0864252\ttest: 0.0863920\tbest: 0.0863920 (31)\ttotal: 7.71s\tremaining: 40m 3s\n",
      "32:\tlearn: 0.0849695\ttest: 0.0849209\tbest: 0.0849209 (32)\ttotal: 7.95s\tremaining: 40m\n",
      "33:\tlearn: 0.0835703\ttest: 0.0835451\tbest: 0.0835451 (33)\ttotal: 8.16s\tremaining: 39m 52s\n",
      "34:\tlearn: 0.0815152\ttest: 0.0815130\tbest: 0.0815130 (34)\ttotal: 8.42s\tremaining: 39m 56s\n",
      "35:\tlearn: 0.0802618\ttest: 0.0803000\tbest: 0.0803000 (35)\ttotal: 8.66s\tremaining: 39m 57s\n",
      "36:\tlearn: 0.0791239\ttest: 0.0791554\tbest: 0.0791554 (36)\ttotal: 8.9s\tremaining: 39m 55s\n",
      "37:\tlearn: 0.0776734\ttest: 0.0776566\tbest: 0.0776566 (37)\ttotal: 9.12s\tremaining: 39m 49s\n",
      "38:\tlearn: 0.0766344\ttest: 0.0766378\tbest: 0.0766378 (38)\ttotal: 9.34s\tremaining: 39m 44s\n",
      "39:\tlearn: 0.0754247\ttest: 0.0753763\tbest: 0.0753763 (39)\ttotal: 9.57s\tremaining: 39m 42s\n",
      "40:\tlearn: 0.0742239\ttest: 0.0741848\tbest: 0.0741848 (40)\ttotal: 9.8s\tremaining: 39m 39s\n",
      "41:\tlearn: 0.0731535\ttest: 0.0731156\tbest: 0.0731156 (41)\ttotal: 10s\tremaining: 39m 34s\n",
      "42:\tlearn: 0.0721352\ttest: 0.0720872\tbest: 0.0720872 (42)\ttotal: 10.3s\tremaining: 39m 33s\n",
      "43:\tlearn: 0.0713681\ttest: 0.0713191\tbest: 0.0713191 (43)\ttotal: 10.5s\tremaining: 39m 32s\n",
      "44:\tlearn: 0.0703720\ttest: 0.0703532\tbest: 0.0703532 (44)\ttotal: 10.7s\tremaining: 39m 26s\n",
      "45:\tlearn: 0.0695844\ttest: 0.0695582\tbest: 0.0695582 (45)\ttotal: 10.9s\tremaining: 39m 25s\n",
      "46:\tlearn: 0.0688737\ttest: 0.0687981\tbest: 0.0687981 (46)\ttotal: 11.2s\tremaining: 39m 22s\n",
      "47:\tlearn: 0.0681008\ttest: 0.0680918\tbest: 0.0680918 (47)\ttotal: 11.4s\tremaining: 39m 23s\n",
      "48:\tlearn: 0.0674385\ttest: 0.0673947\tbest: 0.0673947 (48)\ttotal: 11.6s\tremaining: 39m 17s\n",
      "49:\tlearn: 0.0666422\ttest: 0.0665523\tbest: 0.0665523 (49)\ttotal: 11.8s\tremaining: 39m 17s\n",
      "50:\tlearn: 0.0660328\ttest: 0.0659448\tbest: 0.0659448 (50)\ttotal: 12.1s\tremaining: 39m 19s\n",
      "51:\tlearn: 0.0653610\ttest: 0.0653325\tbest: 0.0653325 (51)\ttotal: 12.3s\tremaining: 39m 19s\n",
      "52:\tlearn: 0.0648621\ttest: 0.0648201\tbest: 0.0648201 (52)\ttotal: 12.6s\tremaining: 39m 19s\n",
      "53:\tlearn: 0.0642493\ttest: 0.0641926\tbest: 0.0641926 (53)\ttotal: 12.8s\tremaining: 39m 18s\n",
      "54:\tlearn: 0.0637002\ttest: 0.0636095\tbest: 0.0636095 (54)\ttotal: 13s\tremaining: 39m 16s\n",
      "55:\tlearn: 0.0632307\ttest: 0.0631531\tbest: 0.0631531 (55)\ttotal: 13.3s\tremaining: 39m 13s\n",
      "56:\tlearn: 0.0626724\ttest: 0.0626566\tbest: 0.0626566 (56)\ttotal: 13.5s\tremaining: 39m 11s\n",
      "57:\tlearn: 0.0621663\ttest: 0.0621862\tbest: 0.0621862 (57)\ttotal: 13.7s\tremaining: 39m 9s\n",
      "58:\tlearn: 0.0617726\ttest: 0.0617138\tbest: 0.0617138 (58)\ttotal: 13.9s\tremaining: 39m 9s\n",
      "59:\tlearn: 0.0614278\ttest: 0.0613411\tbest: 0.0613411 (59)\ttotal: 14.2s\tremaining: 39m 6s\n",
      "60:\tlearn: 0.0609955\ttest: 0.0609832\tbest: 0.0609832 (60)\ttotal: 14.4s\tremaining: 39m 7s\n",
      "61:\tlearn: 0.0606702\ttest: 0.0606372\tbest: 0.0606372 (61)\ttotal: 14.6s\tremaining: 39m 3s\n",
      "62:\tlearn: 0.0603275\ttest: 0.0603060\tbest: 0.0603060 (62)\ttotal: 14.9s\tremaining: 39m 3s\n",
      "63:\tlearn: 0.0600765\ttest: 0.0599875\tbest: 0.0599875 (63)\ttotal: 15.1s\tremaining: 39m 3s\n",
      "64:\tlearn: 0.0597858\ttest: 0.0597145\tbest: 0.0597145 (64)\ttotal: 15.3s\tremaining: 39m\n",
      "65:\tlearn: 0.0593490\ttest: 0.0593647\tbest: 0.0593647 (65)\ttotal: 15.6s\tremaining: 39m 2s\n",
      "66:\tlearn: 0.0591258\ttest: 0.0591067\tbest: 0.0591067 (66)\ttotal: 15.8s\tremaining: 39m 3s\n",
      "67:\tlearn: 0.0588607\ttest: 0.0588585\tbest: 0.0588585 (67)\ttotal: 16s\tremaining: 39m 1s\n",
      "68:\tlearn: 0.0586514\ttest: 0.0586289\tbest: 0.0586289 (68)\ttotal: 16.3s\tremaining: 39m 1s\n",
      "69:\tlearn: 0.0584659\ttest: 0.0584048\tbest: 0.0584048 (69)\ttotal: 16.5s\tremaining: 38m 59s\n",
      "70:\tlearn: 0.0582836\ttest: 0.0582269\tbest: 0.0582269 (70)\ttotal: 16.7s\tremaining: 38m 53s\n",
      "71:\tlearn: 0.0580961\ttest: 0.0580266\tbest: 0.0580266 (71)\ttotal: 16.9s\tremaining: 38m 52s\n",
      "72:\tlearn: 0.0578942\ttest: 0.0578319\tbest: 0.0578319 (72)\ttotal: 17.1s\tremaining: 38m 48s\n",
      "73:\tlearn: 0.0577060\ttest: 0.0576489\tbest: 0.0576489 (73)\ttotal: 17.4s\tremaining: 38m 48s\n",
      "74:\tlearn: 0.0575559\ttest: 0.0574979\tbest: 0.0574979 (74)\ttotal: 17.6s\tremaining: 38m 48s\n",
      "75:\tlearn: 0.0573989\ttest: 0.0573324\tbest: 0.0573324 (75)\ttotal: 17.8s\tremaining: 38m 42s\n",
      "76:\tlearn: 0.0572444\ttest: 0.0571948\tbest: 0.0571948 (76)\ttotal: 18s\tremaining: 38m 41s\n",
      "77:\tlearn: 0.0570652\ttest: 0.0570433\tbest: 0.0570433 (77)\ttotal: 18.2s\tremaining: 38m 37s\n",
      "78:\tlearn: 0.0569060\ttest: 0.0568951\tbest: 0.0568951 (78)\ttotal: 18.4s\tremaining: 38m 34s\n",
      "79:\tlearn: 0.0567760\ttest: 0.0567427\tbest: 0.0567427 (79)\ttotal: 18.7s\tremaining: 38m 34s\n",
      "80:\tlearn: 0.0566359\ttest: 0.0566276\tbest: 0.0566276 (80)\ttotal: 18.9s\tremaining: 38m 32s\n",
      "81:\tlearn: 0.0565621\ttest: 0.0565182\tbest: 0.0565182 (81)\ttotal: 19.1s\tremaining: 38m 32s\n",
      "82:\tlearn: 0.0564216\ttest: 0.0564164\tbest: 0.0564164 (82)\ttotal: 19.3s\tremaining: 38m 29s\n",
      "83:\tlearn: 0.0563291\ttest: 0.0562856\tbest: 0.0562856 (83)\ttotal: 19.5s\tremaining: 38m 26s\n",
      "84:\tlearn: 0.0561716\ttest: 0.0561545\tbest: 0.0561545 (84)\ttotal: 19.8s\tremaining: 38m 27s\n",
      "85:\tlearn: 0.0560975\ttest: 0.0560635\tbest: 0.0560635 (85)\ttotal: 20s\tremaining: 38m 23s\n",
      "86:\tlearn: 0.0560266\ttest: 0.0559761\tbest: 0.0559761 (86)\ttotal: 20.2s\tremaining: 38m 24s\n",
      "87:\tlearn: 0.0558952\ttest: 0.0558754\tbest: 0.0558754 (87)\ttotal: 20.4s\tremaining: 38m 23s\n",
      "88:\tlearn: 0.0558141\ttest: 0.0557957\tbest: 0.0557957 (88)\ttotal: 20.7s\tremaining: 38m 20s\n",
      "89:\tlearn: 0.0557251\ttest: 0.0556876\tbest: 0.0556876 (89)\ttotal: 20.9s\tremaining: 38m 21s\n",
      "90:\tlearn: 0.0556656\ttest: 0.0556146\tbest: 0.0556146 (90)\ttotal: 21.1s\tremaining: 38m 20s\n",
      "91:\tlearn: 0.0555675\ttest: 0.0555181\tbest: 0.0555181 (91)\ttotal: 21.4s\tremaining: 38m 20s\n",
      "92:\tlearn: 0.0555092\ttest: 0.0554507\tbest: 0.0554507 (92)\ttotal: 21.6s\tremaining: 38m 20s\n",
      "93:\tlearn: 0.0554490\ttest: 0.0553868\tbest: 0.0553868 (93)\ttotal: 21.8s\tremaining: 38m 18s\n",
      "94:\tlearn: 0.0553842\ttest: 0.0553244\tbest: 0.0553244 (94)\ttotal: 22s\tremaining: 38m 17s\n",
      "95:\tlearn: 0.0553064\ttest: 0.0552497\tbest: 0.0552497 (95)\ttotal: 22.3s\tremaining: 38m 15s\n",
      "96:\tlearn: 0.0552471\ttest: 0.0551928\tbest: 0.0551928 (96)\ttotal: 22.5s\tremaining: 38m 15s\n",
      "97:\tlearn: 0.0551682\ttest: 0.0551180\tbest: 0.0551180 (97)\ttotal: 22.7s\tremaining: 38m 13s\n",
      "98:\tlearn: 0.0550984\ttest: 0.0550521\tbest: 0.0550521 (98)\ttotal: 22.9s\tremaining: 38m 11s\n",
      "99:\tlearn: 0.0550515\ttest: 0.0550021\tbest: 0.0550021 (99)\ttotal: 23.1s\tremaining: 38m 11s\n",
      "100:\tlearn: 0.0549805\ttest: 0.0549406\tbest: 0.0549406 (100)\ttotal: 23.4s\tremaining: 38m 10s\n",
      "101:\tlearn: 0.0548965\ttest: 0.0548754\tbest: 0.0548754 (101)\ttotal: 23.6s\tremaining: 38m 10s\n",
      "102:\tlearn: 0.0548344\ttest: 0.0548126\tbest: 0.0548126 (102)\ttotal: 23.8s\tremaining: 38m 10s\n",
      "103:\tlearn: 0.0548158\ttest: 0.0547549\tbest: 0.0547549 (103)\ttotal: 24.1s\tremaining: 38m 10s\n",
      "104:\tlearn: 0.0547633\ttest: 0.0547068\tbest: 0.0547068 (104)\ttotal: 24.3s\tremaining: 38m 9s\n",
      "105:\tlearn: 0.0547018\ttest: 0.0546682\tbest: 0.0546682 (105)\ttotal: 24.5s\tremaining: 38m 9s\n",
      "106:\tlearn: 0.0546503\ttest: 0.0546253\tbest: 0.0546253 (106)\ttotal: 24.7s\tremaining: 38m 7s\n",
      "107:\tlearn: 0.0546424\ttest: 0.0545898\tbest: 0.0545898 (107)\ttotal: 24.9s\tremaining: 38m 4s\n",
      "108:\tlearn: 0.0545904\ttest: 0.0545456\tbest: 0.0545456 (108)\ttotal: 25.2s\tremaining: 38m 3s\n",
      "109:\tlearn: 0.0545314\ttest: 0.0545137\tbest: 0.0545137 (109)\ttotal: 25.4s\tremaining: 38m\n",
      "110:\tlearn: 0.0545238\ttest: 0.0544679\tbest: 0.0544679 (110)\ttotal: 25.6s\tremaining: 37m 59s\n",
      "111:\tlearn: 0.0544735\ttest: 0.0544286\tbest: 0.0544286 (111)\ttotal: 25.8s\tremaining: 37m 58s\n",
      "112:\tlearn: 0.0544155\ttest: 0.0543908\tbest: 0.0543908 (112)\ttotal: 26s\tremaining: 37m 56s\n",
      "113:\tlearn: 0.0544033\ttest: 0.0543578\tbest: 0.0543578 (113)\ttotal: 26.2s\tremaining: 37m 54s\n",
      "114:\tlearn: 0.0543140\ttest: 0.0543285\tbest: 0.0543285 (114)\ttotal: 26.5s\tremaining: 37m 55s\n",
      "115:\tlearn: 0.0543120\ttest: 0.0542999\tbest: 0.0542999 (115)\ttotal: 26.7s\tremaining: 37m 52s\n",
      "116:\tlearn: 0.0542626\ttest: 0.0542691\tbest: 0.0542691 (116)\ttotal: 26.9s\tremaining: 37m 49s\n",
      "117:\tlearn: 0.0542526\ttest: 0.0542411\tbest: 0.0542411 (117)\ttotal: 27.1s\tremaining: 37m 48s\n",
      "118:\tlearn: 0.0542574\ttest: 0.0542151\tbest: 0.0542151 (118)\ttotal: 27.3s\tremaining: 37m 47s\n",
      "119:\tlearn: 0.0541866\ttest: 0.0541918\tbest: 0.0541918 (119)\ttotal: 27.5s\tremaining: 37m 46s\n",
      "120:\tlearn: 0.0541640\ttest: 0.0541618\tbest: 0.0541618 (120)\ttotal: 27.8s\tremaining: 37m 46s\n",
      "121:\tlearn: 0.0541057\ttest: 0.0541341\tbest: 0.0541341 (121)\ttotal: 28s\tremaining: 37m 44s\n",
      "122:\tlearn: 0.0541057\ttest: 0.0541080\tbest: 0.0541080 (122)\ttotal: 28.2s\tremaining: 37m 43s\n",
      "123:\tlearn: 0.0541055\ttest: 0.0540846\tbest: 0.0540846 (123)\ttotal: 28.4s\tremaining: 37m 40s\n",
      "124:\tlearn: 0.0540398\ttest: 0.0540580\tbest: 0.0540580 (124)\ttotal: 28.6s\tremaining: 37m 39s\n",
      "125:\tlearn: 0.0540377\ttest: 0.0540309\tbest: 0.0540309 (125)\ttotal: 28.8s\tremaining: 37m 37s\n",
      "126:\tlearn: 0.0539860\ttest: 0.0540121\tbest: 0.0540121 (126)\ttotal: 29s\tremaining: 37m 35s\n",
      "127:\tlearn: 0.0539951\ttest: 0.0539843\tbest: 0.0539843 (127)\ttotal: 29.2s\tremaining: 37m 34s\n",
      "128:\tlearn: 0.0539406\ttest: 0.0539640\tbest: 0.0539640 (128)\ttotal: 29.5s\tremaining: 37m 33s\n",
      "129:\tlearn: 0.0539230\ttest: 0.0539348\tbest: 0.0539348 (129)\ttotal: 29.7s\tremaining: 37m 33s\n",
      "130:\tlearn: 0.0539253\ttest: 0.0539187\tbest: 0.0539187 (130)\ttotal: 29.9s\tremaining: 37m 34s\n",
      "131:\tlearn: 0.0538696\ttest: 0.0538942\tbest: 0.0538942 (131)\ttotal: 30.1s\tremaining: 37m 33s\n",
      "132:\tlearn: 0.0538721\ttest: 0.0538761\tbest: 0.0538761 (132)\ttotal: 30.4s\tremaining: 37m 32s\n",
      "133:\tlearn: 0.0538758\ttest: 0.0538618\tbest: 0.0538618 (133)\ttotal: 30.6s\tremaining: 37m 33s\n",
      "134:\tlearn: 0.0538219\ttest: 0.0538479\tbest: 0.0538479 (134)\ttotal: 30.8s\tremaining: 37m 31s\n",
      "135:\tlearn: 0.0538264\ttest: 0.0538249\tbest: 0.0538249 (135)\ttotal: 31s\tremaining: 37m 30s\n",
      "136:\tlearn: 0.0538209\ttest: 0.0538094\tbest: 0.0538094 (136)\ttotal: 31.2s\tremaining: 37m 29s\n",
      "137:\tlearn: 0.0537689\ttest: 0.0537965\tbest: 0.0537965 (137)\ttotal: 31.5s\tremaining: 37m 30s\n",
      "138:\tlearn: 0.0537811\ttest: 0.0537818\tbest: 0.0537818 (138)\ttotal: 31.7s\tremaining: 37m 29s\n",
      "139:\tlearn: 0.0537742\ttest: 0.0537642\tbest: 0.0537642 (139)\ttotal: 31.9s\tremaining: 37m 29s\n",
      "140:\tlearn: 0.0537276\ttest: 0.0537459\tbest: 0.0537459 (140)\ttotal: 32.2s\tremaining: 37m 28s\n",
      "141:\tlearn: 0.0537206\ttest: 0.0537284\tbest: 0.0537284 (141)\ttotal: 32.4s\tremaining: 37m 26s\n",
      "142:\tlearn: 0.0537198\ttest: 0.0537053\tbest: 0.0537053 (142)\ttotal: 32.6s\tremaining: 37m 24s\n",
      "143:\tlearn: 0.0536602\ttest: 0.0536894\tbest: 0.0536894 (143)\ttotal: 32.8s\tremaining: 37m 24s\n",
      "144:\tlearn: 0.0536526\ttest: 0.0536756\tbest: 0.0536756 (144)\ttotal: 33s\tremaining: 37m 23s\n",
      "145:\tlearn: 0.0536624\ttest: 0.0536606\tbest: 0.0536606 (145)\ttotal: 33.2s\tremaining: 37m 21s\n",
      "146:\tlearn: 0.0536484\ttest: 0.0536400\tbest: 0.0536400 (146)\ttotal: 33.5s\tremaining: 37m 22s\n",
      "147:\tlearn: 0.0536030\ttest: 0.0536275\tbest: 0.0536275 (147)\ttotal: 33.7s\tremaining: 37m 20s\n",
      "148:\tlearn: 0.0535942\ttest: 0.0536069\tbest: 0.0536069 (148)\ttotal: 33.9s\tremaining: 37m 18s\n",
      "149:\tlearn: 0.0536032\ttest: 0.0535969\tbest: 0.0535969 (149)\ttotal: 34.1s\tremaining: 37m 19s\n",
      "150:\tlearn: 0.0536116\ttest: 0.0535776\tbest: 0.0535776 (150)\ttotal: 34.3s\tremaining: 37m 19s\n",
      "151:\tlearn: 0.0535931\ttest: 0.0535669\tbest: 0.0535669 (151)\ttotal: 34.6s\tremaining: 37m 18s\n",
      "152:\tlearn: 0.0535533\ttest: 0.0535588\tbest: 0.0535588 (152)\ttotal: 34.8s\tremaining: 37m 18s\n",
      "153:\tlearn: 0.0535463\ttest: 0.0535511\tbest: 0.0535511 (153)\ttotal: 35s\tremaining: 37m 16s\n",
      "154:\tlearn: 0.0535544\ttest: 0.0535333\tbest: 0.0535333 (154)\ttotal: 35.2s\tremaining: 37m 14s\n",
      "155:\tlearn: 0.0535475\ttest: 0.0535219\tbest: 0.0535219 (155)\ttotal: 35.4s\tremaining: 37m 12s\n",
      "156:\tlearn: 0.0535544\ttest: 0.0535146\tbest: 0.0535146 (156)\ttotal: 35.6s\tremaining: 37m 13s\n",
      "157:\tlearn: 0.0535089\ttest: 0.0535060\tbest: 0.0535060 (157)\ttotal: 35.8s\tremaining: 37m 13s\n",
      "158:\tlearn: 0.0535042\ttest: 0.0534994\tbest: 0.0534994 (158)\ttotal: 36.1s\tremaining: 37m 13s\n",
      "159:\tlearn: 0.0535146\ttest: 0.0534904\tbest: 0.0534904 (159)\ttotal: 36.3s\tremaining: 37m 11s\n",
      "160:\tlearn: 0.0535069\ttest: 0.0534813\tbest: 0.0534813 (160)\ttotal: 36.5s\tremaining: 37m 11s\n",
      "161:\tlearn: 0.0535076\ttest: 0.0534641\tbest: 0.0534641 (161)\ttotal: 36.7s\tremaining: 37m 11s\n",
      "162:\tlearn: 0.0534613\ttest: 0.0534532\tbest: 0.0534532 (162)\ttotal: 37s\tremaining: 37m 10s\n",
      "163:\tlearn: 0.0534525\ttest: 0.0534463\tbest: 0.0534463 (163)\ttotal: 37.2s\tremaining: 37m 8s\n",
      "164:\tlearn: 0.0534593\ttest: 0.0534413\tbest: 0.0534413 (164)\ttotal: 37.4s\tremaining: 37m 7s\n",
      "165:\tlearn: 0.0534688\ttest: 0.0534356\tbest: 0.0534356 (165)\ttotal: 37.6s\tremaining: 37m 5s\n",
      "166:\tlearn: 0.0534614\ttest: 0.0534213\tbest: 0.0534213 (166)\ttotal: 37.8s\tremaining: 37m 3s\n",
      "167:\tlearn: 0.0534421\ttest: 0.0534074\tbest: 0.0534074 (167)\ttotal: 38s\tremaining: 37m 2s\n",
      "168:\tlearn: 0.0534491\ttest: 0.0534021\tbest: 0.0534021 (168)\ttotal: 38.2s\tremaining: 37m\n",
      "169:\tlearn: 0.0534029\ttest: 0.0533969\tbest: 0.0533969 (169)\ttotal: 38.4s\tremaining: 37m\n",
      "170:\tlearn: 0.0533779\ttest: 0.0533633\tbest: 0.0533633 (170)\ttotal: 38.6s\tremaining: 37m\n",
      "171:\tlearn: 0.0533853\ttest: 0.0533560\tbest: 0.0533560 (171)\ttotal: 38.8s\tremaining: 36m 58s\n",
      "172:\tlearn: 0.0533872\ttest: 0.0533519\tbest: 0.0533519 (172)\ttotal: 39s\tremaining: 36m 57s\n",
      "173:\tlearn: 0.0533938\ttest: 0.0533455\tbest: 0.0533455 (173)\ttotal: 39.2s\tremaining: 36m 55s\n",
      "174:\tlearn: 0.0533929\ttest: 0.0533404\tbest: 0.0533404 (174)\ttotal: 39.4s\tremaining: 36m 53s\n",
      "175:\tlearn: 0.0533811\ttest: 0.0533333\tbest: 0.0533333 (175)\ttotal: 39.6s\tremaining: 36m 52s\n",
      "176:\tlearn: 0.0533834\ttest: 0.0533066\tbest: 0.0533066 (176)\ttotal: 39.9s\tremaining: 36m 52s\n",
      "177:\tlearn: 0.0533384\ttest: 0.0533002\tbest: 0.0533002 (177)\ttotal: 40.1s\tremaining: 36m 51s\n",
      "178:\tlearn: 0.0533438\ttest: 0.0532938\tbest: 0.0532938 (178)\ttotal: 40.3s\tremaining: 36m 51s\n",
      "179:\tlearn: 0.0533321\ttest: 0.0532888\tbest: 0.0532888 (179)\ttotal: 40.5s\tremaining: 36m 50s\n",
      "180:\tlearn: 0.0533198\ttest: 0.0532816\tbest: 0.0532816 (180)\ttotal: 40.7s\tremaining: 36m 48s\n",
      "181:\tlearn: 0.0533172\ttest: 0.0532774\tbest: 0.0532774 (181)\ttotal: 40.9s\tremaining: 36m 46s\n",
      "182:\tlearn: 0.0533189\ttest: 0.0532725\tbest: 0.0532725 (182)\ttotal: 41.1s\tremaining: 36m 45s\n",
      "183:\tlearn: 0.0533188\ttest: 0.0532661\tbest: 0.0532661 (183)\ttotal: 41.3s\tremaining: 36m 44s\n",
      "184:\tlearn: 0.0533162\ttest: 0.0532601\tbest: 0.0532601 (184)\ttotal: 41.5s\tremaining: 36m 43s\n",
      "185:\tlearn: 0.0533087\ttest: 0.0532525\tbest: 0.0532525 (185)\ttotal: 41.7s\tremaining: 36m 41s\n",
      "186:\tlearn: 0.0533013\ttest: 0.0532474\tbest: 0.0532474 (186)\ttotal: 42s\tremaining: 36m 41s\n",
      "187:\tlearn: 0.0533033\ttest: 0.0532407\tbest: 0.0532407 (187)\ttotal: 42.2s\tremaining: 36m 42s\n",
      "188:\tlearn: 0.0533003\ttest: 0.0532374\tbest: 0.0532374 (188)\ttotal: 42.4s\tremaining: 36m 40s\n",
      "189:\tlearn: 0.0533044\ttest: 0.0532317\tbest: 0.0532317 (189)\ttotal: 42.6s\tremaining: 36m 39s\n",
      "190:\tlearn: 0.0532579\ttest: 0.0532259\tbest: 0.0532259 (190)\ttotal: 42.8s\tremaining: 36m 39s\n",
      "191:\tlearn: 0.0532550\ttest: 0.0532208\tbest: 0.0532208 (191)\ttotal: 43s\tremaining: 36m 36s\n",
      "192:\tlearn: 0.0532484\ttest: 0.0532144\tbest: 0.0532144 (192)\ttotal: 43.2s\tremaining: 36m 34s\n",
      "193:\tlearn: 0.0532484\ttest: 0.0532104\tbest: 0.0532104 (193)\ttotal: 43.4s\tremaining: 36m 33s\n",
      "194:\tlearn: 0.0532353\ttest: 0.0532048\tbest: 0.0532048 (194)\ttotal: 43.6s\tremaining: 36m 32s\n",
      "195:\tlearn: 0.0532390\ttest: 0.0532002\tbest: 0.0532002 (195)\ttotal: 43.8s\tremaining: 36m 31s\n",
      "196:\tlearn: 0.0532377\ttest: 0.0531970\tbest: 0.0531970 (196)\ttotal: 44s\tremaining: 36m 29s\n",
      "197:\tlearn: 0.0532063\ttest: 0.0531698\tbest: 0.0531698 (197)\ttotal: 44.2s\tremaining: 36m 29s\n",
      "198:\tlearn: 0.0532082\ttest: 0.0531670\tbest: 0.0531670 (198)\ttotal: 44.4s\tremaining: 36m 28s\n",
      "199:\tlearn: 0.0532130\ttest: 0.0531639\tbest: 0.0531639 (199)\ttotal: 44.6s\tremaining: 36m 25s\n",
      "200:\tlearn: 0.0532052\ttest: 0.0531496\tbest: 0.0531496 (200)\ttotal: 44.8s\tremaining: 36m 23s\n",
      "201:\tlearn: 0.0532037\ttest: 0.0531456\tbest: 0.0531456 (201)\ttotal: 45s\tremaining: 36m 21s\n",
      "202:\tlearn: 0.0532019\ttest: 0.0531410\tbest: 0.0531410 (202)\ttotal: 45.2s\tremaining: 36m 20s\n",
      "203:\tlearn: 0.0532013\ttest: 0.0531341\tbest: 0.0531341 (203)\ttotal: 45.4s\tremaining: 36m 19s\n",
      "204:\tlearn: 0.0531876\ttest: 0.0531318\tbest: 0.0531318 (204)\ttotal: 45.6s\tremaining: 36m 19s\n",
      "205:\tlearn: 0.0531868\ttest: 0.0531282\tbest: 0.0531282 (205)\ttotal: 45.8s\tremaining: 36m 17s\n",
      "206:\tlearn: 0.0531841\ttest: 0.0531239\tbest: 0.0531239 (206)\ttotal: 46s\tremaining: 36m 16s\n",
      "207:\tlearn: 0.0531890\ttest: 0.0531211\tbest: 0.0531211 (207)\ttotal: 46.2s\tremaining: 36m 16s\n",
      "208:\tlearn: 0.0531861\ttest: 0.0531161\tbest: 0.0531161 (208)\ttotal: 46.4s\tremaining: 36m 15s\n",
      "209:\tlearn: 0.0531336\ttest: 0.0531116\tbest: 0.0531116 (209)\ttotal: 46.6s\tremaining: 36m 13s\n",
      "210:\tlearn: 0.0531377\ttest: 0.0531075\tbest: 0.0531075 (210)\ttotal: 46.8s\tremaining: 36m 13s\n",
      "211:\tlearn: 0.0531375\ttest: 0.0531052\tbest: 0.0531052 (211)\ttotal: 47s\tremaining: 36m 12s\n",
      "212:\tlearn: 0.0531331\ttest: 0.0531010\tbest: 0.0531010 (212)\ttotal: 47.3s\tremaining: 36m 12s\n",
      "213:\tlearn: 0.0531312\ttest: 0.0530956\tbest: 0.0530956 (213)\ttotal: 47.5s\tremaining: 36m 11s\n",
      "214:\tlearn: 0.0531296\ttest: 0.0530915\tbest: 0.0530915 (214)\ttotal: 47.7s\tremaining: 36m 10s\n",
      "215:\tlearn: 0.0531327\ttest: 0.0530876\tbest: 0.0530876 (215)\ttotal: 47.9s\tremaining: 36m 10s\n",
      "216:\tlearn: 0.0531103\ttest: 0.0530823\tbest: 0.0530823 (216)\ttotal: 48.1s\tremaining: 36m 9s\n",
      "217:\tlearn: 0.0531162\ttest: 0.0530798\tbest: 0.0530798 (217)\ttotal: 48.3s\tremaining: 36m 8s\n",
      "218:\tlearn: 0.0531168\ttest: 0.0530772\tbest: 0.0530772 (218)\ttotal: 48.5s\tremaining: 36m 8s\n",
      "219:\tlearn: 0.0530985\ttest: 0.0530570\tbest: 0.0530570 (219)\ttotal: 48.8s\tremaining: 36m 8s\n",
      "220:\tlearn: 0.0530998\ttest: 0.0530544\tbest: 0.0530544 (220)\ttotal: 49s\tremaining: 36m 8s\n",
      "221:\tlearn: 0.0531029\ttest: 0.0530494\tbest: 0.0530494 (221)\ttotal: 49.2s\tremaining: 36m 6s\n",
      "222:\tlearn: 0.0531062\ttest: 0.0530448\tbest: 0.0530448 (222)\ttotal: 49.4s\tremaining: 36m 6s\n",
      "223:\tlearn: 0.0531062\ttest: 0.0530415\tbest: 0.0530415 (223)\ttotal: 49.6s\tremaining: 36m 4s\n",
      "224:\tlearn: 0.0530971\ttest: 0.0530152\tbest: 0.0530152 (224)\ttotal: 49.8s\tremaining: 36m 3s\n",
      "225:\tlearn: 0.0530917\ttest: 0.0530117\tbest: 0.0530117 (225)\ttotal: 50s\tremaining: 36m 2s\n",
      "226:\tlearn: 0.0530948\ttest: 0.0530078\tbest: 0.0530078 (226)\ttotal: 50.2s\tremaining: 36m 2s\n",
      "227:\tlearn: 0.0530899\ttest: 0.0529910\tbest: 0.0529910 (227)\ttotal: 50.4s\tremaining: 36m 1s\n",
      "228:\tlearn: 0.0530687\ttest: 0.0529834\tbest: 0.0529834 (228)\ttotal: 50.7s\tremaining: 36m 1s\n",
      "229:\tlearn: 0.0530586\ttest: 0.0529804\tbest: 0.0529804 (229)\ttotal: 50.9s\tremaining: 36m 1s\n",
      "230:\tlearn: 0.0530704\ttest: 0.0529788\tbest: 0.0529788 (230)\ttotal: 51s\tremaining: 35m 58s\n",
      "231:\tlearn: 0.0530575\ttest: 0.0529766\tbest: 0.0529766 (231)\ttotal: 51.3s\tremaining: 35m 58s\n",
      "232:\tlearn: 0.0530545\ttest: 0.0529718\tbest: 0.0529718 (232)\ttotal: 51.5s\tremaining: 35m 57s\n",
      "233:\tlearn: 0.0530511\ttest: 0.0529702\tbest: 0.0529702 (233)\ttotal: 51.7s\tremaining: 35m 56s\n",
      "234:\tlearn: 0.0530510\ttest: 0.0529685\tbest: 0.0529685 (234)\ttotal: 51.9s\tremaining: 35m 55s\n",
      "235:\tlearn: 0.0529735\ttest: 0.0529508\tbest: 0.0529508 (235)\ttotal: 52.1s\tremaining: 35m 55s\n",
      "236:\tlearn: 0.0529750\ttest: 0.0529488\tbest: 0.0529488 (236)\ttotal: 52.3s\tremaining: 35m 56s\n",
      "237:\tlearn: 0.0529740\ttest: 0.0529438\tbest: 0.0529438 (237)\ttotal: 52.6s\tremaining: 35m 55s\n",
      "238:\tlearn: 0.0529191\ttest: 0.0529313\tbest: 0.0529313 (238)\ttotal: 52.8s\tremaining: 35m 56s\n",
      "239:\tlearn: 0.0529183\ttest: 0.0529297\tbest: 0.0529297 (239)\ttotal: 53s\tremaining: 35m 55s\n",
      "240:\tlearn: 0.0529184\ttest: 0.0529285\tbest: 0.0529285 (240)\ttotal: 53.2s\tremaining: 35m 54s\n",
      "241:\tlearn: 0.0529166\ttest: 0.0529241\tbest: 0.0529241 (241)\ttotal: 53.4s\tremaining: 35m 53s\n",
      "242:\tlearn: 0.0529203\ttest: 0.0529223\tbest: 0.0529223 (242)\ttotal: 53.6s\tremaining: 35m 51s\n",
      "243:\tlearn: 0.0529206\ttest: 0.0529172\tbest: 0.0529172 (243)\ttotal: 53.8s\tremaining: 35m 51s\n",
      "244:\tlearn: 0.0529173\ttest: 0.0529152\tbest: 0.0529152 (244)\ttotal: 54s\tremaining: 35m 50s\n",
      "245:\tlearn: 0.0529169\ttest: 0.0529127\tbest: 0.0529127 (245)\ttotal: 54.2s\tremaining: 35m 50s\n",
      "246:\tlearn: 0.0529149\ttest: 0.0529070\tbest: 0.0529070 (246)\ttotal: 54.5s\tremaining: 35m 50s\n",
      "247:\tlearn: 0.0528965\ttest: 0.0529052\tbest: 0.0529052 (247)\ttotal: 54.7s\tremaining: 35m 49s\n",
      "248:\tlearn: 0.0528990\ttest: 0.0529040\tbest: 0.0529040 (248)\ttotal: 54.9s\tremaining: 35m 48s\n",
      "249:\tlearn: 0.0528999\ttest: 0.0529015\tbest: 0.0529015 (249)\ttotal: 55.1s\tremaining: 35m 48s\n",
      "250:\tlearn: 0.0529024\ttest: 0.0528991\tbest: 0.0528991 (250)\ttotal: 55.3s\tremaining: 35m 48s\n",
      "251:\tlearn: 0.0529012\ttest: 0.0528961\tbest: 0.0528961 (251)\ttotal: 55.5s\tremaining: 35m 47s\n",
      "252:\tlearn: 0.0528963\ttest: 0.0528937\tbest: 0.0528937 (252)\ttotal: 55.8s\tremaining: 35m 47s\n",
      "253:\tlearn: 0.0528975\ttest: 0.0528923\tbest: 0.0528923 (253)\ttotal: 55.9s\tremaining: 35m 46s\n",
      "254:\tlearn: 0.0528976\ttest: 0.0528912\tbest: 0.0528912 (254)\ttotal: 56.1s\tremaining: 35m 45s\n",
      "255:\tlearn: 0.0528968\ttest: 0.0528884\tbest: 0.0528884 (255)\ttotal: 56.3s\tremaining: 35m 43s\n",
      "256:\tlearn: 0.0528986\ttest: 0.0528852\tbest: 0.0528852 (256)\ttotal: 56.5s\tremaining: 35m 41s\n",
      "257:\tlearn: 0.0528993\ttest: 0.0528839\tbest: 0.0528839 (257)\ttotal: 56.7s\tremaining: 35m 40s\n",
      "258:\tlearn: 0.0529009\ttest: 0.0528826\tbest: 0.0528826 (258)\ttotal: 56.9s\tremaining: 35m 40s\n",
      "259:\tlearn: 0.0529005\ttest: 0.0528820\tbest: 0.0528820 (259)\ttotal: 57.1s\tremaining: 35m 38s\n",
      "260:\tlearn: 0.0529011\ttest: 0.0528802\tbest: 0.0528802 (260)\ttotal: 57.3s\tremaining: 35m 38s\n",
      "261:\tlearn: 0.0528993\ttest: 0.0528788\tbest: 0.0528788 (261)\ttotal: 57.5s\tremaining: 35m 38s\n",
      "262:\tlearn: 0.0529006\ttest: 0.0528764\tbest: 0.0528764 (262)\ttotal: 57.7s\tremaining: 35m 36s\n",
      "263:\tlearn: 0.0528941\ttest: 0.0528688\tbest: 0.0528688 (263)\ttotal: 57.9s\tremaining: 35m 36s\n",
      "264:\tlearn: 0.0528942\ttest: 0.0528669\tbest: 0.0528669 (264)\ttotal: 58.1s\tremaining: 35m 35s\n",
      "265:\tlearn: 0.0528929\ttest: 0.0528659\tbest: 0.0528659 (265)\ttotal: 58.3s\tremaining: 35m 34s\n",
      "266:\tlearn: 0.0528928\ttest: 0.0528650\tbest: 0.0528650 (266)\ttotal: 58.5s\tremaining: 35m 32s\n",
      "267:\tlearn: 0.0528946\ttest: 0.0528644\tbest: 0.0528644 (267)\ttotal: 58.7s\tremaining: 35m 31s\n",
      "268:\tlearn: 0.0528937\ttest: 0.0528635\tbest: 0.0528635 (268)\ttotal: 58.9s\tremaining: 35m 30s\n",
      "269:\tlearn: 0.0528938\ttest: 0.0528622\tbest: 0.0528622 (269)\ttotal: 59.1s\tremaining: 35m 30s\n",
      "270:\tlearn: 0.0528938\ttest: 0.0528613\tbest: 0.0528613 (270)\ttotal: 59.3s\tremaining: 35m 28s\n",
      "271:\tlearn: 0.0528945\ttest: 0.0528603\tbest: 0.0528603 (271)\ttotal: 59.5s\tremaining: 35m 27s\n",
      "272:\tlearn: 0.0528806\ttest: 0.0528590\tbest: 0.0528590 (272)\ttotal: 59.7s\tremaining: 35m 27s\n",
      "273:\tlearn: 0.0528800\ttest: 0.0528548\tbest: 0.0528548 (273)\ttotal: 59.9s\tremaining: 35m 26s\n",
      "274:\tlearn: 0.0528827\ttest: 0.0528505\tbest: 0.0528505 (274)\ttotal: 1m\tremaining: 35m 25s\n",
      "275:\tlearn: 0.0528845\ttest: 0.0528500\tbest: 0.0528500 (275)\ttotal: 1m\tremaining: 35m 23s\n",
      "276:\tlearn: 0.0528745\ttest: 0.0528449\tbest: 0.0528449 (276)\ttotal: 1m\tremaining: 35m 21s\n",
      "277:\tlearn: 0.0528700\ttest: 0.0528439\tbest: 0.0528439 (277)\ttotal: 1m\tremaining: 35m 21s\n",
      "278:\tlearn: 0.0528708\ttest: 0.0528428\tbest: 0.0528428 (278)\ttotal: 1m\tremaining: 35m 20s\n",
      "279:\tlearn: 0.0528713\ttest: 0.0528423\tbest: 0.0528423 (279)\ttotal: 1m 1s\tremaining: 35m 19s\n",
      "280:\tlearn: 0.0528697\ttest: 0.0528409\tbest: 0.0528409 (280)\ttotal: 1m 1s\tremaining: 35m 18s\n",
      "281:\tlearn: 0.0528717\ttest: 0.0528401\tbest: 0.0528401 (281)\ttotal: 1m 1s\tremaining: 35m 18s\n",
      "282:\tlearn: 0.0528712\ttest: 0.0528377\tbest: 0.0528377 (282)\ttotal: 1m 1s\tremaining: 35m 18s\n",
      "283:\tlearn: 0.0528690\ttest: 0.0528363\tbest: 0.0528363 (283)\ttotal: 1m 1s\tremaining: 35m 17s\n",
      "284:\tlearn: 0.0528674\ttest: 0.0528310\tbest: 0.0528310 (284)\ttotal: 1m 2s\tremaining: 35m 16s\n",
      "285:\tlearn: 0.0528673\ttest: 0.0528294\tbest: 0.0528294 (285)\ttotal: 1m 2s\tremaining: 35m 16s\n",
      "286:\tlearn: 0.0528657\ttest: 0.0528269\tbest: 0.0528269 (286)\ttotal: 1m 2s\tremaining: 35m 14s\n",
      "287:\tlearn: 0.0528647\ttest: 0.0528255\tbest: 0.0528255 (287)\ttotal: 1m 2s\tremaining: 35m 13s\n",
      "288:\tlearn: 0.0528653\ttest: 0.0528232\tbest: 0.0528232 (288)\ttotal: 1m 2s\tremaining: 35m 12s\n",
      "289:\tlearn: 0.0528645\ttest: 0.0528221\tbest: 0.0528221 (289)\ttotal: 1m 3s\tremaining: 35m 11s\n",
      "290:\tlearn: 0.0528106\ttest: 0.0528209\tbest: 0.0528209 (290)\ttotal: 1m 3s\tremaining: 35m 11s\n",
      "291:\tlearn: 0.0528607\ttest: 0.0528196\tbest: 0.0528196 (291)\ttotal: 1m 3s\tremaining: 35m 10s\n",
      "292:\tlearn: 0.0528076\ttest: 0.0528189\tbest: 0.0528189 (292)\ttotal: 1m 3s\tremaining: 35m 10s\n",
      "293:\tlearn: 0.0528076\ttest: 0.0528183\tbest: 0.0528183 (293)\ttotal: 1m 3s\tremaining: 35m 8s\n",
      "294:\tlearn: 0.0528101\ttest: 0.0528160\tbest: 0.0528160 (294)\ttotal: 1m 4s\tremaining: 35m 8s\n",
      "295:\tlearn: 0.0528095\ttest: 0.0528148\tbest: 0.0528148 (295)\ttotal: 1m 4s\tremaining: 35m 7s\n",
      "296:\tlearn: 0.0528087\ttest: 0.0528128\tbest: 0.0528128 (296)\ttotal: 1m 4s\tremaining: 35m 7s\n",
      "297:\tlearn: 0.0528094\ttest: 0.0528107\tbest: 0.0528107 (297)\ttotal: 1m 4s\tremaining: 35m 6s\n",
      "298:\tlearn: 0.0528052\ttest: 0.0528093\tbest: 0.0528093 (298)\ttotal: 1m 4s\tremaining: 35m 6s\n",
      "299:\tlearn: 0.0528053\ttest: 0.0528072\tbest: 0.0528072 (299)\ttotal: 1m 5s\tremaining: 35m 5s\n",
      "300:\tlearn: 0.0527986\ttest: 0.0528039\tbest: 0.0528039 (300)\ttotal: 1m 5s\tremaining: 35m 4s\n",
      "301:\tlearn: 0.0528005\ttest: 0.0528031\tbest: 0.0528031 (301)\ttotal: 1m 5s\tremaining: 35m 2s\n",
      "302:\tlearn: 0.0527960\ttest: 0.0527984\tbest: 0.0527984 (302)\ttotal: 1m 5s\tremaining: 35m 2s\n",
      "303:\tlearn: 0.0527899\ttest: 0.0527939\tbest: 0.0527939 (303)\ttotal: 1m 5s\tremaining: 35m\n",
      "304:\tlearn: 0.0527891\ttest: 0.0527918\tbest: 0.0527918 (304)\ttotal: 1m 6s\tremaining: 35m 1s\n",
      "305:\tlearn: 0.0527875\ttest: 0.0527903\tbest: 0.0527903 (305)\ttotal: 1m 6s\tremaining: 35m\n",
      "306:\tlearn: 0.0527874\ttest: 0.0527891\tbest: 0.0527891 (306)\ttotal: 1m 6s\tremaining: 35m\n",
      "307:\tlearn: 0.0527339\ttest: 0.0527680\tbest: 0.0527680 (307)\ttotal: 1m 6s\tremaining: 35m\n",
      "308:\tlearn: 0.0527241\ttest: 0.0527510\tbest: 0.0527510 (308)\ttotal: 1m 6s\tremaining: 34m 59s\n",
      "309:\tlearn: 0.0527212\ttest: 0.0527481\tbest: 0.0527481 (309)\ttotal: 1m 7s\tremaining: 34m 58s\n",
      "310:\tlearn: 0.0527214\ttest: 0.0527449\tbest: 0.0527449 (310)\ttotal: 1m 7s\tremaining: 34m 58s\n",
      "311:\tlearn: 0.0527200\ttest: 0.0527429\tbest: 0.0527429 (311)\ttotal: 1m 7s\tremaining: 34m 57s\n",
      "312:\tlearn: 0.0527064\ttest: 0.0527369\tbest: 0.0527369 (312)\ttotal: 1m 7s\tremaining: 34m 56s\n",
      "313:\tlearn: 0.0527059\ttest: 0.0527339\tbest: 0.0527339 (313)\ttotal: 1m 7s\tremaining: 34m 56s\n",
      "314:\tlearn: 0.0527057\ttest: 0.0527330\tbest: 0.0527330 (314)\ttotal: 1m 8s\tremaining: 34m 56s\n",
      "315:\tlearn: 0.0527051\ttest: 0.0527325\tbest: 0.0527325 (315)\ttotal: 1m 8s\tremaining: 34m 55s\n",
      "316:\tlearn: 0.0527024\ttest: 0.0527304\tbest: 0.0527304 (316)\ttotal: 1m 8s\tremaining: 34m 55s\n",
      "317:\tlearn: 0.0527026\ttest: 0.0527298\tbest: 0.0527298 (317)\ttotal: 1m 8s\tremaining: 34m 55s\n",
      "318:\tlearn: 0.0527004\ttest: 0.0527288\tbest: 0.0527288 (318)\ttotal: 1m 9s\tremaining: 34m 55s\n",
      "319:\tlearn: 0.0527028\ttest: 0.0527261\tbest: 0.0527261 (319)\ttotal: 1m 9s\tremaining: 34m 54s\n",
      "320:\tlearn: 0.0526975\ttest: 0.0527212\tbest: 0.0527212 (320)\ttotal: 1m 9s\tremaining: 34m 53s\n",
      "321:\tlearn: 0.0526970\ttest: 0.0527205\tbest: 0.0527205 (321)\ttotal: 1m 9s\tremaining: 34m 52s\n",
      "322:\tlearn: 0.0526972\ttest: 0.0527203\tbest: 0.0527203 (322)\ttotal: 1m 9s\tremaining: 34m 50s\n",
      "323:\tlearn: 0.0527021\ttest: 0.0527195\tbest: 0.0527195 (323)\ttotal: 1m 9s\tremaining: 34m 50s\n",
      "324:\tlearn: 0.0527013\ttest: 0.0527192\tbest: 0.0527192 (324)\ttotal: 1m 10s\tremaining: 34m 49s\n",
      "325:\tlearn: 0.0526981\ttest: 0.0527162\tbest: 0.0527162 (325)\ttotal: 1m 10s\tremaining: 34m 48s\n",
      "326:\tlearn: 0.0526969\ttest: 0.0527153\tbest: 0.0527153 (326)\ttotal: 1m 10s\tremaining: 34m 47s\n",
      "327:\tlearn: 0.0526971\ttest: 0.0527149\tbest: 0.0527149 (327)\ttotal: 1m 10s\tremaining: 34m 46s\n",
      "328:\tlearn: 0.0526827\ttest: 0.0527128\tbest: 0.0527128 (328)\ttotal: 1m 10s\tremaining: 34m 45s\n",
      "329:\tlearn: 0.0526813\ttest: 0.0527112\tbest: 0.0527112 (329)\ttotal: 1m 11s\tremaining: 34m 45s\n",
      "330:\tlearn: 0.0526797\ttest: 0.0527086\tbest: 0.0527086 (330)\ttotal: 1m 11s\tremaining: 34m 44s\n",
      "331:\tlearn: 0.0526784\ttest: 0.0527075\tbest: 0.0527075 (331)\ttotal: 1m 11s\tremaining: 34m 44s\n",
      "332:\tlearn: 0.0526777\ttest: 0.0527041\tbest: 0.0527041 (332)\ttotal: 1m 11s\tremaining: 34m 43s\n",
      "333:\tlearn: 0.0526767\ttest: 0.0527031\tbest: 0.0527031 (333)\ttotal: 1m 11s\tremaining: 34m 42s\n",
      "334:\tlearn: 0.0526764\ttest: 0.0527027\tbest: 0.0527027 (334)\ttotal: 1m 12s\tremaining: 34m 40s\n",
      "335:\tlearn: 0.0526750\ttest: 0.0527014\tbest: 0.0527014 (335)\ttotal: 1m 12s\tremaining: 34m 40s\n",
      "336:\tlearn: 0.0526738\ttest: 0.0527009\tbest: 0.0527009 (336)\ttotal: 1m 12s\tremaining: 34m 39s\n",
      "337:\tlearn: 0.0526734\ttest: 0.0526998\tbest: 0.0526998 (337)\ttotal: 1m 12s\tremaining: 34m 39s\n",
      "338:\tlearn: 0.0526718\ttest: 0.0526984\tbest: 0.0526984 (338)\ttotal: 1m 12s\tremaining: 34m 39s\n",
      "339:\tlearn: 0.0526677\ttest: 0.0526942\tbest: 0.0526942 (339)\ttotal: 1m 13s\tremaining: 34m 38s\n",
      "340:\tlearn: 0.0526673\ttest: 0.0526933\tbest: 0.0526933 (340)\ttotal: 1m 13s\tremaining: 34m 38s\n",
      "341:\tlearn: 0.0526663\ttest: 0.0526924\tbest: 0.0526924 (341)\ttotal: 1m 13s\tremaining: 34m 37s\n",
      "342:\tlearn: 0.0526659\ttest: 0.0526920\tbest: 0.0526920 (342)\ttotal: 1m 13s\tremaining: 34m 37s\n",
      "343:\tlearn: 0.0526671\ttest: 0.0526917\tbest: 0.0526917 (343)\ttotal: 1m 13s\tremaining: 34m 36s\n",
      "344:\tlearn: 0.0526660\ttest: 0.0526905\tbest: 0.0526905 (344)\ttotal: 1m 14s\tremaining: 34m 36s\n",
      "345:\tlearn: 0.0526653\ttest: 0.0526870\tbest: 0.0526870 (345)\ttotal: 1m 14s\tremaining: 34m 35s\n",
      "346:\tlearn: 0.0526642\ttest: 0.0526861\tbest: 0.0526861 (346)\ttotal: 1m 14s\tremaining: 34m 34s\n",
      "347:\tlearn: 0.0526620\ttest: 0.0526751\tbest: 0.0526751 (347)\ttotal: 1m 14s\tremaining: 34m 34s\n",
      "348:\tlearn: 0.0526620\ttest: 0.0526751\tbest: 0.0526751 (347)\ttotal: 1m 14s\tremaining: 34m 33s\n",
      "349:\tlearn: 0.0526588\ttest: 0.0526717\tbest: 0.0526717 (349)\ttotal: 1m 15s\tremaining: 34m 32s\n",
      "350:\tlearn: 0.0526576\ttest: 0.0526708\tbest: 0.0526708 (350)\ttotal: 1m 15s\tremaining: 34m 33s\n",
      "351:\tlearn: 0.0526563\ttest: 0.0526690\tbest: 0.0526690 (351)\ttotal: 1m 15s\tremaining: 34m 32s\n",
      "352:\tlearn: 0.0526540\ttest: 0.0526657\tbest: 0.0526657 (352)\ttotal: 1m 15s\tremaining: 34m 31s\n",
      "353:\tlearn: 0.0526325\ttest: 0.0526476\tbest: 0.0526476 (353)\ttotal: 1m 16s\tremaining: 34m 31s\n",
      "354:\tlearn: 0.0526314\ttest: 0.0526469\tbest: 0.0526469 (354)\ttotal: 1m 16s\tremaining: 34m 30s\n",
      "355:\tlearn: 0.0526309\ttest: 0.0526466\tbest: 0.0526466 (355)\ttotal: 1m 16s\tremaining: 34m 30s\n",
      "356:\tlearn: 0.0526298\ttest: 0.0526454\tbest: 0.0526454 (356)\ttotal: 1m 16s\tremaining: 34m 29s\n",
      "357:\tlearn: 0.0526304\ttest: 0.0526442\tbest: 0.0526442 (357)\ttotal: 1m 16s\tremaining: 34m 28s\n",
      "358:\tlearn: 0.0526288\ttest: 0.0526348\tbest: 0.0526348 (358)\ttotal: 1m 17s\tremaining: 34m 28s\n",
      "359:\tlearn: 0.0526212\ttest: 0.0526213\tbest: 0.0526213 (359)\ttotal: 1m 17s\tremaining: 34m 27s\n",
      "360:\tlearn: 0.0526123\ttest: 0.0526101\tbest: 0.0526101 (360)\ttotal: 1m 17s\tremaining: 34m 27s\n",
      "361:\tlearn: 0.0526122\ttest: 0.0526098\tbest: 0.0526098 (361)\ttotal: 1m 17s\tremaining: 34m 26s\n",
      "362:\tlearn: 0.0526107\ttest: 0.0526085\tbest: 0.0526085 (362)\ttotal: 1m 17s\tremaining: 34m 26s\n",
      "363:\tlearn: 0.0526103\ttest: 0.0526080\tbest: 0.0526080 (363)\ttotal: 1m 18s\tremaining: 34m 26s\n",
      "364:\tlearn: 0.0526096\ttest: 0.0526071\tbest: 0.0526071 (364)\ttotal: 1m 18s\tremaining: 34m 26s\n",
      "365:\tlearn: 0.0526061\ttest: 0.0525984\tbest: 0.0525984 (365)\ttotal: 1m 18s\tremaining: 34m 25s\n",
      "366:\tlearn: 0.0526063\ttest: 0.0525971\tbest: 0.0525971 (366)\ttotal: 1m 18s\tremaining: 34m 25s\n",
      "367:\tlearn: 0.0526060\ttest: 0.0525971\tbest: 0.0525971 (367)\ttotal: 1m 18s\tremaining: 34m 24s\n",
      "368:\tlearn: 0.0526058\ttest: 0.0525945\tbest: 0.0525945 (368)\ttotal: 1m 19s\tremaining: 34m 24s\n",
      "369:\tlearn: 0.0526092\ttest: 0.0525896\tbest: 0.0525896 (369)\ttotal: 1m 19s\tremaining: 34m 24s\n",
      "370:\tlearn: 0.0526036\ttest: 0.0525877\tbest: 0.0525877 (370)\ttotal: 1m 19s\tremaining: 34m 23s\n",
      "371:\tlearn: 0.0526019\ttest: 0.0525802\tbest: 0.0525802 (371)\ttotal: 1m 19s\tremaining: 34m 22s\n",
      "372:\tlearn: 0.0526014\ttest: 0.0525794\tbest: 0.0525794 (372)\ttotal: 1m 19s\tremaining: 34m 22s\n",
      "373:\tlearn: 0.0526021\ttest: 0.0525785\tbest: 0.0525785 (373)\ttotal: 1m 20s\tremaining: 34m 22s\n",
      "374:\tlearn: 0.0525658\ttest: 0.0525720\tbest: 0.0525720 (374)\ttotal: 1m 20s\tremaining: 34m 22s\n",
      "375:\tlearn: 0.0525658\ttest: 0.0525720\tbest: 0.0525720 (375)\ttotal: 1m 20s\tremaining: 34m 20s\n",
      "376:\tlearn: 0.0525649\ttest: 0.0525714\tbest: 0.0525714 (376)\ttotal: 1m 20s\tremaining: 34m 20s\n",
      "377:\tlearn: 0.0525637\ttest: 0.0525701\tbest: 0.0525701 (377)\ttotal: 1m 20s\tremaining: 34m 19s\n",
      "378:\tlearn: 0.0525618\ttest: 0.0525689\tbest: 0.0525689 (378)\ttotal: 1m 21s\tremaining: 34m 19s\n",
      "379:\tlearn: 0.0525631\ttest: 0.0525677\tbest: 0.0525677 (379)\ttotal: 1m 21s\tremaining: 34m 17s\n",
      "380:\tlearn: 0.0525618\ttest: 0.0525656\tbest: 0.0525656 (380)\ttotal: 1m 21s\tremaining: 34m 17s\n",
      "381:\tlearn: 0.0525608\ttest: 0.0525630\tbest: 0.0525630 (381)\ttotal: 1m 21s\tremaining: 34m 16s\n",
      "382:\tlearn: 0.0525602\ttest: 0.0525627\tbest: 0.0525627 (382)\ttotal: 1m 21s\tremaining: 34m 15s\n",
      "383:\tlearn: 0.0525572\ttest: 0.0525605\tbest: 0.0525605 (383)\ttotal: 1m 22s\tremaining: 34m 14s\n",
      "384:\tlearn: 0.0525554\ttest: 0.0525590\tbest: 0.0525590 (384)\ttotal: 1m 22s\tremaining: 34m 14s\n",
      "385:\tlearn: 0.0525550\ttest: 0.0525586\tbest: 0.0525586 (385)\ttotal: 1m 22s\tremaining: 34m 13s\n",
      "386:\tlearn: 0.0525515\ttest: 0.0525515\tbest: 0.0525515 (386)\ttotal: 1m 22s\tremaining: 34m 13s\n",
      "387:\tlearn: 0.0525512\ttest: 0.0525510\tbest: 0.0525510 (387)\ttotal: 1m 22s\tremaining: 34m 13s\n",
      "388:\tlearn: 0.0525488\ttest: 0.0525491\tbest: 0.0525491 (388)\ttotal: 1m 23s\tremaining: 34m 12s\n",
      "389:\tlearn: 0.0525461\ttest: 0.0525472\tbest: 0.0525472 (389)\ttotal: 1m 23s\tremaining: 34m 12s\n",
      "390:\tlearn: 0.0525386\ttest: 0.0525440\tbest: 0.0525440 (390)\ttotal: 1m 23s\tremaining: 34m 11s\n",
      "391:\tlearn: 0.0525348\ttest: 0.0525379\tbest: 0.0525379 (391)\ttotal: 1m 23s\tremaining: 34m 10s\n",
      "392:\tlearn: 0.0525294\ttest: 0.0525319\tbest: 0.0525319 (392)\ttotal: 1m 23s\tremaining: 34m 10s\n",
      "393:\tlearn: 0.0525278\ttest: 0.0525314\tbest: 0.0525314 (393)\ttotal: 1m 24s\tremaining: 34m 10s\n",
      "394:\tlearn: 0.0525278\ttest: 0.0525314\tbest: 0.0525314 (394)\ttotal: 1m 24s\tremaining: 34m 8s\n",
      "395:\tlearn: 0.0525265\ttest: 0.0525307\tbest: 0.0525307 (395)\ttotal: 1m 24s\tremaining: 34m 7s\n",
      "396:\tlearn: 0.0525256\ttest: 0.0525303\tbest: 0.0525303 (396)\ttotal: 1m 24s\tremaining: 34m 6s\n",
      "397:\tlearn: 0.0525257\ttest: 0.0525291\tbest: 0.0525291 (397)\ttotal: 1m 24s\tremaining: 34m 6s\n",
      "398:\tlearn: 0.0525226\ttest: 0.0525273\tbest: 0.0525273 (398)\ttotal: 1m 25s\tremaining: 34m 6s\n",
      "399:\tlearn: 0.0525241\ttest: 0.0525264\tbest: 0.0525264 (399)\ttotal: 1m 25s\tremaining: 34m 6s\n",
      "400:\tlearn: 0.0525226\ttest: 0.0525250\tbest: 0.0525250 (400)\ttotal: 1m 25s\tremaining: 34m 6s\n",
      "401:\tlearn: 0.0525239\ttest: 0.0525235\tbest: 0.0525235 (401)\ttotal: 1m 25s\tremaining: 34m 5s\n",
      "402:\tlearn: 0.0525254\ttest: 0.0525226\tbest: 0.0525226 (402)\ttotal: 1m 25s\tremaining: 34m 5s\n",
      "403:\tlearn: 0.0525254\ttest: 0.0525226\tbest: 0.0525226 (403)\ttotal: 1m 26s\tremaining: 34m 4s\n",
      "404:\tlearn: 0.0525233\ttest: 0.0525205\tbest: 0.0525205 (404)\ttotal: 1m 26s\tremaining: 34m 4s\n",
      "405:\tlearn: 0.0525211\ttest: 0.0525143\tbest: 0.0525143 (405)\ttotal: 1m 26s\tremaining: 34m 3s\n",
      "406:\tlearn: 0.0525219\ttest: 0.0525128\tbest: 0.0525128 (406)\ttotal: 1m 26s\tremaining: 34m 3s\n",
      "407:\tlearn: 0.0525171\ttest: 0.0525065\tbest: 0.0525065 (407)\ttotal: 1m 26s\tremaining: 34m 2s\n",
      "408:\tlearn: 0.0524790\ttest: 0.0525001\tbest: 0.0525001 (408)\ttotal: 1m 27s\tremaining: 34m 1s\n",
      "409:\tlearn: 0.0524793\ttest: 0.0524996\tbest: 0.0524996 (409)\ttotal: 1m 27s\tremaining: 33m 59s\n",
      "410:\tlearn: 0.0524684\ttest: 0.0524888\tbest: 0.0524888 (410)\ttotal: 1m 27s\tremaining: 33m 59s\n",
      "411:\tlearn: 0.0524675\ttest: 0.0524871\tbest: 0.0524871 (411)\ttotal: 1m 27s\tremaining: 33m 58s\n",
      "412:\tlearn: 0.0524673\ttest: 0.0524850\tbest: 0.0524850 (412)\ttotal: 1m 27s\tremaining: 33m 59s\n",
      "413:\tlearn: 0.0524667\ttest: 0.0524836\tbest: 0.0524836 (413)\ttotal: 1m 28s\tremaining: 33m 59s\n",
      "414:\tlearn: 0.0524660\ttest: 0.0524831\tbest: 0.0524831 (414)\ttotal: 1m 28s\tremaining: 33m 58s\n",
      "415:\tlearn: 0.0524652\ttest: 0.0524825\tbest: 0.0524825 (415)\ttotal: 1m 28s\tremaining: 33m 57s\n",
      "416:\tlearn: 0.0524690\ttest: 0.0524806\tbest: 0.0524806 (416)\ttotal: 1m 28s\tremaining: 33m 58s\n",
      "417:\tlearn: 0.0524665\ttest: 0.0524761\tbest: 0.0524761 (417)\ttotal: 1m 28s\tremaining: 33m 58s\n",
      "418:\tlearn: 0.0524662\ttest: 0.0524756\tbest: 0.0524756 (418)\ttotal: 1m 29s\tremaining: 33m 57s\n",
      "419:\tlearn: 0.0524658\ttest: 0.0524753\tbest: 0.0524753 (419)\ttotal: 1m 29s\tremaining: 33m 57s\n",
      "420:\tlearn: 0.0524647\ttest: 0.0524742\tbest: 0.0524742 (420)\ttotal: 1m 29s\tremaining: 33m 56s\n",
      "421:\tlearn: 0.0524685\ttest: 0.0524732\tbest: 0.0524732 (421)\ttotal: 1m 29s\tremaining: 33m 55s\n",
      "422:\tlearn: 0.0524653\ttest: 0.0524695\tbest: 0.0524695 (422)\ttotal: 1m 29s\tremaining: 33m 55s\n",
      "423:\tlearn: 0.0524660\ttest: 0.0524692\tbest: 0.0524692 (423)\ttotal: 1m 30s\tremaining: 33m 55s\n",
      "424:\tlearn: 0.0524620\ttest: 0.0524664\tbest: 0.0524664 (424)\ttotal: 1m 30s\tremaining: 33m 54s\n",
      "425:\tlearn: 0.0524615\ttest: 0.0524621\tbest: 0.0524621 (425)\ttotal: 1m 30s\tremaining: 33m 54s\n",
      "426:\tlearn: 0.0524595\ttest: 0.0524605\tbest: 0.0524605 (426)\ttotal: 1m 30s\tremaining: 33m 54s\n",
      "427:\tlearn: 0.0524593\ttest: 0.0524603\tbest: 0.0524603 (427)\ttotal: 1m 30s\tremaining: 33m 54s\n",
      "428:\tlearn: 0.0524591\ttest: 0.0524602\tbest: 0.0524602 (428)\ttotal: 1m 31s\tremaining: 33m 54s\n",
      "429:\tlearn: 0.0524580\ttest: 0.0524592\tbest: 0.0524592 (429)\ttotal: 1m 31s\tremaining: 33m 53s\n",
      "430:\tlearn: 0.0524576\ttest: 0.0524588\tbest: 0.0524588 (430)\ttotal: 1m 31s\tremaining: 33m 53s\n",
      "431:\tlearn: 0.0524403\ttest: 0.0524477\tbest: 0.0524477 (431)\ttotal: 1m 31s\tremaining: 33m 53s\n",
      "432:\tlearn: 0.0524385\ttest: 0.0524427\tbest: 0.0524427 (432)\ttotal: 1m 32s\tremaining: 33m 53s\n",
      "433:\tlearn: 0.0524359\ttest: 0.0524390\tbest: 0.0524390 (433)\ttotal: 1m 32s\tremaining: 33m 52s\n",
      "434:\tlearn: 0.0524362\ttest: 0.0524325\tbest: 0.0524325 (434)\ttotal: 1m 32s\tremaining: 33m 53s\n",
      "435:\tlearn: 0.0524378\ttest: 0.0524290\tbest: 0.0524290 (435)\ttotal: 1m 32s\tremaining: 33m 53s\n",
      "436:\tlearn: 0.0524374\ttest: 0.0524283\tbest: 0.0524283 (436)\ttotal: 1m 32s\tremaining: 33m 52s\n",
      "437:\tlearn: 0.0524332\ttest: 0.0524235\tbest: 0.0524235 (437)\ttotal: 1m 33s\tremaining: 33m 52s\n",
      "438:\tlearn: 0.0524342\ttest: 0.0524194\tbest: 0.0524194 (438)\ttotal: 1m 33s\tremaining: 33m 52s\n",
      "439:\tlearn: 0.0524339\ttest: 0.0524190\tbest: 0.0524190 (439)\ttotal: 1m 33s\tremaining: 33m 52s\n",
      "440:\tlearn: 0.0524313\ttest: 0.0524175\tbest: 0.0524175 (440)\ttotal: 1m 33s\tremaining: 33m 51s\n",
      "441:\tlearn: 0.0524306\ttest: 0.0524171\tbest: 0.0524171 (441)\ttotal: 1m 33s\tremaining: 33m 50s\n",
      "442:\tlearn: 0.0524298\ttest: 0.0524160\tbest: 0.0524160 (442)\ttotal: 1m 34s\tremaining: 33m 50s\n",
      "443:\tlearn: 0.0524275\ttest: 0.0524138\tbest: 0.0524138 (443)\ttotal: 1m 34s\tremaining: 33m 50s\n",
      "444:\tlearn: 0.0524273\ttest: 0.0524137\tbest: 0.0524137 (444)\ttotal: 1m 34s\tremaining: 33m 49s\n",
      "445:\tlearn: 0.0524213\ttest: 0.0524093\tbest: 0.0524093 (445)\ttotal: 1m 34s\tremaining: 33m 49s\n",
      "446:\tlearn: 0.0524204\ttest: 0.0524076\tbest: 0.0524076 (446)\ttotal: 1m 34s\tremaining: 33m 49s\n",
      "447:\tlearn: 0.0524193\ttest: 0.0524065\tbest: 0.0524065 (447)\ttotal: 1m 35s\tremaining: 33m 49s\n",
      "448:\tlearn: 0.0524203\ttest: 0.0524056\tbest: 0.0524056 (448)\ttotal: 1m 35s\tremaining: 33m 49s\n",
      "449:\tlearn: 0.0524222\ttest: 0.0524041\tbest: 0.0524041 (449)\ttotal: 1m 35s\tremaining: 33m 48s\n",
      "450:\tlearn: 0.0524213\ttest: 0.0523994\tbest: 0.0523994 (450)\ttotal: 1m 35s\tremaining: 33m 48s\n",
      "451:\tlearn: 0.0524213\ttest: 0.0523994\tbest: 0.0523994 (451)\ttotal: 1m 35s\tremaining: 33m 47s\n",
      "452:\tlearn: 0.0524212\ttest: 0.0523994\tbest: 0.0523994 (452)\ttotal: 1m 36s\tremaining: 33m 46s\n",
      "453:\tlearn: 0.0524190\ttest: 0.0523986\tbest: 0.0523986 (453)\ttotal: 1m 36s\tremaining: 33m 46s\n",
      "454:\tlearn: 0.0524191\ttest: 0.0523974\tbest: 0.0523974 (454)\ttotal: 1m 36s\tremaining: 33m 46s\n",
      "455:\tlearn: 0.0524149\ttest: 0.0523946\tbest: 0.0523946 (455)\ttotal: 1m 36s\tremaining: 33m 46s\n",
      "456:\tlearn: 0.0524132\ttest: 0.0523928\tbest: 0.0523928 (456)\ttotal: 1m 37s\tremaining: 33m 45s\n",
      "457:\tlearn: 0.0524105\ttest: 0.0523915\tbest: 0.0523915 (457)\ttotal: 1m 37s\tremaining: 33m 44s\n",
      "458:\tlearn: 0.0524112\ttest: 0.0523911\tbest: 0.0523911 (458)\ttotal: 1m 37s\tremaining: 33m 44s\n",
      "459:\tlearn: 0.0524104\ttest: 0.0523905\tbest: 0.0523905 (459)\ttotal: 1m 37s\tremaining: 33m 43s\n",
      "460:\tlearn: 0.0524110\ttest: 0.0523891\tbest: 0.0523891 (460)\ttotal: 1m 37s\tremaining: 33m 43s\n",
      "461:\tlearn: 0.0524052\ttest: 0.0523858\tbest: 0.0523858 (461)\ttotal: 1m 37s\tremaining: 33m 43s\n",
      "462:\tlearn: 0.0524048\ttest: 0.0523856\tbest: 0.0523856 (462)\ttotal: 1m 38s\tremaining: 33m 42s\n",
      "463:\tlearn: 0.0524041\ttest: 0.0523849\tbest: 0.0523849 (463)\ttotal: 1m 38s\tremaining: 33m 41s\n",
      "464:\tlearn: 0.0524012\ttest: 0.0523813\tbest: 0.0523813 (464)\ttotal: 1m 38s\tremaining: 33m 41s\n",
      "465:\tlearn: 0.0524011\ttest: 0.0523810\tbest: 0.0523810 (465)\ttotal: 1m 38s\tremaining: 33m 41s\n",
      "466:\tlearn: 0.0523843\ttest: 0.0523788\tbest: 0.0523788 (466)\ttotal: 1m 38s\tremaining: 33m 40s\n",
      "467:\tlearn: 0.0523840\ttest: 0.0523786\tbest: 0.0523786 (467)\ttotal: 1m 39s\tremaining: 33m 40s\n",
      "468:\tlearn: 0.0523833\ttest: 0.0523779\tbest: 0.0523779 (468)\ttotal: 1m 39s\tremaining: 33m 39s\n",
      "469:\tlearn: 0.0523794\ttest: 0.0523768\tbest: 0.0523768 (469)\ttotal: 1m 39s\tremaining: 33m 38s\n",
      "470:\tlearn: 0.0523836\ttest: 0.0523755\tbest: 0.0523755 (470)\ttotal: 1m 39s\tremaining: 33m 38s\n",
      "471:\tlearn: 0.0523834\ttest: 0.0523749\tbest: 0.0523749 (471)\ttotal: 1m 39s\tremaining: 33m 38s\n",
      "472:\tlearn: 0.0523827\ttest: 0.0523743\tbest: 0.0523743 (472)\ttotal: 1m 40s\tremaining: 33m 38s\n",
      "473:\tlearn: 0.0523809\ttest: 0.0523711\tbest: 0.0523711 (473)\ttotal: 1m 40s\tremaining: 33m 38s\n",
      "474:\tlearn: 0.0523803\ttest: 0.0523687\tbest: 0.0523687 (474)\ttotal: 1m 40s\tremaining: 33m 37s\n",
      "475:\tlearn: 0.0523799\ttest: 0.0523684\tbest: 0.0523684 (475)\ttotal: 1m 40s\tremaining: 33m 37s\n",
      "476:\tlearn: 0.0523786\ttest: 0.0523672\tbest: 0.0523672 (476)\ttotal: 1m 41s\tremaining: 33m 37s\n",
      "477:\tlearn: 0.0523784\ttest: 0.0523669\tbest: 0.0523669 (477)\ttotal: 1m 41s\tremaining: 33m 36s\n",
      "478:\tlearn: 0.0523783\ttest: 0.0523667\tbest: 0.0523667 (478)\ttotal: 1m 41s\tremaining: 33m 35s\n",
      "479:\tlearn: 0.0523775\ttest: 0.0523662\tbest: 0.0523662 (479)\ttotal: 1m 41s\tremaining: 33m 35s\n",
      "480:\tlearn: 0.0523767\ttest: 0.0523649\tbest: 0.0523649 (480)\ttotal: 1m 41s\tremaining: 33m 34s\n",
      "481:\tlearn: 0.0523789\ttest: 0.0523634\tbest: 0.0523634 (481)\ttotal: 1m 42s\tremaining: 33m 34s\n",
      "482:\tlearn: 0.0523781\ttest: 0.0523627\tbest: 0.0523627 (482)\ttotal: 1m 42s\tremaining: 33m 34s\n",
      "483:\tlearn: 0.0523779\ttest: 0.0523625\tbest: 0.0523625 (483)\ttotal: 1m 42s\tremaining: 33m 34s\n",
      "484:\tlearn: 0.0523772\ttest: 0.0523616\tbest: 0.0523616 (484)\ttotal: 1m 42s\tremaining: 33m 33s\n",
      "485:\tlearn: 0.0523762\ttest: 0.0523607\tbest: 0.0523607 (485)\ttotal: 1m 42s\tremaining: 33m 33s\n",
      "486:\tlearn: 0.0523756\ttest: 0.0523602\tbest: 0.0523602 (486)\ttotal: 1m 43s\tremaining: 33m 33s\n",
      "487:\tlearn: 0.0523751\ttest: 0.0523594\tbest: 0.0523594 (487)\ttotal: 1m 43s\tremaining: 33m 33s\n",
      "488:\tlearn: 0.0523725\ttest: 0.0523589\tbest: 0.0523589 (488)\ttotal: 1m 43s\tremaining: 33m 32s\n",
      "489:\tlearn: 0.0523723\ttest: 0.0523531\tbest: 0.0523531 (489)\ttotal: 1m 43s\tremaining: 33m 32s\n",
      "490:\tlearn: 0.0523719\ttest: 0.0523519\tbest: 0.0523519 (490)\ttotal: 1m 43s\tremaining: 33m 32s\n",
      "491:\tlearn: 0.0523708\ttest: 0.0523493\tbest: 0.0523493 (491)\ttotal: 1m 44s\tremaining: 33m 32s\n",
      "492:\tlearn: 0.0523705\ttest: 0.0523483\tbest: 0.0523483 (492)\ttotal: 1m 44s\tremaining: 33m 31s\n",
      "493:\tlearn: 0.0523692\ttest: 0.0523479\tbest: 0.0523479 (493)\ttotal: 1m 44s\tremaining: 33m 31s\n",
      "494:\tlearn: 0.0523686\ttest: 0.0523472\tbest: 0.0523472 (494)\ttotal: 1m 44s\tremaining: 33m 30s\n",
      "495:\tlearn: 0.0523661\ttest: 0.0523428\tbest: 0.0523428 (495)\ttotal: 1m 44s\tremaining: 33m 29s\n",
      "496:\tlearn: 0.0523647\ttest: 0.0523421\tbest: 0.0523421 (496)\ttotal: 1m 45s\tremaining: 33m 29s\n",
      "497:\tlearn: 0.0523659\ttest: 0.0523413\tbest: 0.0523413 (497)\ttotal: 1m 45s\tremaining: 33m 28s\n",
      "498:\tlearn: 0.0523640\ttest: 0.0523393\tbest: 0.0523393 (498)\ttotal: 1m 45s\tremaining: 33m 28s\n",
      "499:\tlearn: 0.0523629\ttest: 0.0523379\tbest: 0.0523379 (499)\ttotal: 1m 45s\tremaining: 33m 27s\n",
      "500:\tlearn: 0.0523625\ttest: 0.0523371\tbest: 0.0523371 (500)\ttotal: 1m 45s\tremaining: 33m 26s\n",
      "501:\tlearn: 0.0523620\ttest: 0.0523357\tbest: 0.0523357 (501)\ttotal: 1m 45s\tremaining: 33m 25s\n",
      "502:\tlearn: 0.0523618\ttest: 0.0523354\tbest: 0.0523354 (502)\ttotal: 1m 46s\tremaining: 33m 24s\n",
      "503:\tlearn: 0.0523607\ttest: 0.0523341\tbest: 0.0523341 (503)\ttotal: 1m 46s\tremaining: 33m 24s\n",
      "504:\tlearn: 0.0523604\ttest: 0.0523340\tbest: 0.0523340 (504)\ttotal: 1m 46s\tremaining: 33m 23s\n",
      "505:\tlearn: 0.0523600\ttest: 0.0523336\tbest: 0.0523336 (505)\ttotal: 1m 46s\tremaining: 33m 22s\n",
      "506:\tlearn: 0.0523637\ttest: 0.0523327\tbest: 0.0523327 (506)\ttotal: 1m 46s\tremaining: 33m 21s\n",
      "507:\tlearn: 0.0523606\ttest: 0.0523312\tbest: 0.0523312 (507)\ttotal: 1m 47s\tremaining: 33m 21s\n",
      "508:\tlearn: 0.0523602\ttest: 0.0523302\tbest: 0.0523302 (508)\ttotal: 1m 47s\tremaining: 33m 21s\n",
      "509:\tlearn: 0.0523636\ttest: 0.0523290\tbest: 0.0523290 (509)\ttotal: 1m 47s\tremaining: 33m 20s\n",
      "510:\tlearn: 0.0523580\ttest: 0.0523284\tbest: 0.0523284 (510)\ttotal: 1m 47s\tremaining: 33m 20s\n",
      "511:\tlearn: 0.0523577\ttest: 0.0523265\tbest: 0.0523265 (511)\ttotal: 1m 47s\tremaining: 33m 20s\n",
      "512:\tlearn: 0.0523569\ttest: 0.0523256\tbest: 0.0523256 (512)\ttotal: 1m 48s\tremaining: 33m 19s\n",
      "513:\tlearn: 0.0523570\ttest: 0.0523249\tbest: 0.0523249 (513)\ttotal: 1m 48s\tremaining: 33m 18s\n",
      "514:\tlearn: 0.0523561\ttest: 0.0523247\tbest: 0.0523247 (514)\ttotal: 1m 48s\tremaining: 33m 18s\n",
      "515:\tlearn: 0.0523561\ttest: 0.0523242\tbest: 0.0523242 (515)\ttotal: 1m 48s\tremaining: 33m 17s\n",
      "516:\tlearn: 0.0523553\ttest: 0.0523230\tbest: 0.0523230 (516)\ttotal: 1m 48s\tremaining: 33m 16s\n",
      "517:\tlearn: 0.0523548\ttest: 0.0523223\tbest: 0.0523223 (517)\ttotal: 1m 49s\tremaining: 33m 16s\n",
      "518:\tlearn: 0.0523548\ttest: 0.0523214\tbest: 0.0523214 (518)\ttotal: 1m 49s\tremaining: 33m 16s\n",
      "519:\tlearn: 0.0523539\ttest: 0.0523202\tbest: 0.0523202 (519)\ttotal: 1m 49s\tremaining: 33m 16s\n",
      "520:\tlearn: 0.0523528\ttest: 0.0523195\tbest: 0.0523195 (520)\ttotal: 1m 49s\tremaining: 33m 16s\n",
      "521:\tlearn: 0.0523526\ttest: 0.0523190\tbest: 0.0523190 (521)\ttotal: 1m 49s\tremaining: 33m 16s\n",
      "522:\tlearn: 0.0523534\ttest: 0.0523189\tbest: 0.0523189 (522)\ttotal: 1m 50s\tremaining: 33m 15s\n",
      "523:\tlearn: 0.0523530\ttest: 0.0523180\tbest: 0.0523180 (523)\ttotal: 1m 50s\tremaining: 33m 15s\n",
      "524:\tlearn: 0.0523565\ttest: 0.0523171\tbest: 0.0523171 (524)\ttotal: 1m 50s\tremaining: 33m 15s\n",
      "525:\tlearn: 0.0523559\ttest: 0.0523162\tbest: 0.0523162 (525)\ttotal: 1m 50s\tremaining: 33m 14s\n",
      "526:\tlearn: 0.0523555\ttest: 0.0523141\tbest: 0.0523141 (526)\ttotal: 1m 50s\tremaining: 33m 14s\n",
      "527:\tlearn: 0.0523549\ttest: 0.0523133\tbest: 0.0523133 (527)\ttotal: 1m 51s\tremaining: 33m 14s\n",
      "528:\tlearn: 0.0523543\ttest: 0.0523126\tbest: 0.0523126 (528)\ttotal: 1m 51s\tremaining: 33m 14s\n",
      "529:\tlearn: 0.0523542\ttest: 0.0523126\tbest: 0.0523126 (529)\ttotal: 1m 51s\tremaining: 33m 13s\n",
      "530:\tlearn: 0.0523515\ttest: 0.0523114\tbest: 0.0523114 (530)\ttotal: 1m 51s\tremaining: 33m 13s\n",
      "531:\tlearn: 0.0523502\ttest: 0.0523099\tbest: 0.0523099 (531)\ttotal: 1m 51s\tremaining: 33m 13s\n",
      "532:\tlearn: 0.0523502\ttest: 0.0523094\tbest: 0.0523094 (532)\ttotal: 1m 52s\tremaining: 33m 12s\n",
      "533:\tlearn: 0.0523486\ttest: 0.0523057\tbest: 0.0523057 (533)\ttotal: 1m 52s\tremaining: 33m 11s\n",
      "534:\tlearn: 0.0523482\ttest: 0.0523054\tbest: 0.0523054 (534)\ttotal: 1m 52s\tremaining: 33m 11s\n",
      "535:\tlearn: 0.0523481\ttest: 0.0523048\tbest: 0.0523048 (535)\ttotal: 1m 52s\tremaining: 33m 11s\n",
      "536:\tlearn: 0.0523474\ttest: 0.0523042\tbest: 0.0523042 (536)\ttotal: 1m 52s\tremaining: 33m 10s\n",
      "537:\tlearn: 0.0523472\ttest: 0.0523034\tbest: 0.0523034 (537)\ttotal: 1m 53s\tremaining: 33m 9s\n",
      "538:\tlearn: 0.0523470\ttest: 0.0523030\tbest: 0.0523030 (538)\ttotal: 1m 53s\tremaining: 33m 9s\n",
      "539:\tlearn: 0.0523464\ttest: 0.0523027\tbest: 0.0523027 (539)\ttotal: 1m 53s\tremaining: 33m 9s\n",
      "540:\tlearn: 0.0523458\ttest: 0.0523013\tbest: 0.0523013 (540)\ttotal: 1m 53s\tremaining: 33m 9s\n",
      "541:\tlearn: 0.0523458\ttest: 0.0523012\tbest: 0.0523012 (541)\ttotal: 1m 53s\tremaining: 33m 7s\n",
      "542:\tlearn: 0.0523458\ttest: 0.0523012\tbest: 0.0523012 (541)\ttotal: 1m 54s\tremaining: 33m 6s\n",
      "543:\tlearn: 0.0523454\ttest: 0.0523010\tbest: 0.0523010 (543)\ttotal: 1m 54s\tremaining: 33m 6s\n",
      "544:\tlearn: 0.0523454\ttest: 0.0523010\tbest: 0.0523010 (543)\ttotal: 1m 54s\tremaining: 33m 5s\n",
      "545:\tlearn: 0.0523411\ttest: 0.0522981\tbest: 0.0522981 (545)\ttotal: 1m 54s\tremaining: 33m 5s\n",
      "546:\tlearn: 0.0523396\ttest: 0.0522975\tbest: 0.0522975 (546)\ttotal: 1m 54s\tremaining: 33m 5s\n",
      "547:\tlearn: 0.0523392\ttest: 0.0522969\tbest: 0.0522969 (547)\ttotal: 1m 55s\tremaining: 33m 5s\n",
      "548:\tlearn: 0.0523354\ttest: 0.0522940\tbest: 0.0522940 (548)\ttotal: 1m 55s\tremaining: 33m 4s\n",
      "549:\tlearn: 0.0523348\ttest: 0.0522931\tbest: 0.0522931 (549)\ttotal: 1m 55s\tremaining: 33m 4s\n",
      "550:\tlearn: 0.0523340\ttest: 0.0522920\tbest: 0.0522920 (550)\ttotal: 1m 55s\tremaining: 33m 4s\n",
      "551:\tlearn: 0.0523371\ttest: 0.0522912\tbest: 0.0522912 (551)\ttotal: 1m 55s\tremaining: 33m 3s\n",
      "552:\tlearn: 0.0523371\ttest: 0.0522905\tbest: 0.0522905 (552)\ttotal: 1m 56s\tremaining: 33m 2s\n",
      "553:\tlearn: 0.0523356\ttest: 0.0522902\tbest: 0.0522902 (553)\ttotal: 1m 56s\tremaining: 33m 2s\n",
      "554:\tlearn: 0.0523359\ttest: 0.0522902\tbest: 0.0522902 (554)\ttotal: 1m 56s\tremaining: 33m 1s\n",
      "555:\tlearn: 0.0523355\ttest: 0.0522898\tbest: 0.0522898 (555)\ttotal: 1m 56s\tremaining: 33m 1s\n",
      "556:\tlearn: 0.0523353\ttest: 0.0522894\tbest: 0.0522894 (556)\ttotal: 1m 56s\tremaining: 33m\n",
      "557:\tlearn: 0.0523347\ttest: 0.0522889\tbest: 0.0522889 (557)\ttotal: 1m 57s\tremaining: 32m 59s\n",
      "558:\tlearn: 0.0523330\ttest: 0.0522874\tbest: 0.0522874 (558)\ttotal: 1m 57s\tremaining: 32m 59s\n",
      "559:\tlearn: 0.0523321\ttest: 0.0522868\tbest: 0.0522868 (559)\ttotal: 1m 57s\tremaining: 32m 58s\n",
      "560:\tlearn: 0.0523314\ttest: 0.0522862\tbest: 0.0522862 (560)\ttotal: 1m 57s\tremaining: 32m 58s\n",
      "561:\tlearn: 0.0523316\ttest: 0.0522862\tbest: 0.0522862 (561)\ttotal: 1m 57s\tremaining: 32m 57s\n",
      "562:\tlearn: 0.0523324\ttest: 0.0522837\tbest: 0.0522837 (562)\ttotal: 1m 58s\tremaining: 32m 58s\n",
      "563:\tlearn: 0.0523322\ttest: 0.0522834\tbest: 0.0522834 (563)\ttotal: 1m 58s\tremaining: 32m 57s\n",
      "564:\tlearn: 0.0523325\ttest: 0.0522834\tbest: 0.0522834 (564)\ttotal: 1m 58s\tremaining: 32m 57s\n",
      "565:\tlearn: 0.0523313\ttest: 0.0522819\tbest: 0.0522819 (565)\ttotal: 1m 58s\tremaining: 32m 56s\n",
      "566:\tlearn: 0.0523310\ttest: 0.0522813\tbest: 0.0522813 (566)\ttotal: 1m 58s\tremaining: 32m 56s\n",
      "567:\tlearn: 0.0523309\ttest: 0.0522811\tbest: 0.0522811 (567)\ttotal: 1m 59s\tremaining: 32m 56s\n",
      "568:\tlearn: 0.0523309\ttest: 0.0522811\tbest: 0.0522811 (568)\ttotal: 1m 59s\tremaining: 32m 55s\n",
      "569:\tlearn: 0.0523307\ttest: 0.0522808\tbest: 0.0522808 (569)\ttotal: 1m 59s\tremaining: 32m 55s\n",
      "570:\tlearn: 0.0523304\ttest: 0.0522802\tbest: 0.0522802 (570)\ttotal: 1m 59s\tremaining: 32m 54s\n",
      "571:\tlearn: 0.0523300\ttest: 0.0522798\tbest: 0.0522798 (571)\ttotal: 1m 59s\tremaining: 32m 54s\n",
      "572:\tlearn: 0.0523290\ttest: 0.0522794\tbest: 0.0522794 (572)\ttotal: 2m\tremaining: 32m 54s\n",
      "573:\tlearn: 0.0523286\ttest: 0.0522790\tbest: 0.0522790 (573)\ttotal: 2m\tremaining: 32m 54s\n",
      "574:\tlearn: 0.0523285\ttest: 0.0522787\tbest: 0.0522787 (574)\ttotal: 2m\tremaining: 32m 54s\n",
      "575:\tlearn: 0.0523283\ttest: 0.0522784\tbest: 0.0522784 (575)\ttotal: 2m\tremaining: 32m 53s\n",
      "576:\tlearn: 0.0523280\ttest: 0.0522779\tbest: 0.0522779 (576)\ttotal: 2m\tremaining: 32m 53s\n",
      "577:\tlearn: 0.0523298\ttest: 0.0522768\tbest: 0.0522768 (577)\ttotal: 2m 1s\tremaining: 32m 52s\n",
      "578:\tlearn: 0.0523292\ttest: 0.0522760\tbest: 0.0522760 (578)\ttotal: 2m 1s\tremaining: 32m 52s\n",
      "579:\tlearn: 0.0523229\ttest: 0.0522752\tbest: 0.0522752 (579)\ttotal: 2m 1s\tremaining: 32m 52s\n",
      "580:\tlearn: 0.0523225\ttest: 0.0522746\tbest: 0.0522746 (580)\ttotal: 2m 1s\tremaining: 32m 51s\n",
      "581:\tlearn: 0.0523224\ttest: 0.0522745\tbest: 0.0522745 (581)\ttotal: 2m 1s\tremaining: 32m 51s\n",
      "582:\tlearn: 0.0523224\ttest: 0.0522745\tbest: 0.0522745 (582)\ttotal: 2m 2s\tremaining: 32m 50s\n",
      "583:\tlearn: 0.0523201\ttest: 0.0522711\tbest: 0.0522711 (583)\ttotal: 2m 2s\tremaining: 32m 50s\n",
      "584:\tlearn: 0.0523196\ttest: 0.0522703\tbest: 0.0522703 (584)\ttotal: 2m 2s\tremaining: 32m 49s\n",
      "585:\tlearn: 0.0523195\ttest: 0.0522703\tbest: 0.0522703 (585)\ttotal: 2m 2s\tremaining: 32m 49s\n",
      "586:\tlearn: 0.0523221\ttest: 0.0522695\tbest: 0.0522695 (586)\ttotal: 2m 2s\tremaining: 32m 48s\n",
      "587:\tlearn: 0.0523214\ttest: 0.0522690\tbest: 0.0522690 (587)\ttotal: 2m 2s\tremaining: 32m 48s\n",
      "588:\tlearn: 0.0523208\ttest: 0.0522685\tbest: 0.0522685 (588)\ttotal: 2m 3s\tremaining: 32m 47s\n",
      "589:\tlearn: 0.0523208\ttest: 0.0522685\tbest: 0.0522685 (588)\ttotal: 2m 3s\tremaining: 32m 47s\n",
      "590:\tlearn: 0.0523203\ttest: 0.0522674\tbest: 0.0522674 (590)\ttotal: 2m 3s\tremaining: 32m 46s\n",
      "591:\tlearn: 0.0523203\ttest: 0.0522674\tbest: 0.0522674 (590)\ttotal: 2m 3s\tremaining: 32m 45s\n",
      "592:\tlearn: 0.0523175\ttest: 0.0522649\tbest: 0.0522649 (592)\ttotal: 2m 3s\tremaining: 32m 45s\n",
      "593:\tlearn: 0.0523174\ttest: 0.0522645\tbest: 0.0522645 (593)\ttotal: 2m 4s\tremaining: 32m 45s\n",
      "594:\tlearn: 0.0523165\ttest: 0.0522630\tbest: 0.0522630 (594)\ttotal: 2m 4s\tremaining: 32m 45s\n",
      "595:\tlearn: 0.0523165\ttest: 0.0522628\tbest: 0.0522628 (595)\ttotal: 2m 4s\tremaining: 32m 44s\n",
      "596:\tlearn: 0.0523145\ttest: 0.0522604\tbest: 0.0522604 (596)\ttotal: 2m 4s\tremaining: 32m 44s\n",
      "597:\tlearn: 0.0523145\ttest: 0.0522604\tbest: 0.0522604 (597)\ttotal: 2m 4s\tremaining: 32m 43s\n",
      "598:\tlearn: 0.0522611\ttest: 0.0522596\tbest: 0.0522596 (598)\ttotal: 2m 5s\tremaining: 32m 43s\n",
      "599:\tlearn: 0.0522607\ttest: 0.0522590\tbest: 0.0522590 (599)\ttotal: 2m 5s\tremaining: 32m 43s\n",
      "600:\tlearn: 0.0522599\ttest: 0.0522582\tbest: 0.0522582 (600)\ttotal: 2m 5s\tremaining: 32m 43s\n",
      "601:\tlearn: 0.0522593\ttest: 0.0522574\tbest: 0.0522574 (601)\ttotal: 2m 5s\tremaining: 32m 43s\n",
      "602:\tlearn: 0.0522588\ttest: 0.0522560\tbest: 0.0522560 (602)\ttotal: 2m 5s\tremaining: 32m 43s\n",
      "603:\tlearn: 0.0522600\ttest: 0.0522550\tbest: 0.0522550 (603)\ttotal: 2m 6s\tremaining: 32m 43s\n",
      "604:\tlearn: 0.0522600\ttest: 0.0522550\tbest: 0.0522550 (604)\ttotal: 2m 6s\tremaining: 32m 42s\n",
      "605:\tlearn: 0.0522613\ttest: 0.0522546\tbest: 0.0522546 (605)\ttotal: 2m 6s\tremaining: 32m 42s\n",
      "606:\tlearn: 0.0522603\ttest: 0.0522536\tbest: 0.0522536 (606)\ttotal: 2m 6s\tremaining: 32m 42s\n",
      "607:\tlearn: 0.0522619\ttest: 0.0522533\tbest: 0.0522533 (607)\ttotal: 2m 6s\tremaining: 32m 41s\n",
      "608:\tlearn: 0.0522611\ttest: 0.0522525\tbest: 0.0522525 (608)\ttotal: 2m 7s\tremaining: 32m 41s\n",
      "609:\tlearn: 0.0522609\ttest: 0.0522523\tbest: 0.0522523 (609)\ttotal: 2m 7s\tremaining: 32m 41s\n",
      "610:\tlearn: 0.0522609\ttest: 0.0522523\tbest: 0.0522523 (609)\ttotal: 2m 7s\tremaining: 32m 40s\n",
      "611:\tlearn: 0.0522599\ttest: 0.0522520\tbest: 0.0522520 (611)\ttotal: 2m 7s\tremaining: 32m 39s\n",
      "612:\tlearn: 0.0522597\ttest: 0.0522512\tbest: 0.0522512 (612)\ttotal: 2m 7s\tremaining: 32m 39s\n",
      "613:\tlearn: 0.0522597\ttest: 0.0522512\tbest: 0.0522512 (613)\ttotal: 2m 8s\tremaining: 32m 38s\n",
      "614:\tlearn: 0.0522471\ttest: 0.0522506\tbest: 0.0522506 (614)\ttotal: 2m 8s\tremaining: 32m 38s\n",
      "615:\tlearn: 0.0522461\ttest: 0.0522496\tbest: 0.0522496 (615)\ttotal: 2m 8s\tremaining: 32m 38s\n",
      "616:\tlearn: 0.0522464\ttest: 0.0522489\tbest: 0.0522489 (616)\ttotal: 2m 8s\tremaining: 32m 38s\n",
      "617:\tlearn: 0.0522461\ttest: 0.0522484\tbest: 0.0522484 (617)\ttotal: 2m 8s\tremaining: 32m 37s\n",
      "618:\tlearn: 0.0522461\ttest: 0.0522479\tbest: 0.0522479 (618)\ttotal: 2m 9s\tremaining: 32m 37s\n",
      "619:\tlearn: 0.0522454\ttest: 0.0522474\tbest: 0.0522474 (619)\ttotal: 2m 9s\tremaining: 32m 37s\n",
      "620:\tlearn: 0.0522442\ttest: 0.0522463\tbest: 0.0522463 (620)\ttotal: 2m 9s\tremaining: 32m 37s\n",
      "621:\tlearn: 0.0522443\ttest: 0.0522456\tbest: 0.0522456 (621)\ttotal: 2m 9s\tremaining: 32m 36s\n",
      "622:\tlearn: 0.0522465\ttest: 0.0522438\tbest: 0.0522438 (622)\ttotal: 2m 9s\tremaining: 32m 36s\n",
      "623:\tlearn: 0.0522461\ttest: 0.0522432\tbest: 0.0522432 (623)\ttotal: 2m 10s\tremaining: 32m 35s\n",
      "624:\tlearn: 0.0522426\ttest: 0.0522424\tbest: 0.0522424 (624)\ttotal: 2m 10s\tremaining: 32m 34s\n",
      "625:\tlearn: 0.0522422\ttest: 0.0522421\tbest: 0.0522421 (625)\ttotal: 2m 10s\tremaining: 32m 34s\n",
      "626:\tlearn: 0.0522425\ttest: 0.0522411\tbest: 0.0522411 (626)\ttotal: 2m 10s\tremaining: 32m 33s\n",
      "627:\tlearn: 0.0522422\ttest: 0.0522407\tbest: 0.0522407 (627)\ttotal: 2m 10s\tremaining: 32m 33s\n",
      "628:\tlearn: 0.0522408\ttest: 0.0522405\tbest: 0.0522405 (628)\ttotal: 2m 11s\tremaining: 32m 32s\n",
      "629:\tlearn: 0.0522407\ttest: 0.0522396\tbest: 0.0522396 (629)\ttotal: 2m 11s\tremaining: 32m 32s\n",
      "630:\tlearn: 0.0522398\ttest: 0.0522392\tbest: 0.0522392 (630)\ttotal: 2m 11s\tremaining: 32m 32s\n",
      "631:\tlearn: 0.0522392\ttest: 0.0522385\tbest: 0.0522385 (631)\ttotal: 2m 11s\tremaining: 32m 32s\n",
      "632:\tlearn: 0.0522397\ttest: 0.0522381\tbest: 0.0522381 (632)\ttotal: 2m 11s\tremaining: 32m 31s\n",
      "633:\tlearn: 0.0522397\ttest: 0.0522381\tbest: 0.0522381 (633)\ttotal: 2m 12s\tremaining: 32m 31s\n",
      "634:\tlearn: 0.0522395\ttest: 0.0522379\tbest: 0.0522379 (634)\ttotal: 2m 12s\tremaining: 32m 31s\n",
      "635:\tlearn: 0.0522395\ttest: 0.0522379\tbest: 0.0522379 (634)\ttotal: 2m 12s\tremaining: 32m 30s\n",
      "636:\tlearn: 0.0522395\ttest: 0.0522379\tbest: 0.0522379 (634)\ttotal: 2m 12s\tremaining: 32m 29s\n",
      "637:\tlearn: 0.0522406\ttest: 0.0522349\tbest: 0.0522349 (637)\ttotal: 2m 12s\tremaining: 32m 28s\n",
      "638:\tlearn: 0.0522387\ttest: 0.0522333\tbest: 0.0522333 (638)\ttotal: 2m 12s\tremaining: 32m 28s\n",
      "639:\tlearn: 0.0522383\ttest: 0.0522329\tbest: 0.0522329 (639)\ttotal: 2m 13s\tremaining: 32m 28s\n",
      "640:\tlearn: 0.0522380\ttest: 0.0522325\tbest: 0.0522325 (640)\ttotal: 2m 13s\tremaining: 32m 27s\n",
      "641:\tlearn: 0.0522378\ttest: 0.0522314\tbest: 0.0522314 (641)\ttotal: 2m 13s\tremaining: 32m 27s\n",
      "642:\tlearn: 0.0522376\ttest: 0.0522313\tbest: 0.0522313 (642)\ttotal: 2m 13s\tremaining: 32m 27s\n",
      "643:\tlearn: 0.0522387\ttest: 0.0522309\tbest: 0.0522309 (643)\ttotal: 2m 13s\tremaining: 32m 26s\n",
      "644:\tlearn: 0.0522384\ttest: 0.0522299\tbest: 0.0522299 (644)\ttotal: 2m 14s\tremaining: 32m 26s\n",
      "645:\tlearn: 0.0522394\ttest: 0.0522291\tbest: 0.0522291 (645)\ttotal: 2m 14s\tremaining: 32m 26s\n",
      "646:\tlearn: 0.0522394\ttest: 0.0522291\tbest: 0.0522291 (645)\ttotal: 2m 14s\tremaining: 32m 25s\n",
      "647:\tlearn: 0.0522383\ttest: 0.0522284\tbest: 0.0522284 (647)\ttotal: 2m 14s\tremaining: 32m 25s\n",
      "648:\tlearn: 0.0522383\ttest: 0.0522284\tbest: 0.0522284 (647)\ttotal: 2m 14s\tremaining: 32m 24s\n",
      "649:\tlearn: 0.0522384\ttest: 0.0522283\tbest: 0.0522283 (649)\ttotal: 2m 15s\tremaining: 32m 24s\n",
      "650:\tlearn: 0.0522377\ttest: 0.0522276\tbest: 0.0522276 (650)\ttotal: 2m 15s\tremaining: 32m 23s\n",
      "651:\tlearn: 0.0522352\ttest: 0.0522268\tbest: 0.0522268 (651)\ttotal: 2m 15s\tremaining: 32m 23s\n",
      "652:\tlearn: 0.0522355\ttest: 0.0522262\tbest: 0.0522262 (652)\ttotal: 2m 15s\tremaining: 32m 22s\n",
      "653:\tlearn: 0.0522355\ttest: 0.0522262\tbest: 0.0522262 (653)\ttotal: 2m 15s\tremaining: 32m 22s\n",
      "654:\tlearn: 0.0522356\ttest: 0.0522257\tbest: 0.0522257 (654)\ttotal: 2m 16s\tremaining: 32m 22s\n",
      "655:\tlearn: 0.0522355\ttest: 0.0522257\tbest: 0.0522257 (655)\ttotal: 2m 16s\tremaining: 32m 21s\n",
      "656:\tlearn: 0.0522354\ttest: 0.0522255\tbest: 0.0522255 (656)\ttotal: 2m 16s\tremaining: 32m 21s\n",
      "657:\tlearn: 0.0522352\ttest: 0.0522255\tbest: 0.0522255 (657)\ttotal: 2m 16s\tremaining: 32m 20s\n",
      "658:\tlearn: 0.0522351\ttest: 0.0522251\tbest: 0.0522251 (658)\ttotal: 2m 16s\tremaining: 32m 19s\n",
      "659:\tlearn: 0.0522351\ttest: 0.0522251\tbest: 0.0522251 (659)\ttotal: 2m 17s\tremaining: 32m 19s\n",
      "660:\tlearn: 0.0522339\ttest: 0.0522245\tbest: 0.0522245 (660)\ttotal: 2m 17s\tremaining: 32m 19s\n",
      "661:\tlearn: 0.0522327\ttest: 0.0522239\tbest: 0.0522239 (661)\ttotal: 2m 17s\tremaining: 32m 18s\n",
      "662:\tlearn: 0.0522346\ttest: 0.0522231\tbest: 0.0522231 (662)\ttotal: 2m 17s\tremaining: 32m 18s\n",
      "663:\tlearn: 0.0522343\ttest: 0.0522225\tbest: 0.0522225 (663)\ttotal: 2m 17s\tremaining: 32m 17s\n",
      "664:\tlearn: 0.0522344\ttest: 0.0522225\tbest: 0.0522225 (664)\ttotal: 2m 18s\tremaining: 32m 17s\n",
      "665:\tlearn: 0.0522334\ttest: 0.0522222\tbest: 0.0522222 (665)\ttotal: 2m 18s\tremaining: 32m 16s\n",
      "666:\tlearn: 0.0522328\ttest: 0.0522217\tbest: 0.0522217 (666)\ttotal: 2m 18s\tremaining: 32m 16s\n",
      "667:\tlearn: 0.0522328\ttest: 0.0522216\tbest: 0.0522216 (667)\ttotal: 2m 18s\tremaining: 32m 15s\n",
      "668:\tlearn: 0.0522316\ttest: 0.0522211\tbest: 0.0522211 (668)\ttotal: 2m 18s\tremaining: 32m 15s\n",
      "669:\tlearn: 0.0522307\ttest: 0.0522200\tbest: 0.0522200 (669)\ttotal: 2m 18s\tremaining: 32m 15s\n",
      "670:\tlearn: 0.0522298\ttest: 0.0522191\tbest: 0.0522191 (670)\ttotal: 2m 19s\tremaining: 32m 15s\n",
      "671:\tlearn: 0.0522299\ttest: 0.0522191\tbest: 0.0522191 (671)\ttotal: 2m 19s\tremaining: 32m 14s\n",
      "672:\tlearn: 0.0522294\ttest: 0.0522184\tbest: 0.0522184 (672)\ttotal: 2m 19s\tremaining: 32m 13s\n",
      "673:\tlearn: 0.0522261\ttest: 0.0522154\tbest: 0.0522154 (673)\ttotal: 2m 19s\tremaining: 32m 13s\n",
      "674:\tlearn: 0.0522261\ttest: 0.0522152\tbest: 0.0522152 (674)\ttotal: 2m 19s\tremaining: 32m 12s\n",
      "675:\tlearn: 0.0522256\ttest: 0.0522147\tbest: 0.0522147 (675)\ttotal: 2m 20s\tremaining: 32m 12s\n",
      "676:\tlearn: 0.0522258\ttest: 0.0522142\tbest: 0.0522142 (676)\ttotal: 2m 20s\tremaining: 32m 12s\n",
      "677:\tlearn: 0.0522253\ttest: 0.0522135\tbest: 0.0522135 (677)\ttotal: 2m 20s\tremaining: 32m 12s\n",
      "678:\tlearn: 0.0522248\ttest: 0.0522131\tbest: 0.0522131 (678)\ttotal: 2m 20s\tremaining: 32m 11s\n",
      "679:\tlearn: 0.0522241\ttest: 0.0522125\tbest: 0.0522125 (679)\ttotal: 2m 20s\tremaining: 32m 10s\n",
      "680:\tlearn: 0.0522245\ttest: 0.0522122\tbest: 0.0522122 (680)\ttotal: 2m 21s\tremaining: 32m 9s\n",
      "681:\tlearn: 0.0522244\ttest: 0.0522120\tbest: 0.0522120 (681)\ttotal: 2m 21s\tremaining: 32m 9s\n",
      "682:\tlearn: 0.0522241\ttest: 0.0522117\tbest: 0.0522117 (682)\ttotal: 2m 21s\tremaining: 32m 9s\n",
      "683:\tlearn: 0.0522235\ttest: 0.0522112\tbest: 0.0522112 (683)\ttotal: 2m 21s\tremaining: 32m 8s\n",
      "684:\tlearn: 0.0522229\ttest: 0.0522109\tbest: 0.0522109 (684)\ttotal: 2m 21s\tremaining: 32m 8s\n",
      "685:\tlearn: 0.0522227\ttest: 0.0522107\tbest: 0.0522107 (685)\ttotal: 2m 22s\tremaining: 32m 8s\n",
      "686:\tlearn: 0.0522225\ttest: 0.0522103\tbest: 0.0522103 (686)\ttotal: 2m 22s\tremaining: 32m 7s\n",
      "687:\tlearn: 0.0522219\ttest: 0.0522094\tbest: 0.0522094 (687)\ttotal: 2m 22s\tremaining: 32m 7s\n",
      "688:\tlearn: 0.0522209\ttest: 0.0522070\tbest: 0.0522070 (688)\ttotal: 2m 22s\tremaining: 32m 7s\n",
      "689:\tlearn: 0.0522227\ttest: 0.0522067\tbest: 0.0522067 (689)\ttotal: 2m 22s\tremaining: 32m 7s\n",
      "690:\tlearn: 0.0522218\ttest: 0.0522056\tbest: 0.0522056 (690)\ttotal: 2m 23s\tremaining: 32m 7s\n",
      "691:\tlearn: 0.0522217\ttest: 0.0522056\tbest: 0.0522056 (691)\ttotal: 2m 23s\tremaining: 32m 6s\n",
      "692:\tlearn: 0.0522214\ttest: 0.0522053\tbest: 0.0522053 (692)\ttotal: 2m 23s\tremaining: 32m 6s\n",
      "693:\tlearn: 0.0522210\ttest: 0.0522047\tbest: 0.0522047 (693)\ttotal: 2m 23s\tremaining: 32m 5s\n",
      "694:\tlearn: 0.0522224\ttest: 0.0522043\tbest: 0.0522043 (694)\ttotal: 2m 23s\tremaining: 32m 5s\n",
      "695:\tlearn: 0.0522223\ttest: 0.0522043\tbest: 0.0522043 (695)\ttotal: 2m 24s\tremaining: 32m 5s\n",
      "696:\tlearn: 0.0522213\ttest: 0.0522034\tbest: 0.0522034 (696)\ttotal: 2m 24s\tremaining: 32m 4s\n",
      "697:\tlearn: 0.0522214\ttest: 0.0522034\tbest: 0.0522034 (697)\ttotal: 2m 24s\tremaining: 32m 4s\n",
      "698:\tlearn: 0.0522212\ttest: 0.0522034\tbest: 0.0522034 (698)\ttotal: 2m 24s\tremaining: 32m 4s\n",
      "699:\tlearn: 0.0522210\ttest: 0.0522032\tbest: 0.0522032 (699)\ttotal: 2m 24s\tremaining: 32m 3s\n",
      "700:\tlearn: 0.0522207\ttest: 0.0522026\tbest: 0.0522026 (700)\ttotal: 2m 25s\tremaining: 32m 3s\n",
      "701:\tlearn: 0.0522206\ttest: 0.0522024\tbest: 0.0522024 (701)\ttotal: 2m 25s\tremaining: 32m 3s\n",
      "702:\tlearn: 0.0522206\ttest: 0.0522024\tbest: 0.0522024 (702)\ttotal: 2m 25s\tremaining: 32m 2s\n",
      "703:\tlearn: 0.0522198\ttest: 0.0522020\tbest: 0.0522020 (703)\ttotal: 2m 25s\tremaining: 32m 2s\n",
      "704:\tlearn: 0.0522194\ttest: 0.0522015\tbest: 0.0522015 (704)\ttotal: 2m 25s\tremaining: 32m 1s\n",
      "705:\tlearn: 0.0522197\ttest: 0.0522012\tbest: 0.0522012 (705)\ttotal: 2m 25s\tremaining: 32m 1s\n",
      "706:\tlearn: 0.0522185\ttest: 0.0522005\tbest: 0.0522005 (706)\ttotal: 2m 26s\tremaining: 32m 1s\n",
      "707:\tlearn: 0.0522183\ttest: 0.0521997\tbest: 0.0521997 (707)\ttotal: 2m 26s\tremaining: 32m 1s\n",
      "708:\tlearn: 0.0522182\ttest: 0.0521994\tbest: 0.0521994 (708)\ttotal: 2m 26s\tremaining: 32m\n",
      "709:\tlearn: 0.0522168\ttest: 0.0521983\tbest: 0.0521983 (709)\ttotal: 2m 26s\tremaining: 32m\n",
      "710:\tlearn: 0.0522167\ttest: 0.0521981\tbest: 0.0521981 (710)\ttotal: 2m 26s\tremaining: 32m\n",
      "711:\tlearn: 0.0522169\ttest: 0.0521973\tbest: 0.0521973 (711)\ttotal: 2m 27s\tremaining: 31m 59s\n",
      "712:\tlearn: 0.0522160\ttest: 0.0521969\tbest: 0.0521969 (712)\ttotal: 2m 27s\tremaining: 31m 59s\n",
      "713:\tlearn: 0.0522159\ttest: 0.0521969\tbest: 0.0521969 (713)\ttotal: 2m 27s\tremaining: 31m 58s\n",
      "714:\tlearn: 0.0522159\ttest: 0.0521969\tbest: 0.0521969 (714)\ttotal: 2m 27s\tremaining: 31m 57s\n",
      "715:\tlearn: 0.0522158\ttest: 0.0521967\tbest: 0.0521967 (715)\ttotal: 2m 27s\tremaining: 31m 57s\n",
      "716:\tlearn: 0.0522153\ttest: 0.0521962\tbest: 0.0521962 (716)\ttotal: 2m 28s\tremaining: 31m 57s\n",
      "717:\tlearn: 0.0522136\ttest: 0.0521945\tbest: 0.0521945 (717)\ttotal: 2m 28s\tremaining: 31m 57s\n",
      "718:\tlearn: 0.0522137\ttest: 0.0521945\tbest: 0.0521945 (718)\ttotal: 2m 28s\tremaining: 31m 56s\n",
      "719:\tlearn: 0.0522131\ttest: 0.0521940\tbest: 0.0521940 (719)\ttotal: 2m 28s\tremaining: 31m 55s\n",
      "720:\tlearn: 0.0522131\ttest: 0.0521940\tbest: 0.0521940 (720)\ttotal: 2m 28s\tremaining: 31m 55s\n",
      "721:\tlearn: 0.0522127\ttest: 0.0521936\tbest: 0.0521936 (721)\ttotal: 2m 29s\tremaining: 31m 55s\n",
      "722:\tlearn: 0.0522127\ttest: 0.0521936\tbest: 0.0521936 (722)\ttotal: 2m 29s\tremaining: 31m 54s\n",
      "723:\tlearn: 0.0522141\ttest: 0.0521933\tbest: 0.0521933 (723)\ttotal: 2m 29s\tremaining: 31m 53s\n",
      "724:\tlearn: 0.0522140\ttest: 0.0521931\tbest: 0.0521931 (724)\ttotal: 2m 29s\tremaining: 31m 53s\n",
      "725:\tlearn: 0.0522140\ttest: 0.0521931\tbest: 0.0521931 (725)\ttotal: 2m 29s\tremaining: 31m 53s\n",
      "726:\tlearn: 0.0522138\ttest: 0.0521923\tbest: 0.0521923 (726)\ttotal: 2m 29s\tremaining: 31m 52s\n",
      "727:\tlearn: 0.0522135\ttest: 0.0521921\tbest: 0.0521921 (727)\ttotal: 2m 30s\tremaining: 31m 52s\n",
      "728:\tlearn: 0.0522135\ttest: 0.0521921\tbest: 0.0521921 (728)\ttotal: 2m 30s\tremaining: 31m 51s\n",
      "729:\tlearn: 0.0522101\ttest: 0.0521917\tbest: 0.0521917 (729)\ttotal: 2m 30s\tremaining: 31m 51s\n",
      "730:\tlearn: 0.0522101\ttest: 0.0521917\tbest: 0.0521917 (730)\ttotal: 2m 30s\tremaining: 31m 51s\n",
      "731:\tlearn: 0.0522101\ttest: 0.0521917\tbest: 0.0521917 (731)\ttotal: 2m 30s\tremaining: 31m 51s\n",
      "732:\tlearn: 0.0522093\ttest: 0.0521910\tbest: 0.0521910 (732)\ttotal: 2m 31s\tremaining: 31m 50s\n",
      "733:\tlearn: 0.0522089\ttest: 0.0521907\tbest: 0.0521907 (733)\ttotal: 2m 31s\tremaining: 31m 50s\n",
      "734:\tlearn: 0.0522089\ttest: 0.0521907\tbest: 0.0521907 (734)\ttotal: 2m 31s\tremaining: 31m 49s\n",
      "735:\tlearn: 0.0522112\ttest: 0.0521901\tbest: 0.0521901 (735)\ttotal: 2m 31s\tremaining: 31m 49s\n",
      "736:\tlearn: 0.0522097\ttest: 0.0521898\tbest: 0.0521898 (736)\ttotal: 2m 31s\tremaining: 31m 49s\n",
      "737:\tlearn: 0.0522097\ttest: 0.0521898\tbest: 0.0521898 (737)\ttotal: 2m 32s\tremaining: 31m 48s\n",
      "738:\tlearn: 0.0522097\ttest: 0.0521898\tbest: 0.0521898 (738)\ttotal: 2m 32s\tremaining: 31m 48s\n",
      "739:\tlearn: 0.0522095\ttest: 0.0521898\tbest: 0.0521898 (739)\ttotal: 2m 32s\tremaining: 31m 47s\n",
      "740:\tlearn: 0.0522095\ttest: 0.0521898\tbest: 0.0521898 (740)\ttotal: 2m 32s\tremaining: 31m 47s\n",
      "741:\tlearn: 0.0522093\ttest: 0.0521897\tbest: 0.0521897 (741)\ttotal: 2m 32s\tremaining: 31m 46s\n",
      "742:\tlearn: 0.0522101\ttest: 0.0521894\tbest: 0.0521894 (742)\ttotal: 2m 32s\tremaining: 31m 46s\n",
      "743:\tlearn: 0.0522101\ttest: 0.0521894\tbest: 0.0521894 (743)\ttotal: 2m 33s\tremaining: 31m 45s\n",
      "744:\tlearn: 0.0522100\ttest: 0.0521894\tbest: 0.0521894 (744)\ttotal: 2m 33s\tremaining: 31m 44s\n",
      "745:\tlearn: 0.0522082\ttest: 0.0521894\tbest: 0.0521894 (745)\ttotal: 2m 33s\tremaining: 31m 43s\n",
      "746:\tlearn: 0.0522091\ttest: 0.0521893\tbest: 0.0521893 (746)\ttotal: 2m 33s\tremaining: 31m 43s\n",
      "747:\tlearn: 0.0522086\ttest: 0.0521893\tbest: 0.0521893 (747)\ttotal: 2m 33s\tremaining: 31m 42s\n",
      "748:\tlearn: 0.0522085\ttest: 0.0521887\tbest: 0.0521887 (748)\ttotal: 2m 34s\tremaining: 31m 42s\n",
      "749:\tlearn: 0.0522085\ttest: 0.0521887\tbest: 0.0521887 (749)\ttotal: 2m 34s\tremaining: 31m 41s\n",
      "750:\tlearn: 0.0522074\ttest: 0.0521879\tbest: 0.0521879 (750)\ttotal: 2m 34s\tremaining: 31m 41s\n",
      "751:\tlearn: 0.0522072\ttest: 0.0521877\tbest: 0.0521877 (751)\ttotal: 2m 34s\tremaining: 31m 40s\n",
      "752:\tlearn: 0.0522072\ttest: 0.0521877\tbest: 0.0521877 (752)\ttotal: 2m 34s\tremaining: 31m 40s\n",
      "753:\tlearn: 0.0522066\ttest: 0.0521873\tbest: 0.0521873 (753)\ttotal: 2m 34s\tremaining: 31m 39s\n",
      "754:\tlearn: 0.0522066\ttest: 0.0521873\tbest: 0.0521873 (754)\ttotal: 2m 35s\tremaining: 31m 39s\n",
      "755:\tlearn: 0.0522066\ttest: 0.0521873\tbest: 0.0521873 (755)\ttotal: 2m 35s\tremaining: 31m 38s\n",
      "756:\tlearn: 0.0522062\ttest: 0.0521869\tbest: 0.0521869 (756)\ttotal: 2m 35s\tremaining: 31m 38s\n",
      "757:\tlearn: 0.0522062\ttest: 0.0521869\tbest: 0.0521869 (757)\ttotal: 2m 35s\tremaining: 31m 37s\n",
      "758:\tlearn: 0.0522062\ttest: 0.0521868\tbest: 0.0521868 (758)\ttotal: 2m 35s\tremaining: 31m 37s\n",
      "759:\tlearn: 0.0522062\ttest: 0.0521868\tbest: 0.0521868 (759)\ttotal: 2m 36s\tremaining: 31m 36s\n",
      "760:\tlearn: 0.0522058\ttest: 0.0521863\tbest: 0.0521863 (760)\ttotal: 2m 36s\tremaining: 31m 36s\n",
      "761:\tlearn: 0.0522056\ttest: 0.0521862\tbest: 0.0521862 (761)\ttotal: 2m 36s\tremaining: 31m 36s\n",
      "762:\tlearn: 0.0522079\ttest: 0.0521856\tbest: 0.0521856 (762)\ttotal: 2m 36s\tremaining: 31m 35s\n",
      "763:\tlearn: 0.0522069\ttest: 0.0521849\tbest: 0.0521849 (763)\ttotal: 2m 36s\tremaining: 31m 35s\n",
      "764:\tlearn: 0.0522071\ttest: 0.0521849\tbest: 0.0521849 (764)\ttotal: 2m 36s\tremaining: 31m 34s\n",
      "765:\tlearn: 0.0522061\ttest: 0.0521849\tbest: 0.0521849 (765)\ttotal: 2m 37s\tremaining: 31m 34s\n",
      "766:\tlearn: 0.0522058\ttest: 0.0521846\tbest: 0.0521846 (766)\ttotal: 2m 37s\tremaining: 31m 34s\n",
      "767:\tlearn: 0.0522058\ttest: 0.0521846\tbest: 0.0521846 (766)\ttotal: 2m 37s\tremaining: 31m 33s\n",
      "768:\tlearn: 0.0522058\ttest: 0.0521846\tbest: 0.0521846 (766)\ttotal: 2m 37s\tremaining: 31m 33s\n",
      "769:\tlearn: 0.0522058\ttest: 0.0521846\tbest: 0.0521846 (766)\ttotal: 2m 37s\tremaining: 31m 32s\n",
      "770:\tlearn: 0.0522058\ttest: 0.0521846\tbest: 0.0521846 (766)\ttotal: 2m 38s\tremaining: 31m 31s\n",
      "771:\tlearn: 0.0522058\ttest: 0.0521846\tbest: 0.0521846 (766)\ttotal: 2m 38s\tremaining: 31m 31s\n",
      "772:\tlearn: 0.0522058\ttest: 0.0521846\tbest: 0.0521846 (766)\ttotal: 2m 38s\tremaining: 31m 30s\n",
      "773:\tlearn: 0.0522058\ttest: 0.0521846\tbest: 0.0521846 (766)\ttotal: 2m 38s\tremaining: 31m 29s\n",
      "774:\tlearn: 0.0522058\ttest: 0.0521846\tbest: 0.0521846 (766)\ttotal: 2m 38s\tremaining: 31m 29s\n",
      "775:\tlearn: 0.0522058\ttest: 0.0521846\tbest: 0.0521846 (766)\ttotal: 2m 38s\tremaining: 31m 28s\n",
      "776:\tlearn: 0.0522058\ttest: 0.0521846\tbest: 0.0521846 (766)\ttotal: 2m 39s\tremaining: 31m 27s\n",
      "777:\tlearn: 0.0522059\ttest: 0.0521846\tbest: 0.0521846 (777)\ttotal: 2m 39s\tremaining: 31m 27s\n",
      "778:\tlearn: 0.0522058\ttest: 0.0521846\tbest: 0.0521846 (778)\ttotal: 2m 39s\tremaining: 31m 26s\n",
      "779:\tlearn: 0.0522058\ttest: 0.0521846\tbest: 0.0521846 (778)\ttotal: 2m 39s\tremaining: 31m 25s\n",
      "780:\tlearn: 0.0522058\ttest: 0.0521846\tbest: 0.0521846 (778)\ttotal: 2m 39s\tremaining: 31m 25s\n",
      "781:\tlearn: 0.0522058\ttest: 0.0521846\tbest: 0.0521846 (778)\ttotal: 2m 39s\tremaining: 31m 24s\n",
      "782:\tlearn: 0.0522058\ttest: 0.0521846\tbest: 0.0521846 (778)\ttotal: 2m 40s\tremaining: 31m 23s\n",
      "783:\tlearn: 0.0522068\ttest: 0.0521843\tbest: 0.0521843 (783)\ttotal: 2m 40s\tremaining: 31m 23s\n",
      "784:\tlearn: 0.0522072\ttest: 0.0521841\tbest: 0.0521841 (784)\ttotal: 2m 40s\tremaining: 31m 23s\n",
      "785:\tlearn: 0.0522070\ttest: 0.0521841\tbest: 0.0521841 (785)\ttotal: 2m 40s\tremaining: 31m 22s\n",
      "786:\tlearn: 0.0522070\ttest: 0.0521841\tbest: 0.0521841 (785)\ttotal: 2m 40s\tremaining: 31m 22s\n",
      "787:\tlearn: 0.0522078\ttest: 0.0521841\tbest: 0.0521841 (787)\ttotal: 2m 40s\tremaining: 31m 21s\n",
      "788:\tlearn: 0.0522070\ttest: 0.0521841\tbest: 0.0521841 (788)\ttotal: 2m 41s\tremaining: 31m 21s\n",
      "789:\tlearn: 0.0522072\ttest: 0.0521841\tbest: 0.0521841 (789)\ttotal: 2m 41s\tremaining: 31m 20s\n",
      "790:\tlearn: 0.0522072\ttest: 0.0521841\tbest: 0.0521841 (790)\ttotal: 2m 41s\tremaining: 31m 19s\n",
      "791:\tlearn: 0.0522072\ttest: 0.0521841\tbest: 0.0521841 (791)\ttotal: 2m 41s\tremaining: 31m 19s\n",
      "792:\tlearn: 0.0522072\ttest: 0.0521841\tbest: 0.0521841 (792)\ttotal: 2m 41s\tremaining: 31m 18s\n",
      "793:\tlearn: 0.0522072\ttest: 0.0521841\tbest: 0.0521841 (792)\ttotal: 2m 41s\tremaining: 31m 18s\n",
      "794:\tlearn: 0.0522072\ttest: 0.0521841\tbest: 0.0521841 (792)\ttotal: 2m 42s\tremaining: 31m 17s\n",
      "795:\tlearn: 0.0522072\ttest: 0.0521841\tbest: 0.0521841 (792)\ttotal: 2m 42s\tremaining: 31m 16s\n",
      "796:\tlearn: 0.0522072\ttest: 0.0521841\tbest: 0.0521841 (792)\ttotal: 2m 42s\tremaining: 31m 15s\n",
      "797:\tlearn: 0.0522072\ttest: 0.0521841\tbest: 0.0521841 (792)\ttotal: 2m 42s\tremaining: 31m 15s\n",
      "798:\tlearn: 0.0522072\ttest: 0.0521841\tbest: 0.0521841 (792)\ttotal: 2m 42s\tremaining: 31m 14s\n",
      "799:\tlearn: 0.0522072\ttest: 0.0521841\tbest: 0.0521841 (792)\ttotal: 2m 42s\tremaining: 31m 13s\n",
      "800:\tlearn: 0.0522072\ttest: 0.0521841\tbest: 0.0521841 (792)\ttotal: 2m 43s\tremaining: 31m 13s\n",
      "801:\tlearn: 0.0522072\ttest: 0.0521841\tbest: 0.0521841 (792)\ttotal: 2m 43s\tremaining: 31m 12s\n",
      "802:\tlearn: 0.0522072\ttest: 0.0521841\tbest: 0.0521841 (792)\ttotal: 2m 43s\tremaining: 31m 12s\n",
      "803:\tlearn: 0.0522072\ttest: 0.0521841\tbest: 0.0521841 (792)\ttotal: 2m 43s\tremaining: 31m 11s\n",
      "804:\tlearn: 0.0522072\ttest: 0.0521841\tbest: 0.0521841 (792)\ttotal: 2m 43s\tremaining: 31m 10s\n",
      "805:\tlearn: 0.0522072\ttest: 0.0521841\tbest: 0.0521841 (792)\ttotal: 2m 43s\tremaining: 31m 10s\n",
      "806:\tlearn: 0.0522072\ttest: 0.0521841\tbest: 0.0521841 (792)\ttotal: 2m 44s\tremaining: 31m 9s\n",
      "807:\tlearn: 0.0522072\ttest: 0.0521841\tbest: 0.0521841 (792)\ttotal: 2m 44s\tremaining: 31m 9s\n",
      "808:\tlearn: 0.0522072\ttest: 0.0521841\tbest: 0.0521841 (792)\ttotal: 2m 44s\tremaining: 31m 8s\n",
      "809:\tlearn: 0.0522072\ttest: 0.0521841\tbest: 0.0521841 (792)\ttotal: 2m 44s\tremaining: 31m 8s\n",
      "810:\tlearn: 0.0522072\ttest: 0.0521841\tbest: 0.0521841 (792)\ttotal: 2m 44s\tremaining: 31m 7s\n",
      "811:\tlearn: 0.0522072\ttest: 0.0521841\tbest: 0.0521841 (792)\ttotal: 2m 44s\tremaining: 31m 6s\n",
      "812:\tlearn: 0.0522072\ttest: 0.0521841\tbest: 0.0521841 (792)\ttotal: 2m 45s\tremaining: 31m 6s\n",
      "813:\tlearn: 0.0522072\ttest: 0.0521841\tbest: 0.0521841 (792)\ttotal: 2m 45s\tremaining: 31m 5s\n",
      "814:\tlearn: 0.0522072\ttest: 0.0521841\tbest: 0.0521841 (792)\ttotal: 2m 45s\tremaining: 31m 5s\n",
      "815:\tlearn: 0.0522072\ttest: 0.0521841\tbest: 0.0521841 (792)\ttotal: 2m 45s\tremaining: 31m 4s\n",
      "816:\tlearn: 0.0522072\ttest: 0.0521841\tbest: 0.0521841 (792)\ttotal: 2m 45s\tremaining: 31m 3s\n",
      "817:\tlearn: 0.0522072\ttest: 0.0521841\tbest: 0.0521841 (792)\ttotal: 2m 45s\tremaining: 31m 3s\n",
      "818:\tlearn: 0.0522072\ttest: 0.0521841\tbest: 0.0521841 (792)\ttotal: 2m 46s\tremaining: 31m 2s\n",
      "819:\tlearn: 0.0522072\ttest: 0.0521841\tbest: 0.0521841 (792)\ttotal: 2m 46s\tremaining: 31m 1s\n",
      "820:\tlearn: 0.0522072\ttest: 0.0521841\tbest: 0.0521841 (792)\ttotal: 2m 46s\tremaining: 31m 1s\n",
      "821:\tlearn: 0.0522072\ttest: 0.0521841\tbest: 0.0521841 (792)\ttotal: 2m 46s\tremaining: 31m\n",
      "822:\tlearn: 0.0522072\ttest: 0.0521841\tbest: 0.0521841 (792)\ttotal: 2m 46s\tremaining: 31m\n",
      "823:\tlearn: 0.0522072\ttest: 0.0521841\tbest: 0.0521841 (792)\ttotal: 2m 46s\tremaining: 30m 59s\n",
      "824:\tlearn: 0.0522072\ttest: 0.0521841\tbest: 0.0521841 (792)\ttotal: 2m 47s\tremaining: 30m 58s\n",
      "825:\tlearn: 0.0522072\ttest: 0.0521841\tbest: 0.0521841 (792)\ttotal: 2m 47s\tremaining: 30m 58s\n",
      "826:\tlearn: 0.0522072\ttest: 0.0521841\tbest: 0.0521841 (792)\ttotal: 2m 47s\tremaining: 30m 57s\n",
      "827:\tlearn: 0.0522072\ttest: 0.0521841\tbest: 0.0521841 (792)\ttotal: 2m 47s\tremaining: 30m 57s\n",
      "828:\tlearn: 0.0522072\ttest: 0.0521841\tbest: 0.0521841 (792)\ttotal: 2m 47s\tremaining: 30m 56s\n",
      "829:\tlearn: 0.0522072\ttest: 0.0521841\tbest: 0.0521841 (792)\ttotal: 2m 47s\tremaining: 30m 55s\n",
      "830:\tlearn: 0.0522072\ttest: 0.0521841\tbest: 0.0521841 (792)\ttotal: 2m 48s\tremaining: 30m 55s\n",
      "831:\tlearn: 0.0522072\ttest: 0.0521841\tbest: 0.0521841 (792)\ttotal: 2m 48s\tremaining: 30m 54s\n",
      "832:\tlearn: 0.0522072\ttest: 0.0521841\tbest: 0.0521841 (792)\ttotal: 2m 48s\tremaining: 30m 53s\n",
      "833:\tlearn: 0.0522072\ttest: 0.0521841\tbest: 0.0521841 (792)\ttotal: 2m 48s\tremaining: 30m 53s\n",
      "834:\tlearn: 0.0522072\ttest: 0.0521841\tbest: 0.0521841 (792)\ttotal: 2m 48s\tremaining: 30m 52s\n",
      "835:\tlearn: 0.0522072\ttest: 0.0521841\tbest: 0.0521841 (792)\ttotal: 2m 48s\tremaining: 30m 51s\n",
      "836:\tlearn: 0.0522072\ttest: 0.0521841\tbest: 0.0521841 (792)\ttotal: 2m 49s\tremaining: 30m 51s\n",
      "837:\tlearn: 0.0522072\ttest: 0.0521841\tbest: 0.0521841 (792)\ttotal: 2m 49s\tremaining: 30m 50s\n",
      "838:\tlearn: 0.0522072\ttest: 0.0521841\tbest: 0.0521841 (792)\ttotal: 2m 49s\tremaining: 30m 50s\n",
      "839:\tlearn: 0.0522072\ttest: 0.0521841\tbest: 0.0521841 (792)\ttotal: 2m 49s\tremaining: 30m 49s\n",
      "840:\tlearn: 0.0522072\ttest: 0.0521841\tbest: 0.0521841 (792)\ttotal: 2m 49s\tremaining: 30m 49s\n",
      "841:\tlearn: 0.0522072\ttest: 0.0521841\tbest: 0.0521841 (792)\ttotal: 2m 49s\tremaining: 30m 48s\n",
      "842:\tlearn: 0.0522072\ttest: 0.0521841\tbest: 0.0521841 (792)\ttotal: 2m 50s\tremaining: 30m 48s\n",
      "843:\tlearn: 0.0522072\ttest: 0.0521841\tbest: 0.0521841 (792)\ttotal: 2m 50s\tremaining: 30m 47s\n",
      "844:\tlearn: 0.0522072\ttest: 0.0521841\tbest: 0.0521841 (792)\ttotal: 2m 50s\tremaining: 30m 46s\n",
      "845:\tlearn: 0.0522072\ttest: 0.0521841\tbest: 0.0521841 (792)\ttotal: 2m 50s\tremaining: 30m 46s\n",
      "846:\tlearn: 0.0522072\ttest: 0.0521841\tbest: 0.0521841 (792)\ttotal: 2m 50s\tremaining: 30m 45s\n",
      "847:\tlearn: 0.0522072\ttest: 0.0521841\tbest: 0.0521841 (792)\ttotal: 2m 50s\tremaining: 30m 45s\n",
      "848:\tlearn: 0.0522072\ttest: 0.0521841\tbest: 0.0521841 (792)\ttotal: 2m 51s\tremaining: 30m 44s\n",
      "849:\tlearn: 0.0522072\ttest: 0.0521841\tbest: 0.0521841 (792)\ttotal: 2m 51s\tremaining: 30m 44s\n",
      "850:\tlearn: 0.0522072\ttest: 0.0521841\tbest: 0.0521841 (792)\ttotal: 2m 51s\tremaining: 30m 43s\n",
      "851:\tlearn: 0.0522072\ttest: 0.0521841\tbest: 0.0521841 (792)\ttotal: 2m 51s\tremaining: 30m 42s\n",
      "852:\tlearn: 0.0522072\ttest: 0.0521841\tbest: 0.0521841 (792)\ttotal: 2m 51s\tremaining: 30m 42s\n",
      "853:\tlearn: 0.0522072\ttest: 0.0521841\tbest: 0.0521841 (792)\ttotal: 2m 51s\tremaining: 30m 41s\n",
      "854:\tlearn: 0.0522072\ttest: 0.0521841\tbest: 0.0521841 (792)\ttotal: 2m 52s\tremaining: 30m 41s\n",
      "855:\tlearn: 0.0522072\ttest: 0.0521841\tbest: 0.0521841 (792)\ttotal: 2m 52s\tremaining: 30m 40s\n",
      "856:\tlearn: 0.0522072\ttest: 0.0521841\tbest: 0.0521841 (792)\ttotal: 2m 52s\tremaining: 30m 40s\n",
      "857:\tlearn: 0.0522072\ttest: 0.0521841\tbest: 0.0521841 (792)\ttotal: 2m 52s\tremaining: 30m 39s\n",
      "858:\tlearn: 0.0522072\ttest: 0.0521841\tbest: 0.0521841 (792)\ttotal: 2m 52s\tremaining: 30m 38s\n",
      "859:\tlearn: 0.0522072\ttest: 0.0521841\tbest: 0.0521841 (792)\ttotal: 2m 52s\tremaining: 30m 38s\n",
      "860:\tlearn: 0.0522072\ttest: 0.0521841\tbest: 0.0521841 (792)\ttotal: 2m 53s\tremaining: 30m 37s\n",
      "861:\tlearn: 0.0522072\ttest: 0.0521841\tbest: 0.0521841 (792)\ttotal: 2m 53s\tremaining: 30m 37s\n",
      "862:\tlearn: 0.0522072\ttest: 0.0521841\tbest: 0.0521841 (792)\ttotal: 2m 53s\tremaining: 30m 36s\n",
      "863:\tlearn: 0.0522072\ttest: 0.0521841\tbest: 0.0521841 (792)\ttotal: 2m 53s\tremaining: 30m 35s\n",
      "864:\tlearn: 0.0522072\ttest: 0.0521841\tbest: 0.0521841 (792)\ttotal: 2m 53s\tremaining: 30m 35s\n",
      "865:\tlearn: 0.0522072\ttest: 0.0521841\tbest: 0.0521841 (792)\ttotal: 2m 53s\tremaining: 30m 34s\n",
      "866:\tlearn: 0.0522072\ttest: 0.0521841\tbest: 0.0521841 (792)\ttotal: 2m 54s\tremaining: 30m 34s\n",
      "867:\tlearn: 0.0522072\ttest: 0.0521841\tbest: 0.0521841 (792)\ttotal: 2m 54s\tremaining: 30m 33s\n",
      "868:\tlearn: 0.0522072\ttest: 0.0521841\tbest: 0.0521841 (792)\ttotal: 2m 54s\tremaining: 30m 33s\n",
      "869:\tlearn: 0.0522072\ttest: 0.0521841\tbest: 0.0521841 (792)\ttotal: 2m 54s\tremaining: 30m 32s\n",
      "870:\tlearn: 0.0522072\ttest: 0.0521841\tbest: 0.0521841 (792)\ttotal: 2m 54s\tremaining: 30m 32s\n",
      "871:\tlearn: 0.0522072\ttest: 0.0521841\tbest: 0.0521841 (792)\ttotal: 2m 54s\tremaining: 30m 31s\n",
      "872:\tlearn: 0.0522072\ttest: 0.0521841\tbest: 0.0521841 (792)\ttotal: 2m 55s\tremaining: 30m 30s\n",
      "873:\tlearn: 0.0522072\ttest: 0.0521841\tbest: 0.0521841 (792)\ttotal: 2m 55s\tremaining: 30m 30s\n",
      "874:\tlearn: 0.0522072\ttest: 0.0521841\tbest: 0.0521841 (792)\ttotal: 2m 55s\tremaining: 30m 29s\n",
      "875:\tlearn: 0.0522072\ttest: 0.0521841\tbest: 0.0521841 (792)\ttotal: 2m 55s\tremaining: 30m 29s\n",
      "876:\tlearn: 0.0522072\ttest: 0.0521841\tbest: 0.0521841 (792)\ttotal: 2m 55s\tremaining: 30m 28s\n",
      "877:\tlearn: 0.0522072\ttest: 0.0521841\tbest: 0.0521841 (792)\ttotal: 2m 55s\tremaining: 30m 28s\n",
      "878:\tlearn: 0.0522072\ttest: 0.0521841\tbest: 0.0521841 (792)\ttotal: 2m 56s\tremaining: 30m 27s\n",
      "879:\tlearn: 0.0522072\ttest: 0.0521841\tbest: 0.0521841 (792)\ttotal: 2m 56s\tremaining: 30m 27s\n",
      "880:\tlearn: 0.0522072\ttest: 0.0521841\tbest: 0.0521841 (792)\ttotal: 2m 56s\tremaining: 30m 26s\n",
      "881:\tlearn: 0.0522072\ttest: 0.0521841\tbest: 0.0521841 (792)\ttotal: 2m 56s\tremaining: 30m 25s\n",
      "882:\tlearn: 0.0522072\ttest: 0.0521841\tbest: 0.0521841 (792)\ttotal: 2m 56s\tremaining: 30m 25s\n",
      "883:\tlearn: 0.0522072\ttest: 0.0521841\tbest: 0.0521841 (792)\ttotal: 2m 56s\tremaining: 30m 24s\n",
      "884:\tlearn: 0.0522072\ttest: 0.0521841\tbest: 0.0521841 (792)\ttotal: 2m 57s\tremaining: 30m 24s\n",
      "885:\tlearn: 0.0522072\ttest: 0.0521841\tbest: 0.0521841 (792)\ttotal: 2m 57s\tremaining: 30m 23s\n",
      "886:\tlearn: 0.0522072\ttest: 0.0521841\tbest: 0.0521841 (792)\ttotal: 2m 57s\tremaining: 30m 23s\n",
      "887:\tlearn: 0.0522072\ttest: 0.0521841\tbest: 0.0521841 (792)\ttotal: 2m 57s\tremaining: 30m 22s\n",
      "888:\tlearn: 0.0522072\ttest: 0.0521841\tbest: 0.0521841 (792)\ttotal: 2m 57s\tremaining: 30m 22s\n",
      "889:\tlearn: 0.0522072\ttest: 0.0521841\tbest: 0.0521841 (792)\ttotal: 2m 57s\tremaining: 30m 21s\n",
      "890:\tlearn: 0.0522072\ttest: 0.0521841\tbest: 0.0521841 (792)\ttotal: 2m 58s\tremaining: 30m 20s\n",
      "891:\tlearn: 0.0522072\ttest: 0.0521841\tbest: 0.0521841 (792)\ttotal: 2m 58s\tremaining: 30m 20s\n",
      "892:\tlearn: 0.0522072\ttest: 0.0521841\tbest: 0.0521841 (792)\ttotal: 2m 58s\tremaining: 30m 19s\n",
      "893:\tlearn: 0.0522072\ttest: 0.0521841\tbest: 0.0521841 (792)\ttotal: 2m 58s\tremaining: 30m 19s\n",
      "894:\tlearn: 0.0522072\ttest: 0.0521841\tbest: 0.0521841 (792)\ttotal: 2m 58s\tremaining: 30m 19s\n",
      "895:\tlearn: 0.0522072\ttest: 0.0521841\tbest: 0.0521841 (792)\ttotal: 2m 58s\tremaining: 30m 18s\n",
      "896:\tlearn: 0.0522072\ttest: 0.0521841\tbest: 0.0521841 (792)\ttotal: 2m 59s\tremaining: 30m 18s\n",
      "897:\tlearn: 0.0522072\ttest: 0.0521841\tbest: 0.0521841 (792)\ttotal: 2m 59s\tremaining: 30m 17s\n",
      "898:\tlearn: 0.0522072\ttest: 0.0521841\tbest: 0.0521841 (792)\ttotal: 2m 59s\tremaining: 30m 16s\n",
      "899:\tlearn: 0.0522072\ttest: 0.0521841\tbest: 0.0521841 (792)\ttotal: 2m 59s\tremaining: 30m 16s\n",
      "900:\tlearn: 0.0522072\ttest: 0.0521841\tbest: 0.0521841 (792)\ttotal: 2m 59s\tremaining: 30m 15s\n",
      "901:\tlearn: 0.0522072\ttest: 0.0521841\tbest: 0.0521841 (792)\ttotal: 2m 59s\tremaining: 30m 15s\n",
      "902:\tlearn: 0.0522072\ttest: 0.0521841\tbest: 0.0521841 (792)\ttotal: 3m\tremaining: 30m 14s\n",
      "903:\tlearn: 0.0522072\ttest: 0.0521841\tbest: 0.0521841 (792)\ttotal: 3m\tremaining: 30m 14s\n",
      "904:\tlearn: 0.0522072\ttest: 0.0521841\tbest: 0.0521841 (792)\ttotal: 3m\tremaining: 30m 13s\n",
      "905:\tlearn: 0.0522072\ttest: 0.0521841\tbest: 0.0521841 (792)\ttotal: 3m\tremaining: 30m 12s\n",
      "906:\tlearn: 0.0522072\ttest: 0.0521841\tbest: 0.0521841 (792)\ttotal: 3m\tremaining: 30m 12s\n",
      "907:\tlearn: 0.0522072\ttest: 0.0521841\tbest: 0.0521841 (792)\ttotal: 3m\tremaining: 30m 11s\n",
      "908:\tlearn: 0.0522072\ttest: 0.0521841\tbest: 0.0521841 (792)\ttotal: 3m 1s\tremaining: 30m 11s\n",
      "909:\tlearn: 0.0522072\ttest: 0.0521841\tbest: 0.0521841 (792)\ttotal: 3m 1s\tremaining: 30m 10s\n",
      "910:\tlearn: 0.0522072\ttest: 0.0521841\tbest: 0.0521841 (792)\ttotal: 3m 1s\tremaining: 30m 10s\n",
      "911:\tlearn: 0.0522072\ttest: 0.0521841\tbest: 0.0521841 (792)\ttotal: 3m 1s\tremaining: 30m 9s\n",
      "912:\tlearn: 0.0522072\ttest: 0.0521841\tbest: 0.0521841 (792)\ttotal: 3m 1s\tremaining: 30m 9s\n",
      "913:\tlearn: 0.0522072\ttest: 0.0521841\tbest: 0.0521841 (792)\ttotal: 3m 1s\tremaining: 30m 8s\n",
      "914:\tlearn: 0.0522072\ttest: 0.0521841\tbest: 0.0521841 (792)\ttotal: 3m 2s\tremaining: 30m 8s\n",
      "915:\tlearn: 0.0522072\ttest: 0.0521841\tbest: 0.0521841 (792)\ttotal: 3m 2s\tremaining: 30m 8s\n",
      "916:\tlearn: 0.0522072\ttest: 0.0521841\tbest: 0.0521841 (792)\ttotal: 3m 2s\tremaining: 30m 7s\n",
      "917:\tlearn: 0.0522072\ttest: 0.0521841\tbest: 0.0521841 (792)\ttotal: 3m 2s\tremaining: 30m 6s\n",
      "918:\tlearn: 0.0522072\ttest: 0.0521841\tbest: 0.0521841 (792)\ttotal: 3m 2s\tremaining: 30m 6s\n",
      "919:\tlearn: 0.0522072\ttest: 0.0521841\tbest: 0.0521841 (792)\ttotal: 3m 2s\tremaining: 30m 5s\n",
      "920:\tlearn: 0.0522072\ttest: 0.0521841\tbest: 0.0521841 (792)\ttotal: 3m 3s\tremaining: 30m 5s\n",
      "921:\tlearn: 0.0522072\ttest: 0.0521841\tbest: 0.0521841 (792)\ttotal: 3m 3s\tremaining: 30m 4s\n",
      "922:\tlearn: 0.0522072\ttest: 0.0521841\tbest: 0.0521841 (792)\ttotal: 3m 3s\tremaining: 30m 4s\n",
      "923:\tlearn: 0.0522072\ttest: 0.0521841\tbest: 0.0521841 (792)\ttotal: 3m 3s\tremaining: 30m 3s\n",
      "924:\tlearn: 0.0522072\ttest: 0.0521841\tbest: 0.0521841 (792)\ttotal: 3m 3s\tremaining: 30m 3s\n",
      "925:\tlearn: 0.0522072\ttest: 0.0521841\tbest: 0.0521841 (792)\ttotal: 3m 3s\tremaining: 30m 2s\n",
      "926:\tlearn: 0.0522072\ttest: 0.0521841\tbest: 0.0521841 (792)\ttotal: 3m 4s\tremaining: 30m 2s\n",
      "927:\tlearn: 0.0522072\ttest: 0.0521841\tbest: 0.0521841 (792)\ttotal: 3m 4s\tremaining: 30m 1s\n",
      "928:\tlearn: 0.0522072\ttest: 0.0521841\tbest: 0.0521841 (792)\ttotal: 3m 4s\tremaining: 30m 1s\n",
      "929:\tlearn: 0.0522072\ttest: 0.0521841\tbest: 0.0521841 (792)\ttotal: 3m 4s\tremaining: 30m\n",
      "930:\tlearn: 0.0522072\ttest: 0.0521841\tbest: 0.0521841 (792)\ttotal: 3m 4s\tremaining: 30m\n",
      "931:\tlearn: 0.0522072\ttest: 0.0521841\tbest: 0.0521841 (792)\ttotal: 3m 4s\tremaining: 29m 59s\n",
      "932:\tlearn: 0.0522072\ttest: 0.0521841\tbest: 0.0521841 (792)\ttotal: 3m 5s\tremaining: 29m 59s\n",
      "933:\tlearn: 0.0522072\ttest: 0.0521841\tbest: 0.0521841 (792)\ttotal: 3m 5s\tremaining: 29m 58s\n",
      "934:\tlearn: 0.0522072\ttest: 0.0521841\tbest: 0.0521841 (792)\ttotal: 3m 5s\tremaining: 29m 58s\n",
      "935:\tlearn: 0.0522072\ttest: 0.0521841\tbest: 0.0521841 (792)\ttotal: 3m 5s\tremaining: 29m 57s\n",
      "936:\tlearn: 0.0522072\ttest: 0.0521841\tbest: 0.0521841 (792)\ttotal: 3m 5s\tremaining: 29m 57s\n",
      "937:\tlearn: 0.0522072\ttest: 0.0521841\tbest: 0.0521841 (792)\ttotal: 3m 6s\tremaining: 29m 57s\n",
      "938:\tlearn: 0.0522072\ttest: 0.0521841\tbest: 0.0521841 (792)\ttotal: 3m 6s\tremaining: 29m 56s\n",
      "939:\tlearn: 0.0522072\ttest: 0.0521841\tbest: 0.0521841 (792)\ttotal: 3m 6s\tremaining: 29m 56s\n",
      "940:\tlearn: 0.0522072\ttest: 0.0521841\tbest: 0.0521841 (792)\ttotal: 3m 6s\tremaining: 29m 55s\n",
      "941:\tlearn: 0.0522072\ttest: 0.0521841\tbest: 0.0521841 (792)\ttotal: 3m 6s\tremaining: 29m 55s\n",
      "942:\tlearn: 0.0522072\ttest: 0.0521841\tbest: 0.0521841 (792)\ttotal: 3m 6s\tremaining: 29m 54s\n",
      "943:\tlearn: 0.0522072\ttest: 0.0521841\tbest: 0.0521841 (792)\ttotal: 3m 7s\tremaining: 29m 54s\n",
      "944:\tlearn: 0.0522072\ttest: 0.0521841\tbest: 0.0521841 (792)\ttotal: 3m 7s\tremaining: 29m 53s\n",
      "945:\tlearn: 0.0522072\ttest: 0.0521841\tbest: 0.0521841 (792)\ttotal: 3m 7s\tremaining: 29m 53s\n",
      "946:\tlearn: 0.0522072\ttest: 0.0521841\tbest: 0.0521841 (792)\ttotal: 3m 7s\tremaining: 29m 52s\n",
      "947:\tlearn: 0.0522072\ttest: 0.0521841\tbest: 0.0521841 (792)\ttotal: 3m 7s\tremaining: 29m 52s\n",
      "948:\tlearn: 0.0522072\ttest: 0.0521841\tbest: 0.0521841 (792)\ttotal: 3m 7s\tremaining: 29m 51s\n",
      "949:\tlearn: 0.0522072\ttest: 0.0521841\tbest: 0.0521841 (792)\ttotal: 3m 8s\tremaining: 29m 51s\n",
      "950:\tlearn: 0.0522072\ttest: 0.0521841\tbest: 0.0521841 (792)\ttotal: 3m 8s\tremaining: 29m 50s\n",
      "951:\tlearn: 0.0522072\ttest: 0.0521841\tbest: 0.0521841 (792)\ttotal: 3m 8s\tremaining: 29m 50s\n",
      "952:\tlearn: 0.0522072\ttest: 0.0521841\tbest: 0.0521841 (792)\ttotal: 3m 8s\tremaining: 29m 49s\n",
      "953:\tlearn: 0.0522072\ttest: 0.0521841\tbest: 0.0521841 (792)\ttotal: 3m 8s\tremaining: 29m 49s\n",
      "954:\tlearn: 0.0522072\ttest: 0.0521841\tbest: 0.0521841 (792)\ttotal: 3m 8s\tremaining: 29m 48s\n",
      "955:\tlearn: 0.0522072\ttest: 0.0521841\tbest: 0.0521841 (792)\ttotal: 3m 9s\tremaining: 29m 48s\n",
      "956:\tlearn: 0.0522072\ttest: 0.0521841\tbest: 0.0521841 (792)\ttotal: 3m 9s\tremaining: 29m 47s\n",
      "957:\tlearn: 0.0522072\ttest: 0.0521841\tbest: 0.0521841 (792)\ttotal: 3m 9s\tremaining: 29m 47s\n",
      "958:\tlearn: 0.0522072\ttest: 0.0521841\tbest: 0.0521841 (792)\ttotal: 3m 9s\tremaining: 29m 46s\n",
      "959:\tlearn: 0.0522072\ttest: 0.0521841\tbest: 0.0521841 (792)\ttotal: 3m 9s\tremaining: 29m 46s\n",
      "960:\tlearn: 0.0522072\ttest: 0.0521841\tbest: 0.0521841 (792)\ttotal: 3m 9s\tremaining: 29m 45s\n",
      "961:\tlearn: 0.0522072\ttest: 0.0521841\tbest: 0.0521841 (792)\ttotal: 3m 9s\tremaining: 29m 45s\n",
      "962:\tlearn: 0.0522072\ttest: 0.0521841\tbest: 0.0521841 (792)\ttotal: 3m 10s\tremaining: 29m 44s\n",
      "963:\tlearn: 0.0522072\ttest: 0.0521841\tbest: 0.0521841 (792)\ttotal: 3m 10s\tremaining: 29m 44s\n",
      "964:\tlearn: 0.0522072\ttest: 0.0521841\tbest: 0.0521841 (792)\ttotal: 3m 10s\tremaining: 29m 43s\n",
      "965:\tlearn: 0.0522072\ttest: 0.0521841\tbest: 0.0521841 (792)\ttotal: 3m 10s\tremaining: 29m 42s\n",
      "966:\tlearn: 0.0522072\ttest: 0.0521841\tbest: 0.0521841 (792)\ttotal: 3m 10s\tremaining: 29m 42s\n",
      "967:\tlearn: 0.0522072\ttest: 0.0521841\tbest: 0.0521841 (792)\ttotal: 3m 10s\tremaining: 29m 41s\n",
      "968:\tlearn: 0.0522072\ttest: 0.0521841\tbest: 0.0521841 (792)\ttotal: 3m 11s\tremaining: 29m 41s\n",
      "969:\tlearn: 0.0522072\ttest: 0.0521841\tbest: 0.0521841 (792)\ttotal: 3m 11s\tremaining: 29m 40s\n",
      "970:\tlearn: 0.0522072\ttest: 0.0521841\tbest: 0.0521841 (792)\ttotal: 3m 11s\tremaining: 29m 40s\n",
      "971:\tlearn: 0.0522072\ttest: 0.0521841\tbest: 0.0521841 (792)\ttotal: 3m 11s\tremaining: 29m 39s\n",
      "972:\tlearn: 0.0522072\ttest: 0.0521841\tbest: 0.0521841 (792)\ttotal: 3m 11s\tremaining: 29m 39s\n",
      "973:\tlearn: 0.0522072\ttest: 0.0521841\tbest: 0.0521841 (792)\ttotal: 3m 11s\tremaining: 29m 38s\n",
      "974:\tlearn: 0.0522072\ttest: 0.0521841\tbest: 0.0521841 (792)\ttotal: 3m 12s\tremaining: 29m 38s\n",
      "975:\tlearn: 0.0522072\ttest: 0.0521841\tbest: 0.0521841 (792)\ttotal: 3m 12s\tremaining: 29m 37s\n",
      "976:\tlearn: 0.0522072\ttest: 0.0521841\tbest: 0.0521841 (792)\ttotal: 3m 12s\tremaining: 29m 37s\n",
      "977:\tlearn: 0.0522072\ttest: 0.0521841\tbest: 0.0521841 (792)\ttotal: 3m 12s\tremaining: 29m 36s\n",
      "978:\tlearn: 0.0522072\ttest: 0.0521841\tbest: 0.0521841 (792)\ttotal: 3m 12s\tremaining: 29m 36s\n",
      "979:\tlearn: 0.0522072\ttest: 0.0521841\tbest: 0.0521841 (792)\ttotal: 3m 12s\tremaining: 29m 35s\n",
      "980:\tlearn: 0.0522072\ttest: 0.0521841\tbest: 0.0521841 (792)\ttotal: 3m 13s\tremaining: 29m 35s\n",
      "981:\tlearn: 0.0522072\ttest: 0.0521841\tbest: 0.0521841 (792)\ttotal: 3m 13s\tremaining: 29m 34s\n",
      "982:\tlearn: 0.0522072\ttest: 0.0521841\tbest: 0.0521841 (792)\ttotal: 3m 13s\tremaining: 29m 34s\n",
      "983:\tlearn: 0.0522072\ttest: 0.0521841\tbest: 0.0521841 (792)\ttotal: 3m 13s\tremaining: 29m 33s\n",
      "984:\tlearn: 0.0522072\ttest: 0.0521841\tbest: 0.0521841 (792)\ttotal: 3m 13s\tremaining: 29m 33s\n",
      "985:\tlearn: 0.0522072\ttest: 0.0521841\tbest: 0.0521841 (792)\ttotal: 3m 13s\tremaining: 29m 33s\n",
      "986:\tlearn: 0.0522072\ttest: 0.0521841\tbest: 0.0521841 (792)\ttotal: 3m 14s\tremaining: 29m 32s\n",
      "987:\tlearn: 0.0522072\ttest: 0.0521841\tbest: 0.0521841 (792)\ttotal: 3m 14s\tremaining: 29m 32s\n",
      "988:\tlearn: 0.0522072\ttest: 0.0521841\tbest: 0.0521841 (792)\ttotal: 3m 14s\tremaining: 29m 31s\n",
      "989:\tlearn: 0.0522072\ttest: 0.0521841\tbest: 0.0521841 (792)\ttotal: 3m 14s\tremaining: 29m 31s\n",
      "990:\tlearn: 0.0522072\ttest: 0.0521841\tbest: 0.0521841 (792)\ttotal: 3m 14s\tremaining: 29m 30s\n",
      "991:\tlearn: 0.0522072\ttest: 0.0521841\tbest: 0.0521841 (792)\ttotal: 3m 14s\tremaining: 29m 30s\n",
      "992:\tlearn: 0.0522072\ttest: 0.0521841\tbest: 0.0521841 (792)\ttotal: 3m 15s\tremaining: 29m 29s\n",
      "993:\tlearn: 0.0522072\ttest: 0.0521841\tbest: 0.0521841 (792)\ttotal: 3m 15s\tremaining: 29m 29s\n",
      "994:\tlearn: 0.0522072\ttest: 0.0521841\tbest: 0.0521841 (792)\ttotal: 3m 15s\tremaining: 29m 28s\n",
      "995:\tlearn: 0.0522072\ttest: 0.0521841\tbest: 0.0521841 (792)\ttotal: 3m 15s\tremaining: 29m 28s\n",
      "996:\tlearn: 0.0522072\ttest: 0.0521841\tbest: 0.0521841 (792)\ttotal: 3m 15s\tremaining: 29m 27s\n",
      "997:\tlearn: 0.0522072\ttest: 0.0521841\tbest: 0.0521841 (792)\ttotal: 3m 15s\tremaining: 29m 27s\n",
      "998:\tlearn: 0.0522072\ttest: 0.0521841\tbest: 0.0521841 (792)\ttotal: 3m 16s\tremaining: 29m 26s\n",
      "999:\tlearn: 0.0522072\ttest: 0.0521841\tbest: 0.0521841 (792)\ttotal: 3m 16s\tremaining: 29m 26s\n",
      "1000:\tlearn: 0.0522072\ttest: 0.0521841\tbest: 0.0521841 (792)\ttotal: 3m 16s\tremaining: 29m 25s\n",
      "1001:\tlearn: 0.0522072\ttest: 0.0521841\tbest: 0.0521841 (792)\ttotal: 3m 16s\tremaining: 29m 25s\n",
      "1002:\tlearn: 0.0522072\ttest: 0.0521841\tbest: 0.0521841 (792)\ttotal: 3m 16s\tremaining: 29m 24s\n",
      "1003:\tlearn: 0.0522072\ttest: 0.0521841\tbest: 0.0521841 (792)\ttotal: 3m 16s\tremaining: 29m 24s\n",
      "1004:\tlearn: 0.0522072\ttest: 0.0521841\tbest: 0.0521841 (792)\ttotal: 3m 17s\tremaining: 29m 23s\n",
      "1005:\tlearn: 0.0522072\ttest: 0.0521841\tbest: 0.0521841 (792)\ttotal: 3m 17s\tremaining: 29m 23s\n",
      "1006:\tlearn: 0.0522072\ttest: 0.0521841\tbest: 0.0521841 (792)\ttotal: 3m 17s\tremaining: 29m 22s\n",
      "1007:\tlearn: 0.0522072\ttest: 0.0521841\tbest: 0.0521841 (792)\ttotal: 3m 17s\tremaining: 29m 22s\n",
      "1008:\tlearn: 0.0522072\ttest: 0.0521841\tbest: 0.0521841 (792)\ttotal: 3m 17s\tremaining: 29m 22s\n",
      "1009:\tlearn: 0.0522072\ttest: 0.0521841\tbest: 0.0521841 (792)\ttotal: 3m 17s\tremaining: 29m 21s\n",
      "1010:\tlearn: 0.0522072\ttest: 0.0521841\tbest: 0.0521841 (792)\ttotal: 3m 18s\tremaining: 29m 21s\n",
      "1011:\tlearn: 0.0522072\ttest: 0.0521841\tbest: 0.0521841 (792)\ttotal: 3m 18s\tremaining: 29m 20s\n",
      "1012:\tlearn: 0.0522072\ttest: 0.0521841\tbest: 0.0521841 (792)\ttotal: 3m 18s\tremaining: 29m 20s\n",
      "1013:\tlearn: 0.0522072\ttest: 0.0521841\tbest: 0.0521841 (792)\ttotal: 3m 18s\tremaining: 29m 19s\n",
      "1014:\tlearn: 0.0522072\ttest: 0.0521841\tbest: 0.0521841 (792)\ttotal: 3m 18s\tremaining: 29m 19s\n",
      "1015:\tlearn: 0.0522072\ttest: 0.0521841\tbest: 0.0521841 (792)\ttotal: 3m 18s\tremaining: 29m 19s\n",
      "1016:\tlearn: 0.0522072\ttest: 0.0521841\tbest: 0.0521841 (792)\ttotal: 3m 19s\tremaining: 29m 18s\n",
      "1017:\tlearn: 0.0522072\ttest: 0.0521841\tbest: 0.0521841 (792)\ttotal: 3m 19s\tremaining: 29m 18s\n",
      "1018:\tlearn: 0.0522072\ttest: 0.0521841\tbest: 0.0521841 (792)\ttotal: 3m 19s\tremaining: 29m 17s\n",
      "1019:\tlearn: 0.0522072\ttest: 0.0521841\tbest: 0.0521841 (792)\ttotal: 3m 19s\tremaining: 29m 17s\n",
      "1020:\tlearn: 0.0522072\ttest: 0.0521841\tbest: 0.0521841 (792)\ttotal: 3m 19s\tremaining: 29m 16s\n",
      "1021:\tlearn: 0.0522072\ttest: 0.0521841\tbest: 0.0521841 (792)\ttotal: 3m 19s\tremaining: 29m 16s\n",
      "1022:\tlearn: 0.0522072\ttest: 0.0521841\tbest: 0.0521841 (792)\ttotal: 3m 20s\tremaining: 29m 15s\n",
      "1023:\tlearn: 0.0522072\ttest: 0.0521841\tbest: 0.0521841 (792)\ttotal: 3m 20s\tremaining: 29m 15s\n",
      "1024:\tlearn: 0.0522072\ttest: 0.0521841\tbest: 0.0521841 (792)\ttotal: 3m 20s\tremaining: 29m 14s\n",
      "1025:\tlearn: 0.0522072\ttest: 0.0521841\tbest: 0.0521841 (792)\ttotal: 3m 20s\tremaining: 29m 14s\n",
      "1026:\tlearn: 0.0522072\ttest: 0.0521841\tbest: 0.0521841 (792)\ttotal: 3m 20s\tremaining: 29m 13s\n",
      "1027:\tlearn: 0.0522072\ttest: 0.0521841\tbest: 0.0521841 (792)\ttotal: 3m 20s\tremaining: 29m 13s\n",
      "1028:\tlearn: 0.0522072\ttest: 0.0521841\tbest: 0.0521841 (792)\ttotal: 3m 21s\tremaining: 29m 13s\n",
      "1029:\tlearn: 0.0522072\ttest: 0.0521841\tbest: 0.0521841 (792)\ttotal: 3m 21s\tremaining: 29m 12s\n",
      "1030:\tlearn: 0.0522072\ttest: 0.0521841\tbest: 0.0521841 (792)\ttotal: 3m 21s\tremaining: 29m 12s\n",
      "1031:\tlearn: 0.0522072\ttest: 0.0521841\tbest: 0.0521841 (792)\ttotal: 3m 21s\tremaining: 29m 11s\n",
      "1032:\tlearn: 0.0522072\ttest: 0.0521841\tbest: 0.0521841 (792)\ttotal: 3m 21s\tremaining: 29m 11s\n",
      "1033:\tlearn: 0.0522072\ttest: 0.0521841\tbest: 0.0521841 (792)\ttotal: 3m 21s\tremaining: 29m 10s\n",
      "1034:\tlearn: 0.0522072\ttest: 0.0521841\tbest: 0.0521841 (792)\ttotal: 3m 22s\tremaining: 29m 10s\n",
      "1035:\tlearn: 0.0522072\ttest: 0.0521841\tbest: 0.0521841 (792)\ttotal: 3m 22s\tremaining: 29m 9s\n",
      "1036:\tlearn: 0.0522072\ttest: 0.0521841\tbest: 0.0521841 (792)\ttotal: 3m 22s\tremaining: 29m 9s\n",
      "1037:\tlearn: 0.0522072\ttest: 0.0521841\tbest: 0.0521841 (792)\ttotal: 3m 22s\tremaining: 29m 8s\n",
      "1038:\tlearn: 0.0522072\ttest: 0.0521841\tbest: 0.0521841 (792)\ttotal: 3m 22s\tremaining: 29m 8s\n",
      "1039:\tlearn: 0.0522072\ttest: 0.0521841\tbest: 0.0521841 (792)\ttotal: 3m 22s\tremaining: 29m 8s\n",
      "1040:\tlearn: 0.0522072\ttest: 0.0521841\tbest: 0.0521841 (792)\ttotal: 3m 23s\tremaining: 29m 7s\n",
      "1041:\tlearn: 0.0522072\ttest: 0.0521841\tbest: 0.0521841 (792)\ttotal: 3m 23s\tremaining: 29m 7s\n",
      "1042:\tlearn: 0.0522072\ttest: 0.0521841\tbest: 0.0521841 (792)\ttotal: 3m 23s\tremaining: 29m 6s\n",
      "1043:\tlearn: 0.0522072\ttest: 0.0521841\tbest: 0.0521841 (792)\ttotal: 3m 23s\tremaining: 29m 6s\n",
      "1044:\tlearn: 0.0522072\ttest: 0.0521841\tbest: 0.0521841 (792)\ttotal: 3m 23s\tremaining: 29m 5s\n",
      "1045:\tlearn: 0.0522072\ttest: 0.0521841\tbest: 0.0521841 (792)\ttotal: 3m 23s\tremaining: 29m 5s\n",
      "1046:\tlearn: 0.0522072\ttest: 0.0521841\tbest: 0.0521841 (792)\ttotal: 3m 24s\tremaining: 29m 4s\n",
      "1047:\tlearn: 0.0522072\ttest: 0.0521841\tbest: 0.0521841 (792)\ttotal: 3m 24s\tremaining: 29m 4s\n",
      "1048:\tlearn: 0.0522072\ttest: 0.0521841\tbest: 0.0521841 (792)\ttotal: 3m 24s\tremaining: 29m 4s\n",
      "1049:\tlearn: 0.0522072\ttest: 0.0521841\tbest: 0.0521841 (792)\ttotal: 3m 24s\tremaining: 29m 3s\n",
      "1050:\tlearn: 0.0522072\ttest: 0.0521841\tbest: 0.0521841 (792)\ttotal: 3m 24s\tremaining: 29m 3s\n",
      "\n",
      "bestTest = 0.0521840975\n",
      "bestIteration = 792\n",
      "\n",
      "Shrink model to first 793 iterations.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\tDropped 0 of 30 features.\n",
      "\tFitting S1F4 with 'num_gpus': 0, 'num_cpus': 8\n",
      "\tWarning: Potentially not enough memory to safely train CatBoost model, roughly requires: 4.463 GB, but only 5.102 GB is available...\n",
      "\tCatboost model hyperparameters: {'iterations': 10000, 'learning_rate': 0.02057151708150835, 'random_seed': 0, 'allow_writing_files': False, 'eval_metric': 'Logloss', 'depth': 5, 'l2_leaf_reg': 4.854651042004117, 'thread_count': 8}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:\tlearn: 0.6171602\ttest: 0.6171395\tbest: 0.6171395 (0)\ttotal: 233ms\tremaining: 38m 52s\n",
      "1:\tlearn: 0.5528051\ttest: 0.5530397\tbest: 0.5530397 (1)\ttotal: 477ms\tremaining: 39m 44s\n",
      "2:\tlearn: 0.4937311\ttest: 0.4936579\tbest: 0.4936579 (2)\ttotal: 715ms\tremaining: 39m 43s\n",
      "3:\tlearn: 0.4414068\ttest: 0.4417372\tbest: 0.4417372 (3)\ttotal: 961ms\tremaining: 40m\n",
      "4:\tlearn: 0.3962192\ttest: 0.3964701\tbest: 0.3964701 (4)\ttotal: 1.2s\tremaining: 40m\n",
      "5:\tlearn: 0.3570641\ttest: 0.3571874\tbest: 0.3571874 (5)\ttotal: 1.45s\tremaining: 40m 16s\n",
      "6:\tlearn: 0.3229272\ttest: 0.3229542\tbest: 0.3229542 (6)\ttotal: 1.7s\tremaining: 40m 22s\n",
      "7:\tlearn: 0.2933845\ttest: 0.2932478\tbest: 0.2932478 (7)\ttotal: 1.94s\tremaining: 40m 28s\n",
      "8:\tlearn: 0.2673255\ttest: 0.2674699\tbest: 0.2674699 (8)\ttotal: 2.2s\tremaining: 40m 41s\n",
      "9:\tlearn: 0.2449649\ttest: 0.2450936\tbest: 0.2450936 (9)\ttotal: 2.45s\tremaining: 40m 44s\n",
      "10:\tlearn: 0.2253377\ttest: 0.2256413\tbest: 0.2256413 (10)\ttotal: 2.69s\tremaining: 40m 39s\n",
      "11:\tlearn: 0.2086033\ttest: 0.2087063\tbest: 0.2087063 (11)\ttotal: 2.92s\tremaining: 40m 30s\n",
      "12:\tlearn: 0.1938559\ttest: 0.1939077\tbest: 0.1939077 (12)\ttotal: 3.16s\tremaining: 40m 27s\n",
      "13:\tlearn: 0.1808819\ttest: 0.1809630\tbest: 0.1809630 (13)\ttotal: 3.4s\tremaining: 40m 26s\n",
      "14:\tlearn: 0.1694575\ttest: 0.1696053\tbest: 0.1696053 (14)\ttotal: 3.65s\tremaining: 40m 28s\n",
      "15:\tlearn: 0.1596356\ttest: 0.1595925\tbest: 0.1595925 (15)\ttotal: 3.89s\tremaining: 40m 26s\n",
      "16:\tlearn: 0.1507520\ttest: 0.1507420\tbest: 0.1507420 (16)\ttotal: 4.13s\tremaining: 40m 24s\n",
      "17:\tlearn: 0.1428637\ttest: 0.1428882\tbest: 0.1428882 (17)\ttotal: 4.37s\tremaining: 40m 20s\n",
      "18:\tlearn: 0.1359046\ttest: 0.1358871\tbest: 0.1358871 (18)\ttotal: 4.61s\tremaining: 40m 22s\n",
      "19:\tlearn: 0.1293292\ttest: 0.1293398\tbest: 0.1293398 (19)\ttotal: 4.84s\tremaining: 40m 16s\n",
      "20:\tlearn: 0.1237115\ttest: 0.1237049\tbest: 0.1237049 (20)\ttotal: 5.08s\tremaining: 40m 14s\n",
      "21:\tlearn: 0.1181632\ttest: 0.1181586\tbest: 0.1181586 (21)\ttotal: 5.32s\tremaining: 40m 11s\n",
      "22:\tlearn: 0.1136219\ttest: 0.1135226\tbest: 0.1135226 (22)\ttotal: 5.55s\tremaining: 40m 8s\n",
      "23:\tlearn: 0.1094385\ttest: 0.1093595\tbest: 0.1093595 (23)\ttotal: 5.8s\tremaining: 40m 12s\n",
      "24:\tlearn: 0.1057305\ttest: 0.1055899\tbest: 0.1055899 (24)\ttotal: 6.05s\tremaining: 40m 12s\n",
      "25:\tlearn: 0.1019572\ttest: 0.1018160\tbest: 0.1018160 (25)\ttotal: 6.29s\tremaining: 40m 12s\n",
      "26:\tlearn: 0.0989484\ttest: 0.0987233\tbest: 0.0987233 (26)\ttotal: 6.53s\tremaining: 40m 11s\n",
      "27:\tlearn: 0.0958450\ttest: 0.0956941\tbest: 0.0956941 (27)\ttotal: 6.75s\tremaining: 40m 4s\n",
      "28:\tlearn: 0.0927877\ttest: 0.0927092\tbest: 0.0927092 (28)\ttotal: 6.99s\tremaining: 40m 4s\n",
      "29:\tlearn: 0.0904901\ttest: 0.0903200\tbest: 0.0903200 (29)\ttotal: 7.24s\tremaining: 40m 4s\n",
      "30:\tlearn: 0.0883341\ttest: 0.0882366\tbest: 0.0882366 (30)\ttotal: 7.46s\tremaining: 40m\n",
      "31:\tlearn: 0.0863915\ttest: 0.0861949\tbest: 0.0861949 (31)\ttotal: 7.69s\tremaining: 39m 55s\n",
      "32:\tlearn: 0.0848992\ttest: 0.0847130\tbest: 0.0847130 (32)\ttotal: 7.93s\tremaining: 39m 56s\n",
      "33:\tlearn: 0.0834528\ttest: 0.0833214\tbest: 0.0833214 (33)\ttotal: 8.16s\tremaining: 39m 52s\n",
      "34:\tlearn: 0.0820971\ttest: 0.0819957\tbest: 0.0819957 (34)\ttotal: 8.4s\tremaining: 39m 52s\n",
      "35:\tlearn: 0.0804746\ttest: 0.0803360\tbest: 0.0803360 (35)\ttotal: 8.63s\tremaining: 39m 47s\n",
      "36:\tlearn: 0.0790058\ttest: 0.0788337\tbest: 0.0788337 (36)\ttotal: 8.84s\tremaining: 39m 40s\n",
      "37:\tlearn: 0.0774386\ttest: 0.0772550\tbest: 0.0772550 (37)\ttotal: 9.08s\tremaining: 39m 39s\n",
      "38:\tlearn: 0.0763735\ttest: 0.0762155\tbest: 0.0762155 (38)\ttotal: 9.32s\tremaining: 39m 39s\n",
      "39:\tlearn: 0.0752061\ttest: 0.0750282\tbest: 0.0750282 (39)\ttotal: 9.56s\tremaining: 39m 40s\n",
      "40:\tlearn: 0.0743418\ttest: 0.0741044\tbest: 0.0741044 (40)\ttotal: 9.8s\tremaining: 39m 39s\n",
      "41:\tlearn: 0.0733052\ttest: 0.0731448\tbest: 0.0731448 (41)\ttotal: 10s\tremaining: 39m 40s\n",
      "42:\tlearn: 0.0722787\ttest: 0.0720746\tbest: 0.0720746 (42)\ttotal: 10.3s\tremaining: 39m 36s\n",
      "43:\tlearn: 0.0713529\ttest: 0.0711895\tbest: 0.0711895 (43)\ttotal: 10.5s\tremaining: 39m 33s\n",
      "44:\tlearn: 0.0704542\ttest: 0.0702496\tbest: 0.0702496 (44)\ttotal: 10.7s\tremaining: 39m 28s\n",
      "45:\tlearn: 0.0697197\ttest: 0.0695184\tbest: 0.0695184 (45)\ttotal: 10.9s\tremaining: 39m 21s\n",
      "46:\tlearn: 0.0687444\ttest: 0.0685649\tbest: 0.0685649 (46)\ttotal: 11.1s\tremaining: 39m 20s\n",
      "47:\tlearn: 0.0678695\ttest: 0.0676020\tbest: 0.0676020 (47)\ttotal: 11.4s\tremaining: 39m 23s\n",
      "48:\tlearn: 0.0670256\ttest: 0.0667670\tbest: 0.0667670 (48)\ttotal: 11.6s\tremaining: 39m 21s\n",
      "49:\tlearn: 0.0663809\ttest: 0.0661012\tbest: 0.0661012 (49)\ttotal: 11.9s\tremaining: 39m 21s\n",
      "50:\tlearn: 0.0656535\ttest: 0.0654001\tbest: 0.0654001 (50)\ttotal: 12.1s\tremaining: 39m 19s\n",
      "51:\tlearn: 0.0650639\ttest: 0.0648412\tbest: 0.0648412 (51)\ttotal: 12.3s\tremaining: 39m 17s\n",
      "52:\tlearn: 0.0645561\ttest: 0.0642939\tbest: 0.0642939 (52)\ttotal: 12.5s\tremaining: 39m 14s\n",
      "53:\tlearn: 0.0640091\ttest: 0.0637942\tbest: 0.0637942 (53)\ttotal: 12.8s\tremaining: 39m 15s\n",
      "54:\tlearn: 0.0635747\ttest: 0.0633481\tbest: 0.0633481 (54)\ttotal: 13s\tremaining: 39m 7s\n",
      "55:\tlearn: 0.0630490\ttest: 0.0628320\tbest: 0.0628320 (55)\ttotal: 13.2s\tremaining: 39m 3s\n",
      "56:\tlearn: 0.0626501\ttest: 0.0624305\tbest: 0.0624305 (56)\ttotal: 13.4s\tremaining: 39m\n",
      "57:\tlearn: 0.0622254\ttest: 0.0619699\tbest: 0.0619699 (57)\ttotal: 13.6s\tremaining: 38m 58s\n",
      "58:\tlearn: 0.0617694\ttest: 0.0615040\tbest: 0.0615040 (58)\ttotal: 13.9s\tremaining: 38m 55s\n",
      "59:\tlearn: 0.0614145\ttest: 0.0611224\tbest: 0.0611224 (59)\ttotal: 14.1s\tremaining: 38m 53s\n",
      "60:\tlearn: 0.0610253\ttest: 0.0607596\tbest: 0.0607596 (60)\ttotal: 14.3s\tremaining: 38m 54s\n",
      "61:\tlearn: 0.0607190\ttest: 0.0604494\tbest: 0.0604494 (61)\ttotal: 14.5s\tremaining: 38m 49s\n",
      "62:\tlearn: 0.0604149\ttest: 0.0601382\tbest: 0.0601382 (62)\ttotal: 14.8s\tremaining: 38m 47s\n",
      "63:\tlearn: 0.0600135\ttest: 0.0597884\tbest: 0.0597884 (63)\ttotal: 15s\tremaining: 38m 44s\n",
      "64:\tlearn: 0.0597242\ttest: 0.0595036\tbest: 0.0595036 (64)\ttotal: 15.2s\tremaining: 38m 44s\n",
      "65:\tlearn: 0.0594080\ttest: 0.0592442\tbest: 0.0592442 (65)\ttotal: 15.4s\tremaining: 38m 39s\n",
      "66:\tlearn: 0.0592034\ttest: 0.0589886\tbest: 0.0589886 (66)\ttotal: 15.6s\tremaining: 38m 39s\n",
      "67:\tlearn: 0.0589384\ttest: 0.0587443\tbest: 0.0587443 (67)\ttotal: 15.9s\tremaining: 38m 40s\n",
      "68:\tlearn: 0.0587223\ttest: 0.0585168\tbest: 0.0585168 (68)\ttotal: 16.1s\tremaining: 38m 38s\n",
      "69:\tlearn: 0.0585462\ttest: 0.0582947\tbest: 0.0582947 (69)\ttotal: 16.3s\tremaining: 38m 35s\n",
      "70:\tlearn: 0.0582814\ttest: 0.0580107\tbest: 0.0580107 (70)\ttotal: 16.6s\tremaining: 38m 36s\n",
      "71:\tlearn: 0.0580519\ttest: 0.0578097\tbest: 0.0578097 (71)\ttotal: 16.8s\tremaining: 38m 35s\n",
      "72:\tlearn: 0.0578934\ttest: 0.0576381\tbest: 0.0576381 (72)\ttotal: 17s\tremaining: 38m 34s\n",
      "73:\tlearn: 0.0577261\ttest: 0.0574597\tbest: 0.0574597 (73)\ttotal: 17.3s\tremaining: 38m 34s\n",
      "74:\tlearn: 0.0576087\ttest: 0.0572890\tbest: 0.0572890 (74)\ttotal: 17.5s\tremaining: 38m 33s\n",
      "75:\tlearn: 0.0574428\ttest: 0.0571225\tbest: 0.0571225 (75)\ttotal: 17.7s\tremaining: 38m 34s\n",
      "76:\tlearn: 0.0573045\ttest: 0.0569782\tbest: 0.0569782 (76)\ttotal: 17.9s\tremaining: 38m 32s\n",
      "77:\tlearn: 0.0571239\ttest: 0.0568198\tbest: 0.0568198 (77)\ttotal: 18.2s\tremaining: 38m 30s\n",
      "78:\tlearn: 0.0569535\ttest: 0.0566618\tbest: 0.0566618 (78)\ttotal: 18.4s\tremaining: 38m 30s\n",
      "79:\tlearn: 0.0568004\ttest: 0.0565350\tbest: 0.0565350 (79)\ttotal: 18.6s\tremaining: 38m 28s\n",
      "80:\tlearn: 0.0567200\ttest: 0.0564155\tbest: 0.0564155 (80)\ttotal: 18.8s\tremaining: 38m 22s\n",
      "81:\tlearn: 0.0565752\ttest: 0.0563012\tbest: 0.0563012 (81)\ttotal: 19s\tremaining: 38m 17s\n",
      "82:\tlearn: 0.0564943\ttest: 0.0561939\tbest: 0.0561939 (82)\ttotal: 19.2s\tremaining: 38m 16s\n",
      "83:\tlearn: 0.0563602\ttest: 0.0560700\tbest: 0.0560700 (83)\ttotal: 19.4s\tremaining: 38m 16s\n",
      "84:\tlearn: 0.0562520\ttest: 0.0559397\tbest: 0.0559397 (84)\ttotal: 19.7s\tremaining: 38m 15s\n",
      "85:\tlearn: 0.0561504\ttest: 0.0558194\tbest: 0.0558194 (85)\ttotal: 19.9s\tremaining: 38m 12s\n",
      "86:\tlearn: 0.0560156\ttest: 0.0557093\tbest: 0.0557093 (86)\ttotal: 20.1s\tremaining: 38m 9s\n",
      "87:\tlearn: 0.0559420\ttest: 0.0556196\tbest: 0.0556196 (87)\ttotal: 20.3s\tremaining: 38m 9s\n",
      "88:\tlearn: 0.0558824\ttest: 0.0555340\tbest: 0.0555340 (88)\ttotal: 20.5s\tremaining: 38m 8s\n",
      "89:\tlearn: 0.0558022\ttest: 0.0554512\tbest: 0.0554512 (89)\ttotal: 20.8s\tremaining: 38m 7s\n",
      "90:\tlearn: 0.0556916\ttest: 0.0553737\tbest: 0.0553737 (90)\ttotal: 21s\tremaining: 38m 3s\n",
      "91:\tlearn: 0.0556091\ttest: 0.0552766\tbest: 0.0552766 (91)\ttotal: 21.2s\tremaining: 38m 4s\n",
      "92:\tlearn: 0.0555330\ttest: 0.0552048\tbest: 0.0552048 (92)\ttotal: 21.4s\tremaining: 38m 3s\n",
      "93:\tlearn: 0.0554598\ttest: 0.0551212\tbest: 0.0551212 (93)\ttotal: 21.7s\tremaining: 38m 2s\n",
      "94:\tlearn: 0.0553951\ttest: 0.0550561\tbest: 0.0550561 (94)\ttotal: 21.9s\tremaining: 37m 58s\n",
      "95:\tlearn: 0.0553367\ttest: 0.0549933\tbest: 0.0549933 (95)\ttotal: 22.1s\tremaining: 37m 56s\n",
      "96:\tlearn: 0.0552816\ttest: 0.0549334\tbest: 0.0549334 (96)\ttotal: 22.3s\tremaining: 37m 55s\n",
      "97:\tlearn: 0.0552010\ttest: 0.0548553\tbest: 0.0548553 (97)\ttotal: 22.5s\tremaining: 37m 55s\n",
      "98:\tlearn: 0.0551434\ttest: 0.0547863\tbest: 0.0547863 (98)\ttotal: 22.7s\tremaining: 37m 54s\n",
      "99:\tlearn: 0.0550692\ttest: 0.0547159\tbest: 0.0547159 (99)\ttotal: 23s\tremaining: 37m 54s\n",
      "100:\tlearn: 0.0550584\ttest: 0.0546640\tbest: 0.0546640 (100)\ttotal: 23.2s\tremaining: 37m 53s\n",
      "101:\tlearn: 0.0549858\ttest: 0.0546002\tbest: 0.0546002 (101)\ttotal: 23.4s\tremaining: 37m 54s\n",
      "102:\tlearn: 0.0549186\ttest: 0.0545412\tbest: 0.0545412 (102)\ttotal: 23.7s\tremaining: 37m 53s\n",
      "103:\tlearn: 0.0548508\ttest: 0.0544849\tbest: 0.0544849 (103)\ttotal: 23.9s\tremaining: 37m 52s\n",
      "104:\tlearn: 0.0547989\ttest: 0.0544362\tbest: 0.0544362 (104)\ttotal: 24.1s\tremaining: 37m 49s\n",
      "105:\tlearn: 0.0547358\ttest: 0.0543871\tbest: 0.0543871 (105)\ttotal: 24.3s\tremaining: 37m 48s\n",
      "106:\tlearn: 0.0547354\ttest: 0.0543391\tbest: 0.0543391 (106)\ttotal: 24.5s\tremaining: 37m 47s\n",
      "107:\tlearn: 0.0546713\ttest: 0.0542972\tbest: 0.0542972 (107)\ttotal: 24.8s\tremaining: 37m 48s\n",
      "108:\tlearn: 0.0546169\ttest: 0.0542506\tbest: 0.0542506 (108)\ttotal: 25s\tremaining: 37m 46s\n",
      "109:\tlearn: 0.0546032\ttest: 0.0542065\tbest: 0.0542065 (109)\ttotal: 25.2s\tremaining: 37m 44s\n",
      "110:\tlearn: 0.0545022\ttest: 0.0541620\tbest: 0.0541620 (110)\ttotal: 25.4s\tremaining: 37m 45s\n",
      "111:\tlearn: 0.0544533\ttest: 0.0541232\tbest: 0.0541232 (111)\ttotal: 25.6s\tremaining: 37m 40s\n",
      "112:\tlearn: 0.0544437\ttest: 0.0540828\tbest: 0.0540828 (112)\ttotal: 25.8s\tremaining: 37m 39s\n",
      "113:\tlearn: 0.0543762\ttest: 0.0540441\tbest: 0.0540441 (113)\ttotal: 26s\tremaining: 37m 35s\n",
      "114:\tlearn: 0.0543764\ttest: 0.0540120\tbest: 0.0540120 (114)\ttotal: 26.2s\tremaining: 37m 34s\n",
      "115:\tlearn: 0.0543257\ttest: 0.0539820\tbest: 0.0539820 (115)\ttotal: 26.5s\tremaining: 37m 34s\n",
      "116:\tlearn: 0.0542732\ttest: 0.0539473\tbest: 0.0539473 (116)\ttotal: 26.6s\tremaining: 37m 30s\n",
      "117:\tlearn: 0.0542782\ttest: 0.0539240\tbest: 0.0539240 (117)\ttotal: 26.8s\tremaining: 37m 26s\n",
      "118:\tlearn: 0.0542263\ttest: 0.0538972\tbest: 0.0538972 (118)\ttotal: 27.1s\tremaining: 37m 26s\n",
      "119:\tlearn: 0.0542245\ttest: 0.0538633\tbest: 0.0538633 (119)\ttotal: 27.3s\tremaining: 37m 25s\n",
      "120:\tlearn: 0.0541554\ttest: 0.0538156\tbest: 0.0538156 (120)\ttotal: 27.5s\tremaining: 37m 24s\n",
      "121:\tlearn: 0.0541642\ttest: 0.0537969\tbest: 0.0537969 (121)\ttotal: 27.7s\tremaining: 37m 20s\n",
      "122:\tlearn: 0.0541552\ttest: 0.0537686\tbest: 0.0537686 (122)\ttotal: 27.9s\tremaining: 37m 19s\n",
      "123:\tlearn: 0.0541021\ttest: 0.0537410\tbest: 0.0537410 (123)\ttotal: 28.1s\tremaining: 37m 17s\n",
      "124:\tlearn: 0.0541098\ttest: 0.0537220\tbest: 0.0537220 (124)\ttotal: 28.3s\tremaining: 37m 13s\n",
      "125:\tlearn: 0.0540691\ttest: 0.0537040\tbest: 0.0537040 (125)\ttotal: 28.5s\tremaining: 37m 10s\n",
      "126:\tlearn: 0.0540674\ttest: 0.0536883\tbest: 0.0536883 (126)\ttotal: 28.6s\tremaining: 37m 6s\n",
      "127:\tlearn: 0.0540196\ttest: 0.0536690\tbest: 0.0536690 (127)\ttotal: 28.9s\tremaining: 37m 7s\n",
      "128:\tlearn: 0.0540229\ttest: 0.0536506\tbest: 0.0536506 (128)\ttotal: 29.1s\tremaining: 37m 5s\n",
      "129:\tlearn: 0.0540146\ttest: 0.0536265\tbest: 0.0536265 (129)\ttotal: 29.3s\tremaining: 37m 5s\n",
      "130:\tlearn: 0.0539656\ttest: 0.0536080\tbest: 0.0536080 (130)\ttotal: 29.6s\tremaining: 37m 6s\n",
      "131:\tlearn: 0.0539686\ttest: 0.0535728\tbest: 0.0535728 (131)\ttotal: 29.8s\tremaining: 37m 5s\n",
      "132:\tlearn: 0.0539031\ttest: 0.0535556\tbest: 0.0535556 (132)\ttotal: 30s\tremaining: 37m 5s\n",
      "133:\tlearn: 0.0538941\ttest: 0.0535346\tbest: 0.0535346 (133)\ttotal: 30.2s\tremaining: 37m 4s\n",
      "134:\tlearn: 0.0539235\ttest: 0.0535164\tbest: 0.0535164 (134)\ttotal: 30.4s\tremaining: 37m 3s\n",
      "135:\tlearn: 0.0538588\ttest: 0.0535006\tbest: 0.0535006 (135)\ttotal: 30.7s\tremaining: 37m 3s\n",
      "136:\tlearn: 0.0538422\ttest: 0.0534747\tbest: 0.0534747 (136)\ttotal: 30.9s\tremaining: 37m 3s\n",
      "137:\tlearn: 0.0538602\ttest: 0.0534613\tbest: 0.0534613 (137)\ttotal: 31.1s\tremaining: 37m 1s\n",
      "138:\tlearn: 0.0538040\ttest: 0.0534434\tbest: 0.0534434 (138)\ttotal: 31.3s\tremaining: 37m 2s\n",
      "139:\tlearn: 0.0538011\ttest: 0.0534316\tbest: 0.0534316 (139)\ttotal: 31.6s\tremaining: 37m 2s\n",
      "140:\tlearn: 0.0538092\ttest: 0.0534144\tbest: 0.0534144 (140)\ttotal: 31.8s\tremaining: 37m 2s\n",
      "141:\tlearn: 0.0538046\ttest: 0.0534015\tbest: 0.0534015 (141)\ttotal: 32s\tremaining: 37m 1s\n",
      "142:\tlearn: 0.0537487\ttest: 0.0533855\tbest: 0.0533855 (142)\ttotal: 32.2s\tremaining: 37m 1s\n",
      "143:\tlearn: 0.0537651\ttest: 0.0533735\tbest: 0.0533735 (143)\ttotal: 32.5s\tremaining: 37m 3s\n",
      "144:\tlearn: 0.0537616\ttest: 0.0533606\tbest: 0.0533606 (144)\ttotal: 32.7s\tremaining: 37m 2s\n",
      "145:\tlearn: 0.0537144\ttest: 0.0533427\tbest: 0.0533427 (145)\ttotal: 32.9s\tremaining: 37m 1s\n",
      "146:\tlearn: 0.0537116\ttest: 0.0533308\tbest: 0.0533308 (146)\ttotal: 33.1s\tremaining: 37m 1s\n",
      "147:\tlearn: 0.0537213\ttest: 0.0533195\tbest: 0.0533195 (147)\ttotal: 33.3s\tremaining: 36m 58s\n",
      "148:\tlearn: 0.0537191\ttest: 0.0533091\tbest: 0.0533091 (148)\ttotal: 33.5s\tremaining: 36m 58s\n",
      "149:\tlearn: 0.0536625\ttest: 0.0532888\tbest: 0.0532888 (149)\ttotal: 33.7s\tremaining: 36m 56s\n",
      "150:\tlearn: 0.0536607\ttest: 0.0532788\tbest: 0.0532788 (150)\ttotal: 33.9s\tremaining: 36m 54s\n",
      "151:\tlearn: 0.0536739\ttest: 0.0532709\tbest: 0.0532709 (151)\ttotal: 34.2s\tremaining: 36m 54s\n",
      "152:\tlearn: 0.0536589\ttest: 0.0532519\tbest: 0.0532519 (152)\ttotal: 34.4s\tremaining: 36m 52s\n",
      "153:\tlearn: 0.0536698\ttest: 0.0532437\tbest: 0.0532437 (153)\ttotal: 34.6s\tremaining: 36m 53s\n",
      "154:\tlearn: 0.0536251\ttest: 0.0532340\tbest: 0.0532340 (154)\ttotal: 34.8s\tremaining: 36m 51s\n",
      "155:\tlearn: 0.0536176\ttest: 0.0532219\tbest: 0.0532219 (155)\ttotal: 35.1s\tremaining: 36m 51s\n",
      "156:\tlearn: 0.0536245\ttest: 0.0532105\tbest: 0.0532105 (156)\ttotal: 35.3s\tremaining: 36m 51s\n",
      "157:\tlearn: 0.0536169\ttest: 0.0531962\tbest: 0.0531962 (157)\ttotal: 35.5s\tremaining: 36m 50s\n",
      "158:\tlearn: 0.0535768\ttest: 0.0531899\tbest: 0.0531899 (158)\ttotal: 35.7s\tremaining: 36m 51s\n",
      "159:\tlearn: 0.0535805\ttest: 0.0531815\tbest: 0.0531815 (159)\ttotal: 35.9s\tremaining: 36m 49s\n",
      "160:\tlearn: 0.0535753\ttest: 0.0531713\tbest: 0.0531713 (160)\ttotal: 36.1s\tremaining: 36m 48s\n",
      "161:\tlearn: 0.0535845\ttest: 0.0531631\tbest: 0.0531631 (161)\ttotal: 36.4s\tremaining: 36m 48s\n",
      "162:\tlearn: 0.0535748\ttest: 0.0531520\tbest: 0.0531520 (162)\ttotal: 36.6s\tremaining: 36m 46s\n",
      "163:\tlearn: 0.0535729\ttest: 0.0531372\tbest: 0.0531372 (163)\ttotal: 36.8s\tremaining: 36m 45s\n",
      "164:\tlearn: 0.0535354\ttest: 0.0531320\tbest: 0.0531320 (164)\ttotal: 37s\tremaining: 36m 43s\n",
      "165:\tlearn: 0.0535211\ttest: 0.0531222\tbest: 0.0531222 (165)\ttotal: 37.2s\tremaining: 36m 42s\n",
      "166:\tlearn: 0.0535153\ttest: 0.0531044\tbest: 0.0531044 (166)\ttotal: 37.4s\tremaining: 36m 42s\n",
      "167:\tlearn: 0.0535246\ttest: 0.0530972\tbest: 0.0530972 (167)\ttotal: 37.6s\tremaining: 36m 42s\n",
      "168:\tlearn: 0.0535142\ttest: 0.0530926\tbest: 0.0530926 (168)\ttotal: 37.8s\tremaining: 36m 40s\n",
      "169:\tlearn: 0.0535167\ttest: 0.0530792\tbest: 0.0530792 (169)\ttotal: 38s\tremaining: 36m 39s\n",
      "170:\tlearn: 0.0534717\ttest: 0.0530736\tbest: 0.0530736 (170)\ttotal: 38.3s\tremaining: 36m 39s\n",
      "171:\tlearn: 0.0534781\ttest: 0.0530666\tbest: 0.0530666 (171)\ttotal: 38.5s\tremaining: 36m 39s\n",
      "172:\tlearn: 0.0534729\ttest: 0.0530600\tbest: 0.0530600 (172)\ttotal: 38.7s\tremaining: 36m 38s\n",
      "173:\tlearn: 0.0534728\ttest: 0.0530537\tbest: 0.0530537 (173)\ttotal: 38.9s\tremaining: 36m 38s\n",
      "174:\tlearn: 0.0534827\ttest: 0.0530455\tbest: 0.0530455 (174)\ttotal: 39.2s\tremaining: 36m 38s\n",
      "175:\tlearn: 0.0534818\ttest: 0.0530384\tbest: 0.0530384 (175)\ttotal: 39.4s\tremaining: 36m 38s\n",
      "176:\tlearn: 0.0534647\ttest: 0.0530308\tbest: 0.0530308 (176)\ttotal: 39.6s\tremaining: 36m 37s\n",
      "177:\tlearn: 0.0534715\ttest: 0.0530266\tbest: 0.0530266 (177)\ttotal: 39.8s\tremaining: 36m 36s\n",
      "178:\tlearn: 0.0534232\ttest: 0.0530185\tbest: 0.0530185 (178)\ttotal: 40s\tremaining: 36m 35s\n",
      "179:\tlearn: 0.0534229\ttest: 0.0530094\tbest: 0.0530094 (179)\ttotal: 40.2s\tremaining: 36m 34s\n",
      "180:\tlearn: 0.0534109\ttest: 0.0530024\tbest: 0.0530024 (180)\ttotal: 40.4s\tremaining: 36m 33s\n",
      "181:\tlearn: 0.0534135\ttest: 0.0529960\tbest: 0.0529960 (181)\ttotal: 40.6s\tremaining: 36m 31s\n",
      "182:\tlearn: 0.0534189\ttest: 0.0529896\tbest: 0.0529896 (182)\ttotal: 40.8s\tremaining: 36m 30s\n",
      "183:\tlearn: 0.0534216\ttest: 0.0529830\tbest: 0.0529830 (183)\ttotal: 41s\tremaining: 36m 29s\n",
      "184:\tlearn: 0.0534248\ttest: 0.0529767\tbest: 0.0529767 (184)\ttotal: 41.3s\tremaining: 36m 28s\n",
      "185:\tlearn: 0.0534276\ttest: 0.0529705\tbest: 0.0529705 (185)\ttotal: 41.5s\tremaining: 36m 27s\n",
      "186:\tlearn: 0.0534119\ttest: 0.0529645\tbest: 0.0529645 (186)\ttotal: 41.7s\tremaining: 36m 27s\n",
      "187:\tlearn: 0.0534106\ttest: 0.0529558\tbest: 0.0529558 (187)\ttotal: 41.9s\tremaining: 36m 25s\n",
      "188:\tlearn: 0.0534073\ttest: 0.0529485\tbest: 0.0529485 (188)\ttotal: 42.1s\tremaining: 36m 23s\n",
      "189:\tlearn: 0.0533591\ttest: 0.0529437\tbest: 0.0529437 (189)\ttotal: 42.2s\tremaining: 36m 20s\n",
      "190:\tlearn: 0.0533600\ttest: 0.0529374\tbest: 0.0529374 (190)\ttotal: 42.4s\tremaining: 36m 19s\n",
      "191:\tlearn: 0.0533580\ttest: 0.0529294\tbest: 0.0529294 (191)\ttotal: 42.6s\tremaining: 36m 17s\n",
      "192:\tlearn: 0.0533532\ttest: 0.0529245\tbest: 0.0529245 (192)\ttotal: 42.8s\tremaining: 36m 16s\n",
      "193:\tlearn: 0.0533548\ttest: 0.0529207\tbest: 0.0529207 (193)\ttotal: 43s\tremaining: 36m 14s\n",
      "194:\tlearn: 0.0533576\ttest: 0.0529169\tbest: 0.0529169 (194)\ttotal: 43.2s\tremaining: 36m 13s\n",
      "195:\tlearn: 0.0533390\ttest: 0.0529099\tbest: 0.0529099 (195)\ttotal: 43.4s\tremaining: 36m 12s\n",
      "196:\tlearn: 0.0533354\ttest: 0.0529033\tbest: 0.0529033 (196)\ttotal: 43.6s\tremaining: 36m 10s\n",
      "197:\tlearn: 0.0533390\ttest: 0.0528996\tbest: 0.0528996 (197)\ttotal: 43.8s\tremaining: 36m 7s\n",
      "198:\tlearn: 0.0533427\ttest: 0.0528941\tbest: 0.0528941 (198)\ttotal: 44s\tremaining: 36m 7s\n",
      "199:\tlearn: 0.0533416\ttest: 0.0528829\tbest: 0.0528829 (199)\ttotal: 44.2s\tremaining: 36m 7s\n",
      "200:\tlearn: 0.0533393\ttest: 0.0528767\tbest: 0.0528767 (200)\ttotal: 44.4s\tremaining: 36m 5s\n",
      "201:\tlearn: 0.0533370\ttest: 0.0528723\tbest: 0.0528723 (201)\ttotal: 44.6s\tremaining: 36m 5s\n",
      "202:\tlearn: 0.0533338\ttest: 0.0528598\tbest: 0.0528598 (202)\ttotal: 44.8s\tremaining: 36m 4s\n",
      "203:\tlearn: 0.0533356\ttest: 0.0528556\tbest: 0.0528556 (203)\ttotal: 45s\tremaining: 36m 3s\n",
      "204:\tlearn: 0.0533114\ttest: 0.0528265\tbest: 0.0528265 (204)\ttotal: 45.3s\tremaining: 36m 2s\n",
      "205:\tlearn: 0.0533087\ttest: 0.0528196\tbest: 0.0528196 (205)\ttotal: 45.5s\tremaining: 36m 1s\n",
      "206:\tlearn: 0.0532995\ttest: 0.0528020\tbest: 0.0528020 (206)\ttotal: 45.7s\tremaining: 36m\n",
      "207:\tlearn: 0.0533006\ttest: 0.0527992\tbest: 0.0527992 (207)\ttotal: 45.9s\tremaining: 35m 59s\n",
      "208:\tlearn: 0.0532985\ttest: 0.0527942\tbest: 0.0527942 (208)\ttotal: 46s\tremaining: 35m 57s\n",
      "209:\tlearn: 0.0532978\ttest: 0.0527906\tbest: 0.0527906 (209)\ttotal: 46.2s\tremaining: 35m 55s\n",
      "210:\tlearn: 0.0532645\ttest: 0.0527669\tbest: 0.0527669 (210)\ttotal: 46.5s\tremaining: 35m 55s\n",
      "211:\tlearn: 0.0532145\ttest: 0.0527624\tbest: 0.0527624 (211)\ttotal: 46.6s\tremaining: 35m 53s\n",
      "212:\tlearn: 0.0532160\ttest: 0.0527591\tbest: 0.0527591 (212)\ttotal: 46.8s\tremaining: 35m 52s\n",
      "213:\tlearn: 0.0532160\ttest: 0.0527549\tbest: 0.0527549 (213)\ttotal: 47s\tremaining: 35m 50s\n",
      "214:\tlearn: 0.0532074\ttest: 0.0527487\tbest: 0.0527487 (214)\ttotal: 47.2s\tremaining: 35m 50s\n",
      "215:\tlearn: 0.0532080\ttest: 0.0527455\tbest: 0.0527455 (215)\ttotal: 47.4s\tremaining: 35m 49s\n",
      "216:\tlearn: 0.0532115\ttest: 0.0527426\tbest: 0.0527426 (216)\ttotal: 47.6s\tremaining: 35m 47s\n",
      "217:\tlearn: 0.0531952\ttest: 0.0527374\tbest: 0.0527374 (217)\ttotal: 47.8s\tremaining: 35m 46s\n",
      "218:\tlearn: 0.0531972\ttest: 0.0527356\tbest: 0.0527356 (218)\ttotal: 48.1s\tremaining: 35m 46s\n",
      "219:\tlearn: 0.0531959\ttest: 0.0527326\tbest: 0.0527326 (219)\ttotal: 48.2s\tremaining: 35m 44s\n",
      "220:\tlearn: 0.0532016\ttest: 0.0527306\tbest: 0.0527306 (220)\ttotal: 48.5s\tremaining: 35m 44s\n",
      "221:\tlearn: 0.0531966\ttest: 0.0527267\tbest: 0.0527267 (221)\ttotal: 48.7s\tremaining: 35m 42s\n",
      "222:\tlearn: 0.0531975\ttest: 0.0527239\tbest: 0.0527239 (222)\ttotal: 48.9s\tremaining: 35m 43s\n",
      "223:\tlearn: 0.0531963\ttest: 0.0527192\tbest: 0.0527192 (223)\ttotal: 49.1s\tremaining: 35m 42s\n",
      "224:\tlearn: 0.0531874\ttest: 0.0526941\tbest: 0.0526941 (224)\ttotal: 49.3s\tremaining: 35m 42s\n",
      "225:\tlearn: 0.0531635\ttest: 0.0526745\tbest: 0.0526745 (225)\ttotal: 49.5s\tremaining: 35m 40s\n",
      "226:\tlearn: 0.0531687\ttest: 0.0526703\tbest: 0.0526703 (226)\ttotal: 49.7s\tremaining: 35m 39s\n",
      "227:\tlearn: 0.0531690\ttest: 0.0526687\tbest: 0.0526687 (227)\ttotal: 49.9s\tremaining: 35m 36s\n",
      "228:\tlearn: 0.0531633\ttest: 0.0526645\tbest: 0.0526645 (228)\ttotal: 50.1s\tremaining: 35m 35s\n",
      "229:\tlearn: 0.0531679\ttest: 0.0526602\tbest: 0.0526602 (229)\ttotal: 50.3s\tremaining: 35m 35s\n",
      "230:\tlearn: 0.0531658\ttest: 0.0526566\tbest: 0.0526566 (230)\ttotal: 50.5s\tremaining: 35m 34s\n",
      "231:\tlearn: 0.0531649\ttest: 0.0526547\tbest: 0.0526547 (231)\ttotal: 50.7s\tremaining: 35m 32s\n",
      "232:\tlearn: 0.0531638\ttest: 0.0526500\tbest: 0.0526500 (232)\ttotal: 50.9s\tremaining: 35m 31s\n",
      "233:\tlearn: 0.0531460\ttest: 0.0526460\tbest: 0.0526460 (233)\ttotal: 51.1s\tremaining: 35m 31s\n",
      "234:\tlearn: 0.0531462\ttest: 0.0526445\tbest: 0.0526445 (234)\ttotal: 51.3s\tremaining: 35m 30s\n",
      "235:\tlearn: 0.0531382\ttest: 0.0526262\tbest: 0.0526262 (235)\ttotal: 51.5s\tremaining: 35m 30s\n",
      "236:\tlearn: 0.0531416\ttest: 0.0526249\tbest: 0.0526249 (236)\ttotal: 51.7s\tremaining: 35m 28s\n",
      "237:\tlearn: 0.0531400\ttest: 0.0526208\tbest: 0.0526208 (237)\ttotal: 51.9s\tremaining: 35m 28s\n",
      "238:\tlearn: 0.0531386\ttest: 0.0526196\tbest: 0.0526196 (238)\ttotal: 52.1s\tremaining: 35m 27s\n",
      "239:\tlearn: 0.0531381\ttest: 0.0526180\tbest: 0.0526180 (239)\ttotal: 52.3s\tremaining: 35m 25s\n",
      "240:\tlearn: 0.0531419\ttest: 0.0526136\tbest: 0.0526136 (240)\ttotal: 52.5s\tremaining: 35m 24s\n",
      "241:\tlearn: 0.0530912\ttest: 0.0526111\tbest: 0.0526111 (241)\ttotal: 52.7s\tremaining: 35m 23s\n",
      "242:\tlearn: 0.0530884\ttest: 0.0526075\tbest: 0.0526075 (242)\ttotal: 52.9s\tremaining: 35m 23s\n",
      "243:\tlearn: 0.0530913\ttest: 0.0526055\tbest: 0.0526055 (243)\ttotal: 53.1s\tremaining: 35m 22s\n",
      "244:\tlearn: 0.0530889\ttest: 0.0526035\tbest: 0.0526035 (244)\ttotal: 53.3s\tremaining: 35m 21s\n",
      "245:\tlearn: 0.0530865\ttest: 0.0526013\tbest: 0.0526013 (245)\ttotal: 53.5s\tremaining: 35m 20s\n",
      "246:\tlearn: 0.0530867\ttest: 0.0525984\tbest: 0.0525984 (246)\ttotal: 53.7s\tremaining: 35m 19s\n",
      "247:\tlearn: 0.0530866\ttest: 0.0525952\tbest: 0.0525952 (247)\ttotal: 53.9s\tremaining: 35m 17s\n",
      "248:\tlearn: 0.0530829\ttest: 0.0525941\tbest: 0.0525941 (248)\ttotal: 54.1s\tremaining: 35m 16s\n",
      "249:\tlearn: 0.0530851\ttest: 0.0525928\tbest: 0.0525928 (249)\ttotal: 54.2s\tremaining: 35m 14s\n",
      "250:\tlearn: 0.0530863\ttest: 0.0525914\tbest: 0.0525914 (250)\ttotal: 54.4s\tremaining: 35m 13s\n",
      "251:\tlearn: 0.0530870\ttest: 0.0525869\tbest: 0.0525869 (251)\ttotal: 54.6s\tremaining: 35m 12s\n",
      "252:\tlearn: 0.0530713\ttest: 0.0525851\tbest: 0.0525851 (252)\ttotal: 54.8s\tremaining: 35m 12s\n",
      "253:\tlearn: 0.0530709\ttest: 0.0525820\tbest: 0.0525820 (253)\ttotal: 55s\tremaining: 35m 11s\n",
      "254:\tlearn: 0.0530713\ttest: 0.0525810\tbest: 0.0525810 (254)\ttotal: 55.2s\tremaining: 35m 10s\n",
      "255:\tlearn: 0.0530724\ttest: 0.0525792\tbest: 0.0525792 (255)\ttotal: 55.4s\tremaining: 35m 10s\n",
      "256:\tlearn: 0.0530725\ttest: 0.0525768\tbest: 0.0525768 (256)\ttotal: 55.6s\tremaining: 35m 8s\n",
      "257:\tlearn: 0.0530739\ttest: 0.0525750\tbest: 0.0525750 (257)\ttotal: 55.8s\tremaining: 35m 7s\n",
      "258:\tlearn: 0.0530703\ttest: 0.0525732\tbest: 0.0525732 (258)\ttotal: 56s\tremaining: 35m 7s\n",
      "259:\tlearn: 0.0530694\ttest: 0.0525715\tbest: 0.0525715 (259)\ttotal: 56.2s\tremaining: 35m 6s\n",
      "260:\tlearn: 0.0530702\ttest: 0.0525698\tbest: 0.0525698 (260)\ttotal: 56.4s\tremaining: 35m 5s\n",
      "261:\tlearn: 0.0530226\ttest: 0.0525515\tbest: 0.0525515 (261)\ttotal: 56.6s\tremaining: 35m 4s\n",
      "262:\tlearn: 0.0530219\ttest: 0.0525503\tbest: 0.0525503 (262)\ttotal: 56.8s\tremaining: 35m 3s\n",
      "263:\tlearn: 0.0530173\ttest: 0.0525429\tbest: 0.0525429 (263)\ttotal: 57s\tremaining: 35m 2s\n",
      "264:\tlearn: 0.0530177\ttest: 0.0525413\tbest: 0.0525413 (264)\ttotal: 57.2s\tremaining: 35m 2s\n",
      "265:\tlearn: 0.0530159\ttest: 0.0525368\tbest: 0.0525368 (265)\ttotal: 57.4s\tremaining: 35m 2s\n",
      "266:\tlearn: 0.0530086\ttest: 0.0525279\tbest: 0.0525279 (266)\ttotal: 57.6s\tremaining: 35m\n",
      "267:\tlearn: 0.0530100\ttest: 0.0525254\tbest: 0.0525254 (267)\ttotal: 57.8s\tremaining: 35m\n",
      "268:\tlearn: 0.0530027\ttest: 0.0525193\tbest: 0.0525193 (268)\ttotal: 58.1s\tremaining: 35m\n",
      "269:\tlearn: 0.0530063\ttest: 0.0525152\tbest: 0.0525152 (269)\ttotal: 58.3s\tremaining: 34m 59s\n",
      "270:\tlearn: 0.0530045\ttest: 0.0525127\tbest: 0.0525127 (270)\ttotal: 58.5s\tremaining: 34m 58s\n",
      "271:\tlearn: 0.0530055\ttest: 0.0525114\tbest: 0.0525114 (271)\ttotal: 58.7s\tremaining: 34m 58s\n",
      "272:\tlearn: 0.0530019\ttest: 0.0525072\tbest: 0.0525072 (272)\ttotal: 58.9s\tremaining: 34m 57s\n",
      "273:\tlearn: 0.0530000\ttest: 0.0525060\tbest: 0.0525060 (273)\ttotal: 59.1s\tremaining: 34m 56s\n",
      "274:\tlearn: 0.0529956\ttest: 0.0525041\tbest: 0.0525041 (274)\ttotal: 59.3s\tremaining: 34m 56s\n",
      "275:\tlearn: 0.0529963\ttest: 0.0525023\tbest: 0.0525023 (275)\ttotal: 59.5s\tremaining: 34m 54s\n",
      "276:\tlearn: 0.0529919\ttest: 0.0524964\tbest: 0.0524964 (276)\ttotal: 59.6s\tremaining: 34m 53s\n",
      "277:\tlearn: 0.0529917\ttest: 0.0524954\tbest: 0.0524954 (277)\ttotal: 59.8s\tremaining: 34m 51s\n",
      "278:\tlearn: 0.0529863\ttest: 0.0524945\tbest: 0.0524945 (278)\ttotal: 1m\tremaining: 34m 51s\n",
      "279:\tlearn: 0.0529835\ttest: 0.0524864\tbest: 0.0524864 (279)\ttotal: 1m\tremaining: 34m 50s\n",
      "280:\tlearn: 0.0529822\ttest: 0.0524842\tbest: 0.0524842 (280)\ttotal: 1m\tremaining: 34m 49s\n",
      "281:\tlearn: 0.0529868\ttest: 0.0524829\tbest: 0.0524829 (281)\ttotal: 1m\tremaining: 34m 49s\n",
      "282:\tlearn: 0.0529865\ttest: 0.0524807\tbest: 0.0524807 (282)\ttotal: 1m\tremaining: 34m 48s\n",
      "283:\tlearn: 0.0529869\ttest: 0.0524795\tbest: 0.0524795 (283)\ttotal: 1m 1s\tremaining: 34m 48s\n",
      "284:\tlearn: 0.0529841\ttest: 0.0524738\tbest: 0.0524738 (284)\ttotal: 1m 1s\tremaining: 34m 47s\n",
      "285:\tlearn: 0.0529717\ttest: 0.0524701\tbest: 0.0524701 (285)\ttotal: 1m 1s\tremaining: 34m 46s\n",
      "286:\tlearn: 0.0529725\ttest: 0.0524696\tbest: 0.0524696 (286)\ttotal: 1m 1s\tremaining: 34m 45s\n",
      "287:\tlearn: 0.0529578\ttest: 0.0524661\tbest: 0.0524661 (287)\ttotal: 1m 1s\tremaining: 34m 45s\n",
      "288:\tlearn: 0.0529563\ttest: 0.0524652\tbest: 0.0524652 (288)\ttotal: 1m 2s\tremaining: 34m 45s\n",
      "289:\tlearn: 0.0529544\ttest: 0.0524627\tbest: 0.0524627 (289)\ttotal: 1m 2s\tremaining: 34m 45s\n",
      "290:\tlearn: 0.0529503\ttest: 0.0524579\tbest: 0.0524579 (290)\ttotal: 1m 2s\tremaining: 34m 44s\n",
      "291:\tlearn: 0.0529511\ttest: 0.0524570\tbest: 0.0524570 (291)\ttotal: 1m 2s\tremaining: 34m 44s\n",
      "292:\tlearn: 0.0529553\ttest: 0.0524546\tbest: 0.0524546 (292)\ttotal: 1m 2s\tremaining: 34m 44s\n",
      "293:\tlearn: 0.0529550\ttest: 0.0524541\tbest: 0.0524541 (293)\ttotal: 1m 3s\tremaining: 34m 43s\n",
      "294:\tlearn: 0.0529537\ttest: 0.0524528\tbest: 0.0524528 (294)\ttotal: 1m 3s\tremaining: 34m 43s\n",
      "295:\tlearn: 0.0529494\ttest: 0.0524477\tbest: 0.0524477 (295)\ttotal: 1m 3s\tremaining: 34m 41s\n",
      "296:\tlearn: 0.0529491\ttest: 0.0524467\tbest: 0.0524467 (296)\ttotal: 1m 3s\tremaining: 34m 42s\n",
      "297:\tlearn: 0.0529440\ttest: 0.0524453\tbest: 0.0524453 (297)\ttotal: 1m 3s\tremaining: 34m 40s\n",
      "298:\tlearn: 0.0529476\ttest: 0.0524425\tbest: 0.0524425 (298)\ttotal: 1m 4s\tremaining: 34m 39s\n",
      "299:\tlearn: 0.0529403\ttest: 0.0524256\tbest: 0.0524256 (299)\ttotal: 1m 4s\tremaining: 34m 39s\n",
      "300:\tlearn: 0.0528666\ttest: 0.0524126\tbest: 0.0524126 (300)\ttotal: 1m 4s\tremaining: 34m 39s\n",
      "301:\tlearn: 0.0528661\ttest: 0.0524118\tbest: 0.0524118 (301)\ttotal: 1m 4s\tremaining: 34m 39s\n",
      "302:\tlearn: 0.0528655\ttest: 0.0524110\tbest: 0.0524110 (302)\ttotal: 1m 4s\tremaining: 34m 38s\n",
      "303:\tlearn: 0.0528664\ttest: 0.0524099\tbest: 0.0524099 (303)\ttotal: 1m 5s\tremaining: 34m 37s\n",
      "304:\tlearn: 0.0528682\ttest: 0.0524090\tbest: 0.0524090 (304)\ttotal: 1m 5s\tremaining: 34m 35s\n",
      "305:\tlearn: 0.0528056\ttest: 0.0524025\tbest: 0.0524025 (305)\ttotal: 1m 5s\tremaining: 34m 34s\n",
      "306:\tlearn: 0.0528044\ttest: 0.0524012\tbest: 0.0524012 (306)\ttotal: 1m 5s\tremaining: 34m 34s\n",
      "307:\tlearn: 0.0528437\ttest: 0.0523842\tbest: 0.0523842 (307)\ttotal: 1m 5s\tremaining: 34m 33s\n",
      "308:\tlearn: 0.0528415\ttest: 0.0523813\tbest: 0.0523813 (308)\ttotal: 1m 6s\tremaining: 34m 32s\n",
      "309:\tlearn: 0.0528410\ttest: 0.0523806\tbest: 0.0523806 (309)\ttotal: 1m 6s\tremaining: 34m 31s\n",
      "310:\tlearn: 0.0528420\ttest: 0.0523786\tbest: 0.0523786 (310)\ttotal: 1m 6s\tremaining: 34m 31s\n",
      "311:\tlearn: 0.0527908\ttest: 0.0523754\tbest: 0.0523754 (311)\ttotal: 1m 6s\tremaining: 34m 30s\n",
      "312:\tlearn: 0.0527897\ttest: 0.0523750\tbest: 0.0523750 (312)\ttotal: 1m 6s\tremaining: 34m 29s\n",
      "313:\tlearn: 0.0527893\ttest: 0.0523746\tbest: 0.0523746 (313)\ttotal: 1m 7s\tremaining: 34m 29s\n",
      "314:\tlearn: 0.0527837\ttest: 0.0523603\tbest: 0.0523603 (314)\ttotal: 1m 7s\tremaining: 34m 28s\n",
      "315:\tlearn: 0.0527849\ttest: 0.0523575\tbest: 0.0523575 (315)\ttotal: 1m 7s\tremaining: 34m 28s\n",
      "316:\tlearn: 0.0527858\ttest: 0.0523565\tbest: 0.0523565 (316)\ttotal: 1m 7s\tremaining: 34m 27s\n",
      "317:\tlearn: 0.0527754\ttest: 0.0523349\tbest: 0.0523349 (317)\ttotal: 1m 7s\tremaining: 34m 27s\n",
      "318:\tlearn: 0.0527746\ttest: 0.0523343\tbest: 0.0523343 (318)\ttotal: 1m 8s\tremaining: 34m 25s\n",
      "319:\tlearn: 0.0527733\ttest: 0.0523328\tbest: 0.0523328 (319)\ttotal: 1m 8s\tremaining: 34m 25s\n",
      "320:\tlearn: 0.0527624\ttest: 0.0523198\tbest: 0.0523198 (320)\ttotal: 1m 8s\tremaining: 34m 24s\n",
      "321:\tlearn: 0.0527634\ttest: 0.0523190\tbest: 0.0523190 (321)\ttotal: 1m 8s\tremaining: 34m 24s\n",
      "322:\tlearn: 0.0527623\ttest: 0.0523173\tbest: 0.0523173 (322)\ttotal: 1m 8s\tremaining: 34m 23s\n",
      "323:\tlearn: 0.0527611\ttest: 0.0523166\tbest: 0.0523166 (323)\ttotal: 1m 9s\tremaining: 34m 23s\n",
      "324:\tlearn: 0.0527609\ttest: 0.0523152\tbest: 0.0523152 (324)\ttotal: 1m 9s\tremaining: 34m 22s\n",
      "325:\tlearn: 0.0527534\ttest: 0.0523117\tbest: 0.0523117 (325)\ttotal: 1m 9s\tremaining: 34m 20s\n",
      "326:\tlearn: 0.0527525\ttest: 0.0523107\tbest: 0.0523107 (326)\ttotal: 1m 9s\tremaining: 34m 19s\n",
      "327:\tlearn: 0.0527502\ttest: 0.0523051\tbest: 0.0523051 (327)\ttotal: 1m 9s\tremaining: 34m 18s\n",
      "328:\tlearn: 0.0527502\ttest: 0.0523051\tbest: 0.0523051 (327)\ttotal: 1m 9s\tremaining: 34m 17s\n",
      "329:\tlearn: 0.0527475\ttest: 0.0523026\tbest: 0.0523026 (329)\ttotal: 1m 10s\tremaining: 34m 16s\n",
      "330:\tlearn: 0.0527409\ttest: 0.0522980\tbest: 0.0522980 (330)\ttotal: 1m 10s\tremaining: 34m 16s\n",
      "331:\tlearn: 0.0527409\ttest: 0.0522980\tbest: 0.0522980 (331)\ttotal: 1m 10s\tremaining: 34m 15s\n",
      "332:\tlearn: 0.0527417\ttest: 0.0522974\tbest: 0.0522974 (332)\ttotal: 1m 10s\tremaining: 34m 14s\n",
      "333:\tlearn: 0.0527327\ttest: 0.0522863\tbest: 0.0522863 (333)\ttotal: 1m 10s\tremaining: 34m 14s\n",
      "334:\tlearn: 0.0527293\ttest: 0.0522827\tbest: 0.0522827 (334)\ttotal: 1m 11s\tremaining: 34m 13s\n",
      "335:\tlearn: 0.0527320\ttest: 0.0522819\tbest: 0.0522819 (335)\ttotal: 1m 11s\tremaining: 34m 13s\n",
      "336:\tlearn: 0.0527246\ttest: 0.0522812\tbest: 0.0522812 (336)\ttotal: 1m 11s\tremaining: 34m 12s\n",
      "337:\tlearn: 0.0527227\ttest: 0.0522790\tbest: 0.0522790 (337)\ttotal: 1m 11s\tremaining: 34m 11s\n",
      "338:\tlearn: 0.0527260\ttest: 0.0522782\tbest: 0.0522782 (338)\ttotal: 1m 11s\tremaining: 34m 11s\n",
      "339:\tlearn: 0.0527130\ttest: 0.0522710\tbest: 0.0522710 (339)\ttotal: 1m 12s\tremaining: 34m 10s\n",
      "340:\tlearn: 0.0527127\ttest: 0.0522695\tbest: 0.0522695 (340)\ttotal: 1m 12s\tremaining: 34m 10s\n",
      "341:\tlearn: 0.0527084\ttest: 0.0522687\tbest: 0.0522687 (341)\ttotal: 1m 12s\tremaining: 34m 9s\n",
      "342:\tlearn: 0.0527069\ttest: 0.0522679\tbest: 0.0522679 (342)\ttotal: 1m 12s\tremaining: 34m 9s\n",
      "343:\tlearn: 0.0527069\ttest: 0.0522674\tbest: 0.0522674 (343)\ttotal: 1m 12s\tremaining: 34m 8s\n",
      "344:\tlearn: 0.0527063\ttest: 0.0522667\tbest: 0.0522667 (344)\ttotal: 1m 13s\tremaining: 34m 7s\n",
      "345:\tlearn: 0.0527064\ttest: 0.0522614\tbest: 0.0522614 (345)\ttotal: 1m 13s\tremaining: 34m 6s\n",
      "346:\tlearn: 0.0527038\ttest: 0.0522586\tbest: 0.0522586 (346)\ttotal: 1m 13s\tremaining: 34m 6s\n",
      "347:\tlearn: 0.0527030\ttest: 0.0522571\tbest: 0.0522571 (347)\ttotal: 1m 13s\tremaining: 34m 5s\n",
      "348:\tlearn: 0.0527004\ttest: 0.0522547\tbest: 0.0522547 (348)\ttotal: 1m 14s\tremaining: 34m 6s\n",
      "349:\tlearn: 0.0527020\ttest: 0.0522541\tbest: 0.0522541 (349)\ttotal: 1m 14s\tremaining: 34m 5s\n",
      "350:\tlearn: 0.0527000\ttest: 0.0522536\tbest: 0.0522536 (350)\ttotal: 1m 14s\tremaining: 34m 4s\n",
      "351:\tlearn: 0.0527000\ttest: 0.0522536\tbest: 0.0522536 (351)\ttotal: 1m 14s\tremaining: 34m 3s\n",
      "352:\tlearn: 0.0527008\ttest: 0.0522501\tbest: 0.0522501 (352)\ttotal: 1m 14s\tremaining: 34m 3s\n",
      "353:\tlearn: 0.0526995\ttest: 0.0522471\tbest: 0.0522471 (353)\ttotal: 1m 14s\tremaining: 34m 2s\n",
      "354:\tlearn: 0.0526974\ttest: 0.0522387\tbest: 0.0522387 (354)\ttotal: 1m 15s\tremaining: 34m 1s\n",
      "355:\tlearn: 0.0526976\ttest: 0.0522384\tbest: 0.0522384 (355)\ttotal: 1m 15s\tremaining: 34m 1s\n",
      "356:\tlearn: 0.0526962\ttest: 0.0522379\tbest: 0.0522379 (356)\ttotal: 1m 15s\tremaining: 33m 59s\n",
      "357:\tlearn: 0.0526980\ttest: 0.0522370\tbest: 0.0522370 (357)\ttotal: 1m 15s\tremaining: 33m 59s\n",
      "358:\tlearn: 0.0526953\ttest: 0.0522335\tbest: 0.0522335 (358)\ttotal: 1m 15s\tremaining: 33m 59s\n",
      "359:\tlearn: 0.0526956\ttest: 0.0522331\tbest: 0.0522331 (359)\ttotal: 1m 16s\tremaining: 33m 58s\n",
      "360:\tlearn: 0.0526938\ttest: 0.0522307\tbest: 0.0522307 (360)\ttotal: 1m 16s\tremaining: 33m 58s\n",
      "361:\tlearn: 0.0526930\ttest: 0.0522299\tbest: 0.0522299 (361)\ttotal: 1m 16s\tremaining: 33m 58s\n",
      "362:\tlearn: 0.0526769\ttest: 0.0522285\tbest: 0.0522285 (362)\ttotal: 1m 16s\tremaining: 33m 58s\n",
      "363:\tlearn: 0.0526727\ttest: 0.0522248\tbest: 0.0522248 (363)\ttotal: 1m 16s\tremaining: 33m 57s\n",
      "364:\tlearn: 0.0526708\ttest: 0.0522234\tbest: 0.0522234 (364)\ttotal: 1m 17s\tremaining: 33m 57s\n",
      "365:\tlearn: 0.0526706\ttest: 0.0522229\tbest: 0.0522229 (365)\ttotal: 1m 17s\tremaining: 33m 56s\n",
      "366:\tlearn: 0.0526658\ttest: 0.0522115\tbest: 0.0522115 (366)\ttotal: 1m 17s\tremaining: 33m 56s\n",
      "367:\tlearn: 0.0526641\ttest: 0.0522102\tbest: 0.0522102 (367)\ttotal: 1m 17s\tremaining: 33m 55s\n",
      "368:\tlearn: 0.0526635\ttest: 0.0522087\tbest: 0.0522087 (368)\ttotal: 1m 17s\tremaining: 33m 55s\n",
      "369:\tlearn: 0.0526616\ttest: 0.0522072\tbest: 0.0522072 (369)\ttotal: 1m 18s\tremaining: 33m 54s\n",
      "370:\tlearn: 0.0526592\ttest: 0.0521986\tbest: 0.0521986 (370)\ttotal: 1m 18s\tremaining: 33m 54s\n",
      "371:\tlearn: 0.0526301\ttest: 0.0521895\tbest: 0.0521895 (371)\ttotal: 1m 18s\tremaining: 33m 54s\n",
      "372:\tlearn: 0.0526283\ttest: 0.0521826\tbest: 0.0521826 (372)\ttotal: 1m 18s\tremaining: 33m 54s\n",
      "373:\tlearn: 0.0526283\ttest: 0.0521825\tbest: 0.0521825 (373)\ttotal: 1m 18s\tremaining: 33m 52s\n",
      "374:\tlearn: 0.0526095\ttest: 0.0521802\tbest: 0.0521802 (374)\ttotal: 1m 19s\tremaining: 33m 52s\n",
      "375:\tlearn: 0.0526238\ttest: 0.0521764\tbest: 0.0521764 (375)\ttotal: 1m 19s\tremaining: 33m 50s\n",
      "376:\tlearn: 0.0526240\ttest: 0.0521754\tbest: 0.0521754 (376)\ttotal: 1m 19s\tremaining: 33m 50s\n",
      "377:\tlearn: 0.0526225\ttest: 0.0521745\tbest: 0.0521745 (377)\ttotal: 1m 19s\tremaining: 33m 49s\n",
      "378:\tlearn: 0.0526218\ttest: 0.0521739\tbest: 0.0521739 (378)\ttotal: 1m 19s\tremaining: 33m 48s\n",
      "379:\tlearn: 0.0526209\ttest: 0.0521732\tbest: 0.0521732 (379)\ttotal: 1m 20s\tremaining: 33m 48s\n",
      "380:\tlearn: 0.0526198\ttest: 0.0521700\tbest: 0.0521700 (380)\ttotal: 1m 20s\tremaining: 33m 47s\n",
      "381:\tlearn: 0.0526116\ttest: 0.0521669\tbest: 0.0521669 (381)\ttotal: 1m 20s\tremaining: 33m 47s\n",
      "382:\tlearn: 0.0525933\ttest: 0.0521651\tbest: 0.0521651 (382)\ttotal: 1m 20s\tremaining: 33m 47s\n",
      "383:\tlearn: 0.0525926\ttest: 0.0521649\tbest: 0.0521649 (383)\ttotal: 1m 20s\tremaining: 33m 45s\n",
      "384:\tlearn: 0.0525921\ttest: 0.0521645\tbest: 0.0521645 (384)\ttotal: 1m 21s\tremaining: 33m 44s\n",
      "385:\tlearn: 0.0525917\ttest: 0.0521638\tbest: 0.0521638 (385)\ttotal: 1m 21s\tremaining: 33m 44s\n",
      "386:\tlearn: 0.0525906\ttest: 0.0521617\tbest: 0.0521617 (386)\ttotal: 1m 21s\tremaining: 33m 44s\n",
      "387:\tlearn: 0.0525901\ttest: 0.0521612\tbest: 0.0521612 (387)\ttotal: 1m 21s\tremaining: 33m 43s\n",
      "388:\tlearn: 0.0525890\ttest: 0.0521607\tbest: 0.0521607 (388)\ttotal: 1m 21s\tremaining: 33m 43s\n",
      "389:\tlearn: 0.0525882\ttest: 0.0521602\tbest: 0.0521602 (389)\ttotal: 1m 22s\tremaining: 33m 43s\n",
      "390:\tlearn: 0.0525900\ttest: 0.0521593\tbest: 0.0521593 (390)\ttotal: 1m 22s\tremaining: 33m 43s\n",
      "391:\tlearn: 0.0525897\ttest: 0.0521590\tbest: 0.0521590 (391)\ttotal: 1m 22s\tremaining: 33m 42s\n",
      "392:\tlearn: 0.0525894\ttest: 0.0521587\tbest: 0.0521587 (392)\ttotal: 1m 22s\tremaining: 33m 42s\n",
      "393:\tlearn: 0.0525888\ttest: 0.0521580\tbest: 0.0521580 (393)\ttotal: 1m 22s\tremaining: 33m 41s\n",
      "394:\tlearn: 0.0525870\ttest: 0.0521564\tbest: 0.0521564 (394)\ttotal: 1m 23s\tremaining: 33m 41s\n",
      "395:\tlearn: 0.0525866\ttest: 0.0521559\tbest: 0.0521559 (395)\ttotal: 1m 23s\tremaining: 33m 41s\n",
      "396:\tlearn: 0.0525860\ttest: 0.0521552\tbest: 0.0521552 (396)\ttotal: 1m 23s\tremaining: 33m 40s\n",
      "397:\tlearn: 0.0525849\ttest: 0.0521545\tbest: 0.0521545 (397)\ttotal: 1m 23s\tremaining: 33m 40s\n",
      "398:\tlearn: 0.0525868\ttest: 0.0521534\tbest: 0.0521534 (398)\ttotal: 1m 23s\tremaining: 33m 39s\n",
      "399:\tlearn: 0.0525866\ttest: 0.0521529\tbest: 0.0521529 (399)\ttotal: 1m 24s\tremaining: 33m 39s\n",
      "400:\tlearn: 0.0525836\ttest: 0.0521491\tbest: 0.0521491 (400)\ttotal: 1m 24s\tremaining: 33m 39s\n",
      "401:\tlearn: 0.0525818\ttest: 0.0521477\tbest: 0.0521477 (401)\ttotal: 1m 24s\tremaining: 33m 38s\n",
      "402:\tlearn: 0.0525809\ttest: 0.0521454\tbest: 0.0521454 (402)\ttotal: 1m 24s\tremaining: 33m 38s\n",
      "403:\tlearn: 0.0525836\ttest: 0.0521439\tbest: 0.0521439 (403)\ttotal: 1m 24s\tremaining: 33m 37s\n",
      "404:\tlearn: 0.0525846\ttest: 0.0521429\tbest: 0.0521429 (404)\ttotal: 1m 25s\tremaining: 33m 37s\n",
      "405:\tlearn: 0.0525793\ttest: 0.0521412\tbest: 0.0521412 (405)\ttotal: 1m 25s\tremaining: 33m 37s\n",
      "406:\tlearn: 0.0525797\ttest: 0.0521407\tbest: 0.0521407 (406)\ttotal: 1m 25s\tremaining: 33m 36s\n",
      "407:\tlearn: 0.0525787\ttest: 0.0521399\tbest: 0.0521399 (407)\ttotal: 1m 25s\tremaining: 33m 36s\n",
      "408:\tlearn: 0.0525785\ttest: 0.0521398\tbest: 0.0521398 (408)\ttotal: 1m 25s\tremaining: 33m 35s\n",
      "409:\tlearn: 0.0525797\ttest: 0.0521392\tbest: 0.0521392 (409)\ttotal: 1m 26s\tremaining: 33m 34s\n",
      "410:\tlearn: 0.0525778\ttest: 0.0521374\tbest: 0.0521374 (410)\ttotal: 1m 26s\tremaining: 33m 34s\n",
      "411:\tlearn: 0.0525778\ttest: 0.0521374\tbest: 0.0521374 (411)\ttotal: 1m 26s\tremaining: 33m 32s\n",
      "412:\tlearn: 0.0525775\ttest: 0.0521370\tbest: 0.0521370 (412)\ttotal: 1m 26s\tremaining: 33m 32s\n",
      "413:\tlearn: 0.0525753\ttest: 0.0521333\tbest: 0.0521333 (413)\ttotal: 1m 26s\tremaining: 33m 31s\n",
      "414:\tlearn: 0.0525749\ttest: 0.0521330\tbest: 0.0521330 (414)\ttotal: 1m 27s\tremaining: 33m 31s\n",
      "415:\tlearn: 0.0525726\ttest: 0.0521304\tbest: 0.0521304 (415)\ttotal: 1m 27s\tremaining: 33m 30s\n",
      "416:\tlearn: 0.0525751\ttest: 0.0521286\tbest: 0.0521286 (416)\ttotal: 1m 27s\tremaining: 33m 30s\n",
      "417:\tlearn: 0.0525761\ttest: 0.0521281\tbest: 0.0521281 (417)\ttotal: 1m 27s\tremaining: 33m 30s\n",
      "418:\tlearn: 0.0525744\ttest: 0.0521276\tbest: 0.0521276 (418)\ttotal: 1m 27s\tremaining: 33m 30s\n",
      "419:\tlearn: 0.0525733\ttest: 0.0521271\tbest: 0.0521271 (419)\ttotal: 1m 28s\tremaining: 33m 30s\n",
      "420:\tlearn: 0.0525720\ttest: 0.0521252\tbest: 0.0521252 (420)\ttotal: 1m 28s\tremaining: 33m 29s\n",
      "421:\tlearn: 0.0525733\ttest: 0.0521248\tbest: 0.0521248 (421)\ttotal: 1m 28s\tremaining: 33m 29s\n",
      "422:\tlearn: 0.0525717\ttest: 0.0521226\tbest: 0.0521226 (422)\ttotal: 1m 28s\tremaining: 33m 29s\n",
      "423:\tlearn: 0.0525711\ttest: 0.0521220\tbest: 0.0521220 (423)\ttotal: 1m 28s\tremaining: 33m 29s\n",
      "424:\tlearn: 0.0525690\ttest: 0.0521197\tbest: 0.0521197 (424)\ttotal: 1m 29s\tremaining: 33m 29s\n",
      "425:\tlearn: 0.0525679\ttest: 0.0521181\tbest: 0.0521181 (425)\ttotal: 1m 29s\tremaining: 33m 29s\n",
      "426:\tlearn: 0.0525459\ttest: 0.0521127\tbest: 0.0521127 (426)\ttotal: 1m 29s\tremaining: 33m 29s\n",
      "427:\tlearn: 0.0525687\ttest: 0.0521112\tbest: 0.0521112 (427)\ttotal: 1m 29s\tremaining: 33m 28s\n",
      "428:\tlearn: 0.0525683\ttest: 0.0521109\tbest: 0.0521109 (428)\ttotal: 1m 30s\tremaining: 33m 28s\n",
      "429:\tlearn: 0.0525679\ttest: 0.0521106\tbest: 0.0521106 (429)\ttotal: 1m 30s\tremaining: 33m 27s\n",
      "430:\tlearn: 0.0525677\ttest: 0.0521103\tbest: 0.0521103 (430)\ttotal: 1m 30s\tremaining: 33m 26s\n",
      "431:\tlearn: 0.0525465\ttest: 0.0521040\tbest: 0.0521040 (431)\ttotal: 1m 30s\tremaining: 33m 26s\n",
      "432:\tlearn: 0.0525458\ttest: 0.0521034\tbest: 0.0521034 (432)\ttotal: 1m 30s\tremaining: 33m 24s\n",
      "433:\tlearn: 0.0525453\ttest: 0.0521024\tbest: 0.0521024 (433)\ttotal: 1m 30s\tremaining: 33m 24s\n",
      "434:\tlearn: 0.0525301\ttest: 0.0520977\tbest: 0.0520977 (434)\ttotal: 1m 31s\tremaining: 33m 24s\n",
      "435:\tlearn: 0.0525296\ttest: 0.0520973\tbest: 0.0520973 (435)\ttotal: 1m 31s\tremaining: 33m 24s\n",
      "436:\tlearn: 0.0525303\ttest: 0.0520972\tbest: 0.0520972 (436)\ttotal: 1m 31s\tremaining: 33m 23s\n",
      "437:\tlearn: 0.0525296\ttest: 0.0520965\tbest: 0.0520965 (437)\ttotal: 1m 31s\tremaining: 33m 22s\n",
      "438:\tlearn: 0.0525276\ttest: 0.0520961\tbest: 0.0520961 (438)\ttotal: 1m 31s\tremaining: 33m 22s\n",
      "439:\tlearn: 0.0525293\ttest: 0.0520956\tbest: 0.0520956 (439)\ttotal: 1m 32s\tremaining: 33m 22s\n",
      "440:\tlearn: 0.0525293\ttest: 0.0520952\tbest: 0.0520952 (440)\ttotal: 1m 32s\tremaining: 33m 22s\n",
      "441:\tlearn: 0.0525286\ttest: 0.0520949\tbest: 0.0520949 (441)\ttotal: 1m 32s\tremaining: 33m 21s\n",
      "442:\tlearn: 0.0525279\ttest: 0.0520941\tbest: 0.0520941 (442)\ttotal: 1m 32s\tremaining: 33m 21s\n",
      "443:\tlearn: 0.0525274\ttest: 0.0520934\tbest: 0.0520934 (443)\ttotal: 1m 32s\tremaining: 33m 20s\n",
      "444:\tlearn: 0.0525272\ttest: 0.0520931\tbest: 0.0520931 (444)\ttotal: 1m 33s\tremaining: 33m 19s\n",
      "445:\tlearn: 0.0525263\ttest: 0.0520923\tbest: 0.0520923 (445)\ttotal: 1m 33s\tremaining: 33m 19s\n",
      "446:\tlearn: 0.0525254\ttest: 0.0520919\tbest: 0.0520919 (446)\ttotal: 1m 33s\tremaining: 33m 19s\n",
      "447:\tlearn: 0.0525269\ttest: 0.0520915\tbest: 0.0520915 (447)\ttotal: 1m 33s\tremaining: 33m 18s\n",
      "448:\tlearn: 0.0525264\ttest: 0.0520910\tbest: 0.0520910 (448)\ttotal: 1m 33s\tremaining: 33m 18s\n",
      "449:\tlearn: 0.0525286\ttest: 0.0520903\tbest: 0.0520903 (449)\ttotal: 1m 34s\tremaining: 33m 18s\n",
      "450:\tlearn: 0.0525277\ttest: 0.0520896\tbest: 0.0520896 (450)\ttotal: 1m 34s\tremaining: 33m 18s\n",
      "451:\tlearn: 0.0525258\ttest: 0.0520882\tbest: 0.0520882 (451)\ttotal: 1m 34s\tremaining: 33m 17s\n",
      "452:\tlearn: 0.0525181\ttest: 0.0520819\tbest: 0.0520819 (452)\ttotal: 1m 34s\tremaining: 33m 17s\n",
      "453:\tlearn: 0.0525186\ttest: 0.0520814\tbest: 0.0520814 (453)\ttotal: 1m 35s\tremaining: 33m 17s\n",
      "454:\tlearn: 0.0525164\ttest: 0.0520804\tbest: 0.0520804 (454)\ttotal: 1m 35s\tremaining: 33m 17s\n",
      "455:\tlearn: 0.0525167\ttest: 0.0520799\tbest: 0.0520799 (455)\ttotal: 1m 35s\tremaining: 33m 16s\n",
      "456:\tlearn: 0.0525184\ttest: 0.0520755\tbest: 0.0520755 (456)\ttotal: 1m 35s\tremaining: 33m 16s\n",
      "457:\tlearn: 0.0525168\ttest: 0.0520738\tbest: 0.0520738 (457)\ttotal: 1m 35s\tremaining: 33m 16s\n",
      "458:\tlearn: 0.0525088\ttest: 0.0520699\tbest: 0.0520699 (458)\ttotal: 1m 36s\tremaining: 33m 16s\n",
      "459:\tlearn: 0.0525115\ttest: 0.0520698\tbest: 0.0520698 (459)\ttotal: 1m 36s\tremaining: 33m 15s\n",
      "460:\tlearn: 0.0525113\ttest: 0.0520688\tbest: 0.0520688 (460)\ttotal: 1m 36s\tremaining: 33m 15s\n",
      "461:\tlearn: 0.0525106\ttest: 0.0520634\tbest: 0.0520634 (461)\ttotal: 1m 36s\tremaining: 33m 14s\n",
      "462:\tlearn: 0.0525074\ttest: 0.0520588\tbest: 0.0520588 (462)\ttotal: 1m 36s\tremaining: 33m 14s\n",
      "463:\tlearn: 0.0525044\ttest: 0.0520545\tbest: 0.0520545 (463)\ttotal: 1m 37s\tremaining: 33m 14s\n",
      "464:\tlearn: 0.0525044\ttest: 0.0520545\tbest: 0.0520545 (464)\ttotal: 1m 37s\tremaining: 33m 14s\n",
      "465:\tlearn: 0.0525007\ttest: 0.0520518\tbest: 0.0520518 (465)\ttotal: 1m 37s\tremaining: 33m 13s\n",
      "466:\tlearn: 0.0525003\ttest: 0.0520507\tbest: 0.0520507 (466)\ttotal: 1m 37s\tremaining: 33m 13s\n",
      "467:\tlearn: 0.0524999\ttest: 0.0520502\tbest: 0.0520502 (467)\ttotal: 1m 37s\tremaining: 33m 12s\n",
      "468:\tlearn: 0.0524998\ttest: 0.0520501\tbest: 0.0520501 (468)\ttotal: 1m 37s\tremaining: 33m 11s\n",
      "469:\tlearn: 0.0524994\ttest: 0.0520497\tbest: 0.0520497 (469)\ttotal: 1m 38s\tremaining: 33m 11s\n",
      "470:\tlearn: 0.0525003\ttest: 0.0520492\tbest: 0.0520492 (470)\ttotal: 1m 38s\tremaining: 33m 10s\n",
      "471:\tlearn: 0.0524984\ttest: 0.0520479\tbest: 0.0520479 (471)\ttotal: 1m 38s\tremaining: 33m 9s\n",
      "472:\tlearn: 0.0524988\ttest: 0.0520472\tbest: 0.0520472 (472)\ttotal: 1m 38s\tremaining: 33m 8s\n",
      "473:\tlearn: 0.0524975\ttest: 0.0520468\tbest: 0.0520468 (473)\ttotal: 1m 38s\tremaining: 33m 7s\n",
      "474:\tlearn: 0.0524980\ttest: 0.0520466\tbest: 0.0520466 (474)\ttotal: 1m 39s\tremaining: 33m 7s\n",
      "475:\tlearn: 0.0524962\ttest: 0.0520440\tbest: 0.0520440 (475)\ttotal: 1m 39s\tremaining: 33m 7s\n",
      "476:\tlearn: 0.0524959\ttest: 0.0520439\tbest: 0.0520439 (476)\ttotal: 1m 39s\tremaining: 33m 6s\n",
      "477:\tlearn: 0.0524939\ttest: 0.0520414\tbest: 0.0520414 (477)\ttotal: 1m 39s\tremaining: 33m 7s\n",
      "478:\tlearn: 0.0524933\ttest: 0.0520403\tbest: 0.0520403 (478)\ttotal: 1m 39s\tremaining: 33m 7s\n",
      "479:\tlearn: 0.0524944\ttest: 0.0520398\tbest: 0.0520398 (479)\ttotal: 1m 40s\tremaining: 33m 6s\n",
      "480:\tlearn: 0.0524942\ttest: 0.0520397\tbest: 0.0520397 (480)\ttotal: 1m 40s\tremaining: 33m 5s\n",
      "481:\tlearn: 0.0524910\ttest: 0.0520358\tbest: 0.0520358 (481)\ttotal: 1m 40s\tremaining: 33m 5s\n",
      "482:\tlearn: 0.0524896\ttest: 0.0520353\tbest: 0.0520353 (482)\ttotal: 1m 40s\tremaining: 33m 5s\n",
      "483:\tlearn: 0.0524896\ttest: 0.0520353\tbest: 0.0520353 (482)\ttotal: 1m 40s\tremaining: 33m 4s\n",
      "484:\tlearn: 0.0524887\ttest: 0.0520344\tbest: 0.0520344 (484)\ttotal: 1m 41s\tremaining: 33m 4s\n",
      "485:\tlearn: 0.0524882\ttest: 0.0520339\tbest: 0.0520339 (485)\ttotal: 1m 41s\tremaining: 33m 3s\n",
      "486:\tlearn: 0.0524887\ttest: 0.0520338\tbest: 0.0520338 (486)\ttotal: 1m 41s\tremaining: 33m 3s\n",
      "487:\tlearn: 0.0524887\ttest: 0.0520338\tbest: 0.0520338 (487)\ttotal: 1m 41s\tremaining: 33m 2s\n",
      "488:\tlearn: 0.0524919\ttest: 0.0520329\tbest: 0.0520329 (488)\ttotal: 1m 41s\tremaining: 33m 3s\n",
      "489:\tlearn: 0.0524915\ttest: 0.0520322\tbest: 0.0520322 (489)\ttotal: 1m 42s\tremaining: 33m 2s\n",
      "490:\tlearn: 0.0524913\ttest: 0.0520319\tbest: 0.0520319 (490)\ttotal: 1m 42s\tremaining: 33m 2s\n",
      "491:\tlearn: 0.0524900\ttest: 0.0520307\tbest: 0.0520307 (491)\ttotal: 1m 42s\tremaining: 33m 1s\n",
      "492:\tlearn: 0.0524897\ttest: 0.0520304\tbest: 0.0520304 (492)\ttotal: 1m 42s\tremaining: 33m 1s\n",
      "493:\tlearn: 0.0524890\ttest: 0.0520300\tbest: 0.0520300 (493)\ttotal: 1m 42s\tremaining: 33m\n",
      "494:\tlearn: 0.0524886\ttest: 0.0520296\tbest: 0.0520296 (494)\ttotal: 1m 43s\tremaining: 33m\n",
      "495:\tlearn: 0.0524883\ttest: 0.0520294\tbest: 0.0520294 (495)\ttotal: 1m 43s\tremaining: 33m\n",
      "496:\tlearn: 0.0524871\ttest: 0.0520277\tbest: 0.0520277 (496)\ttotal: 1m 43s\tremaining: 32m 59s\n",
      "497:\tlearn: 0.0524871\ttest: 0.0520276\tbest: 0.0520276 (497)\ttotal: 1m 43s\tremaining: 32m 58s\n",
      "498:\tlearn: 0.0524867\ttest: 0.0520271\tbest: 0.0520271 (498)\ttotal: 1m 43s\tremaining: 32m 58s\n",
      "499:\tlearn: 0.0524825\ttest: 0.0520244\tbest: 0.0520244 (499)\ttotal: 1m 44s\tremaining: 32m 58s\n",
      "500:\tlearn: 0.0524816\ttest: 0.0520240\tbest: 0.0520240 (500)\ttotal: 1m 44s\tremaining: 32m 58s\n",
      "501:\tlearn: 0.0524815\ttest: 0.0520238\tbest: 0.0520238 (501)\ttotal: 1m 44s\tremaining: 32m 57s\n",
      "502:\tlearn: 0.0524815\ttest: 0.0520238\tbest: 0.0520238 (501)\ttotal: 1m 44s\tremaining: 32m 56s\n",
      "503:\tlearn: 0.0524813\ttest: 0.0520235\tbest: 0.0520235 (503)\ttotal: 1m 44s\tremaining: 32m 56s\n",
      "504:\tlearn: 0.0524815\ttest: 0.0520228\tbest: 0.0520228 (504)\ttotal: 1m 45s\tremaining: 32m 55s\n",
      "505:\tlearn: 0.0524777\ttest: 0.0520194\tbest: 0.0520194 (505)\ttotal: 1m 45s\tremaining: 32m 55s\n",
      "506:\tlearn: 0.0524763\ttest: 0.0520194\tbest: 0.0520194 (506)\ttotal: 1m 45s\tremaining: 32m 54s\n",
      "507:\tlearn: 0.0524766\ttest: 0.0520189\tbest: 0.0520189 (507)\ttotal: 1m 45s\tremaining: 32m 54s\n",
      "508:\tlearn: 0.0524754\ttest: 0.0520180\tbest: 0.0520180 (508)\ttotal: 1m 45s\tremaining: 32m 54s\n",
      "509:\tlearn: 0.0524764\ttest: 0.0520170\tbest: 0.0520170 (509)\ttotal: 1m 46s\tremaining: 32m 53s\n",
      "510:\tlearn: 0.0524763\ttest: 0.0520170\tbest: 0.0520170 (510)\ttotal: 1m 46s\tremaining: 32m 53s\n",
      "511:\tlearn: 0.0524759\ttest: 0.0520166\tbest: 0.0520166 (511)\ttotal: 1m 46s\tremaining: 32m 53s\n",
      "512:\tlearn: 0.0524753\ttest: 0.0520161\tbest: 0.0520161 (512)\ttotal: 1m 46s\tremaining: 32m 52s\n",
      "513:\tlearn: 0.0524748\ttest: 0.0520153\tbest: 0.0520153 (513)\ttotal: 1m 46s\tremaining: 32m 52s\n",
      "514:\tlearn: 0.0524733\ttest: 0.0520133\tbest: 0.0520133 (514)\ttotal: 1m 47s\tremaining: 32m 51s\n",
      "515:\tlearn: 0.0524732\ttest: 0.0520128\tbest: 0.0520128 (515)\ttotal: 1m 47s\tremaining: 32m 51s\n",
      "516:\tlearn: 0.0524722\ttest: 0.0520115\tbest: 0.0520115 (516)\ttotal: 1m 47s\tremaining: 32m 50s\n",
      "517:\tlearn: 0.0524722\ttest: 0.0520115\tbest: 0.0520115 (517)\ttotal: 1m 47s\tremaining: 32m 50s\n",
      "518:\tlearn: 0.0524717\ttest: 0.0520110\tbest: 0.0520110 (518)\ttotal: 1m 47s\tremaining: 32m 49s\n",
      "519:\tlearn: 0.0524713\ttest: 0.0520106\tbest: 0.0520106 (519)\ttotal: 1m 48s\tremaining: 32m 49s\n",
      "520:\tlearn: 0.0524727\ttest: 0.0520097\tbest: 0.0520097 (520)\ttotal: 1m 48s\tremaining: 32m 49s\n",
      "521:\tlearn: 0.0524718\ttest: 0.0520097\tbest: 0.0520097 (521)\ttotal: 1m 48s\tremaining: 32m 48s\n",
      "522:\tlearn: 0.0524725\ttest: 0.0520095\tbest: 0.0520095 (522)\ttotal: 1m 48s\tremaining: 32m 48s\n",
      "523:\tlearn: 0.0524721\ttest: 0.0520092\tbest: 0.0520092 (523)\ttotal: 1m 48s\tremaining: 32m 47s\n",
      "524:\tlearn: 0.0524716\ttest: 0.0520086\tbest: 0.0520086 (524)\ttotal: 1m 49s\tremaining: 32m 47s\n",
      "525:\tlearn: 0.0524684\ttest: 0.0520049\tbest: 0.0520049 (525)\ttotal: 1m 49s\tremaining: 32m 46s\n",
      "526:\tlearn: 0.0524684\ttest: 0.0520049\tbest: 0.0520049 (526)\ttotal: 1m 49s\tremaining: 32m 46s\n",
      "527:\tlearn: 0.0524682\ttest: 0.0520047\tbest: 0.0520047 (527)\ttotal: 1m 49s\tremaining: 32m 45s\n",
      "528:\tlearn: 0.0524681\ttest: 0.0520042\tbest: 0.0520042 (528)\ttotal: 1m 49s\tremaining: 32m 45s\n",
      "529:\tlearn: 0.0524677\ttest: 0.0520039\tbest: 0.0520039 (529)\ttotal: 1m 49s\tremaining: 32m 44s\n",
      "530:\tlearn: 0.0524669\ttest: 0.0520032\tbest: 0.0520032 (530)\ttotal: 1m 50s\tremaining: 32m 45s\n",
      "531:\tlearn: 0.0524667\ttest: 0.0520031\tbest: 0.0520031 (531)\ttotal: 1m 50s\tremaining: 32m 43s\n",
      "532:\tlearn: 0.0524662\ttest: 0.0520028\tbest: 0.0520028 (532)\ttotal: 1m 50s\tremaining: 32m 43s\n",
      "533:\tlearn: 0.0524651\ttest: 0.0520015\tbest: 0.0520015 (533)\ttotal: 1m 50s\tremaining: 32m 42s\n",
      "534:\tlearn: 0.0524678\ttest: 0.0519985\tbest: 0.0519985 (534)\ttotal: 1m 50s\tremaining: 32m 42s\n",
      "535:\tlearn: 0.0524624\ttest: 0.0519940\tbest: 0.0519940 (535)\ttotal: 1m 51s\tremaining: 32m 41s\n",
      "536:\tlearn: 0.0524623\ttest: 0.0519939\tbest: 0.0519939 (536)\ttotal: 1m 51s\tremaining: 32m 40s\n",
      "537:\tlearn: 0.0524615\ttest: 0.0519931\tbest: 0.0519931 (537)\ttotal: 1m 51s\tremaining: 32m 40s\n",
      "538:\tlearn: 0.0524609\ttest: 0.0519929\tbest: 0.0519929 (538)\ttotal: 1m 51s\tremaining: 32m 40s\n",
      "539:\tlearn: 0.0524593\ttest: 0.0519888\tbest: 0.0519888 (539)\ttotal: 1m 51s\tremaining: 32m 40s\n",
      "540:\tlearn: 0.0524601\ttest: 0.0519876\tbest: 0.0519876 (540)\ttotal: 1m 52s\tremaining: 32m 39s\n",
      "541:\tlearn: 0.0524612\ttest: 0.0519852\tbest: 0.0519852 (541)\ttotal: 1m 52s\tremaining: 32m 39s\n",
      "542:\tlearn: 0.0524612\ttest: 0.0519852\tbest: 0.0519852 (542)\ttotal: 1m 52s\tremaining: 32m 39s\n",
      "543:\tlearn: 0.0524585\ttest: 0.0519828\tbest: 0.0519828 (543)\ttotal: 1m 52s\tremaining: 32m 38s\n",
      "544:\tlearn: 0.0524577\ttest: 0.0519819\tbest: 0.0519819 (544)\ttotal: 1m 52s\tremaining: 32m 38s\n",
      "545:\tlearn: 0.0524584\ttest: 0.0519819\tbest: 0.0519819 (545)\ttotal: 1m 53s\tremaining: 32m 37s\n",
      "546:\tlearn: 0.0524584\ttest: 0.0519819\tbest: 0.0519819 (546)\ttotal: 1m 53s\tremaining: 32m 37s\n",
      "547:\tlearn: 0.0524571\ttest: 0.0519804\tbest: 0.0519804 (547)\ttotal: 1m 53s\tremaining: 32m 37s\n",
      "548:\tlearn: 0.0524558\ttest: 0.0519793\tbest: 0.0519793 (548)\ttotal: 1m 53s\tremaining: 32m 37s\n",
      "549:\tlearn: 0.0524558\ttest: 0.0519793\tbest: 0.0519793 (549)\ttotal: 1m 53s\tremaining: 32m 36s\n",
      "550:\tlearn: 0.0524557\ttest: 0.0519792\tbest: 0.0519792 (550)\ttotal: 1m 54s\tremaining: 32m 36s\n",
      "551:\tlearn: 0.0524557\ttest: 0.0519792\tbest: 0.0519792 (550)\ttotal: 1m 54s\tremaining: 32m 35s\n",
      "552:\tlearn: 0.0524529\ttest: 0.0519759\tbest: 0.0519759 (552)\ttotal: 1m 54s\tremaining: 32m 35s\n",
      "553:\tlearn: 0.0524529\ttest: 0.0519759\tbest: 0.0519759 (553)\ttotal: 1m 54s\tremaining: 32m 34s\n",
      "554:\tlearn: 0.0524528\ttest: 0.0519755\tbest: 0.0519755 (554)\ttotal: 1m 54s\tremaining: 32m 33s\n",
      "555:\tlearn: 0.0524548\ttest: 0.0519745\tbest: 0.0519745 (555)\ttotal: 1m 55s\tremaining: 32m 33s\n",
      "556:\tlearn: 0.0524548\ttest: 0.0519745\tbest: 0.0519745 (556)\ttotal: 1m 55s\tremaining: 32m 32s\n",
      "557:\tlearn: 0.0524530\ttest: 0.0519734\tbest: 0.0519734 (557)\ttotal: 1m 55s\tremaining: 32m 32s\n",
      "558:\tlearn: 0.0524487\ttest: 0.0519704\tbest: 0.0519704 (558)\ttotal: 1m 55s\tremaining: 32m 32s\n",
      "559:\tlearn: 0.0524487\ttest: 0.0519704\tbest: 0.0519704 (559)\ttotal: 1m 55s\tremaining: 32m 31s\n",
      "560:\tlearn: 0.0524487\ttest: 0.0519704\tbest: 0.0519704 (560)\ttotal: 1m 55s\tremaining: 32m 31s\n",
      "561:\tlearn: 0.0524484\ttest: 0.0519701\tbest: 0.0519701 (561)\ttotal: 1m 56s\tremaining: 32m 31s\n",
      "562:\tlearn: 0.0524480\ttest: 0.0519697\tbest: 0.0519697 (562)\ttotal: 1m 56s\tremaining: 32m 31s\n",
      "563:\tlearn: 0.0524466\ttest: 0.0519686\tbest: 0.0519686 (563)\ttotal: 1m 56s\tremaining: 32m 31s\n",
      "564:\tlearn: 0.0524473\ttest: 0.0519673\tbest: 0.0519673 (564)\ttotal: 1m 56s\tremaining: 32m 30s\n",
      "565:\tlearn: 0.0524473\ttest: 0.0519673\tbest: 0.0519673 (564)\ttotal: 1m 56s\tremaining: 32m 30s\n",
      "566:\tlearn: 0.0524429\ttest: 0.0519634\tbest: 0.0519634 (566)\ttotal: 1m 57s\tremaining: 32m 30s\n",
      "567:\tlearn: 0.0524405\ttest: 0.0519578\tbest: 0.0519578 (567)\ttotal: 1m 57s\tremaining: 32m 29s\n",
      "568:\tlearn: 0.0524405\ttest: 0.0519578\tbest: 0.0519578 (567)\ttotal: 1m 57s\tremaining: 32m 29s\n",
      "569:\tlearn: 0.0524378\ttest: 0.0519541\tbest: 0.0519541 (569)\ttotal: 1m 57s\tremaining: 32m 29s\n",
      "570:\tlearn: 0.0524382\ttest: 0.0519533\tbest: 0.0519533 (570)\ttotal: 1m 57s\tremaining: 32m 28s\n",
      "571:\tlearn: 0.0524369\ttest: 0.0519521\tbest: 0.0519521 (571)\ttotal: 1m 58s\tremaining: 32m 28s\n",
      "572:\tlearn: 0.0524369\ttest: 0.0519521\tbest: 0.0519521 (572)\ttotal: 1m 58s\tremaining: 32m 27s\n",
      "573:\tlearn: 0.0524364\ttest: 0.0519516\tbest: 0.0519516 (573)\ttotal: 1m 58s\tremaining: 32m 27s\n",
      "574:\tlearn: 0.0524366\ttest: 0.0519516\tbest: 0.0519516 (574)\ttotal: 1m 58s\tremaining: 32m 26s\n",
      "575:\tlearn: 0.0524385\ttest: 0.0519510\tbest: 0.0519510 (575)\ttotal: 1m 58s\tremaining: 32m 26s\n",
      "576:\tlearn: 0.0524377\ttest: 0.0519501\tbest: 0.0519501 (576)\ttotal: 1m 59s\tremaining: 32m 25s\n",
      "577:\tlearn: 0.0524377\ttest: 0.0519501\tbest: 0.0519501 (577)\ttotal: 1m 59s\tremaining: 32m 24s\n",
      "578:\tlearn: 0.0524374\ttest: 0.0519500\tbest: 0.0519500 (578)\ttotal: 1m 59s\tremaining: 32m 24s\n",
      "579:\tlearn: 0.0524368\ttest: 0.0519494\tbest: 0.0519494 (579)\ttotal: 1m 59s\tremaining: 32m 24s\n",
      "580:\tlearn: 0.0524399\ttest: 0.0519488\tbest: 0.0519488 (580)\ttotal: 1m 59s\tremaining: 32m 23s\n",
      "581:\tlearn: 0.0524399\ttest: 0.0519488\tbest: 0.0519488 (581)\ttotal: 2m\tremaining: 32m 22s\n",
      "582:\tlearn: 0.0524398\ttest: 0.0519481\tbest: 0.0519481 (582)\ttotal: 2m\tremaining: 32m 22s\n",
      "583:\tlearn: 0.0524392\ttest: 0.0519477\tbest: 0.0519477 (583)\ttotal: 2m\tremaining: 32m 22s\n",
      "584:\tlearn: 0.0524385\ttest: 0.0519469\tbest: 0.0519469 (584)\ttotal: 2m\tremaining: 32m 21s\n",
      "585:\tlearn: 0.0524368\ttest: 0.0519431\tbest: 0.0519431 (585)\ttotal: 2m\tremaining: 32m 21s\n",
      "586:\tlearn: 0.0524362\ttest: 0.0519420\tbest: 0.0519420 (586)\ttotal: 2m 1s\tremaining: 32m 21s\n",
      "587:\tlearn: 0.0524166\ttest: 0.0519413\tbest: 0.0519413 (587)\ttotal: 2m 1s\tremaining: 32m 20s\n",
      "588:\tlearn: 0.0524179\ttest: 0.0519408\tbest: 0.0519408 (588)\ttotal: 2m 1s\tremaining: 32m 20s\n",
      "589:\tlearn: 0.0524170\ttest: 0.0519402\tbest: 0.0519402 (589)\ttotal: 2m 1s\tremaining: 32m 20s\n",
      "590:\tlearn: 0.0524165\ttest: 0.0519398\tbest: 0.0519398 (590)\ttotal: 2m 1s\tremaining: 32m 20s\n",
      "591:\tlearn: 0.0524139\ttest: 0.0519357\tbest: 0.0519357 (591)\ttotal: 2m 2s\tremaining: 32m 19s\n",
      "592:\tlearn: 0.0524304\ttest: 0.0519348\tbest: 0.0519348 (592)\ttotal: 2m 2s\tremaining: 32m 19s\n",
      "593:\tlearn: 0.0524132\ttest: 0.0519344\tbest: 0.0519344 (593)\ttotal: 2m 2s\tremaining: 32m 18s\n",
      "594:\tlearn: 0.0524161\ttest: 0.0519339\tbest: 0.0519339 (594)\ttotal: 2m 2s\tremaining: 32m 18s\n",
      "595:\tlearn: 0.0524163\ttest: 0.0519339\tbest: 0.0519339 (595)\ttotal: 2m 2s\tremaining: 32m 17s\n",
      "596:\tlearn: 0.0524161\ttest: 0.0519338\tbest: 0.0519338 (596)\ttotal: 2m 3s\tremaining: 32m 17s\n",
      "597:\tlearn: 0.0524136\ttest: 0.0519334\tbest: 0.0519334 (597)\ttotal: 2m 3s\tremaining: 32m 17s\n",
      "598:\tlearn: 0.0524136\ttest: 0.0519321\tbest: 0.0519321 (598)\ttotal: 2m 3s\tremaining: 32m 16s\n",
      "599:\tlearn: 0.0524154\ttest: 0.0519316\tbest: 0.0519316 (599)\ttotal: 2m 3s\tremaining: 32m 15s\n",
      "600:\tlearn: 0.0524152\ttest: 0.0519315\tbest: 0.0519315 (600)\ttotal: 2m 3s\tremaining: 32m 15s\n",
      "601:\tlearn: 0.0524150\ttest: 0.0519312\tbest: 0.0519312 (601)\ttotal: 2m 3s\tremaining: 32m 15s\n",
      "602:\tlearn: 0.0524148\ttest: 0.0519311\tbest: 0.0519311 (602)\ttotal: 2m 4s\tremaining: 32m 15s\n",
      "603:\tlearn: 0.0524145\ttest: 0.0519309\tbest: 0.0519309 (603)\ttotal: 2m 4s\tremaining: 32m 14s\n",
      "604:\tlearn: 0.0524139\ttest: 0.0519293\tbest: 0.0519293 (604)\ttotal: 2m 4s\tremaining: 32m 14s\n",
      "605:\tlearn: 0.0524128\ttest: 0.0519288\tbest: 0.0519288 (605)\ttotal: 2m 4s\tremaining: 32m 14s\n",
      "606:\tlearn: 0.0524058\ttest: 0.0519280\tbest: 0.0519280 (606)\ttotal: 2m 4s\tremaining: 32m 13s\n",
      "607:\tlearn: 0.0524058\ttest: 0.0519279\tbest: 0.0519279 (607)\ttotal: 2m 5s\tremaining: 32m 13s\n",
      "608:\tlearn: 0.0524099\ttest: 0.0519269\tbest: 0.0519269 (608)\ttotal: 2m 5s\tremaining: 32m 13s\n",
      "609:\tlearn: 0.0524093\ttest: 0.0519264\tbest: 0.0519264 (609)\ttotal: 2m 5s\tremaining: 32m 13s\n",
      "610:\tlearn: 0.0524093\ttest: 0.0519263\tbest: 0.0519263 (610)\ttotal: 2m 5s\tremaining: 32m 12s\n",
      "611:\tlearn: 0.0524036\ttest: 0.0519258\tbest: 0.0519258 (611)\ttotal: 2m 5s\tremaining: 32m 11s\n",
      "612:\tlearn: 0.0523982\ttest: 0.0519254\tbest: 0.0519254 (612)\ttotal: 2m 6s\tremaining: 32m 11s\n",
      "613:\tlearn: 0.0524010\ttest: 0.0519249\tbest: 0.0519249 (613)\ttotal: 2m 6s\tremaining: 32m 10s\n",
      "614:\tlearn: 0.0523979\ttest: 0.0519245\tbest: 0.0519245 (614)\ttotal: 2m 6s\tremaining: 32m 10s\n",
      "615:\tlearn: 0.0524008\ttest: 0.0519234\tbest: 0.0519234 (615)\ttotal: 2m 6s\tremaining: 32m 9s\n",
      "616:\tlearn: 0.0524024\ttest: 0.0519230\tbest: 0.0519230 (616)\ttotal: 2m 6s\tremaining: 32m 9s\n",
      "617:\tlearn: 0.0524019\ttest: 0.0519227\tbest: 0.0519227 (617)\ttotal: 2m 7s\tremaining: 32m 9s\n",
      "618:\tlearn: 0.0524019\ttest: 0.0519226\tbest: 0.0519226 (618)\ttotal: 2m 7s\tremaining: 32m 8s\n",
      "619:\tlearn: 0.0524014\ttest: 0.0519215\tbest: 0.0519215 (619)\ttotal: 2m 7s\tremaining: 32m 8s\n",
      "620:\tlearn: 0.0524021\ttest: 0.0519212\tbest: 0.0519212 (620)\ttotal: 2m 7s\tremaining: 32m 7s\n",
      "621:\tlearn: 0.0524017\ttest: 0.0519210\tbest: 0.0519210 (621)\ttotal: 2m 7s\tremaining: 32m 7s\n",
      "622:\tlearn: 0.0524013\ttest: 0.0519206\tbest: 0.0519206 (622)\ttotal: 2m 8s\tremaining: 32m 7s\n",
      "623:\tlearn: 0.0524014\ttest: 0.0519200\tbest: 0.0519200 (623)\ttotal: 2m 8s\tremaining: 32m 7s\n",
      "624:\tlearn: 0.0524022\ttest: 0.0519200\tbest: 0.0519200 (624)\ttotal: 2m 8s\tremaining: 32m 6s\n",
      "625:\tlearn: 0.0524024\ttest: 0.0519197\tbest: 0.0519197 (625)\ttotal: 2m 8s\tremaining: 32m 6s\n",
      "626:\tlearn: 0.0524015\ttest: 0.0519194\tbest: 0.0519194 (626)\ttotal: 2m 8s\tremaining: 32m 5s\n",
      "627:\tlearn: 0.0524020\ttest: 0.0519193\tbest: 0.0519193 (627)\ttotal: 2m 9s\tremaining: 32m 5s\n",
      "628:\tlearn: 0.0524020\ttest: 0.0519193\tbest: 0.0519193 (628)\ttotal: 2m 9s\tremaining: 32m 4s\n",
      "629:\tlearn: 0.0523978\ttest: 0.0519190\tbest: 0.0519190 (629)\ttotal: 2m 9s\tremaining: 32m 3s\n",
      "630:\tlearn: 0.0523979\ttest: 0.0519188\tbest: 0.0519188 (630)\ttotal: 2m 9s\tremaining: 32m 3s\n",
      "631:\tlearn: 0.0523981\ttest: 0.0519188\tbest: 0.0519188 (631)\ttotal: 2m 9s\tremaining: 32m 2s\n",
      "632:\tlearn: 0.0523980\ttest: 0.0519174\tbest: 0.0519174 (632)\ttotal: 2m 9s\tremaining: 32m 2s\n",
      "633:\tlearn: 0.0523980\ttest: 0.0519174\tbest: 0.0519174 (633)\ttotal: 2m 10s\tremaining: 32m 1s\n",
      "634:\tlearn: 0.0523977\ttest: 0.0519174\tbest: 0.0519174 (634)\ttotal: 2m 10s\tremaining: 32m 1s\n",
      "635:\tlearn: 0.0523972\ttest: 0.0519168\tbest: 0.0519168 (635)\ttotal: 2m 10s\tremaining: 32m\n",
      "636:\tlearn: 0.0523970\ttest: 0.0519153\tbest: 0.0519153 (636)\ttotal: 2m 10s\tremaining: 32m\n",
      "637:\tlearn: 0.0523975\ttest: 0.0519148\tbest: 0.0519148 (637)\ttotal: 2m 10s\tremaining: 31m 59s\n",
      "638:\tlearn: 0.0524006\ttest: 0.0519144\tbest: 0.0519144 (638)\ttotal: 2m 11s\tremaining: 31m 59s\n",
      "639:\tlearn: 0.0524016\ttest: 0.0519141\tbest: 0.0519141 (639)\ttotal: 2m 11s\tremaining: 31m 58s\n",
      "640:\tlearn: 0.0523994\ttest: 0.0519137\tbest: 0.0519137 (640)\ttotal: 2m 11s\tremaining: 31m 58s\n",
      "641:\tlearn: 0.0524005\ttest: 0.0519132\tbest: 0.0519132 (641)\ttotal: 2m 11s\tremaining: 31m 58s\n",
      "642:\tlearn: 0.0524035\ttest: 0.0519127\tbest: 0.0519127 (642)\ttotal: 2m 11s\tremaining: 31m 57s\n",
      "643:\tlearn: 0.0524035\ttest: 0.0519125\tbest: 0.0519125 (643)\ttotal: 2m 12s\tremaining: 31m 57s\n",
      "644:\tlearn: 0.0524028\ttest: 0.0519121\tbest: 0.0519121 (644)\ttotal: 2m 12s\tremaining: 31m 57s\n",
      "645:\tlearn: 0.0524028\ttest: 0.0519115\tbest: 0.0519115 (645)\ttotal: 2m 12s\tremaining: 31m 56s\n",
      "646:\tlearn: 0.0524028\ttest: 0.0519115\tbest: 0.0519115 (645)\ttotal: 2m 12s\tremaining: 31m 55s\n",
      "647:\tlearn: 0.0524018\ttest: 0.0519112\tbest: 0.0519112 (647)\ttotal: 2m 12s\tremaining: 31m 55s\n",
      "648:\tlearn: 0.0523954\ttest: 0.0519111\tbest: 0.0519111 (648)\ttotal: 2m 12s\tremaining: 31m 55s\n",
      "649:\tlearn: 0.0523976\ttest: 0.0519090\tbest: 0.0519090 (649)\ttotal: 2m 13s\tremaining: 31m 55s\n",
      "650:\tlearn: 0.0523950\ttest: 0.0519079\tbest: 0.0519079 (650)\ttotal: 2m 13s\tremaining: 31m 55s\n",
      "651:\tlearn: 0.0523944\ttest: 0.0519075\tbest: 0.0519075 (651)\ttotal: 2m 13s\tremaining: 31m 55s\n",
      "652:\tlearn: 0.0523940\ttest: 0.0519069\tbest: 0.0519069 (652)\ttotal: 2m 13s\tremaining: 31m 54s\n",
      "653:\tlearn: 0.0523942\ttest: 0.0519065\tbest: 0.0519065 (653)\ttotal: 2m 13s\tremaining: 31m 54s\n",
      "654:\tlearn: 0.0523937\ttest: 0.0519061\tbest: 0.0519061 (654)\ttotal: 2m 14s\tremaining: 31m 54s\n",
      "655:\tlearn: 0.0523923\ttest: 0.0519053\tbest: 0.0519053 (655)\ttotal: 2m 14s\tremaining: 31m 53s\n",
      "656:\tlearn: 0.0523922\ttest: 0.0519048\tbest: 0.0519048 (656)\ttotal: 2m 14s\tremaining: 31m 53s\n",
      "657:\tlearn: 0.0523916\ttest: 0.0519037\tbest: 0.0519037 (657)\ttotal: 2m 14s\tremaining: 31m 53s\n",
      "658:\tlearn: 0.0523914\ttest: 0.0519033\tbest: 0.0519033 (658)\ttotal: 2m 14s\tremaining: 31m 52s\n",
      "659:\tlearn: 0.0523919\ttest: 0.0519033\tbest: 0.0519033 (659)\ttotal: 2m 15s\tremaining: 31m 52s\n",
      "660:\tlearn: 0.0523907\ttest: 0.0519030\tbest: 0.0519030 (660)\ttotal: 2m 15s\tremaining: 31m 51s\n",
      "661:\tlearn: 0.0523905\ttest: 0.0519028\tbest: 0.0519028 (661)\ttotal: 2m 15s\tremaining: 31m 51s\n",
      "662:\tlearn: 0.0523911\ttest: 0.0519027\tbest: 0.0519027 (662)\ttotal: 2m 15s\tremaining: 31m 50s\n",
      "663:\tlearn: 0.0523910\ttest: 0.0519027\tbest: 0.0519027 (663)\ttotal: 2m 15s\tremaining: 31m 50s\n",
      "664:\tlearn: 0.0523904\ttest: 0.0519016\tbest: 0.0519016 (664)\ttotal: 2m 16s\tremaining: 31m 50s\n",
      "665:\tlearn: 0.0523899\ttest: 0.0519016\tbest: 0.0519016 (665)\ttotal: 2m 16s\tremaining: 31m 49s\n",
      "666:\tlearn: 0.0523904\ttest: 0.0519012\tbest: 0.0519012 (666)\ttotal: 2m 16s\tremaining: 31m 48s\n",
      "667:\tlearn: 0.0523913\ttest: 0.0519010\tbest: 0.0519010 (667)\ttotal: 2m 16s\tremaining: 31m 48s\n",
      "668:\tlearn: 0.0523915\ttest: 0.0518998\tbest: 0.0518998 (668)\ttotal: 2m 16s\tremaining: 31m 47s\n",
      "669:\tlearn: 0.0523915\ttest: 0.0518998\tbest: 0.0518998 (669)\ttotal: 2m 16s\tremaining: 31m 47s\n",
      "670:\tlearn: 0.0523912\ttest: 0.0518994\tbest: 0.0518994 (670)\ttotal: 2m 17s\tremaining: 31m 47s\n",
      "671:\tlearn: 0.0523943\ttest: 0.0518990\tbest: 0.0518990 (671)\ttotal: 2m 17s\tremaining: 31m 46s\n",
      "672:\tlearn: 0.0523422\ttest: 0.0518989\tbest: 0.0518989 (672)\ttotal: 2m 17s\tremaining: 31m 45s\n",
      "673:\tlearn: 0.0523428\ttest: 0.0518986\tbest: 0.0518986 (673)\ttotal: 2m 17s\tremaining: 31m 45s\n",
      "674:\tlearn: 0.0523393\ttest: 0.0518948\tbest: 0.0518948 (674)\ttotal: 2m 17s\tremaining: 31m 45s\n",
      "675:\tlearn: 0.0523385\ttest: 0.0518945\tbest: 0.0518945 (675)\ttotal: 2m 18s\tremaining: 31m 45s\n",
      "676:\tlearn: 0.0523376\ttest: 0.0518920\tbest: 0.0518920 (676)\ttotal: 2m 18s\tremaining: 31m 45s\n",
      "677:\tlearn: 0.0523381\ttest: 0.0518919\tbest: 0.0518919 (677)\ttotal: 2m 18s\tremaining: 31m 43s\n",
      "678:\tlearn: 0.0523372\ttest: 0.0518911\tbest: 0.0518911 (678)\ttotal: 2m 18s\tremaining: 31m 43s\n",
      "679:\tlearn: 0.0523356\ttest: 0.0518905\tbest: 0.0518905 (679)\ttotal: 2m 18s\tremaining: 31m 43s\n",
      "680:\tlearn: 0.0523353\ttest: 0.0518904\tbest: 0.0518904 (680)\ttotal: 2m 19s\tremaining: 31m 43s\n",
      "681:\tlearn: 0.0523350\ttest: 0.0518903\tbest: 0.0518903 (681)\ttotal: 2m 19s\tremaining: 31m 43s\n",
      "682:\tlearn: 0.0523343\ttest: 0.0518899\tbest: 0.0518899 (682)\ttotal: 2m 19s\tremaining: 31m 42s\n",
      "683:\tlearn: 0.0523343\ttest: 0.0518899\tbest: 0.0518899 (683)\ttotal: 2m 19s\tremaining: 31m 41s\n",
      "684:\tlearn: 0.0523366\ttest: 0.0518893\tbest: 0.0518893 (684)\ttotal: 2m 19s\tremaining: 31m 41s\n",
      "685:\tlearn: 0.0523361\ttest: 0.0518888\tbest: 0.0518888 (685)\ttotal: 2m 20s\tremaining: 31m 41s\n",
      "686:\tlearn: 0.0523361\ttest: 0.0518888\tbest: 0.0518888 (686)\ttotal: 2m 20s\tremaining: 31m 40s\n",
      "687:\tlearn: 0.0523371\ttest: 0.0518884\tbest: 0.0518884 (687)\ttotal: 2m 20s\tremaining: 31m 40s\n",
      "688:\tlearn: 0.0523366\ttest: 0.0518879\tbest: 0.0518879 (688)\ttotal: 2m 20s\tremaining: 31m 40s\n",
      "689:\tlearn: 0.0523339\ttest: 0.0518878\tbest: 0.0518878 (689)\ttotal: 2m 20s\tremaining: 31m 39s\n",
      "690:\tlearn: 0.0523339\ttest: 0.0518878\tbest: 0.0518878 (690)\ttotal: 2m 20s\tremaining: 31m 38s\n",
      "691:\tlearn: 0.0523335\ttest: 0.0518875\tbest: 0.0518875 (691)\ttotal: 2m 21s\tremaining: 31m 38s\n",
      "692:\tlearn: 0.0523334\ttest: 0.0518874\tbest: 0.0518874 (692)\ttotal: 2m 21s\tremaining: 31m 38s\n",
      "693:\tlearn: 0.0523334\ttest: 0.0518874\tbest: 0.0518874 (693)\ttotal: 2m 21s\tremaining: 31m 37s\n",
      "694:\tlearn: 0.0523282\ttest: 0.0518834\tbest: 0.0518834 (694)\ttotal: 2m 21s\tremaining: 31m 37s\n",
      "695:\tlearn: 0.0523331\ttest: 0.0518831\tbest: 0.0518831 (695)\ttotal: 2m 21s\tremaining: 31m 37s\n",
      "696:\tlearn: 0.0523325\ttest: 0.0518828\tbest: 0.0518828 (696)\ttotal: 2m 22s\tremaining: 31m 36s\n",
      "697:\tlearn: 0.0523324\ttest: 0.0518827\tbest: 0.0518827 (697)\ttotal: 2m 22s\tremaining: 31m 36s\n",
      "698:\tlearn: 0.0523314\ttest: 0.0518811\tbest: 0.0518811 (698)\ttotal: 2m 22s\tremaining: 31m 35s\n",
      "699:\tlearn: 0.0523307\ttest: 0.0518806\tbest: 0.0518806 (699)\ttotal: 2m 22s\tremaining: 31m 35s\n",
      "700:\tlearn: 0.0523305\ttest: 0.0518804\tbest: 0.0518804 (700)\ttotal: 2m 22s\tremaining: 31m 35s\n",
      "701:\tlearn: 0.0523276\ttest: 0.0518800\tbest: 0.0518800 (701)\ttotal: 2m 23s\tremaining: 31m 35s\n",
      "702:\tlearn: 0.0523265\ttest: 0.0518798\tbest: 0.0518798 (702)\ttotal: 2m 23s\tremaining: 31m 35s\n",
      "703:\tlearn: 0.0523259\ttest: 0.0518788\tbest: 0.0518788 (703)\ttotal: 2m 23s\tremaining: 31m 35s\n",
      "704:\tlearn: 0.0523255\ttest: 0.0518785\tbest: 0.0518785 (704)\ttotal: 2m 23s\tremaining: 31m 34s\n",
      "705:\tlearn: 0.0523252\ttest: 0.0518782\tbest: 0.0518782 (705)\ttotal: 2m 23s\tremaining: 31m 34s\n",
      "706:\tlearn: 0.0523251\ttest: 0.0518781\tbest: 0.0518781 (706)\ttotal: 2m 24s\tremaining: 31m 34s\n",
      "707:\tlearn: 0.0523244\ttest: 0.0518776\tbest: 0.0518776 (707)\ttotal: 2m 24s\tremaining: 31m 34s\n",
      "708:\tlearn: 0.0523240\ttest: 0.0518759\tbest: 0.0518759 (708)\ttotal: 2m 24s\tremaining: 31m 34s\n",
      "709:\tlearn: 0.0523240\ttest: 0.0518759\tbest: 0.0518759 (709)\ttotal: 2m 24s\tremaining: 31m 33s\n",
      "710:\tlearn: 0.0523238\ttest: 0.0518754\tbest: 0.0518754 (710)\ttotal: 2m 24s\tremaining: 31m 33s\n",
      "711:\tlearn: 0.0523241\ttest: 0.0518742\tbest: 0.0518742 (711)\ttotal: 2m 25s\tremaining: 31m 33s\n",
      "712:\tlearn: 0.0523247\ttest: 0.0518742\tbest: 0.0518742 (712)\ttotal: 2m 25s\tremaining: 31m 32s\n",
      "713:\tlearn: 0.0523239\ttest: 0.0518742\tbest: 0.0518742 (713)\ttotal: 2m 25s\tremaining: 31m 32s\n",
      "714:\tlearn: 0.0523239\ttest: 0.0518742\tbest: 0.0518742 (714)\ttotal: 2m 25s\tremaining: 31m 31s\n",
      "715:\tlearn: 0.0523239\ttest: 0.0518742\tbest: 0.0518742 (715)\ttotal: 2m 25s\tremaining: 31m 31s\n",
      "716:\tlearn: 0.0523236\ttest: 0.0518739\tbest: 0.0518739 (716)\ttotal: 2m 26s\tremaining: 31m 30s\n",
      "717:\tlearn: 0.0523235\ttest: 0.0518737\tbest: 0.0518737 (717)\ttotal: 2m 26s\tremaining: 31m 30s\n",
      "718:\tlearn: 0.0523233\ttest: 0.0518729\tbest: 0.0518729 (718)\ttotal: 2m 26s\tremaining: 31m 30s\n",
      "719:\tlearn: 0.0523233\ttest: 0.0518729\tbest: 0.0518729 (719)\ttotal: 2m 26s\tremaining: 31m 29s\n",
      "720:\tlearn: 0.0523232\ttest: 0.0518729\tbest: 0.0518729 (720)\ttotal: 2m 26s\tremaining: 31m 29s\n",
      "721:\tlearn: 0.0523233\ttest: 0.0518729\tbest: 0.0518729 (721)\ttotal: 2m 26s\tremaining: 31m 28s\n",
      "722:\tlearn: 0.0523228\ttest: 0.0518721\tbest: 0.0518721 (722)\ttotal: 2m 27s\tremaining: 31m 28s\n",
      "723:\tlearn: 0.0523228\ttest: 0.0518721\tbest: 0.0518721 (723)\ttotal: 2m 27s\tremaining: 31m 28s\n",
      "724:\tlearn: 0.0523229\ttest: 0.0518721\tbest: 0.0518721 (724)\ttotal: 2m 27s\tremaining: 31m 27s\n",
      "725:\tlearn: 0.0523239\ttest: 0.0518720\tbest: 0.0518720 (725)\ttotal: 2m 27s\tremaining: 31m 27s\n",
      "726:\tlearn: 0.0523226\ttest: 0.0518718\tbest: 0.0518718 (726)\ttotal: 2m 27s\tremaining: 31m 26s\n",
      "727:\tlearn: 0.0523223\ttest: 0.0518709\tbest: 0.0518709 (727)\ttotal: 2m 28s\tremaining: 31m 26s\n",
      "728:\tlearn: 0.0523237\ttest: 0.0518704\tbest: 0.0518704 (728)\ttotal: 2m 28s\tremaining: 31m 25s\n",
      "729:\tlearn: 0.0523226\ttest: 0.0518698\tbest: 0.0518698 (729)\ttotal: 2m 28s\tremaining: 31m 25s\n",
      "730:\tlearn: 0.0523226\ttest: 0.0518698\tbest: 0.0518698 (730)\ttotal: 2m 28s\tremaining: 31m 25s\n",
      "731:\tlearn: 0.0523231\ttest: 0.0518694\tbest: 0.0518694 (731)\ttotal: 2m 28s\tremaining: 31m 24s\n",
      "732:\tlearn: 0.0523231\ttest: 0.0518694\tbest: 0.0518694 (732)\ttotal: 2m 29s\tremaining: 31m 23s\n",
      "733:\tlearn: 0.0523231\ttest: 0.0518693\tbest: 0.0518693 (733)\ttotal: 2m 29s\tremaining: 31m 23s\n",
      "734:\tlearn: 0.0523231\ttest: 0.0518692\tbest: 0.0518692 (734)\ttotal: 2m 29s\tremaining: 31m 22s\n",
      "735:\tlearn: 0.0523231\ttest: 0.0518692\tbest: 0.0518692 (734)\ttotal: 2m 29s\tremaining: 31m 22s\n",
      "736:\tlearn: 0.0523231\ttest: 0.0518692\tbest: 0.0518692 (736)\ttotal: 2m 29s\tremaining: 31m 21s\n",
      "737:\tlearn: 0.0523231\ttest: 0.0518692\tbest: 0.0518692 (737)\ttotal: 2m 29s\tremaining: 31m 20s\n",
      "738:\tlearn: 0.0523228\ttest: 0.0518690\tbest: 0.0518690 (738)\ttotal: 2m 30s\tremaining: 31m 20s\n",
      "739:\tlearn: 0.0523229\ttest: 0.0518689\tbest: 0.0518689 (739)\ttotal: 2m 30s\tremaining: 31m 19s\n",
      "740:\tlearn: 0.0523229\ttest: 0.0518689\tbest: 0.0518689 (739)\ttotal: 2m 30s\tremaining: 31m 18s\n",
      "741:\tlearn: 0.0523229\ttest: 0.0518689\tbest: 0.0518689 (739)\ttotal: 2m 30s\tremaining: 31m 18s\n",
      "742:\tlearn: 0.0523227\ttest: 0.0518687\tbest: 0.0518687 (742)\ttotal: 2m 30s\tremaining: 31m 17s\n",
      "743:\tlearn: 0.0523227\ttest: 0.0518687\tbest: 0.0518687 (743)\ttotal: 2m 30s\tremaining: 31m 17s\n",
      "744:\tlearn: 0.0523227\ttest: 0.0518684\tbest: 0.0518684 (744)\ttotal: 2m 31s\tremaining: 31m 16s\n",
      "745:\tlearn: 0.0523245\ttest: 0.0518681\tbest: 0.0518681 (745)\ttotal: 2m 31s\tremaining: 31m 15s\n",
      "746:\tlearn: 0.0523244\ttest: 0.0518678\tbest: 0.0518678 (746)\ttotal: 2m 31s\tremaining: 31m 15s\n",
      "747:\tlearn: 0.0523242\ttest: 0.0518676\tbest: 0.0518676 (747)\ttotal: 2m 31s\tremaining: 31m 15s\n",
      "748:\tlearn: 0.0523243\ttest: 0.0518675\tbest: 0.0518675 (748)\ttotal: 2m 31s\tremaining: 31m 14s\n",
      "749:\tlearn: 0.0523248\ttest: 0.0518668\tbest: 0.0518668 (749)\ttotal: 2m 32s\tremaining: 31m 14s\n",
      "750:\tlearn: 0.0523242\ttest: 0.0518664\tbest: 0.0518664 (750)\ttotal: 2m 32s\tremaining: 31m 14s\n",
      "751:\tlearn: 0.0523242\ttest: 0.0518664\tbest: 0.0518664 (750)\ttotal: 2m 32s\tremaining: 31m 13s\n",
      "752:\tlearn: 0.0523242\ttest: 0.0518664\tbest: 0.0518664 (750)\ttotal: 2m 32s\tremaining: 31m 12s\n",
      "753:\tlearn: 0.0523242\ttest: 0.0518664\tbest: 0.0518664 (753)\ttotal: 2m 32s\tremaining: 31m 12s\n",
      "754:\tlearn: 0.0523242\ttest: 0.0518664\tbest: 0.0518664 (754)\ttotal: 2m 32s\tremaining: 31m 11s\n",
      "755:\tlearn: 0.0523240\ttest: 0.0518663\tbest: 0.0518663 (755)\ttotal: 2m 33s\tremaining: 31m 11s\n",
      "756:\tlearn: 0.0523240\ttest: 0.0518663\tbest: 0.0518663 (756)\ttotal: 2m 33s\tremaining: 31m 11s\n",
      "757:\tlearn: 0.0523243\ttest: 0.0518663\tbest: 0.0518663 (757)\ttotal: 2m 33s\tremaining: 31m 10s\n",
      "758:\tlearn: 0.0523242\ttest: 0.0518662\tbest: 0.0518662 (758)\ttotal: 2m 33s\tremaining: 31m 10s\n",
      "759:\tlearn: 0.0523237\ttest: 0.0518657\tbest: 0.0518657 (759)\ttotal: 2m 33s\tremaining: 31m 10s\n",
      "760:\tlearn: 0.0523237\ttest: 0.0518657\tbest: 0.0518657 (760)\ttotal: 2m 34s\tremaining: 31m 9s\n",
      "761:\tlearn: 0.0523229\ttest: 0.0518653\tbest: 0.0518653 (761)\ttotal: 2m 34s\tremaining: 31m 9s\n",
      "762:\tlearn: 0.0523227\ttest: 0.0518652\tbest: 0.0518652 (762)\ttotal: 2m 34s\tremaining: 31m 9s\n",
      "763:\tlearn: 0.0523240\ttest: 0.0518649\tbest: 0.0518649 (763)\ttotal: 2m 34s\tremaining: 31m 9s\n",
      "764:\tlearn: 0.0523240\ttest: 0.0518649\tbest: 0.0518649 (764)\ttotal: 2m 34s\tremaining: 31m 8s\n",
      "765:\tlearn: 0.0523240\ttest: 0.0518649\tbest: 0.0518649 (764)\ttotal: 2m 34s\tremaining: 31m 7s\n",
      "766:\tlearn: 0.0523215\ttest: 0.0518646\tbest: 0.0518646 (766)\ttotal: 2m 35s\tremaining: 31m 7s\n",
      "767:\tlearn: 0.0523212\ttest: 0.0518644\tbest: 0.0518644 (767)\ttotal: 2m 35s\tremaining: 31m 7s\n",
      "768:\tlearn: 0.0523223\ttest: 0.0518641\tbest: 0.0518641 (768)\ttotal: 2m 35s\tremaining: 31m 6s\n",
      "769:\tlearn: 0.0523223\ttest: 0.0518641\tbest: 0.0518641 (769)\ttotal: 2m 35s\tremaining: 31m 6s\n",
      "770:\tlearn: 0.0523223\ttest: 0.0518641\tbest: 0.0518641 (770)\ttotal: 2m 35s\tremaining: 31m 5s\n",
      "771:\tlearn: 0.0523223\ttest: 0.0518641\tbest: 0.0518641 (771)\ttotal: 2m 36s\tremaining: 31m 4s\n",
      "772:\tlearn: 0.0523223\ttest: 0.0518641\tbest: 0.0518641 (772)\ttotal: 2m 36s\tremaining: 31m 4s\n",
      "773:\tlearn: 0.0523220\ttest: 0.0518637\tbest: 0.0518637 (773)\ttotal: 2m 36s\tremaining: 31m 4s\n",
      "774:\tlearn: 0.0523220\ttest: 0.0518637\tbest: 0.0518637 (774)\ttotal: 2m 36s\tremaining: 31m 3s\n",
      "775:\tlearn: 0.0523220\ttest: 0.0518637\tbest: 0.0518637 (775)\ttotal: 2m 36s\tremaining: 31m 3s\n",
      "776:\tlearn: 0.0523220\ttest: 0.0518637\tbest: 0.0518637 (776)\ttotal: 2m 36s\tremaining: 31m 2s\n",
      "777:\tlearn: 0.0523186\ttest: 0.0518634\tbest: 0.0518634 (777)\ttotal: 2m 37s\tremaining: 31m 2s\n",
      "778:\tlearn: 0.0523182\ttest: 0.0518632\tbest: 0.0518632 (778)\ttotal: 2m 37s\tremaining: 31m 1s\n",
      "779:\tlearn: 0.0523182\ttest: 0.0518632\tbest: 0.0518632 (778)\ttotal: 2m 37s\tremaining: 31m 1s\n",
      "780:\tlearn: 0.0523182\ttest: 0.0518632\tbest: 0.0518632 (778)\ttotal: 2m 37s\tremaining: 31m\n",
      "781:\tlearn: 0.0523182\ttest: 0.0518632\tbest: 0.0518632 (778)\ttotal: 2m 37s\tremaining: 31m\n",
      "782:\tlearn: 0.0523182\ttest: 0.0518632\tbest: 0.0518632 (778)\ttotal: 2m 37s\tremaining: 30m 59s\n",
      "783:\tlearn: 0.0523182\ttest: 0.0518632\tbest: 0.0518632 (778)\ttotal: 2m 38s\tremaining: 30m 59s\n",
      "784:\tlearn: 0.0523182\ttest: 0.0518632\tbest: 0.0518632 (778)\ttotal: 2m 38s\tremaining: 30m 58s\n",
      "785:\tlearn: 0.0523182\ttest: 0.0518632\tbest: 0.0518632 (785)\ttotal: 2m 38s\tremaining: 30m 57s\n",
      "786:\tlearn: 0.0523182\ttest: 0.0518632\tbest: 0.0518632 (785)\ttotal: 2m 38s\tremaining: 30m 56s\n",
      "787:\tlearn: 0.0523182\ttest: 0.0518632\tbest: 0.0518632 (785)\ttotal: 2m 38s\tremaining: 30m 56s\n",
      "788:\tlearn: 0.0523182\ttest: 0.0518632\tbest: 0.0518632 (785)\ttotal: 2m 38s\tremaining: 30m 55s\n",
      "789:\tlearn: 0.0523180\ttest: 0.0518630\tbest: 0.0518630 (789)\ttotal: 2m 39s\tremaining: 30m 55s\n",
      "790:\tlearn: 0.0523198\ttest: 0.0518629\tbest: 0.0518629 (790)\ttotal: 2m 39s\tremaining: 30m 55s\n",
      "791:\tlearn: 0.0523196\ttest: 0.0518627\tbest: 0.0518627 (791)\ttotal: 2m 39s\tremaining: 30m 54s\n",
      "792:\tlearn: 0.0523197\ttest: 0.0518627\tbest: 0.0518627 (792)\ttotal: 2m 39s\tremaining: 30m 54s\n",
      "793:\tlearn: 0.0523197\ttest: 0.0518627\tbest: 0.0518627 (793)\ttotal: 2m 39s\tremaining: 30m 53s\n",
      "794:\tlearn: 0.0523196\ttest: 0.0518627\tbest: 0.0518627 (794)\ttotal: 2m 40s\tremaining: 30m 52s\n",
      "795:\tlearn: 0.0523196\ttest: 0.0518627\tbest: 0.0518627 (794)\ttotal: 2m 40s\tremaining: 30m 52s\n",
      "796:\tlearn: 0.0523196\ttest: 0.0518627\tbest: 0.0518627 (794)\ttotal: 2m 40s\tremaining: 30m 51s\n",
      "797:\tlearn: 0.0523197\ttest: 0.0518627\tbest: 0.0518627 (794)\ttotal: 2m 40s\tremaining: 30m 51s\n",
      "798:\tlearn: 0.0523197\ttest: 0.0518627\tbest: 0.0518627 (794)\ttotal: 2m 40s\tremaining: 30m 50s\n",
      "799:\tlearn: 0.0523197\ttest: 0.0518627\tbest: 0.0518627 (799)\ttotal: 2m 40s\tremaining: 30m 49s\n",
      "800:\tlearn: 0.0523197\ttest: 0.0518627\tbest: 0.0518627 (799)\ttotal: 2m 41s\tremaining: 30m 49s\n",
      "801:\tlearn: 0.0523209\ttest: 0.0518623\tbest: 0.0518623 (801)\ttotal: 2m 41s\tremaining: 30m 49s\n",
      "802:\tlearn: 0.0523204\ttest: 0.0518624\tbest: 0.0518623 (801)\ttotal: 2m 41s\tremaining: 30m 48s\n",
      "803:\tlearn: 0.0523210\ttest: 0.0518623\tbest: 0.0518623 (803)\ttotal: 2m 41s\tremaining: 30m 48s\n",
      "804:\tlearn: 0.0523210\ttest: 0.0518623\tbest: 0.0518623 (804)\ttotal: 2m 41s\tremaining: 30m 47s\n",
      "805:\tlearn: 0.0523208\ttest: 0.0518620\tbest: 0.0518620 (805)\ttotal: 2m 42s\tremaining: 30m 48s\n",
      "806:\tlearn: 0.0523202\ttest: 0.0518618\tbest: 0.0518618 (806)\ttotal: 2m 42s\tremaining: 30m 47s\n",
      "807:\tlearn: 0.0523202\ttest: 0.0518618\tbest: 0.0518618 (807)\ttotal: 2m 42s\tremaining: 30m 47s\n",
      "808:\tlearn: 0.0523200\ttest: 0.0518616\tbest: 0.0518616 (808)\ttotal: 2m 42s\tremaining: 30m 46s\n",
      "809:\tlearn: 0.0523200\ttest: 0.0518616\tbest: 0.0518616 (809)\ttotal: 2m 42s\tremaining: 30m 46s\n",
      "810:\tlearn: 0.0523200\ttest: 0.0518615\tbest: 0.0518615 (810)\ttotal: 2m 42s\tremaining: 30m 45s\n",
      "811:\tlearn: 0.0523199\ttest: 0.0518613\tbest: 0.0518613 (811)\ttotal: 2m 43s\tremaining: 30m 45s\n",
      "812:\tlearn: 0.0523195\ttest: 0.0518611\tbest: 0.0518611 (812)\ttotal: 2m 43s\tremaining: 30m 45s\n",
      "813:\tlearn: 0.0523195\ttest: 0.0518611\tbest: 0.0518611 (813)\ttotal: 2m 43s\tremaining: 30m 44s\n",
      "814:\tlearn: 0.0523196\ttest: 0.0518611\tbest: 0.0518611 (814)\ttotal: 2m 43s\tremaining: 30m 44s\n",
      "815:\tlearn: 0.0523195\ttest: 0.0518611\tbest: 0.0518611 (815)\ttotal: 2m 43s\tremaining: 30m 43s\n",
      "816:\tlearn: 0.0523195\ttest: 0.0518611\tbest: 0.0518611 (816)\ttotal: 2m 44s\tremaining: 30m 43s\n",
      "817:\tlearn: 0.0523194\ttest: 0.0518612\tbest: 0.0518611 (816)\ttotal: 2m 44s\tremaining: 30m 43s\n",
      "818:\tlearn: 0.0523194\ttest: 0.0518611\tbest: 0.0518611 (818)\ttotal: 2m 44s\tremaining: 30m 42s\n",
      "819:\tlearn: 0.0523194\ttest: 0.0518611\tbest: 0.0518611 (818)\ttotal: 2m 44s\tremaining: 30m 42s\n",
      "820:\tlearn: 0.0523194\ttest: 0.0518611\tbest: 0.0518611 (818)\ttotal: 2m 44s\tremaining: 30m 41s\n",
      "821:\tlearn: 0.0523201\ttest: 0.0518611\tbest: 0.0518611 (821)\ttotal: 2m 44s\tremaining: 30m 41s\n",
      "822:\tlearn: 0.0523203\ttest: 0.0518609\tbest: 0.0518609 (822)\ttotal: 2m 45s\tremaining: 30m 41s\n",
      "823:\tlearn: 0.0523205\ttest: 0.0518607\tbest: 0.0518607 (823)\ttotal: 2m 45s\tremaining: 30m 41s\n",
      "824:\tlearn: 0.0523197\ttest: 0.0518603\tbest: 0.0518603 (824)\ttotal: 2m 45s\tremaining: 30m 40s\n",
      "825:\tlearn: 0.0523197\ttest: 0.0518603\tbest: 0.0518603 (825)\ttotal: 2m 45s\tremaining: 30m 40s\n",
      "826:\tlearn: 0.0523194\ttest: 0.0518602\tbest: 0.0518602 (826)\ttotal: 2m 45s\tremaining: 30m 40s\n",
      "827:\tlearn: 0.0523195\ttest: 0.0518602\tbest: 0.0518602 (827)\ttotal: 2m 46s\tremaining: 30m 39s\n",
      "828:\tlearn: 0.0523194\ttest: 0.0518602\tbest: 0.0518602 (828)\ttotal: 2m 46s\tremaining: 30m 39s\n",
      "829:\tlearn: 0.0523187\ttest: 0.0518598\tbest: 0.0518598 (829)\ttotal: 2m 46s\tremaining: 30m 38s\n",
      "830:\tlearn: 0.0523189\ttest: 0.0518597\tbest: 0.0518597 (830)\ttotal: 2m 46s\tremaining: 30m 38s\n",
      "831:\tlearn: 0.0523187\ttest: 0.0518596\tbest: 0.0518596 (831)\ttotal: 2m 46s\tremaining: 30m 37s\n",
      "832:\tlearn: 0.0523187\ttest: 0.0518596\tbest: 0.0518596 (832)\ttotal: 2m 46s\tremaining: 30m 37s\n",
      "833:\tlearn: 0.0523187\ttest: 0.0518596\tbest: 0.0518596 (832)\ttotal: 2m 47s\tremaining: 30m 36s\n",
      "834:\tlearn: 0.0523187\ttest: 0.0518595\tbest: 0.0518595 (834)\ttotal: 2m 47s\tremaining: 30m 36s\n",
      "835:\tlearn: 0.0523189\ttest: 0.0518595\tbest: 0.0518595 (835)\ttotal: 2m 47s\tremaining: 30m 35s\n",
      "836:\tlearn: 0.0523189\ttest: 0.0518595\tbest: 0.0518595 (836)\ttotal: 2m 47s\tremaining: 30m 35s\n",
      "837:\tlearn: 0.0523178\ttest: 0.0518595\tbest: 0.0518595 (837)\ttotal: 2m 47s\tremaining: 30m 34s\n",
      "838:\tlearn: 0.0523178\ttest: 0.0518595\tbest: 0.0518595 (838)\ttotal: 2m 47s\tremaining: 30m 34s\n",
      "839:\tlearn: 0.0523180\ttest: 0.0518594\tbest: 0.0518594 (839)\ttotal: 2m 48s\tremaining: 30m 33s\n",
      "840:\tlearn: 0.0523186\ttest: 0.0518592\tbest: 0.0518592 (840)\ttotal: 2m 48s\tremaining: 30m 33s\n",
      "841:\tlearn: 0.0523194\ttest: 0.0518592\tbest: 0.0518592 (841)\ttotal: 2m 48s\tremaining: 30m 32s\n",
      "842:\tlearn: 0.0523191\ttest: 0.0518591\tbest: 0.0518591 (842)\ttotal: 2m 48s\tremaining: 30m 32s\n",
      "843:\tlearn: 0.0523192\ttest: 0.0518591\tbest: 0.0518591 (843)\ttotal: 2m 48s\tremaining: 30m 31s\n",
      "844:\tlearn: 0.0523191\ttest: 0.0518591\tbest: 0.0518591 (844)\ttotal: 2m 49s\tremaining: 30m 31s\n",
      "845:\tlearn: 0.0523192\ttest: 0.0518590\tbest: 0.0518590 (845)\ttotal: 2m 49s\tremaining: 30m 30s\n",
      "846:\tlearn: 0.0523193\ttest: 0.0518590\tbest: 0.0518590 (846)\ttotal: 2m 49s\tremaining: 30m 30s\n",
      "847:\tlearn: 0.0523192\ttest: 0.0518590\tbest: 0.0518590 (847)\ttotal: 2m 49s\tremaining: 30m 29s\n",
      "848:\tlearn: 0.0523193\ttest: 0.0518590\tbest: 0.0518590 (848)\ttotal: 2m 49s\tremaining: 30m 29s\n",
      "849:\tlearn: 0.0523193\ttest: 0.0518589\tbest: 0.0518589 (849)\ttotal: 2m 49s\tremaining: 30m 28s\n",
      "850:\tlearn: 0.0523191\ttest: 0.0518588\tbest: 0.0518588 (850)\ttotal: 2m 50s\tremaining: 30m 28s\n",
      "851:\tlearn: 0.0523192\ttest: 0.0518587\tbest: 0.0518587 (851)\ttotal: 2m 50s\tremaining: 30m 27s\n",
      "852:\tlearn: 0.0523191\ttest: 0.0518587\tbest: 0.0518587 (852)\ttotal: 2m 50s\tremaining: 30m 27s\n",
      "853:\tlearn: 0.0523192\ttest: 0.0518586\tbest: 0.0518586 (853)\ttotal: 2m 50s\tremaining: 30m 27s\n",
      "854:\tlearn: 0.0523192\ttest: 0.0518585\tbest: 0.0518585 (854)\ttotal: 2m 50s\tremaining: 30m 26s\n",
      "855:\tlearn: 0.0523181\ttest: 0.0518585\tbest: 0.0518585 (855)\ttotal: 2m 50s\tremaining: 30m 26s\n",
      "856:\tlearn: 0.0523183\ttest: 0.0518585\tbest: 0.0518585 (855)\ttotal: 2m 51s\tremaining: 30m 25s\n",
      "857:\tlearn: 0.0523182\ttest: 0.0518584\tbest: 0.0518584 (857)\ttotal: 2m 51s\tremaining: 30m 25s\n",
      "858:\tlearn: 0.0523178\ttest: 0.0518581\tbest: 0.0518581 (858)\ttotal: 2m 51s\tremaining: 30m 25s\n",
      "859:\tlearn: 0.0523178\ttest: 0.0518580\tbest: 0.0518580 (859)\ttotal: 2m 51s\tremaining: 30m 24s\n",
      "860:\tlearn: 0.0523184\ttest: 0.0518579\tbest: 0.0518579 (860)\ttotal: 2m 51s\tremaining: 30m 24s\n",
      "861:\tlearn: 0.0523182\ttest: 0.0518578\tbest: 0.0518578 (861)\ttotal: 2m 52s\tremaining: 30m 23s\n",
      "862:\tlearn: 0.0523183\ttest: 0.0518577\tbest: 0.0518577 (862)\ttotal: 2m 52s\tremaining: 30m 23s\n",
      "863:\tlearn: 0.0523181\ttest: 0.0518577\tbest: 0.0518577 (863)\ttotal: 2m 52s\tremaining: 30m 23s\n",
      "864:\tlearn: 0.0523180\ttest: 0.0518576\tbest: 0.0518576 (864)\ttotal: 2m 52s\tremaining: 30m 22s\n",
      "865:\tlearn: 0.0523178\ttest: 0.0518572\tbest: 0.0518572 (865)\ttotal: 2m 52s\tremaining: 30m 22s\n",
      "866:\tlearn: 0.0523178\ttest: 0.0518572\tbest: 0.0518572 (865)\ttotal: 2m 52s\tremaining: 30m 22s\n",
      "867:\tlearn: 0.0523178\ttest: 0.0518572\tbest: 0.0518572 (867)\ttotal: 2m 53s\tremaining: 30m 21s\n",
      "868:\tlearn: 0.0523178\ttest: 0.0518572\tbest: 0.0518572 (867)\ttotal: 2m 53s\tremaining: 30m 20s\n",
      "869:\tlearn: 0.0523178\ttest: 0.0518572\tbest: 0.0518572 (867)\ttotal: 2m 53s\tremaining: 30m 20s\n",
      "870:\tlearn: 0.0523176\ttest: 0.0518567\tbest: 0.0518567 (870)\ttotal: 2m 53s\tremaining: 30m 20s\n",
      "871:\tlearn: 0.0523172\ttest: 0.0518567\tbest: 0.0518567 (871)\ttotal: 2m 53s\tremaining: 30m 20s\n",
      "872:\tlearn: 0.0523179\ttest: 0.0518566\tbest: 0.0518566 (872)\ttotal: 2m 54s\tremaining: 30m 19s\n",
      "873:\tlearn: 0.0523181\ttest: 0.0518566\tbest: 0.0518566 (873)\ttotal: 2m 54s\tremaining: 30m 19s\n",
      "874:\tlearn: 0.0523179\ttest: 0.0518564\tbest: 0.0518564 (874)\ttotal: 2m 54s\tremaining: 30m 19s\n",
      "875:\tlearn: 0.0523176\ttest: 0.0518562\tbest: 0.0518562 (875)\ttotal: 2m 54s\tremaining: 30m 19s\n",
      "876:\tlearn: 0.0523159\ttest: 0.0518557\tbest: 0.0518557 (876)\ttotal: 2m 54s\tremaining: 30m 18s\n",
      "877:\tlearn: 0.0523163\ttest: 0.0518557\tbest: 0.0518557 (877)\ttotal: 2m 55s\tremaining: 30m 18s\n",
      "878:\tlearn: 0.0523161\ttest: 0.0518556\tbest: 0.0518556 (878)\ttotal: 2m 55s\tremaining: 30m 18s\n",
      "879:\tlearn: 0.0523177\ttest: 0.0518555\tbest: 0.0518555 (879)\ttotal: 2m 55s\tremaining: 30m 17s\n",
      "880:\tlearn: 0.0523177\ttest: 0.0518555\tbest: 0.0518555 (880)\ttotal: 2m 55s\tremaining: 30m 17s\n",
      "881:\tlearn: 0.0523176\ttest: 0.0518553\tbest: 0.0518553 (881)\ttotal: 2m 55s\tremaining: 30m 17s\n",
      "882:\tlearn: 0.0523172\ttest: 0.0518549\tbest: 0.0518549 (882)\ttotal: 2m 55s\tremaining: 30m 17s\n",
      "883:\tlearn: 0.0523174\ttest: 0.0518549\tbest: 0.0518549 (883)\ttotal: 2m 56s\tremaining: 30m 16s\n",
      "884:\tlearn: 0.0523175\ttest: 0.0518549\tbest: 0.0518549 (884)\ttotal: 2m 56s\tremaining: 30m 16s\n",
      "885:\tlearn: 0.0523173\ttest: 0.0518547\tbest: 0.0518547 (885)\ttotal: 2m 56s\tremaining: 30m 15s\n",
      "886:\tlearn: 0.0523169\ttest: 0.0518541\tbest: 0.0518541 (886)\ttotal: 2m 56s\tremaining: 30m 15s\n",
      "887:\tlearn: 0.0523166\ttest: 0.0518540\tbest: 0.0518540 (887)\ttotal: 2m 56s\tremaining: 30m 15s\n",
      "888:\tlearn: 0.0523165\ttest: 0.0518540\tbest: 0.0518540 (888)\ttotal: 2m 57s\tremaining: 30m 15s\n",
      "889:\tlearn: 0.0523165\ttest: 0.0518540\tbest: 0.0518540 (888)\ttotal: 2m 57s\tremaining: 30m 14s\n",
      "890:\tlearn: 0.0523165\ttest: 0.0518540\tbest: 0.0518540 (890)\ttotal: 2m 57s\tremaining: 30m 13s\n",
      "891:\tlearn: 0.0523166\ttest: 0.0518540\tbest: 0.0518540 (891)\ttotal: 2m 57s\tremaining: 30m 13s\n",
      "892:\tlearn: 0.0523166\ttest: 0.0518540\tbest: 0.0518540 (892)\ttotal: 2m 57s\tremaining: 30m 12s\n",
      "893:\tlearn: 0.0523161\ttest: 0.0518535\tbest: 0.0518535 (893)\ttotal: 2m 57s\tremaining: 30m 12s\n",
      "894:\tlearn: 0.0523160\ttest: 0.0518534\tbest: 0.0518534 (894)\ttotal: 2m 58s\tremaining: 30m 12s\n",
      "895:\tlearn: 0.0523160\ttest: 0.0518531\tbest: 0.0518531 (895)\ttotal: 2m 58s\tremaining: 30m 12s\n",
      "896:\tlearn: 0.0523154\ttest: 0.0518528\tbest: 0.0518528 (896)\ttotal: 2m 58s\tremaining: 30m 11s\n",
      "897:\tlearn: 0.0523154\ttest: 0.0518528\tbest: 0.0518528 (897)\ttotal: 2m 58s\tremaining: 30m 11s\n",
      "898:\tlearn: 0.0523151\ttest: 0.0518523\tbest: 0.0518523 (898)\ttotal: 2m 58s\tremaining: 30m 11s\n",
      "899:\tlearn: 0.0523145\ttest: 0.0518520\tbest: 0.0518520 (899)\ttotal: 2m 59s\tremaining: 30m 11s\n",
      "900:\tlearn: 0.0523145\ttest: 0.0518520\tbest: 0.0518520 (900)\ttotal: 2m 59s\tremaining: 30m 10s\n",
      "901:\tlearn: 0.0523143\ttest: 0.0518515\tbest: 0.0518515 (901)\ttotal: 2m 59s\tremaining: 30m 10s\n",
      "902:\tlearn: 0.0523143\ttest: 0.0518515\tbest: 0.0518515 (902)\ttotal: 2m 59s\tremaining: 30m 9s\n",
      "903:\tlearn: 0.0523143\ttest: 0.0518515\tbest: 0.0518515 (903)\ttotal: 2m 59s\tremaining: 30m 9s\n",
      "904:\tlearn: 0.0523145\ttest: 0.0518515\tbest: 0.0518515 (904)\ttotal: 2m 59s\tremaining: 30m 8s\n",
      "905:\tlearn: 0.0523146\ttest: 0.0518514\tbest: 0.0518514 (905)\ttotal: 3m\tremaining: 30m 8s\n",
      "906:\tlearn: 0.0523145\ttest: 0.0518514\tbest: 0.0518514 (906)\ttotal: 3m\tremaining: 30m 8s\n",
      "907:\tlearn: 0.0523144\ttest: 0.0518513\tbest: 0.0518513 (907)\ttotal: 3m\tremaining: 30m 7s\n",
      "908:\tlearn: 0.0523144\ttest: 0.0518513\tbest: 0.0518513 (908)\ttotal: 3m\tremaining: 30m 7s\n",
      "909:\tlearn: 0.0523144\ttest: 0.0518513\tbest: 0.0518513 (909)\ttotal: 3m\tremaining: 30m 6s\n",
      "910:\tlearn: 0.0523144\ttest: 0.0518513\tbest: 0.0518513 (909)\ttotal: 3m 1s\tremaining: 30m 6s\n",
      "911:\tlearn: 0.0523144\ttest: 0.0518513\tbest: 0.0518513 (911)\ttotal: 3m 1s\tremaining: 30m 5s\n",
      "912:\tlearn: 0.0523145\ttest: 0.0518513\tbest: 0.0518513 (912)\ttotal: 3m 1s\tremaining: 30m 5s\n",
      "913:\tlearn: 0.0523151\ttest: 0.0518512\tbest: 0.0518512 (913)\ttotal: 3m 1s\tremaining: 30m 4s\n",
      "914:\tlearn: 0.0523150\ttest: 0.0518512\tbest: 0.0518512 (914)\ttotal: 3m 1s\tremaining: 30m 4s\n",
      "915:\tlearn: 0.0523151\ttest: 0.0518512\tbest: 0.0518512 (915)\ttotal: 3m 1s\tremaining: 30m 3s\n",
      "916:\tlearn: 0.0523147\ttest: 0.0518494\tbest: 0.0518494 (916)\ttotal: 3m 2s\tremaining: 30m 3s\n",
      "917:\tlearn: 0.0523145\ttest: 0.0518489\tbest: 0.0518489 (917)\ttotal: 3m 2s\tremaining: 30m 3s\n",
      "918:\tlearn: 0.0523142\ttest: 0.0518489\tbest: 0.0518489 (918)\ttotal: 3m 2s\tremaining: 30m 2s\n",
      "919:\tlearn: 0.0523139\ttest: 0.0518487\tbest: 0.0518487 (919)\ttotal: 3m 2s\tremaining: 30m 2s\n",
      "920:\tlearn: 0.0523138\ttest: 0.0518485\tbest: 0.0518485 (920)\ttotal: 3m 2s\tremaining: 30m 2s\n",
      "921:\tlearn: 0.0523115\ttest: 0.0518483\tbest: 0.0518483 (921)\ttotal: 3m 3s\tremaining: 30m 2s\n",
      "922:\tlearn: 0.0523115\ttest: 0.0518483\tbest: 0.0518483 (921)\ttotal: 3m 3s\tremaining: 30m 1s\n",
      "923:\tlearn: 0.0523115\ttest: 0.0518483\tbest: 0.0518483 (921)\ttotal: 3m 3s\tremaining: 30m 1s\n",
      "924:\tlearn: 0.0523114\ttest: 0.0518483\tbest: 0.0518483 (924)\ttotal: 3m 3s\tremaining: 30m\n",
      "925:\tlearn: 0.0523115\ttest: 0.0518483\tbest: 0.0518483 (925)\ttotal: 3m 3s\tremaining: 30m\n",
      "926:\tlearn: 0.0523115\ttest: 0.0518483\tbest: 0.0518483 (926)\ttotal: 3m 3s\tremaining: 29m 59s\n",
      "927:\tlearn: 0.0523112\ttest: 0.0518479\tbest: 0.0518479 (927)\ttotal: 3m 4s\tremaining: 29m 59s\n",
      "928:\tlearn: 0.0523105\ttest: 0.0518473\tbest: 0.0518473 (928)\ttotal: 3m 4s\tremaining: 29m 59s\n",
      "929:\tlearn: 0.0523105\ttest: 0.0518473\tbest: 0.0518473 (929)\ttotal: 3m 4s\tremaining: 29m 58s\n",
      "930:\tlearn: 0.0523105\ttest: 0.0518473\tbest: 0.0518473 (930)\ttotal: 3m 4s\tremaining: 29m 58s\n",
      "931:\tlearn: 0.0523105\ttest: 0.0518473\tbest: 0.0518473 (931)\ttotal: 3m 4s\tremaining: 29m 58s\n",
      "932:\tlearn: 0.0523101\ttest: 0.0518471\tbest: 0.0518471 (932)\ttotal: 3m 4s\tremaining: 29m 57s\n",
      "933:\tlearn: 0.0523103\ttest: 0.0518470\tbest: 0.0518470 (933)\ttotal: 3m 5s\tremaining: 29m 57s\n",
      "934:\tlearn: 0.0523103\ttest: 0.0518470\tbest: 0.0518470 (934)\ttotal: 3m 5s\tremaining: 29m 57s\n",
      "935:\tlearn: 0.0523103\ttest: 0.0518470\tbest: 0.0518470 (935)\ttotal: 3m 5s\tremaining: 29m 56s\n",
      "936:\tlearn: 0.0523103\ttest: 0.0518470\tbest: 0.0518470 (936)\ttotal: 3m 5s\tremaining: 29m 56s\n",
      "937:\tlearn: 0.0523101\ttest: 0.0518469\tbest: 0.0518469 (937)\ttotal: 3m 5s\tremaining: 29m 56s\n",
      "938:\tlearn: 0.0523101\ttest: 0.0518469\tbest: 0.0518469 (937)\ttotal: 3m 6s\tremaining: 29m 55s\n",
      "939:\tlearn: 0.0523102\ttest: 0.0518469\tbest: 0.0518469 (939)\ttotal: 3m 6s\tremaining: 29m 55s\n",
      "940:\tlearn: 0.0523101\ttest: 0.0518469\tbest: 0.0518469 (940)\ttotal: 3m 6s\tremaining: 29m 54s\n",
      "941:\tlearn: 0.0523102\ttest: 0.0518469\tbest: 0.0518469 (941)\ttotal: 3m 6s\tremaining: 29m 54s\n",
      "942:\tlearn: 0.0523103\ttest: 0.0518468\tbest: 0.0518468 (942)\ttotal: 3m 6s\tremaining: 29m 53s\n",
      "943:\tlearn: 0.0523094\ttest: 0.0518468\tbest: 0.0518468 (943)\ttotal: 3m 6s\tremaining: 29m 53s\n",
      "944:\tlearn: 0.0523094\ttest: 0.0518468\tbest: 0.0518468 (944)\ttotal: 3m 7s\tremaining: 29m 52s\n",
      "945:\tlearn: 0.0523094\ttest: 0.0518468\tbest: 0.0518468 (944)\ttotal: 3m 7s\tremaining: 29m 51s\n",
      "946:\tlearn: 0.0523094\ttest: 0.0518468\tbest: 0.0518468 (944)\ttotal: 3m 7s\tremaining: 29m 51s\n",
      "947:\tlearn: 0.0523094\ttest: 0.0518468\tbest: 0.0518468 (944)\ttotal: 3m 7s\tremaining: 29m 50s\n",
      "948:\tlearn: 0.0523094\ttest: 0.0518468\tbest: 0.0518468 (944)\ttotal: 3m 7s\tremaining: 29m 50s\n",
      "949:\tlearn: 0.0523094\ttest: 0.0518468\tbest: 0.0518468 (944)\ttotal: 3m 7s\tremaining: 29m 50s\n",
      "950:\tlearn: 0.0523094\ttest: 0.0518468\tbest: 0.0518468 (944)\ttotal: 3m 8s\tremaining: 29m 49s\n",
      "951:\tlearn: 0.0523094\ttest: 0.0518468\tbest: 0.0518468 (944)\ttotal: 3m 8s\tremaining: 29m 49s\n",
      "952:\tlearn: 0.0523100\ttest: 0.0518466\tbest: 0.0518466 (952)\ttotal: 3m 8s\tremaining: 29m 49s\n",
      "953:\tlearn: 0.0523090\ttest: 0.0518466\tbest: 0.0518466 (953)\ttotal: 3m 8s\tremaining: 29m 48s\n",
      "954:\tlearn: 0.0523091\ttest: 0.0518465\tbest: 0.0518465 (954)\ttotal: 3m 8s\tremaining: 29m 48s\n",
      "955:\tlearn: 0.0523085\ttest: 0.0518463\tbest: 0.0518463 (955)\ttotal: 3m 8s\tremaining: 29m 47s\n",
      "956:\tlearn: 0.0523093\ttest: 0.0518462\tbest: 0.0518462 (956)\ttotal: 3m 9s\tremaining: 29m 47s\n",
      "957:\tlearn: 0.0523090\ttest: 0.0518458\tbest: 0.0518458 (957)\ttotal: 3m 9s\tremaining: 29m 47s\n",
      "958:\tlearn: 0.0523079\ttest: 0.0518458\tbest: 0.0518458 (958)\ttotal: 3m 9s\tremaining: 29m 47s\n",
      "959:\tlearn: 0.0523079\ttest: 0.0518458\tbest: 0.0518458 (958)\ttotal: 3m 9s\tremaining: 29m 46s\n",
      "960:\tlearn: 0.0523079\ttest: 0.0518458\tbest: 0.0518458 (958)\ttotal: 3m 9s\tremaining: 29m 46s\n",
      "961:\tlearn: 0.0523080\ttest: 0.0518458\tbest: 0.0518458 (961)\ttotal: 3m 10s\tremaining: 29m 45s\n",
      "962:\tlearn: 0.0523078\ttest: 0.0518458\tbest: 0.0518458 (962)\ttotal: 3m 10s\tremaining: 29m 45s\n",
      "963:\tlearn: 0.0523078\ttest: 0.0518458\tbest: 0.0518458 (963)\ttotal: 3m 10s\tremaining: 29m 44s\n",
      "964:\tlearn: 0.0523078\ttest: 0.0518458\tbest: 0.0518458 (963)\ttotal: 3m 10s\tremaining: 29m 44s\n",
      "965:\tlearn: 0.0523078\ttest: 0.0518458\tbest: 0.0518458 (963)\ttotal: 3m 10s\tremaining: 29m 43s\n",
      "966:\tlearn: 0.0523078\ttest: 0.0518458\tbest: 0.0518458 (966)\ttotal: 3m 10s\tremaining: 29m 43s\n",
      "967:\tlearn: 0.0523078\ttest: 0.0518458\tbest: 0.0518458 (967)\ttotal: 3m 11s\tremaining: 29m 43s\n",
      "968:\tlearn: 0.0523078\ttest: 0.0518458\tbest: 0.0518458 (967)\ttotal: 3m 11s\tremaining: 29m 42s\n",
      "969:\tlearn: 0.0523078\ttest: 0.0518458\tbest: 0.0518458 (967)\ttotal: 3m 11s\tremaining: 29m 42s\n",
      "970:\tlearn: 0.0523078\ttest: 0.0518458\tbest: 0.0518458 (967)\ttotal: 3m 11s\tremaining: 29m 41s\n",
      "971:\tlearn: 0.0523078\ttest: 0.0518458\tbest: 0.0518458 (967)\ttotal: 3m 11s\tremaining: 29m 41s\n",
      "972:\tlearn: 0.0523078\ttest: 0.0518458\tbest: 0.0518458 (967)\ttotal: 3m 11s\tremaining: 29m 40s\n",
      "973:\tlearn: 0.0523078\ttest: 0.0518458\tbest: 0.0518458 (967)\ttotal: 3m 12s\tremaining: 29m 40s\n",
      "974:\tlearn: 0.0523078\ttest: 0.0518458\tbest: 0.0518458 (974)\ttotal: 3m 12s\tremaining: 29m 40s\n",
      "975:\tlearn: 0.0523078\ttest: 0.0518458\tbest: 0.0518458 (975)\ttotal: 3m 12s\tremaining: 29m 39s\n",
      "976:\tlearn: 0.0523077\ttest: 0.0518458\tbest: 0.0518458 (976)\ttotal: 3m 12s\tremaining: 29m 39s\n",
      "977:\tlearn: 0.0523078\ttest: 0.0518457\tbest: 0.0518457 (977)\ttotal: 3m 12s\tremaining: 29m 39s\n",
      "978:\tlearn: 0.0523078\ttest: 0.0518457\tbest: 0.0518457 (977)\ttotal: 3m 13s\tremaining: 29m 38s\n",
      "979:\tlearn: 0.0523078\ttest: 0.0518457\tbest: 0.0518457 (977)\ttotal: 3m 13s\tremaining: 29m 38s\n",
      "980:\tlearn: 0.0523078\ttest: 0.0518457\tbest: 0.0518457 (977)\ttotal: 3m 13s\tremaining: 29m 37s\n",
      "981:\tlearn: 0.0523078\ttest: 0.0518457\tbest: 0.0518457 (977)\ttotal: 3m 13s\tremaining: 29m 37s\n",
      "982:\tlearn: 0.0523078\ttest: 0.0518457\tbest: 0.0518457 (982)\ttotal: 3m 13s\tremaining: 29m 36s\n",
      "983:\tlearn: 0.0523077\ttest: 0.0518457\tbest: 0.0518457 (983)\ttotal: 3m 13s\tremaining: 29m 36s\n",
      "984:\tlearn: 0.0523077\ttest: 0.0518457\tbest: 0.0518457 (983)\ttotal: 3m 14s\tremaining: 29m 36s\n",
      "985:\tlearn: 0.0523084\ttest: 0.0518457\tbest: 0.0518457 (985)\ttotal: 3m 14s\tremaining: 29m 35s\n",
      "986:\tlearn: 0.0523084\ttest: 0.0518457\tbest: 0.0518457 (986)\ttotal: 3m 14s\tremaining: 29m 35s\n",
      "987:\tlearn: 0.0523084\ttest: 0.0518457\tbest: 0.0518457 (987)\ttotal: 3m 14s\tremaining: 29m 34s\n",
      "988:\tlearn: 0.0523084\ttest: 0.0518457\tbest: 0.0518457 (988)\ttotal: 3m 14s\tremaining: 29m 34s\n",
      "989:\tlearn: 0.0523082\ttest: 0.0518457\tbest: 0.0518457 (989)\ttotal: 3m 14s\tremaining: 29m 34s\n",
      "990:\tlearn: 0.0523082\ttest: 0.0518457\tbest: 0.0518457 (989)\ttotal: 3m 15s\tremaining: 29m 33s\n",
      "991:\tlearn: 0.0523082\ttest: 0.0518457\tbest: 0.0518457 (989)\ttotal: 3m 15s\tremaining: 29m 33s\n",
      "992:\tlearn: 0.0523082\ttest: 0.0518457\tbest: 0.0518457 (989)\ttotal: 3m 15s\tremaining: 29m 32s\n",
      "993:\tlearn: 0.0523082\ttest: 0.0518457\tbest: 0.0518457 (989)\ttotal: 3m 15s\tremaining: 29m 32s\n",
      "994:\tlearn: 0.0523082\ttest: 0.0518457\tbest: 0.0518457 (989)\ttotal: 3m 15s\tremaining: 29m 31s\n",
      "995:\tlearn: 0.0523082\ttest: 0.0518457\tbest: 0.0518457 (989)\ttotal: 3m 15s\tremaining: 29m 31s\n",
      "996:\tlearn: 0.0523082\ttest: 0.0518457\tbest: 0.0518457 (989)\ttotal: 3m 16s\tremaining: 29m 31s\n",
      "997:\tlearn: 0.0523082\ttest: 0.0518457\tbest: 0.0518457 (989)\ttotal: 3m 16s\tremaining: 29m 30s\n",
      "998:\tlearn: 0.0523082\ttest: 0.0518457\tbest: 0.0518457 (989)\ttotal: 3m 16s\tremaining: 29m 30s\n",
      "999:\tlearn: 0.0523082\ttest: 0.0518457\tbest: 0.0518457 (989)\ttotal: 3m 16s\tremaining: 29m 29s\n",
      "1000:\tlearn: 0.0523082\ttest: 0.0518457\tbest: 0.0518457 (989)\ttotal: 3m 16s\tremaining: 29m 29s\n",
      "1001:\tlearn: 0.0523082\ttest: 0.0518457\tbest: 0.0518457 (989)\ttotal: 3m 16s\tremaining: 29m 28s\n",
      "1002:\tlearn: 0.0523082\ttest: 0.0518457\tbest: 0.0518457 (989)\ttotal: 3m 17s\tremaining: 29m 28s\n",
      "1003:\tlearn: 0.0523082\ttest: 0.0518457\tbest: 0.0518457 (989)\ttotal: 3m 17s\tremaining: 29m 27s\n",
      "1004:\tlearn: 0.0523082\ttest: 0.0518457\tbest: 0.0518457 (989)\ttotal: 3m 17s\tremaining: 29m 27s\n",
      "1005:\tlearn: 0.0523082\ttest: 0.0518457\tbest: 0.0518457 (989)\ttotal: 3m 17s\tremaining: 29m 27s\n",
      "1006:\tlearn: 0.0523082\ttest: 0.0518457\tbest: 0.0518457 (989)\ttotal: 3m 17s\tremaining: 29m 26s\n",
      "1007:\tlearn: 0.0523082\ttest: 0.0518457\tbest: 0.0518457 (989)\ttotal: 3m 17s\tremaining: 29m 26s\n",
      "1008:\tlearn: 0.0523082\ttest: 0.0518457\tbest: 0.0518457 (989)\ttotal: 3m 18s\tremaining: 29m 25s\n",
      "1009:\tlearn: 0.0523082\ttest: 0.0518457\tbest: 0.0518457 (989)\ttotal: 3m 18s\tremaining: 29m 25s\n",
      "1010:\tlearn: 0.0523082\ttest: 0.0518457\tbest: 0.0518457 (989)\ttotal: 3m 18s\tremaining: 29m 25s\n",
      "1011:\tlearn: 0.0523082\ttest: 0.0518457\tbest: 0.0518457 (989)\ttotal: 3m 18s\tremaining: 29m 24s\n",
      "1012:\tlearn: 0.0523082\ttest: 0.0518457\tbest: 0.0518457 (989)\ttotal: 3m 18s\tremaining: 29m 24s\n",
      "1013:\tlearn: 0.0523082\ttest: 0.0518457\tbest: 0.0518457 (989)\ttotal: 3m 19s\tremaining: 29m 23s\n",
      "1014:\tlearn: 0.0523082\ttest: 0.0518457\tbest: 0.0518457 (989)\ttotal: 3m 19s\tremaining: 29m 23s\n",
      "1015:\tlearn: 0.0523082\ttest: 0.0518457\tbest: 0.0518457 (989)\ttotal: 3m 19s\tremaining: 29m 22s\n",
      "1016:\tlearn: 0.0523082\ttest: 0.0518457\tbest: 0.0518457 (989)\ttotal: 3m 19s\tremaining: 29m 22s\n",
      "1017:\tlearn: 0.0523082\ttest: 0.0518457\tbest: 0.0518457 (989)\ttotal: 3m 19s\tremaining: 29m 22s\n",
      "1018:\tlearn: 0.0523082\ttest: 0.0518457\tbest: 0.0518457 (989)\ttotal: 3m 19s\tremaining: 29m 21s\n",
      "1019:\tlearn: 0.0523082\ttest: 0.0518457\tbest: 0.0518457 (989)\ttotal: 3m 20s\tremaining: 29m 21s\n",
      "1020:\tlearn: 0.0523082\ttest: 0.0518457\tbest: 0.0518457 (989)\ttotal: 3m 20s\tremaining: 29m 20s\n",
      "1021:\tlearn: 0.0523082\ttest: 0.0518457\tbest: 0.0518457 (989)\ttotal: 3m 20s\tremaining: 29m 20s\n",
      "1022:\tlearn: 0.0523082\ttest: 0.0518457\tbest: 0.0518457 (989)\ttotal: 3m 20s\tremaining: 29m 19s\n",
      "1023:\tlearn: 0.0523082\ttest: 0.0518457\tbest: 0.0518457 (989)\ttotal: 3m 20s\tremaining: 29m 19s\n",
      "1024:\tlearn: 0.0523082\ttest: 0.0518457\tbest: 0.0518457 (989)\ttotal: 3m 20s\tremaining: 29m 19s\n",
      "1025:\tlearn: 0.0523082\ttest: 0.0518457\tbest: 0.0518457 (989)\ttotal: 3m 21s\tremaining: 29m 18s\n",
      "1026:\tlearn: 0.0523082\ttest: 0.0518457\tbest: 0.0518457 (989)\ttotal: 3m 21s\tremaining: 29m 18s\n",
      "1027:\tlearn: 0.0523082\ttest: 0.0518457\tbest: 0.0518457 (989)\ttotal: 3m 21s\tremaining: 29m 17s\n",
      "1028:\tlearn: 0.0523082\ttest: 0.0518457\tbest: 0.0518457 (989)\ttotal: 3m 21s\tremaining: 29m 17s\n",
      "1029:\tlearn: 0.0523082\ttest: 0.0518457\tbest: 0.0518457 (989)\ttotal: 3m 21s\tremaining: 29m 16s\n",
      "1030:\tlearn: 0.0523082\ttest: 0.0518457\tbest: 0.0518457 (989)\ttotal: 3m 21s\tremaining: 29m 16s\n",
      "1031:\tlearn: 0.0523082\ttest: 0.0518457\tbest: 0.0518457 (989)\ttotal: 3m 22s\tremaining: 29m 16s\n",
      "1032:\tlearn: 0.0523082\ttest: 0.0518457\tbest: 0.0518457 (989)\ttotal: 3m 22s\tremaining: 29m 15s\n",
      "1033:\tlearn: 0.0523082\ttest: 0.0518457\tbest: 0.0518457 (989)\ttotal: 3m 22s\tremaining: 29m 15s\n",
      "1034:\tlearn: 0.0523082\ttest: 0.0518457\tbest: 0.0518457 (989)\ttotal: 3m 22s\tremaining: 29m 14s\n",
      "1035:\tlearn: 0.0523082\ttest: 0.0518457\tbest: 0.0518457 (989)\ttotal: 3m 22s\tremaining: 29m 14s\n",
      "1036:\tlearn: 0.0523082\ttest: 0.0518457\tbest: 0.0518457 (989)\ttotal: 3m 22s\tremaining: 29m 14s\n",
      "1037:\tlearn: 0.0523082\ttest: 0.0518457\tbest: 0.0518457 (989)\ttotal: 3m 23s\tremaining: 29m 13s\n",
      "1038:\tlearn: 0.0523082\ttest: 0.0518457\tbest: 0.0518457 (989)\ttotal: 3m 23s\tremaining: 29m 13s\n",
      "1039:\tlearn: 0.0523082\ttest: 0.0518457\tbest: 0.0518457 (989)\ttotal: 3m 23s\tremaining: 29m 12s\n",
      "1040:\tlearn: 0.0523082\ttest: 0.0518457\tbest: 0.0518457 (989)\ttotal: 3m 23s\tremaining: 29m 12s\n",
      "1041:\tlearn: 0.0523082\ttest: 0.0518457\tbest: 0.0518457 (989)\ttotal: 3m 23s\tremaining: 29m 12s\n",
      "1042:\tlearn: 0.0523082\ttest: 0.0518457\tbest: 0.0518457 (989)\ttotal: 3m 23s\tremaining: 29m 11s\n",
      "1043:\tlearn: 0.0523082\ttest: 0.0518457\tbest: 0.0518457 (989)\ttotal: 3m 24s\tremaining: 29m 11s\n",
      "1044:\tlearn: 0.0523082\ttest: 0.0518457\tbest: 0.0518457 (989)\ttotal: 3m 24s\tremaining: 29m 10s\n",
      "1045:\tlearn: 0.0523082\ttest: 0.0518457\tbest: 0.0518457 (989)\ttotal: 3m 24s\tremaining: 29m 10s\n",
      "1046:\tlearn: 0.0523082\ttest: 0.0518457\tbest: 0.0518457 (989)\ttotal: 3m 24s\tremaining: 29m 10s\n",
      "1047:\tlearn: 0.0523082\ttest: 0.0518457\tbest: 0.0518457 (989)\ttotal: 3m 24s\tremaining: 29m 9s\n",
      "1048:\tlearn: 0.0523082\ttest: 0.0518457\tbest: 0.0518457 (989)\ttotal: 3m 25s\tremaining: 29m 9s\n",
      "1049:\tlearn: 0.0523082\ttest: 0.0518457\tbest: 0.0518457 (989)\ttotal: 3m 25s\tremaining: 29m 9s\n",
      "1050:\tlearn: 0.0523082\ttest: 0.0518457\tbest: 0.0518457 (989)\ttotal: 3m 25s\tremaining: 29m 8s\n",
      "1051:\tlearn: 0.0523082\ttest: 0.0518457\tbest: 0.0518457 (989)\ttotal: 3m 25s\tremaining: 29m 8s\n",
      "1052:\tlearn: 0.0523082\ttest: 0.0518457\tbest: 0.0518457 (989)\ttotal: 3m 25s\tremaining: 29m 7s\n",
      "1053:\tlearn: 0.0523082\ttest: 0.0518457\tbest: 0.0518457 (989)\ttotal: 3m 25s\tremaining: 29m 7s\n",
      "1054:\tlearn: 0.0523082\ttest: 0.0518457\tbest: 0.0518457 (989)\ttotal: 3m 26s\tremaining: 29m 7s\n",
      "1055:\tlearn: 0.0523082\ttest: 0.0518457\tbest: 0.0518457 (989)\ttotal: 3m 26s\tremaining: 29m 6s\n",
      "1056:\tlearn: 0.0523082\ttest: 0.0518457\tbest: 0.0518457 (989)\ttotal: 3m 26s\tremaining: 29m 6s\n",
      "1057:\tlearn: 0.0523082\ttest: 0.0518457\tbest: 0.0518457 (989)\ttotal: 3m 26s\tremaining: 29m 5s\n",
      "1058:\tlearn: 0.0523082\ttest: 0.0518457\tbest: 0.0518457 (989)\ttotal: 3m 26s\tremaining: 29m 5s\n",
      "1059:\tlearn: 0.0523082\ttest: 0.0518457\tbest: 0.0518457 (989)\ttotal: 3m 26s\tremaining: 29m 5s\n",
      "1060:\tlearn: 0.0523082\ttest: 0.0518457\tbest: 0.0518457 (989)\ttotal: 3m 27s\tremaining: 29m 4s\n",
      "1061:\tlearn: 0.0523082\ttest: 0.0518457\tbest: 0.0518457 (989)\ttotal: 3m 27s\tremaining: 29m 4s\n",
      "1062:\tlearn: 0.0523082\ttest: 0.0518457\tbest: 0.0518457 (989)\ttotal: 3m 27s\tremaining: 29m 3s\n",
      "1063:\tlearn: 0.0523082\ttest: 0.0518457\tbest: 0.0518457 (989)\ttotal: 3m 27s\tremaining: 29m 3s\n",
      "1064:\tlearn: 0.0523082\ttest: 0.0518457\tbest: 0.0518457 (989)\ttotal: 3m 27s\tremaining: 29m 3s\n",
      "1065:\tlearn: 0.0523082\ttest: 0.0518457\tbest: 0.0518457 (989)\ttotal: 3m 27s\tremaining: 29m 2s\n",
      "1066:\tlearn: 0.0523082\ttest: 0.0518457\tbest: 0.0518457 (989)\ttotal: 3m 28s\tremaining: 29m 2s\n",
      "1067:\tlearn: 0.0523082\ttest: 0.0518457\tbest: 0.0518457 (989)\ttotal: 3m 28s\tremaining: 29m 1s\n",
      "1068:\tlearn: 0.0523082\ttest: 0.0518457\tbest: 0.0518457 (989)\ttotal: 3m 28s\tremaining: 29m 1s\n",
      "1069:\tlearn: 0.0523082\ttest: 0.0518457\tbest: 0.0518457 (989)\ttotal: 3m 28s\tremaining: 29m 1s\n",
      "1070:\tlearn: 0.0523082\ttest: 0.0518457\tbest: 0.0518457 (989)\ttotal: 3m 28s\tremaining: 29m\n",
      "1071:\tlearn: 0.0523082\ttest: 0.0518457\tbest: 0.0518457 (989)\ttotal: 3m 28s\tremaining: 29m\n",
      "1072:\tlearn: 0.0523082\ttest: 0.0518457\tbest: 0.0518457 (989)\ttotal: 3m 29s\tremaining: 29m\n",
      "1073:\tlearn: 0.0523082\ttest: 0.0518457\tbest: 0.0518457 (989)\ttotal: 3m 29s\tremaining: 28m 59s\n",
      "1074:\tlearn: 0.0523082\ttest: 0.0518457\tbest: 0.0518457 (989)\ttotal: 3m 29s\tremaining: 28m 59s\n",
      "1075:\tlearn: 0.0523082\ttest: 0.0518457\tbest: 0.0518457 (989)\ttotal: 3m 29s\tremaining: 28m 58s\n",
      "1076:\tlearn: 0.0523082\ttest: 0.0518457\tbest: 0.0518457 (989)\ttotal: 3m 29s\tremaining: 28m 58s\n",
      "1077:\tlearn: 0.0523082\ttest: 0.0518457\tbest: 0.0518457 (989)\ttotal: 3m 29s\tremaining: 28m 57s\n",
      "1078:\tlearn: 0.0523082\ttest: 0.0518457\tbest: 0.0518457 (989)\ttotal: 3m 30s\tremaining: 28m 57s\n",
      "1079:\tlearn: 0.0523082\ttest: 0.0518457\tbest: 0.0518457 (989)\ttotal: 3m 30s\tremaining: 28m 57s\n",
      "1080:\tlearn: 0.0523082\ttest: 0.0518457\tbest: 0.0518457 (989)\ttotal: 3m 30s\tremaining: 28m 56s\n",
      "1081:\tlearn: 0.0523082\ttest: 0.0518457\tbest: 0.0518457 (989)\ttotal: 3m 30s\tremaining: 28m 56s\n",
      "1082:\tlearn: 0.0523082\ttest: 0.0518457\tbest: 0.0518457 (989)\ttotal: 3m 30s\tremaining: 28m 56s\n",
      "1083:\tlearn: 0.0523082\ttest: 0.0518457\tbest: 0.0518457 (989)\ttotal: 3m 30s\tremaining: 28m 55s\n",
      "1084:\tlearn: 0.0523082\ttest: 0.0518457\tbest: 0.0518457 (989)\ttotal: 3m 31s\tremaining: 28m 55s\n",
      "1085:\tlearn: 0.0523082\ttest: 0.0518457\tbest: 0.0518457 (989)\ttotal: 3m 31s\tremaining: 28m 54s\n",
      "1086:\tlearn: 0.0523082\ttest: 0.0518457\tbest: 0.0518457 (989)\ttotal: 3m 31s\tremaining: 28m 54s\n",
      "1087:\tlearn: 0.0523082\ttest: 0.0518457\tbest: 0.0518457 (989)\ttotal: 3m 31s\tremaining: 28m 54s\n",
      "1088:\tlearn: 0.0523082\ttest: 0.0518457\tbest: 0.0518457 (989)\ttotal: 3m 31s\tremaining: 28m 53s\n",
      "1089:\tlearn: 0.0523082\ttest: 0.0518457\tbest: 0.0518457 (989)\ttotal: 3m 32s\tremaining: 28m 53s\n",
      "1090:\tlearn: 0.0523082\ttest: 0.0518457\tbest: 0.0518457 (989)\ttotal: 3m 32s\tremaining: 28m 52s\n",
      "1091:\tlearn: 0.0523082\ttest: 0.0518457\tbest: 0.0518457 (989)\ttotal: 3m 32s\tremaining: 28m 52s\n",
      "1092:\tlearn: 0.0523082\ttest: 0.0518457\tbest: 0.0518457 (989)\ttotal: 3m 32s\tremaining: 28m 51s\n",
      "1093:\tlearn: 0.0523082\ttest: 0.0518457\tbest: 0.0518457 (989)\ttotal: 3m 32s\tremaining: 28m 51s\n",
      "1094:\tlearn: 0.0523082\ttest: 0.0518457\tbest: 0.0518457 (989)\ttotal: 3m 32s\tremaining: 28m 51s\n",
      "1095:\tlearn: 0.0523082\ttest: 0.0518457\tbest: 0.0518457 (989)\ttotal: 3m 33s\tremaining: 28m 50s\n",
      "1096:\tlearn: 0.0523082\ttest: 0.0518457\tbest: 0.0518457 (989)\ttotal: 3m 33s\tremaining: 28m 50s\n",
      "1097:\tlearn: 0.0523082\ttest: 0.0518457\tbest: 0.0518457 (989)\ttotal: 3m 33s\tremaining: 28m 49s\n",
      "1098:\tlearn: 0.0523082\ttest: 0.0518457\tbest: 0.0518457 (989)\ttotal: 3m 33s\tremaining: 28m 49s\n",
      "1099:\tlearn: 0.0523082\ttest: 0.0518457\tbest: 0.0518457 (989)\ttotal: 3m 33s\tremaining: 28m 49s\n",
      "1100:\tlearn: 0.0523082\ttest: 0.0518457\tbest: 0.0518457 (989)\ttotal: 3m 33s\tremaining: 28m 48s\n",
      "1101:\tlearn: 0.0523082\ttest: 0.0518457\tbest: 0.0518457 (989)\ttotal: 3m 34s\tremaining: 28m 48s\n",
      "1102:\tlearn: 0.0523082\ttest: 0.0518457\tbest: 0.0518457 (989)\ttotal: 3m 34s\tremaining: 28m 48s\n",
      "1103:\tlearn: 0.0523082\ttest: 0.0518457\tbest: 0.0518457 (989)\ttotal: 3m 34s\tremaining: 28m 47s\n",
      "1104:\tlearn: 0.0523082\ttest: 0.0518457\tbest: 0.0518457 (989)\ttotal: 3m 34s\tremaining: 28m 47s\n",
      "1105:\tlearn: 0.0523082\ttest: 0.0518457\tbest: 0.0518457 (989)\ttotal: 3m 34s\tremaining: 28m 46s\n",
      "1106:\tlearn: 0.0523082\ttest: 0.0518457\tbest: 0.0518457 (989)\ttotal: 3m 34s\tremaining: 28m 46s\n",
      "1107:\tlearn: 0.0523082\ttest: 0.0518457\tbest: 0.0518457 (989)\ttotal: 3m 35s\tremaining: 28m 46s\n",
      "1108:\tlearn: 0.0523082\ttest: 0.0518457\tbest: 0.0518457 (989)\ttotal: 3m 35s\tremaining: 28m 45s\n",
      "1109:\tlearn: 0.0523082\ttest: 0.0518457\tbest: 0.0518457 (989)\ttotal: 3m 35s\tremaining: 28m 45s\n",
      "1110:\tlearn: 0.0523082\ttest: 0.0518457\tbest: 0.0518457 (989)\ttotal: 3m 35s\tremaining: 28m 44s\n",
      "1111:\tlearn: 0.0523082\ttest: 0.0518457\tbest: 0.0518457 (989)\ttotal: 3m 35s\tremaining: 28m 44s\n",
      "1112:\tlearn: 0.0523082\ttest: 0.0518457\tbest: 0.0518457 (989)\ttotal: 3m 35s\tremaining: 28m 44s\n",
      "1113:\tlearn: 0.0523082\ttest: 0.0518457\tbest: 0.0518457 (989)\ttotal: 3m 36s\tremaining: 28m 43s\n",
      "1114:\tlearn: 0.0523082\ttest: 0.0518457\tbest: 0.0518457 (989)\ttotal: 3m 36s\tremaining: 28m 43s\n",
      "1115:\tlearn: 0.0523082\ttest: 0.0518457\tbest: 0.0518457 (989)\ttotal: 3m 36s\tremaining: 28m 43s\n",
      "1116:\tlearn: 0.0523082\ttest: 0.0518457\tbest: 0.0518457 (989)\ttotal: 3m 36s\tremaining: 28m 42s\n",
      "1117:\tlearn: 0.0523082\ttest: 0.0518457\tbest: 0.0518457 (989)\ttotal: 3m 36s\tremaining: 28m 42s\n",
      "1118:\tlearn: 0.0523082\ttest: 0.0518457\tbest: 0.0518457 (989)\ttotal: 3m 36s\tremaining: 28m 42s\n",
      "1119:\tlearn: 0.0523082\ttest: 0.0518457\tbest: 0.0518457 (989)\ttotal: 3m 37s\tremaining: 28m 41s\n",
      "1120:\tlearn: 0.0523082\ttest: 0.0518457\tbest: 0.0518457 (989)\ttotal: 3m 37s\tremaining: 28m 41s\n",
      "1121:\tlearn: 0.0523082\ttest: 0.0518457\tbest: 0.0518457 (989)\ttotal: 3m 37s\tremaining: 28m 40s\n",
      "1122:\tlearn: 0.0523082\ttest: 0.0518457\tbest: 0.0518457 (989)\ttotal: 3m 37s\tremaining: 28m 40s\n",
      "1123:\tlearn: 0.0523082\ttest: 0.0518457\tbest: 0.0518457 (989)\ttotal: 3m 37s\tremaining: 28m 40s\n",
      "1124:\tlearn: 0.0523082\ttest: 0.0518457\tbest: 0.0518457 (989)\ttotal: 3m 38s\tremaining: 28m 39s\n",
      "1125:\tlearn: 0.0523082\ttest: 0.0518457\tbest: 0.0518457 (989)\ttotal: 3m 38s\tremaining: 28m 39s\n",
      "1126:\tlearn: 0.0523082\ttest: 0.0518457\tbest: 0.0518457 (989)\ttotal: 3m 38s\tremaining: 28m 39s\n",
      "1127:\tlearn: 0.0523082\ttest: 0.0518457\tbest: 0.0518457 (989)\ttotal: 3m 38s\tremaining: 28m 38s\n",
      "1128:\tlearn: 0.0523082\ttest: 0.0518457\tbest: 0.0518457 (989)\ttotal: 3m 38s\tremaining: 28m 38s\n",
      "1129:\tlearn: 0.0523082\ttest: 0.0518457\tbest: 0.0518457 (989)\ttotal: 3m 38s\tremaining: 28m 38s\n",
      "1130:\tlearn: 0.0523082\ttest: 0.0518457\tbest: 0.0518457 (989)\ttotal: 3m 39s\tremaining: 28m 37s\n",
      "1131:\tlearn: 0.0523082\ttest: 0.0518457\tbest: 0.0518457 (989)\ttotal: 3m 39s\tremaining: 28m 37s\n",
      "1132:\tlearn: 0.0523082\ttest: 0.0518457\tbest: 0.0518457 (989)\ttotal: 3m 39s\tremaining: 28m 36s\n",
      "1133:\tlearn: 0.0523082\ttest: 0.0518457\tbest: 0.0518457 (989)\ttotal: 3m 39s\tremaining: 28m 36s\n",
      "1134:\tlearn: 0.0523082\ttest: 0.0518457\tbest: 0.0518457 (989)\ttotal: 3m 39s\tremaining: 28m 36s\n",
      "1135:\tlearn: 0.0523082\ttest: 0.0518457\tbest: 0.0518457 (989)\ttotal: 3m 39s\tremaining: 28m 35s\n",
      "1136:\tlearn: 0.0523082\ttest: 0.0518457\tbest: 0.0518457 (989)\ttotal: 3m 40s\tremaining: 28m 35s\n",
      "1137:\tlearn: 0.0523082\ttest: 0.0518457\tbest: 0.0518457 (989)\ttotal: 3m 40s\tremaining: 28m 34s\n",
      "1138:\tlearn: 0.0523082\ttest: 0.0518457\tbest: 0.0518457 (989)\ttotal: 3m 40s\tremaining: 28m 34s\n",
      "1139:\tlearn: 0.0523082\ttest: 0.0518457\tbest: 0.0518457 (989)\ttotal: 3m 40s\tremaining: 28m 34s\n",
      "1140:\tlearn: 0.0523082\ttest: 0.0518457\tbest: 0.0518457 (989)\ttotal: 3m 40s\tremaining: 28m 33s\n",
      "1141:\tlearn: 0.0523082\ttest: 0.0518457\tbest: 0.0518457 (989)\ttotal: 3m 40s\tremaining: 28m 33s\n",
      "1142:\tlearn: 0.0523082\ttest: 0.0518457\tbest: 0.0518457 (989)\ttotal: 3m 41s\tremaining: 28m 33s\n",
      "1143:\tlearn: 0.0523082\ttest: 0.0518457\tbest: 0.0518457 (989)\ttotal: 3m 41s\tremaining: 28m 32s\n",
      "1144:\tlearn: 0.0523082\ttest: 0.0518457\tbest: 0.0518457 (989)\ttotal: 3m 41s\tremaining: 28m 32s\n",
      "1145:\tlearn: 0.0523082\ttest: 0.0518457\tbest: 0.0518457 (989)\ttotal: 3m 41s\tremaining: 28m 32s\n",
      "1146:\tlearn: 0.0523082\ttest: 0.0518457\tbest: 0.0518457 (989)\ttotal: 3m 41s\tremaining: 28m 31s\n",
      "1147:\tlearn: 0.0523082\ttest: 0.0518457\tbest: 0.0518457 (989)\ttotal: 3m 41s\tremaining: 28m 31s\n",
      "1148:\tlearn: 0.0523082\ttest: 0.0518457\tbest: 0.0518457 (989)\ttotal: 3m 42s\tremaining: 28m 30s\n",
      "1149:\tlearn: 0.0523082\ttest: 0.0518457\tbest: 0.0518457 (989)\ttotal: 3m 42s\tremaining: 28m 30s\n",
      "1150:\tlearn: 0.0523082\ttest: 0.0518457\tbest: 0.0518457 (989)\ttotal: 3m 42s\tremaining: 28m 30s\n",
      "1151:\tlearn: 0.0523082\ttest: 0.0518457\tbest: 0.0518457 (989)\ttotal: 3m 42s\tremaining: 28m 30s\n",
      "1152:\tlearn: 0.0523082\ttest: 0.0518457\tbest: 0.0518457 (989)\ttotal: 3m 42s\tremaining: 28m 29s\n",
      "1153:\tlearn: 0.0523082\ttest: 0.0518457\tbest: 0.0518457 (989)\ttotal: 3m 42s\tremaining: 28m 29s\n",
      "1154:\tlearn: 0.0523082\ttest: 0.0518457\tbest: 0.0518457 (989)\ttotal: 3m 43s\tremaining: 28m 28s\n",
      "1155:\tlearn: 0.0523082\ttest: 0.0518457\tbest: 0.0518457 (989)\ttotal: 3m 43s\tremaining: 28m 28s\n",
      "1156:\tlearn: 0.0523082\ttest: 0.0518457\tbest: 0.0518457 (989)\ttotal: 3m 43s\tremaining: 28m 28s\n",
      "1157:\tlearn: 0.0523082\ttest: 0.0518457\tbest: 0.0518457 (989)\ttotal: 3m 43s\tremaining: 28m 27s\n",
      "1158:\tlearn: 0.0523082\ttest: 0.0518457\tbest: 0.0518457 (989)\ttotal: 3m 43s\tremaining: 28m 27s\n",
      "1159:\tlearn: 0.0523082\ttest: 0.0518457\tbest: 0.0518457 (989)\ttotal: 3m 44s\tremaining: 28m 27s\n",
      "1160:\tlearn: 0.0523082\ttest: 0.0518457\tbest: 0.0518457 (989)\ttotal: 3m 44s\tremaining: 28m 26s\n",
      "1161:\tlearn: 0.0523082\ttest: 0.0518457\tbest: 0.0518457 (989)\ttotal: 3m 44s\tremaining: 28m 26s\n",
      "1162:\tlearn: 0.0523082\ttest: 0.0518457\tbest: 0.0518457 (989)\ttotal: 3m 44s\tremaining: 28m 26s\n",
      "1163:\tlearn: 0.0523082\ttest: 0.0518457\tbest: 0.0518457 (989)\ttotal: 3m 44s\tremaining: 28m 25s\n",
      "1164:\tlearn: 0.0523082\ttest: 0.0518457\tbest: 0.0518457 (989)\ttotal: 3m 44s\tremaining: 28m 25s\n",
      "1165:\tlearn: 0.0523082\ttest: 0.0518457\tbest: 0.0518457 (989)\ttotal: 3m 45s\tremaining: 28m 25s\n",
      "1166:\tlearn: 0.0523082\ttest: 0.0518457\tbest: 0.0518457 (989)\ttotal: 3m 45s\tremaining: 28m 24s\n",
      "1167:\tlearn: 0.0523082\ttest: 0.0518457\tbest: 0.0518457 (989)\ttotal: 3m 45s\tremaining: 28m 24s\n",
      "1168:\tlearn: 0.0523082\ttest: 0.0518457\tbest: 0.0518457 (989)\ttotal: 3m 45s\tremaining: 28m 23s\n",
      "1169:\tlearn: 0.0523082\ttest: 0.0518457\tbest: 0.0518457 (989)\ttotal: 3m 45s\tremaining: 28m 23s\n",
      "1170:\tlearn: 0.0523082\ttest: 0.0518457\tbest: 0.0518457 (989)\ttotal: 3m 45s\tremaining: 28m 23s\n",
      "1171:\tlearn: 0.0523082\ttest: 0.0518457\tbest: 0.0518457 (989)\ttotal: 3m 46s\tremaining: 28m 22s\n",
      "1172:\tlearn: 0.0523082\ttest: 0.0518457\tbest: 0.0518457 (989)\ttotal: 3m 46s\tremaining: 28m 22s\n",
      "1173:\tlearn: 0.0523082\ttest: 0.0518457\tbest: 0.0518457 (989)\ttotal: 3m 46s\tremaining: 28m 22s\n",
      "1174:\tlearn: 0.0523082\ttest: 0.0518457\tbest: 0.0518457 (989)\ttotal: 3m 46s\tremaining: 28m 21s\n",
      "1175:\tlearn: 0.0523082\ttest: 0.0518457\tbest: 0.0518457 (989)\ttotal: 3m 46s\tremaining: 28m 21s\n",
      "1176:\tlearn: 0.0523082\ttest: 0.0518457\tbest: 0.0518457 (989)\ttotal: 3m 46s\tremaining: 28m 21s\n",
      "1177:\tlearn: 0.0523082\ttest: 0.0518457\tbest: 0.0518457 (989)\ttotal: 3m 47s\tremaining: 28m 20s\n",
      "1178:\tlearn: 0.0523082\ttest: 0.0518457\tbest: 0.0518457 (989)\ttotal: 3m 47s\tremaining: 28m 20s\n",
      "1179:\tlearn: 0.0523082\ttest: 0.0518457\tbest: 0.0518457 (989)\ttotal: 3m 47s\tremaining: 28m 20s\n",
      "1180:\tlearn: 0.0523082\ttest: 0.0518457\tbest: 0.0518457 (989)\ttotal: 3m 47s\tremaining: 28m 19s\n",
      "1181:\tlearn: 0.0523082\ttest: 0.0518457\tbest: 0.0518457 (989)\ttotal: 3m 47s\tremaining: 28m 19s\n",
      "1182:\tlearn: 0.0523082\ttest: 0.0518457\tbest: 0.0518457 (989)\ttotal: 3m 47s\tremaining: 28m 19s\n",
      "1183:\tlearn: 0.0523082\ttest: 0.0518457\tbest: 0.0518457 (989)\ttotal: 3m 48s\tremaining: 28m 18s\n",
      "1184:\tlearn: 0.0523082\ttest: 0.0518457\tbest: 0.0518457 (989)\ttotal: 3m 48s\tremaining: 28m 18s\n",
      "1185:\tlearn: 0.0523082\ttest: 0.0518457\tbest: 0.0518457 (989)\ttotal: 3m 48s\tremaining: 28m 18s\n",
      "1186:\tlearn: 0.0523082\ttest: 0.0518457\tbest: 0.0518457 (989)\ttotal: 3m 48s\tremaining: 28m 17s\n",
      "1187:\tlearn: 0.0523082\ttest: 0.0518457\tbest: 0.0518457 (989)\ttotal: 3m 48s\tremaining: 28m 17s\n",
      "1188:\tlearn: 0.0523082\ttest: 0.0518457\tbest: 0.0518457 (989)\ttotal: 3m 49s\tremaining: 28m 17s\n",
      "1189:\tlearn: 0.0523082\ttest: 0.0518457\tbest: 0.0518457 (989)\ttotal: 3m 49s\tremaining: 28m 16s\n",
      "1190:\tlearn: 0.0523082\ttest: 0.0518457\tbest: 0.0518457 (989)\ttotal: 3m 49s\tremaining: 28m 16s\n",
      "1191:\tlearn: 0.0523082\ttest: 0.0518457\tbest: 0.0518457 (989)\ttotal: 3m 49s\tremaining: 28m 16s\n",
      "1192:\tlearn: 0.0523082\ttest: 0.0518457\tbest: 0.0518457 (989)\ttotal: 3m 49s\tremaining: 28m 15s\n",
      "1193:\tlearn: 0.0523082\ttest: 0.0518457\tbest: 0.0518457 (989)\ttotal: 3m 49s\tremaining: 28m 15s\n",
      "1194:\tlearn: 0.0523082\ttest: 0.0518457\tbest: 0.0518457 (989)\ttotal: 3m 50s\tremaining: 28m 15s\n",
      "1195:\tlearn: 0.0523082\ttest: 0.0518457\tbest: 0.0518457 (989)\ttotal: 3m 50s\tremaining: 28m 14s\n",
      "1196:\tlearn: 0.0523082\ttest: 0.0518457\tbest: 0.0518457 (989)\ttotal: 3m 50s\tremaining: 28m 14s\n",
      "1197:\tlearn: 0.0523082\ttest: 0.0518457\tbest: 0.0518457 (989)\ttotal: 3m 50s\tremaining: 28m 14s\n",
      "1198:\tlearn: 0.0523082\ttest: 0.0518457\tbest: 0.0518457 (989)\ttotal: 3m 50s\tremaining: 28m 13s\n",
      "1199:\tlearn: 0.0523082\ttest: 0.0518457\tbest: 0.0518457 (989)\ttotal: 3m 50s\tremaining: 28m 13s\n",
      "1200:\tlearn: 0.0523082\ttest: 0.0518457\tbest: 0.0518457 (989)\ttotal: 3m 51s\tremaining: 28m 13s\n",
      "1201:\tlearn: 0.0523082\ttest: 0.0518457\tbest: 0.0518457 (989)\ttotal: 3m 51s\tremaining: 28m 12s\n",
      "1202:\tlearn: 0.0523082\ttest: 0.0518457\tbest: 0.0518457 (989)\ttotal: 3m 51s\tremaining: 28m 12s\n",
      "1203:\tlearn: 0.0523082\ttest: 0.0518457\tbest: 0.0518457 (989)\ttotal: 3m 51s\tremaining: 28m 12s\n",
      "1204:\tlearn: 0.0523082\ttest: 0.0518457\tbest: 0.0518457 (989)\ttotal: 3m 51s\tremaining: 28m 11s\n",
      "1205:\tlearn: 0.0523082\ttest: 0.0518457\tbest: 0.0518457 (989)\ttotal: 3m 51s\tremaining: 28m 11s\n",
      "1206:\tlearn: 0.0523082\ttest: 0.0518457\tbest: 0.0518457 (989)\ttotal: 3m 52s\tremaining: 28m 11s\n",
      "1207:\tlearn: 0.0523082\ttest: 0.0518457\tbest: 0.0518457 (989)\ttotal: 3m 52s\tremaining: 28m 10s\n",
      "1208:\tlearn: 0.0523082\ttest: 0.0518457\tbest: 0.0518457 (989)\ttotal: 3m 52s\tremaining: 28m 10s\n",
      "1209:\tlearn: 0.0523082\ttest: 0.0518457\tbest: 0.0518457 (989)\ttotal: 3m 52s\tremaining: 28m 10s\n",
      "1210:\tlearn: 0.0523082\ttest: 0.0518457\tbest: 0.0518457 (989)\ttotal: 3m 52s\tremaining: 28m 9s\n",
      "1211:\tlearn: 0.0523082\ttest: 0.0518457\tbest: 0.0518457 (989)\ttotal: 3m 53s\tremaining: 28m 9s\n",
      "1212:\tlearn: 0.0523082\ttest: 0.0518457\tbest: 0.0518457 (989)\ttotal: 3m 53s\tremaining: 28m 9s\n",
      "1213:\tlearn: 0.0523082\ttest: 0.0518457\tbest: 0.0518457 (989)\ttotal: 3m 53s\tremaining: 28m 8s\n",
      "1214:\tlearn: 0.0523082\ttest: 0.0518457\tbest: 0.0518457 (989)\ttotal: 3m 53s\tremaining: 28m 8s\n",
      "1215:\tlearn: 0.0523082\ttest: 0.0518457\tbest: 0.0518457 (989)\ttotal: 3m 53s\tremaining: 28m 8s\n",
      "1216:\tlearn: 0.0523082\ttest: 0.0518457\tbest: 0.0518457 (989)\ttotal: 3m 53s\tremaining: 28m 7s\n",
      "1217:\tlearn: 0.0523082\ttest: 0.0518457\tbest: 0.0518457 (989)\ttotal: 3m 54s\tremaining: 28m 7s\n",
      "1218:\tlearn: 0.0523082\ttest: 0.0518457\tbest: 0.0518457 (989)\ttotal: 3m 54s\tremaining: 28m 7s\n",
      "1219:\tlearn: 0.0523082\ttest: 0.0518457\tbest: 0.0518457 (989)\ttotal: 3m 54s\tremaining: 28m 6s\n",
      "1220:\tlearn: 0.0523082\ttest: 0.0518457\tbest: 0.0518457 (989)\ttotal: 3m 54s\tremaining: 28m 6s\n",
      "1221:\tlearn: 0.0523082\ttest: 0.0518457\tbest: 0.0518457 (989)\ttotal: 3m 54s\tremaining: 28m 6s\n",
      "1222:\tlearn: 0.0523082\ttest: 0.0518457\tbest: 0.0518457 (989)\ttotal: 3m 54s\tremaining: 28m 5s\n",
      "1223:\tlearn: 0.0523082\ttest: 0.0518457\tbest: 0.0518457 (989)\ttotal: 3m 55s\tremaining: 28m 5s\n",
      "1224:\tlearn: 0.0523082\ttest: 0.0518457\tbest: 0.0518457 (989)\ttotal: 3m 55s\tremaining: 28m 5s\n",
      "1225:\tlearn: 0.0523082\ttest: 0.0518457\tbest: 0.0518457 (989)\ttotal: 3m 55s\tremaining: 28m 4s\n",
      "1226:\tlearn: 0.0523082\ttest: 0.0518457\tbest: 0.0518457 (989)\ttotal: 3m 55s\tremaining: 28m 4s\n",
      "1227:\tlearn: 0.0523082\ttest: 0.0518457\tbest: 0.0518457 (989)\ttotal: 3m 55s\tremaining: 28m 4s\n",
      "1228:\tlearn: 0.0523082\ttest: 0.0518457\tbest: 0.0518457 (989)\ttotal: 3m 55s\tremaining: 28m 3s\n",
      "1229:\tlearn: 0.0523082\ttest: 0.0518457\tbest: 0.0518457 (989)\ttotal: 3m 56s\tremaining: 28m 3s\n",
      "1230:\tlearn: 0.0523082\ttest: 0.0518457\tbest: 0.0518457 (989)\ttotal: 3m 56s\tremaining: 28m 3s\n",
      "1231:\tlearn: 0.0523082\ttest: 0.0518457\tbest: 0.0518457 (989)\ttotal: 3m 56s\tremaining: 28m 2s\n",
      "1232:\tlearn: 0.0523082\ttest: 0.0518457\tbest: 0.0518457 (989)\ttotal: 3m 56s\tremaining: 28m 2s\n",
      "1233:\tlearn: 0.0523082\ttest: 0.0518457\tbest: 0.0518457 (989)\ttotal: 3m 56s\tremaining: 28m 2s\n",
      "1234:\tlearn: 0.0523082\ttest: 0.0518457\tbest: 0.0518457 (989)\ttotal: 3m 56s\tremaining: 28m 1s\n",
      "1235:\tlearn: 0.0523082\ttest: 0.0518457\tbest: 0.0518457 (989)\ttotal: 3m 57s\tremaining: 28m 1s\n",
      "1236:\tlearn: 0.0523082\ttest: 0.0518457\tbest: 0.0518457 (989)\ttotal: 3m 57s\tremaining: 28m 1s\n",
      "1237:\tlearn: 0.0523082\ttest: 0.0518457\tbest: 0.0518457 (989)\ttotal: 3m 57s\tremaining: 28m 1s\n",
      "1238:\tlearn: 0.0523082\ttest: 0.0518457\tbest: 0.0518457 (989)\ttotal: 3m 57s\tremaining: 28m\n",
      "1239:\tlearn: 0.0523082\ttest: 0.0518457\tbest: 0.0518457 (989)\ttotal: 3m 57s\tremaining: 28m\n",
      "1240:\tlearn: 0.0523082\ttest: 0.0518457\tbest: 0.0518457 (989)\ttotal: 3m 58s\tremaining: 28m\n",
      "1241:\tlearn: 0.0523082\ttest: 0.0518457\tbest: 0.0518457 (989)\ttotal: 3m 58s\tremaining: 27m 59s\n",
      "1242:\tlearn: 0.0523082\ttest: 0.0518457\tbest: 0.0518457 (989)\ttotal: 3m 58s\tremaining: 27m 59s\n",
      "1243:\tlearn: 0.0523082\ttest: 0.0518457\tbest: 0.0518457 (989)\ttotal: 3m 58s\tremaining: 27m 59s\n",
      "1244:\tlearn: 0.0523082\ttest: 0.0518457\tbest: 0.0518457 (989)\ttotal: 3m 58s\tremaining: 27m 58s\n",
      "1245:\tlearn: 0.0523082\ttest: 0.0518457\tbest: 0.0518457 (989)\ttotal: 3m 58s\tremaining: 27m 58s\n",
      "1246:\tlearn: 0.0523082\ttest: 0.0518457\tbest: 0.0518457 (989)\ttotal: 3m 59s\tremaining: 27m 58s\n",
      "1247:\tlearn: 0.0523082\ttest: 0.0518457\tbest: 0.0518457 (989)\ttotal: 3m 59s\tremaining: 27m 57s\n",
      "1248:\tlearn: 0.0523082\ttest: 0.0518457\tbest: 0.0518457 (989)\ttotal: 3m 59s\tremaining: 27m 57s\n",
      "1249:\tlearn: 0.0523082\ttest: 0.0518457\tbest: 0.0518457 (989)\ttotal: 3m 59s\tremaining: 27m 57s\n",
      "1250:\tlearn: 0.0523082\ttest: 0.0518457\tbest: 0.0518457 (989)\ttotal: 3m 59s\tremaining: 27m 56s\n",
      "1251:\tlearn: 0.0523082\ttest: 0.0518457\tbest: 0.0518457 (989)\ttotal: 3m 59s\tremaining: 27m 56s\n",
      "1252:\tlearn: 0.0523082\ttest: 0.0518457\tbest: 0.0518457 (989)\ttotal: 4m\tremaining: 27m 56s\n",
      "1253:\tlearn: 0.0523082\ttest: 0.0518457\tbest: 0.0518457 (989)\ttotal: 4m\tremaining: 27m 55s\n",
      "1254:\tlearn: 0.0523082\ttest: 0.0518457\tbest: 0.0518457 (989)\ttotal: 4m\tremaining: 27m 55s\n",
      "1255:\tlearn: 0.0523082\ttest: 0.0518457\tbest: 0.0518457 (989)\ttotal: 4m\tremaining: 27m 55s\n",
      "1256:\tlearn: 0.0523082\ttest: 0.0518457\tbest: 0.0518457 (989)\ttotal: 4m\tremaining: 27m 54s\n",
      "1257:\tlearn: 0.0523082\ttest: 0.0518457\tbest: 0.0518457 (989)\ttotal: 4m\tremaining: 27m 54s\n",
      "1258:\tlearn: 0.0523082\ttest: 0.0518457\tbest: 0.0518457 (989)\ttotal: 4m 1s\tremaining: 27m 54s\n",
      "1259:\tlearn: 0.0523082\ttest: 0.0518457\tbest: 0.0518457 (989)\ttotal: 4m 1s\tremaining: 27m 53s\n",
      "1260:\tlearn: 0.0523082\ttest: 0.0518457\tbest: 0.0518457 (989)\ttotal: 4m 1s\tremaining: 27m 53s\n",
      "1261:\tlearn: 0.0523082\ttest: 0.0518457\tbest: 0.0518457 (989)\ttotal: 4m 1s\tremaining: 27m 53s\n",
      "1262:\tlearn: 0.0523082\ttest: 0.0518457\tbest: 0.0518457 (989)\ttotal: 4m 1s\tremaining: 27m 52s\n",
      "1263:\tlearn: 0.0523082\ttest: 0.0518457\tbest: 0.0518457 (989)\ttotal: 4m 2s\tremaining: 27m 52s\n",
      "1264:\tlearn: 0.0523082\ttest: 0.0518457\tbest: 0.0518457 (989)\ttotal: 4m 2s\tremaining: 27m 52s\n",
      "1265:\tlearn: 0.0523082\ttest: 0.0518457\tbest: 0.0518457 (989)\ttotal: 4m 2s\tremaining: 27m 52s\n",
      "1266:\tlearn: 0.0523082\ttest: 0.0518457\tbest: 0.0518457 (989)\ttotal: 4m 2s\tremaining: 27m 51s\n",
      "1267:\tlearn: 0.0523082\ttest: 0.0518457\tbest: 0.0518457 (989)\ttotal: 4m 2s\tremaining: 27m 51s\n",
      "1268:\tlearn: 0.0523082\ttest: 0.0518457\tbest: 0.0518457 (989)\ttotal: 4m 2s\tremaining: 27m 51s\n",
      "1269:\tlearn: 0.0523082\ttest: 0.0518457\tbest: 0.0518457 (989)\ttotal: 4m 3s\tremaining: 27m 50s\n",
      "1270:\tlearn: 0.0523082\ttest: 0.0518457\tbest: 0.0518457 (989)\ttotal: 4m 3s\tremaining: 27m 50s\n",
      "1271:\tlearn: 0.0523082\ttest: 0.0518457\tbest: 0.0518457 (989)\ttotal: 4m 3s\tremaining: 27m 50s\n",
      "1272:\tlearn: 0.0523082\ttest: 0.0518457\tbest: 0.0518457 (989)\ttotal: 4m 3s\tremaining: 27m 49s\n",
      "1273:\tlearn: 0.0523082\ttest: 0.0518457\tbest: 0.0518457 (989)\ttotal: 4m 3s\tremaining: 27m 49s\n",
      "1274:\tlearn: 0.0523082\ttest: 0.0518457\tbest: 0.0518457 (989)\ttotal: 4m 3s\tremaining: 27m 49s\n",
      "1275:\tlearn: 0.0523082\ttest: 0.0518457\tbest: 0.0518457 (989)\ttotal: 4m 4s\tremaining: 27m 48s\n",
      "1276:\tlearn: 0.0523082\ttest: 0.0518457\tbest: 0.0518457 (989)\ttotal: 4m 4s\tremaining: 27m 48s\n",
      "1277:\tlearn: 0.0523082\ttest: 0.0518457\tbest: 0.0518457 (989)\ttotal: 4m 4s\tremaining: 27m 48s\n",
      "1278:\tlearn: 0.0523082\ttest: 0.0518457\tbest: 0.0518457 (989)\ttotal: 4m 4s\tremaining: 27m 48s\n",
      "1279:\tlearn: 0.0523082\ttest: 0.0518457\tbest: 0.0518457 (989)\ttotal: 4m 4s\tremaining: 27m 47s\n",
      "1280:\tlearn: 0.0523082\ttest: 0.0518457\tbest: 0.0518457 (989)\ttotal: 4m 4s\tremaining: 27m 47s\n",
      "1281:\tlearn: 0.0523082\ttest: 0.0518457\tbest: 0.0518457 (989)\ttotal: 4m 5s\tremaining: 27m 47s\n",
      "1282:\tlearn: 0.0523082\ttest: 0.0518457\tbest: 0.0518457 (989)\ttotal: 4m 5s\tremaining: 27m 46s\n",
      "1283:\tlearn: 0.0523082\ttest: 0.0518457\tbest: 0.0518457 (989)\ttotal: 4m 5s\tremaining: 27m 46s\n",
      "1284:\tlearn: 0.0523082\ttest: 0.0518457\tbest: 0.0518457 (989)\ttotal: 4m 5s\tremaining: 27m 46s\n",
      "1285:\tlearn: 0.0523082\ttest: 0.0518457\tbest: 0.0518457 (989)\ttotal: 4m 5s\tremaining: 27m 45s\n",
      "1286:\tlearn: 0.0523082\ttest: 0.0518457\tbest: 0.0518457 (989)\ttotal: 4m 6s\tremaining: 27m 45s\n",
      "1287:\tlearn: 0.0523082\ttest: 0.0518457\tbest: 0.0518457 (989)\ttotal: 4m 6s\tremaining: 27m 45s\n",
      "1288:\tlearn: 0.0523082\ttest: 0.0518457\tbest: 0.0518457 (989)\ttotal: 4m 6s\tremaining: 27m 44s\n",
      "1289:\tlearn: 0.0523082\ttest: 0.0518457\tbest: 0.0518457 (989)\ttotal: 4m 6s\tremaining: 27m 44s\n",
      "1290:\tlearn: 0.0523082\ttest: 0.0518457\tbest: 0.0518457 (989)\ttotal: 4m 6s\tremaining: 27m 44s\n",
      "1291:\tlearn: 0.0523082\ttest: 0.0518457\tbest: 0.0518457 (989)\ttotal: 4m 6s\tremaining: 27m 44s\n",
      "1292:\tlearn: 0.0523082\ttest: 0.0518457\tbest: 0.0518457 (989)\ttotal: 4m 7s\tremaining: 27m 43s\n",
      "1293:\tlearn: 0.0523082\ttest: 0.0518457\tbest: 0.0518457 (989)\ttotal: 4m 7s\tremaining: 27m 43s\n",
      "1294:\tlearn: 0.0523082\ttest: 0.0518457\tbest: 0.0518457 (989)\ttotal: 4m 7s\tremaining: 27m 43s\n",
      "1295:\tlearn: 0.0523082\ttest: 0.0518457\tbest: 0.0518457 (989)\ttotal: 4m 7s\tremaining: 27m 42s\n",
      "1296:\tlearn: 0.0523082\ttest: 0.0518457\tbest: 0.0518457 (989)\ttotal: 4m 7s\tremaining: 27m 42s\n",
      "1297:\tlearn: 0.0523082\ttest: 0.0518457\tbest: 0.0518457 (989)\ttotal: 4m 7s\tremaining: 27m 42s\n",
      "1298:\tlearn: 0.0523082\ttest: 0.0518457\tbest: 0.0518457 (989)\ttotal: 4m 8s\tremaining: 27m 41s\n",
      "1299:\tlearn: 0.0523082\ttest: 0.0518457\tbest: 0.0518457 (989)\ttotal: 4m 8s\tremaining: 27m 41s\n",
      "1300:\tlearn: 0.0523082\ttest: 0.0518457\tbest: 0.0518457 (989)\ttotal: 4m 8s\tremaining: 27m 41s\n",
      "1301:\tlearn: 0.0523082\ttest: 0.0518457\tbest: 0.0518457 (989)\ttotal: 4m 8s\tremaining: 27m 41s\n",
      "1302:\tlearn: 0.0523082\ttest: 0.0518457\tbest: 0.0518457 (989)\ttotal: 4m 8s\tremaining: 27m 40s\n",
      "1303:\tlearn: 0.0523082\ttest: 0.0518457\tbest: 0.0518457 (989)\ttotal: 4m 8s\tremaining: 27m 40s\n",
      "1304:\tlearn: 0.0523082\ttest: 0.0518457\tbest: 0.0518457 (989)\ttotal: 4m 9s\tremaining: 27m 40s\n",
      "1305:\tlearn: 0.0523082\ttest: 0.0518457\tbest: 0.0518457 (989)\ttotal: 4m 9s\tremaining: 27m 39s\n",
      "1306:\tlearn: 0.0523082\ttest: 0.0518457\tbest: 0.0518457 (989)\ttotal: 4m 9s\tremaining: 27m 39s\n",
      "\n",
      "bestTest = 0.051845659\n",
      "bestIteration = 989\n",
      "\n",
      "Shrink model to first 990 iterations.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\tDropped 0 of 30 features.\n",
      "\tFitting S1F5 with 'num_gpus': 0, 'num_cpus': 8\n",
      "\tWarning: Potentially not enough memory to safely train CatBoost model, roughly requires: 4.463 GB, but only 5.061 GB is available...\n",
      "\tCatboost model hyperparameters: {'iterations': 10000, 'learning_rate': 0.02057151708150835, 'random_seed': 0, 'allow_writing_files': False, 'eval_metric': 'Logloss', 'depth': 5, 'l2_leaf_reg': 4.854651042004117, 'thread_count': 8}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:\tlearn: 0.6170043\ttest: 0.6169883\tbest: 0.6169883 (0)\ttotal: 226ms\tremaining: 37m 40s\n",
      "1:\tlearn: 0.5500401\ttest: 0.5499816\tbest: 0.5499816 (1)\ttotal: 482ms\tremaining: 40m 11s\n",
      "2:\tlearn: 0.4937431\ttest: 0.4934130\tbest: 0.4934130 (2)\ttotal: 721ms\tremaining: 40m\n",
      "3:\tlearn: 0.4411679\ttest: 0.4414861\tbest: 0.4414861 (3)\ttotal: 962ms\tremaining: 40m 3s\n",
      "4:\tlearn: 0.3958280\ttest: 0.3961390\tbest: 0.3961390 (4)\ttotal: 1.18s\tremaining: 39m 20s\n",
      "5:\tlearn: 0.3583228\ttest: 0.3585306\tbest: 0.3585306 (5)\ttotal: 1.42s\tremaining: 39m 26s\n",
      "6:\tlearn: 0.3238699\ttest: 0.3240515\tbest: 0.3240515 (6)\ttotal: 1.67s\tremaining: 39m 37s\n",
      "7:\tlearn: 0.2942752\ttest: 0.2941164\tbest: 0.2941164 (7)\ttotal: 1.91s\tremaining: 39m 48s\n",
      "8:\tlearn: 0.2678392\ttest: 0.2681392\tbest: 0.2681392 (8)\ttotal: 2.15s\tremaining: 39m 45s\n",
      "9:\tlearn: 0.2454081\ttest: 0.2456051\tbest: 0.2456051 (9)\ttotal: 2.4s\tremaining: 39m 53s\n",
      "10:\tlearn: 0.2284092\ttest: 0.2284525\tbest: 0.2284525 (10)\ttotal: 2.62s\tremaining: 39m 39s\n",
      "11:\tlearn: 0.2106649\ttest: 0.2109602\tbest: 0.2109602 (11)\ttotal: 2.86s\tremaining: 39m 38s\n",
      "12:\tlearn: 0.1955586\ttest: 0.1957178\tbest: 0.1957178 (12)\ttotal: 3.09s\tremaining: 39m 34s\n",
      "13:\tlearn: 0.1822928\ttest: 0.1823995\tbest: 0.1823995 (13)\ttotal: 3.33s\tremaining: 39m 39s\n",
      "14:\tlearn: 0.1707741\ttest: 0.1707199\tbest: 0.1707199 (14)\ttotal: 3.58s\tremaining: 39m 42s\n",
      "15:\tlearn: 0.1603632\ttest: 0.1605065\tbest: 0.1605065 (15)\ttotal: 3.83s\tremaining: 39m 51s\n",
      "16:\tlearn: 0.1513642\ttest: 0.1514217\tbest: 0.1514217 (16)\ttotal: 4.07s\tremaining: 39m 51s\n",
      "17:\tlearn: 0.1433913\ttest: 0.1433840\tbest: 0.1433840 (17)\ttotal: 4.32s\tremaining: 39m 57s\n",
      "18:\tlearn: 0.1363059\ttest: 0.1363389\tbest: 0.1363389 (18)\ttotal: 4.56s\tremaining: 39m 55s\n",
      "19:\tlearn: 0.1304442\ttest: 0.1305188\tbest: 0.1305188 (19)\ttotal: 4.79s\tremaining: 39m 50s\n",
      "20:\tlearn: 0.1251326\ttest: 0.1251893\tbest: 0.1251893 (20)\ttotal: 5.01s\tremaining: 39m 42s\n",
      "21:\tlearn: 0.1199868\ttest: 0.1200240\tbest: 0.1200240 (21)\ttotal: 5.26s\tremaining: 39m 46s\n",
      "22:\tlearn: 0.1156303\ttest: 0.1155307\tbest: 0.1155307 (22)\ttotal: 5.48s\tremaining: 39m 37s\n",
      "23:\tlearn: 0.1112851\ttest: 0.1111471\tbest: 0.1111471 (23)\ttotal: 5.72s\tremaining: 39m 37s\n",
      "24:\tlearn: 0.1072109\ttest: 0.1071751\tbest: 0.1071751 (24)\ttotal: 5.96s\tremaining: 39m 37s\n",
      "25:\tlearn: 0.1038214\ttest: 0.1037372\tbest: 0.1037372 (25)\ttotal: 6.2s\tremaining: 39m 38s\n",
      "26:\tlearn: 0.1002518\ttest: 0.1001120\tbest: 0.1001120 (26)\ttotal: 6.42s\tremaining: 39m 33s\n",
      "27:\tlearn: 0.0971933\ttest: 0.0970684\tbest: 0.0970684 (27)\ttotal: 6.67s\tremaining: 39m 33s\n",
      "28:\tlearn: 0.0939017\ttest: 0.0937815\tbest: 0.0937815 (28)\ttotal: 6.9s\tremaining: 39m 33s\n",
      "29:\tlearn: 0.0914737\ttest: 0.0914402\tbest: 0.0914402 (29)\ttotal: 7.13s\tremaining: 39m 28s\n",
      "30:\tlearn: 0.0892893\ttest: 0.0892575\tbest: 0.0892575 (30)\ttotal: 7.35s\tremaining: 39m 23s\n",
      "31:\tlearn: 0.0870315\ttest: 0.0868947\tbest: 0.0868947 (31)\ttotal: 7.58s\tremaining: 39m 22s\n",
      "32:\tlearn: 0.0848677\ttest: 0.0848318\tbest: 0.0848318 (32)\ttotal: 7.79s\tremaining: 39m 14s\n",
      "33:\tlearn: 0.0831466\ttest: 0.0830143\tbest: 0.0830143 (33)\ttotal: 8.03s\tremaining: 39m 12s\n",
      "34:\tlearn: 0.0817864\ttest: 0.0817110\tbest: 0.0817110 (34)\ttotal: 8.25s\tremaining: 39m 9s\n",
      "35:\tlearn: 0.0802694\ttest: 0.0801610\tbest: 0.0801610 (35)\ttotal: 8.48s\tremaining: 39m 7s\n",
      "36:\tlearn: 0.0791396\ttest: 0.0790076\tbest: 0.0790076 (36)\ttotal: 8.72s\tremaining: 39m 8s\n",
      "37:\tlearn: 0.0780276\ttest: 0.0778994\tbest: 0.0778994 (37)\ttotal: 8.94s\tremaining: 39m 4s\n",
      "38:\tlearn: 0.0766012\ttest: 0.0765329\tbest: 0.0765329 (38)\ttotal: 9.19s\tremaining: 39m 7s\n",
      "39:\tlearn: 0.0752546\ttest: 0.0751547\tbest: 0.0751547 (39)\ttotal: 9.42s\tremaining: 39m 5s\n",
      "40:\tlearn: 0.0739895\ttest: 0.0738756\tbest: 0.0738756 (40)\ttotal: 9.65s\tremaining: 39m 4s\n",
      "41:\tlearn: 0.0728785\ttest: 0.0727882\tbest: 0.0727882 (41)\ttotal: 9.87s\tremaining: 39m\n",
      "42:\tlearn: 0.0718095\ttest: 0.0717229\tbest: 0.0717229 (42)\ttotal: 10.1s\tremaining: 38m 57s\n",
      "43:\tlearn: 0.0709451\ttest: 0.0708291\tbest: 0.0708291 (43)\ttotal: 10.3s\tremaining: 38m 56s\n",
      "44:\tlearn: 0.0700772\ttest: 0.0699327\tbest: 0.0699327 (44)\ttotal: 10.5s\tremaining: 38m 53s\n",
      "45:\tlearn: 0.0692119\ttest: 0.0690336\tbest: 0.0690336 (45)\ttotal: 10.8s\tremaining: 38m 51s\n",
      "46:\tlearn: 0.0683472\ttest: 0.0682045\tbest: 0.0682045 (46)\ttotal: 11s\tremaining: 38m 49s\n",
      "47:\tlearn: 0.0677276\ttest: 0.0675503\tbest: 0.0675503 (47)\ttotal: 11.2s\tremaining: 38m 44s\n",
      "48:\tlearn: 0.0669558\ttest: 0.0667781\tbest: 0.0667781 (48)\ttotal: 11.4s\tremaining: 38m 43s\n",
      "49:\tlearn: 0.0663048\ttest: 0.0661820\tbest: 0.0661820 (49)\ttotal: 11.7s\tremaining: 38m 42s\n",
      "50:\tlearn: 0.0656498\ttest: 0.0654720\tbest: 0.0654720 (50)\ttotal: 11.9s\tremaining: 38m 38s\n",
      "51:\tlearn: 0.0651521\ttest: 0.0649903\tbest: 0.0649903 (51)\ttotal: 12.1s\tremaining: 38m 36s\n",
      "52:\tlearn: 0.0647352\ttest: 0.0645647\tbest: 0.0645647 (52)\ttotal: 12.3s\tremaining: 38m 30s\n",
      "53:\tlearn: 0.0640862\ttest: 0.0639394\tbest: 0.0639394 (53)\ttotal: 12.5s\tremaining: 38m 26s\n",
      "54:\tlearn: 0.0634941\ttest: 0.0633333\tbest: 0.0633333 (54)\ttotal: 12.8s\tremaining: 38m 28s\n",
      "55:\tlearn: 0.0631248\ttest: 0.0629115\tbest: 0.0629115 (55)\ttotal: 13s\tremaining: 38m 27s\n",
      "56:\tlearn: 0.0626353\ttest: 0.0625052\tbest: 0.0625052 (56)\ttotal: 13.2s\tremaining: 38m 29s\n",
      "57:\tlearn: 0.0621790\ttest: 0.0620876\tbest: 0.0620876 (57)\ttotal: 13.5s\tremaining: 38m 30s\n",
      "58:\tlearn: 0.0617624\ttest: 0.0616058\tbest: 0.0616058 (58)\ttotal: 13.7s\tremaining: 38m 29s\n",
      "59:\tlearn: 0.0613919\ttest: 0.0612184\tbest: 0.0612184 (59)\ttotal: 13.9s\tremaining: 38m 29s\n",
      "60:\tlearn: 0.0610595\ttest: 0.0609131\tbest: 0.0609131 (60)\ttotal: 14.2s\tremaining: 38m 25s\n",
      "61:\tlearn: 0.0607573\ttest: 0.0606027\tbest: 0.0606027 (61)\ttotal: 14.4s\tremaining: 38m 28s\n",
      "62:\tlearn: 0.0604418\ttest: 0.0602314\tbest: 0.0602314 (62)\ttotal: 14.6s\tremaining: 38m 25s\n",
      "63:\tlearn: 0.0601157\ttest: 0.0599103\tbest: 0.0599103 (63)\ttotal: 14.9s\tremaining: 38m 26s\n",
      "64:\tlearn: 0.0598025\ttest: 0.0596205\tbest: 0.0596205 (64)\ttotal: 15.1s\tremaining: 38m 27s\n",
      "65:\tlearn: 0.0595112\ttest: 0.0593285\tbest: 0.0593285 (65)\ttotal: 15.3s\tremaining: 38m 29s\n",
      "66:\tlearn: 0.0592429\ttest: 0.0590742\tbest: 0.0590742 (66)\ttotal: 15.6s\tremaining: 38m 28s\n",
      "67:\tlearn: 0.0590288\ttest: 0.0588358\tbest: 0.0588358 (67)\ttotal: 15.8s\tremaining: 38m 23s\n",
      "68:\tlearn: 0.0587685\ttest: 0.0585959\tbest: 0.0585959 (68)\ttotal: 16s\tremaining: 38m 25s\n",
      "69:\tlearn: 0.0585628\ttest: 0.0583771\tbest: 0.0583771 (69)\ttotal: 16.2s\tremaining: 38m 22s\n",
      "70:\tlearn: 0.0583775\ttest: 0.0581697\tbest: 0.0581697 (70)\ttotal: 16.5s\tremaining: 38m 23s\n",
      "71:\tlearn: 0.0582069\ttest: 0.0579969\tbest: 0.0579969 (71)\ttotal: 16.7s\tremaining: 38m 20s\n",
      "72:\tlearn: 0.0580409\ttest: 0.0578079\tbest: 0.0578079 (72)\ttotal: 16.9s\tremaining: 38m 15s\n",
      "73:\tlearn: 0.0578538\ttest: 0.0576172\tbest: 0.0576172 (73)\ttotal: 17.1s\tremaining: 38m 15s\n",
      "74:\tlearn: 0.0577083\ttest: 0.0574615\tbest: 0.0574615 (74)\ttotal: 17.4s\tremaining: 38m 16s\n",
      "75:\tlearn: 0.0575284\ttest: 0.0572883\tbest: 0.0572883 (75)\ttotal: 17.6s\tremaining: 38m 17s\n",
      "76:\tlearn: 0.0573598\ttest: 0.0571427\tbest: 0.0571427 (76)\ttotal: 17.8s\tremaining: 38m 18s\n",
      "77:\tlearn: 0.0572059\ttest: 0.0569962\tbest: 0.0569962 (77)\ttotal: 18s\tremaining: 38m 15s\n",
      "78:\tlearn: 0.0570697\ttest: 0.0568408\tbest: 0.0568408 (78)\ttotal: 18.3s\tremaining: 38m 13s\n",
      "79:\tlearn: 0.0569178\ttest: 0.0566995\tbest: 0.0566995 (79)\ttotal: 18.5s\tremaining: 38m 14s\n",
      "80:\tlearn: 0.0567795\ttest: 0.0565825\tbest: 0.0565825 (80)\ttotal: 18.7s\tremaining: 38m 11s\n",
      "81:\tlearn: 0.0566919\ttest: 0.0564618\tbest: 0.0564618 (81)\ttotal: 18.9s\tremaining: 38m 10s\n",
      "82:\tlearn: 0.0565516\ttest: 0.0563552\tbest: 0.0563552 (82)\ttotal: 19.2s\tremaining: 38m 10s\n",
      "83:\tlearn: 0.0564831\ttest: 0.0562551\tbest: 0.0562551 (83)\ttotal: 19.4s\tremaining: 38m 11s\n",
      "84:\tlearn: 0.0563983\ttest: 0.0561493\tbest: 0.0561493 (84)\ttotal: 19.6s\tremaining: 38m 7s\n",
      "85:\tlearn: 0.0562575\ttest: 0.0560371\tbest: 0.0560371 (85)\ttotal: 19.8s\tremaining: 38m 7s\n",
      "86:\tlearn: 0.0561704\ttest: 0.0559389\tbest: 0.0559389 (86)\ttotal: 20s\tremaining: 38m 2s\n",
      "87:\tlearn: 0.0560878\ttest: 0.0558451\tbest: 0.0558451 (87)\ttotal: 20.2s\tremaining: 37m 59s\n",
      "88:\tlearn: 0.0560250\ttest: 0.0557633\tbest: 0.0557633 (88)\ttotal: 20.5s\tremaining: 37m 59s\n",
      "89:\tlearn: 0.0558900\ttest: 0.0556685\tbest: 0.0556685 (89)\ttotal: 20.7s\tremaining: 37m 56s\n",
      "90:\tlearn: 0.0558075\ttest: 0.0555837\tbest: 0.0555837 (90)\ttotal: 20.9s\tremaining: 37m 55s\n",
      "91:\tlearn: 0.0557432\ttest: 0.0555119\tbest: 0.0555119 (91)\ttotal: 21.1s\tremaining: 37m 54s\n",
      "92:\tlearn: 0.0556724\ttest: 0.0554279\tbest: 0.0554279 (92)\ttotal: 21.3s\tremaining: 37m 54s\n",
      "93:\tlearn: 0.0555970\ttest: 0.0553459\tbest: 0.0553459 (93)\ttotal: 21.6s\tremaining: 37m 52s\n",
      "94:\tlearn: 0.0555335\ttest: 0.0552828\tbest: 0.0552828 (94)\ttotal: 21.8s\tremaining: 37m 52s\n",
      "95:\tlearn: 0.0554692\ttest: 0.0552182\tbest: 0.0552182 (95)\ttotal: 22s\tremaining: 37m 49s\n",
      "96:\tlearn: 0.0553963\ttest: 0.0551466\tbest: 0.0551466 (96)\ttotal: 22.2s\tremaining: 37m 49s\n",
      "97:\tlearn: 0.0553255\ttest: 0.0550817\tbest: 0.0550817 (97)\ttotal: 22.5s\tremaining: 37m 48s\n",
      "98:\tlearn: 0.0552705\ttest: 0.0550283\tbest: 0.0550283 (98)\ttotal: 22.7s\tremaining: 37m 45s\n",
      "99:\tlearn: 0.0552074\ttest: 0.0549700\tbest: 0.0549700 (99)\ttotal: 22.9s\tremaining: 37m 43s\n",
      "100:\tlearn: 0.0551402\ttest: 0.0549085\tbest: 0.0549085 (100)\ttotal: 23.1s\tremaining: 37m 42s\n",
      "101:\tlearn: 0.0551186\ttest: 0.0548536\tbest: 0.0548536 (101)\ttotal: 23.3s\tremaining: 37m 38s\n",
      "102:\tlearn: 0.0550844\ttest: 0.0548022\tbest: 0.0548022 (102)\ttotal: 23.5s\tremaining: 37m 33s\n",
      "103:\tlearn: 0.0550199\ttest: 0.0547561\tbest: 0.0547561 (103)\ttotal: 23.7s\tremaining: 37m 32s\n",
      "104:\tlearn: 0.0549777\ttest: 0.0547147\tbest: 0.0547147 (104)\ttotal: 23.9s\tremaining: 37m 28s\n",
      "105:\tlearn: 0.0549436\ttest: 0.0546661\tbest: 0.0546661 (105)\ttotal: 24.1s\tremaining: 37m 26s\n",
      "106:\tlearn: 0.0548987\ttest: 0.0546291\tbest: 0.0546291 (106)\ttotal: 24.3s\tremaining: 37m 24s\n",
      "107:\tlearn: 0.0548298\ttest: 0.0545845\tbest: 0.0545845 (107)\ttotal: 24.5s\tremaining: 37m 23s\n",
      "108:\tlearn: 0.0547746\ttest: 0.0545398\tbest: 0.0545398 (108)\ttotal: 24.7s\tremaining: 37m 23s\n",
      "109:\tlearn: 0.0547756\ttest: 0.0544970\tbest: 0.0544970 (109)\ttotal: 25s\tremaining: 37m 23s\n",
      "110:\tlearn: 0.0547093\ttest: 0.0544613\tbest: 0.0544613 (110)\ttotal: 25.2s\tremaining: 37m 21s\n",
      "111:\tlearn: 0.0546605\ttest: 0.0544249\tbest: 0.0544249 (111)\ttotal: 25.4s\tremaining: 37m 21s\n",
      "112:\tlearn: 0.0546583\ttest: 0.0543856\tbest: 0.0543856 (112)\ttotal: 25.6s\tremaining: 37m 20s\n",
      "113:\tlearn: 0.0545963\ttest: 0.0543499\tbest: 0.0543499 (113)\ttotal: 25.8s\tremaining: 37m 19s\n",
      "114:\tlearn: 0.0545814\ttest: 0.0543155\tbest: 0.0543155 (114)\ttotal: 26s\tremaining: 37m 18s\n",
      "115:\tlearn: 0.0545337\ttest: 0.0542849\tbest: 0.0542849 (115)\ttotal: 26.2s\tremaining: 37m 13s\n",
      "116:\tlearn: 0.0545402\ttest: 0.0542511\tbest: 0.0542511 (116)\ttotal: 26.4s\tremaining: 37m 11s\n",
      "117:\tlearn: 0.0544844\ttest: 0.0542199\tbest: 0.0542199 (117)\ttotal: 26.6s\tremaining: 37m 10s\n",
      "118:\tlearn: 0.0544713\ttest: 0.0541896\tbest: 0.0541896 (118)\ttotal: 26.8s\tremaining: 37m 8s\n",
      "119:\tlearn: 0.0544264\ttest: 0.0541668\tbest: 0.0541668 (119)\ttotal: 27s\tremaining: 37m 6s\n",
      "120:\tlearn: 0.0544254\ttest: 0.0541392\tbest: 0.0541392 (120)\ttotal: 27.3s\tremaining: 37m 5s\n",
      "121:\tlearn: 0.0543733\ttest: 0.0541154\tbest: 0.0541154 (121)\ttotal: 27.5s\tremaining: 37m 2s\n",
      "122:\tlearn: 0.0543732\ttest: 0.0540899\tbest: 0.0540899 (122)\ttotal: 27.7s\tremaining: 37m 1s\n",
      "123:\tlearn: 0.0543201\ttest: 0.0540675\tbest: 0.0540675 (123)\ttotal: 27.9s\tremaining: 37m 2s\n",
      "124:\tlearn: 0.0543095\ttest: 0.0540343\tbest: 0.0540343 (124)\ttotal: 28.1s\tremaining: 37m 1s\n",
      "125:\tlearn: 0.0542713\ttest: 0.0540161\tbest: 0.0540161 (125)\ttotal: 28.3s\tremaining: 37m\n",
      "126:\tlearn: 0.0542679\ttest: 0.0539925\tbest: 0.0539925 (126)\ttotal: 28.6s\tremaining: 37m\n",
      "127:\tlearn: 0.0542126\ttest: 0.0539706\tbest: 0.0539706 (127)\ttotal: 28.8s\tremaining: 36m 59s\n",
      "128:\tlearn: 0.0542141\ttest: 0.0539515\tbest: 0.0539515 (128)\ttotal: 29s\tremaining: 36m 55s\n",
      "129:\tlearn: 0.0542127\ttest: 0.0539302\tbest: 0.0539302 (129)\ttotal: 29.2s\tremaining: 36m 56s\n",
      "130:\tlearn: 0.0541623\ttest: 0.0539109\tbest: 0.0539109 (130)\ttotal: 29.4s\tremaining: 36m 55s\n",
      "131:\tlearn: 0.0541641\ttest: 0.0538937\tbest: 0.0538937 (131)\ttotal: 29.6s\tremaining: 36m 54s\n",
      "132:\tlearn: 0.0541616\ttest: 0.0538779\tbest: 0.0538779 (132)\ttotal: 29.8s\tremaining: 36m 53s\n",
      "133:\tlearn: 0.0541090\ttest: 0.0538599\tbest: 0.0538599 (133)\ttotal: 30s\tremaining: 36m 51s\n",
      "134:\tlearn: 0.0540223\ttest: 0.0537929\tbest: 0.0537929 (134)\ttotal: 30.3s\tremaining: 36m 52s\n",
      "135:\tlearn: 0.0540237\ttest: 0.0537786\tbest: 0.0537786 (135)\ttotal: 30.5s\tremaining: 36m 50s\n",
      "136:\tlearn: 0.0539686\ttest: 0.0537653\tbest: 0.0537653 (136)\ttotal: 30.7s\tremaining: 36m 50s\n",
      "137:\tlearn: 0.0539828\ttest: 0.0537518\tbest: 0.0537518 (137)\ttotal: 30.9s\tremaining: 36m 50s\n",
      "138:\tlearn: 0.0539708\ttest: 0.0537085\tbest: 0.0537085 (138)\ttotal: 31.2s\tremaining: 36m 51s\n",
      "139:\tlearn: 0.0539147\ttest: 0.0536845\tbest: 0.0536845 (139)\ttotal: 31.4s\tremaining: 36m 48s\n",
      "140:\tlearn: 0.0539124\ttest: 0.0536720\tbest: 0.0536720 (140)\ttotal: 31.6s\tremaining: 36m 48s\n",
      "141:\tlearn: 0.0539124\ttest: 0.0536456\tbest: 0.0536456 (141)\ttotal: 31.8s\tremaining: 36m 45s\n",
      "142:\tlearn: 0.0538134\ttest: 0.0535891\tbest: 0.0535891 (142)\ttotal: 32s\tremaining: 36m 46s\n",
      "143:\tlearn: 0.0538072\ttest: 0.0535747\tbest: 0.0535747 (143)\ttotal: 32.2s\tremaining: 36m 43s\n",
      "144:\tlearn: 0.0538196\ttest: 0.0535654\tbest: 0.0535654 (144)\ttotal: 32.4s\tremaining: 36m 43s\n",
      "145:\tlearn: 0.0538173\ttest: 0.0535553\tbest: 0.0535553 (145)\ttotal: 32.6s\tremaining: 36m 41s\n",
      "146:\tlearn: 0.0537728\ttest: 0.0535418\tbest: 0.0535418 (146)\ttotal: 32.8s\tremaining: 36m 41s\n",
      "147:\tlearn: 0.0537682\ttest: 0.0535302\tbest: 0.0535302 (147)\ttotal: 33.1s\tremaining: 36m 40s\n",
      "148:\tlearn: 0.0537716\ttest: 0.0535155\tbest: 0.0535155 (148)\ttotal: 33.2s\tremaining: 36m 38s\n",
      "149:\tlearn: 0.0537590\ttest: 0.0534934\tbest: 0.0534934 (149)\ttotal: 33.4s\tremaining: 36m 35s\n",
      "150:\tlearn: 0.0537114\ttest: 0.0534812\tbest: 0.0534812 (150)\ttotal: 33.7s\tremaining: 36m 35s\n",
      "151:\tlearn: 0.0537059\ttest: 0.0534544\tbest: 0.0534544 (151)\ttotal: 33.9s\tremaining: 36m 33s\n",
      "152:\tlearn: 0.0536969\ttest: 0.0534437\tbest: 0.0534437 (152)\ttotal: 34.1s\tremaining: 36m 32s\n",
      "153:\tlearn: 0.0537048\ttest: 0.0534321\tbest: 0.0534321 (153)\ttotal: 34.3s\tremaining: 36m 30s\n",
      "154:\tlearn: 0.0537013\ttest: 0.0534228\tbest: 0.0534228 (154)\ttotal: 34.5s\tremaining: 36m 30s\n",
      "155:\tlearn: 0.0536578\ttest: 0.0534141\tbest: 0.0534141 (155)\ttotal: 34.7s\tremaining: 36m 27s\n",
      "156:\tlearn: 0.0536504\ttest: 0.0534075\tbest: 0.0534075 (156)\ttotal: 34.9s\tremaining: 36m 28s\n",
      "157:\tlearn: 0.0536581\ttest: 0.0533990\tbest: 0.0533990 (157)\ttotal: 35.1s\tremaining: 36m 26s\n",
      "158:\tlearn: 0.0536642\ttest: 0.0533907\tbest: 0.0533907 (158)\ttotal: 35.3s\tremaining: 36m 25s\n",
      "159:\tlearn: 0.0536504\ttest: 0.0533819\tbest: 0.0533819 (159)\ttotal: 35.5s\tremaining: 36m 25s\n",
      "160:\tlearn: 0.0536451\ttest: 0.0533657\tbest: 0.0533657 (160)\ttotal: 35.7s\tremaining: 36m 23s\n",
      "161:\tlearn: 0.0536001\ttest: 0.0533582\tbest: 0.0533582 (161)\ttotal: 35.9s\tremaining: 36m 22s\n",
      "162:\tlearn: 0.0535906\ttest: 0.0533461\tbest: 0.0533461 (162)\ttotal: 36.1s\tremaining: 36m 20s\n",
      "163:\tlearn: 0.0535922\ttest: 0.0533359\tbest: 0.0533359 (163)\ttotal: 36.3s\tremaining: 36m 19s\n",
      "164:\tlearn: 0.0536005\ttest: 0.0533284\tbest: 0.0533284 (164)\ttotal: 36.6s\tremaining: 36m 19s\n",
      "165:\tlearn: 0.0535929\ttest: 0.0533205\tbest: 0.0533205 (165)\ttotal: 36.8s\tremaining: 36m 19s\n",
      "166:\tlearn: 0.0535881\ttest: 0.0533035\tbest: 0.0533035 (166)\ttotal: 37s\tremaining: 36m 19s\n",
      "167:\tlearn: 0.0535318\ttest: 0.0532869\tbest: 0.0532869 (167)\ttotal: 37.2s\tremaining: 36m 18s\n",
      "168:\tlearn: 0.0535357\ttest: 0.0532804\tbest: 0.0532804 (168)\ttotal: 37.4s\tremaining: 36m 16s\n",
      "169:\tlearn: 0.0535168\ttest: 0.0532436\tbest: 0.0532436 (169)\ttotal: 37.6s\tremaining: 36m 15s\n",
      "170:\tlearn: 0.0535225\ttest: 0.0532372\tbest: 0.0532372 (170)\ttotal: 37.9s\tremaining: 36m 16s\n",
      "171:\tlearn: 0.0535279\ttest: 0.0532299\tbest: 0.0532299 (171)\ttotal: 38.1s\tremaining: 36m 16s\n",
      "172:\tlearn: 0.0535274\ttest: 0.0532225\tbest: 0.0532225 (172)\ttotal: 38.3s\tremaining: 36m 14s\n",
      "173:\tlearn: 0.0535239\ttest: 0.0532182\tbest: 0.0532182 (173)\ttotal: 38.5s\tremaining: 36m 13s\n",
      "174:\tlearn: 0.0535156\ttest: 0.0532035\tbest: 0.0532035 (174)\ttotal: 38.7s\tremaining: 36m 12s\n",
      "175:\tlearn: 0.0534714\ttest: 0.0531990\tbest: 0.0531990 (175)\ttotal: 38.9s\tremaining: 36m 11s\n",
      "176:\tlearn: 0.0534582\ttest: 0.0531673\tbest: 0.0531673 (176)\ttotal: 39.1s\tremaining: 36m 10s\n",
      "177:\tlearn: 0.0534401\ttest: 0.0531581\tbest: 0.0531581 (177)\ttotal: 39.3s\tremaining: 36m 8s\n",
      "178:\tlearn: 0.0534454\ttest: 0.0531509\tbest: 0.0531509 (178)\ttotal: 39.5s\tremaining: 36m 8s\n",
      "179:\tlearn: 0.0534566\ttest: 0.0531451\tbest: 0.0531451 (179)\ttotal: 39.7s\tremaining: 36m 7s\n",
      "180:\tlearn: 0.0534623\ttest: 0.0531412\tbest: 0.0531412 (180)\ttotal: 39.9s\tremaining: 36m 6s\n",
      "181:\tlearn: 0.0534515\ttest: 0.0531289\tbest: 0.0531289 (181)\ttotal: 40.1s\tremaining: 36m 3s\n",
      "182:\tlearn: 0.0534410\ttest: 0.0531225\tbest: 0.0531225 (182)\ttotal: 40.3s\tremaining: 36m 3s\n",
      "183:\tlearn: 0.0534436\ttest: 0.0531176\tbest: 0.0531176 (183)\ttotal: 40.5s\tremaining: 36m 1s\n",
      "184:\tlearn: 0.0534427\ttest: 0.0531132\tbest: 0.0531132 (184)\ttotal: 40.7s\tremaining: 36m 1s\n",
      "185:\tlearn: 0.0533652\ttest: 0.0530872\tbest: 0.0530872 (185)\ttotal: 41s\tremaining: 36m\n",
      "186:\tlearn: 0.0533682\ttest: 0.0530821\tbest: 0.0530821 (186)\ttotal: 41.1s\tremaining: 35m 58s\n",
      "187:\tlearn: 0.0533659\ttest: 0.0530772\tbest: 0.0530772 (187)\ttotal: 41.4s\tremaining: 35m 58s\n",
      "188:\tlearn: 0.0533591\ttest: 0.0530728\tbest: 0.0530728 (188)\ttotal: 41.6s\tremaining: 35m 57s\n",
      "189:\tlearn: 0.0533570\ttest: 0.0530668\tbest: 0.0530668 (189)\ttotal: 41.7s\tremaining: 35m 55s\n",
      "190:\tlearn: 0.0533488\ttest: 0.0530438\tbest: 0.0530438 (190)\ttotal: 42s\tremaining: 35m 55s\n",
      "191:\tlearn: 0.0533090\ttest: 0.0530400\tbest: 0.0530400 (191)\ttotal: 42.2s\tremaining: 35m 55s\n",
      "192:\tlearn: 0.0533116\ttest: 0.0530357\tbest: 0.0530357 (192)\ttotal: 42.4s\tremaining: 35m 55s\n",
      "193:\tlearn: 0.0533183\ttest: 0.0530334\tbest: 0.0530334 (193)\ttotal: 42.7s\tremaining: 35m 56s\n",
      "194:\tlearn: 0.0533177\ttest: 0.0530275\tbest: 0.0530275 (194)\ttotal: 42.8s\tremaining: 35m 54s\n",
      "195:\tlearn: 0.0533006\ttest: 0.0530208\tbest: 0.0530208 (195)\ttotal: 43s\tremaining: 35m 52s\n",
      "196:\tlearn: 0.0533026\ttest: 0.0530167\tbest: 0.0530167 (196)\ttotal: 43.2s\tremaining: 35m 51s\n",
      "197:\tlearn: 0.0533062\ttest: 0.0530126\tbest: 0.0530126 (197)\ttotal: 43.4s\tremaining: 35m 50s\n",
      "198:\tlearn: 0.0533000\ttest: 0.0530087\tbest: 0.0530087 (198)\ttotal: 43.6s\tremaining: 35m 49s\n",
      "199:\tlearn: 0.0533041\ttest: 0.0530047\tbest: 0.0530047 (199)\ttotal: 43.8s\tremaining: 35m 47s\n",
      "200:\tlearn: 0.0532527\ttest: 0.0530004\tbest: 0.0530004 (200)\ttotal: 44s\tremaining: 35m 46s\n",
      "201:\tlearn: 0.0532448\ttest: 0.0529810\tbest: 0.0529810 (201)\ttotal: 44.2s\tremaining: 35m 45s\n",
      "202:\tlearn: 0.0532373\ttest: 0.0529707\tbest: 0.0529707 (202)\ttotal: 44.5s\tremaining: 35m 45s\n",
      "203:\tlearn: 0.0532339\ttest: 0.0529649\tbest: 0.0529649 (203)\ttotal: 44.6s\tremaining: 35m 43s\n",
      "204:\tlearn: 0.0532337\ttest: 0.0529593\tbest: 0.0529593 (204)\ttotal: 44.8s\tremaining: 35m 42s\n",
      "205:\tlearn: 0.0532182\ttest: 0.0529534\tbest: 0.0529534 (205)\ttotal: 45s\tremaining: 35m 41s\n",
      "206:\tlearn: 0.0532192\ttest: 0.0529496\tbest: 0.0529496 (206)\ttotal: 45.3s\tremaining: 35m 40s\n",
      "207:\tlearn: 0.0532254\ttest: 0.0529476\tbest: 0.0529476 (207)\ttotal: 45.5s\tremaining: 35m 41s\n",
      "208:\tlearn: 0.0532212\ttest: 0.0529453\tbest: 0.0529453 (208)\ttotal: 45.7s\tremaining: 35m 40s\n",
      "209:\tlearn: 0.0532183\ttest: 0.0529420\tbest: 0.0529420 (209)\ttotal: 45.9s\tremaining: 35m 39s\n",
      "210:\tlearn: 0.0532201\ttest: 0.0529377\tbest: 0.0529377 (210)\ttotal: 46.1s\tremaining: 35m 37s\n",
      "211:\tlearn: 0.0531887\ttest: 0.0529050\tbest: 0.0529050 (211)\ttotal: 46.3s\tremaining: 35m 37s\n",
      "212:\tlearn: 0.0531895\ttest: 0.0529013\tbest: 0.0529013 (212)\ttotal: 46.5s\tremaining: 35m 36s\n",
      "213:\tlearn: 0.0531908\ttest: 0.0528978\tbest: 0.0528978 (213)\ttotal: 46.7s\tremaining: 35m 34s\n",
      "214:\tlearn: 0.0531941\ttest: 0.0528941\tbest: 0.0528941 (214)\ttotal: 46.9s\tremaining: 35m 33s\n",
      "215:\tlearn: 0.0531932\ttest: 0.0528888\tbest: 0.0528888 (215)\ttotal: 47.1s\tremaining: 35m 34s\n",
      "216:\tlearn: 0.0531925\ttest: 0.0528858\tbest: 0.0528858 (216)\ttotal: 47.3s\tremaining: 35m 33s\n",
      "217:\tlearn: 0.0531918\ttest: 0.0528834\tbest: 0.0528834 (217)\ttotal: 47.5s\tremaining: 35m 32s\n",
      "218:\tlearn: 0.0531762\ttest: 0.0528814\tbest: 0.0528814 (218)\ttotal: 47.7s\tremaining: 35m 31s\n",
      "219:\tlearn: 0.0531758\ttest: 0.0528777\tbest: 0.0528777 (219)\ttotal: 47.9s\tremaining: 35m 31s\n",
      "220:\tlearn: 0.0531756\ttest: 0.0528726\tbest: 0.0528726 (220)\ttotal: 48.1s\tremaining: 35m 30s\n",
      "221:\tlearn: 0.0531727\ttest: 0.0528683\tbest: 0.0528683 (221)\ttotal: 48.3s\tremaining: 35m 29s\n",
      "222:\tlearn: 0.0531696\ttest: 0.0528647\tbest: 0.0528647 (222)\ttotal: 48.5s\tremaining: 35m 28s\n",
      "223:\tlearn: 0.0531702\ttest: 0.0528621\tbest: 0.0528621 (223)\ttotal: 48.7s\tremaining: 35m 27s\n",
      "224:\tlearn: 0.0531696\ttest: 0.0528604\tbest: 0.0528604 (224)\ttotal: 48.9s\tremaining: 35m 24s\n",
      "225:\tlearn: 0.0531697\ttest: 0.0528583\tbest: 0.0528583 (225)\ttotal: 49.1s\tremaining: 35m 21s\n",
      "226:\tlearn: 0.0531638\ttest: 0.0528464\tbest: 0.0528464 (226)\ttotal: 49.3s\tremaining: 35m 21s\n",
      "227:\tlearn: 0.0531640\ttest: 0.0528445\tbest: 0.0528445 (227)\ttotal: 49.5s\tremaining: 35m 21s\n",
      "228:\tlearn: 0.0531684\ttest: 0.0528418\tbest: 0.0528418 (228)\ttotal: 49.7s\tremaining: 35m 18s\n",
      "229:\tlearn: 0.0531130\ttest: 0.0528379\tbest: 0.0528379 (229)\ttotal: 49.9s\tremaining: 35m 18s\n",
      "230:\tlearn: 0.0531034\ttest: 0.0528248\tbest: 0.0528248 (230)\ttotal: 50.1s\tremaining: 35m 17s\n",
      "231:\tlearn: 0.0531027\ttest: 0.0528225\tbest: 0.0528225 (231)\ttotal: 50.3s\tremaining: 35m 17s\n",
      "232:\tlearn: 0.0530953\ttest: 0.0528065\tbest: 0.0528065 (232)\ttotal: 50.5s\tremaining: 35m 15s\n",
      "233:\tlearn: 0.0530956\ttest: 0.0528041\tbest: 0.0528041 (233)\ttotal: 50.7s\tremaining: 35m 14s\n",
      "234:\tlearn: 0.0530925\ttest: 0.0528008\tbest: 0.0528008 (234)\ttotal: 50.9s\tremaining: 35m 13s\n",
      "235:\tlearn: 0.0530942\ttest: 0.0527985\tbest: 0.0527985 (235)\ttotal: 51.1s\tremaining: 35m 12s\n",
      "236:\tlearn: 0.0530952\ttest: 0.0527969\tbest: 0.0527969 (236)\ttotal: 51.3s\tremaining: 35m 12s\n",
      "237:\tlearn: 0.0530891\ttest: 0.0527802\tbest: 0.0527802 (237)\ttotal: 51.5s\tremaining: 35m 12s\n",
      "238:\tlearn: 0.0530825\ttest: 0.0527680\tbest: 0.0527680 (238)\ttotal: 51.7s\tremaining: 35m 11s\n",
      "239:\tlearn: 0.0530815\ttest: 0.0527656\tbest: 0.0527656 (239)\ttotal: 51.9s\tremaining: 35m 9s\n",
      "240:\tlearn: 0.0530742\ttest: 0.0527559\tbest: 0.0527559 (240)\ttotal: 52.1s\tremaining: 35m 8s\n",
      "241:\tlearn: 0.0530760\ttest: 0.0527551\tbest: 0.0527551 (241)\ttotal: 52.3s\tremaining: 35m 9s\n",
      "242:\tlearn: 0.0530760\ttest: 0.0527518\tbest: 0.0527518 (242)\ttotal: 52.5s\tremaining: 35m 8s\n",
      "243:\tlearn: 0.0530584\ttest: 0.0527507\tbest: 0.0527507 (243)\ttotal: 52.7s\tremaining: 35m 7s\n",
      "244:\tlearn: 0.0530639\ttest: 0.0527491\tbest: 0.0527491 (244)\ttotal: 52.9s\tremaining: 35m 6s\n",
      "245:\tlearn: 0.0530624\ttest: 0.0527477\tbest: 0.0527477 (245)\ttotal: 53.1s\tremaining: 35m 5s\n",
      "246:\tlearn: 0.0530651\ttest: 0.0527446\tbest: 0.0527446 (246)\ttotal: 53.3s\tremaining: 35m 4s\n",
      "247:\tlearn: 0.0530642\ttest: 0.0527429\tbest: 0.0527429 (247)\ttotal: 53.5s\tremaining: 35m 4s\n",
      "248:\tlearn: 0.0530621\ttest: 0.0527400\tbest: 0.0527400 (248)\ttotal: 53.7s\tremaining: 35m 3s\n",
      "249:\tlearn: 0.0530314\ttest: 0.0527155\tbest: 0.0527155 (249)\ttotal: 53.9s\tremaining: 35m 1s\n",
      "250:\tlearn: 0.0530281\ttest: 0.0527125\tbest: 0.0527125 (250)\ttotal: 54.1s\tremaining: 35m 1s\n",
      "251:\tlearn: 0.0530296\ttest: 0.0527102\tbest: 0.0527102 (251)\ttotal: 54.3s\tremaining: 34m 59s\n",
      "252:\tlearn: 0.0530278\ttest: 0.0527085\tbest: 0.0527085 (252)\ttotal: 54.5s\tremaining: 34m 59s\n",
      "253:\tlearn: 0.0530279\ttest: 0.0527070\tbest: 0.0527070 (253)\ttotal: 54.7s\tremaining: 34m 58s\n",
      "254:\tlearn: 0.0530272\ttest: 0.0527060\tbest: 0.0527060 (254)\ttotal: 54.9s\tremaining: 34m 57s\n",
      "255:\tlearn: 0.0530289\ttest: 0.0527045\tbest: 0.0527045 (255)\ttotal: 55.1s\tremaining: 34m 55s\n",
      "256:\tlearn: 0.0530270\ttest: 0.0527030\tbest: 0.0527030 (256)\ttotal: 55.3s\tremaining: 34m 55s\n",
      "257:\tlearn: 0.0529795\ttest: 0.0526844\tbest: 0.0526844 (257)\ttotal: 55.5s\tremaining: 34m 53s\n",
      "258:\tlearn: 0.0529805\ttest: 0.0526825\tbest: 0.0526825 (258)\ttotal: 55.6s\tremaining: 34m 52s\n",
      "259:\tlearn: 0.0529773\ttest: 0.0526799\tbest: 0.0526799 (259)\ttotal: 55.8s\tremaining: 34m 51s\n",
      "260:\tlearn: 0.0529792\ttest: 0.0526787\tbest: 0.0526787 (260)\ttotal: 56s\tremaining: 34m 50s\n",
      "261:\tlearn: 0.0529809\ttest: 0.0526764\tbest: 0.0526764 (261)\ttotal: 56.2s\tremaining: 34m 49s\n",
      "262:\tlearn: 0.0529792\ttest: 0.0526739\tbest: 0.0526739 (262)\ttotal: 56.4s\tremaining: 34m 48s\n",
      "263:\tlearn: 0.0529777\ttest: 0.0526724\tbest: 0.0526724 (263)\ttotal: 56.6s\tremaining: 34m 47s\n",
      "264:\tlearn: 0.0529571\ttest: 0.0526524\tbest: 0.0526524 (264)\ttotal: 56.8s\tremaining: 34m 47s\n",
      "265:\tlearn: 0.0529599\ttest: 0.0526513\tbest: 0.0526513 (265)\ttotal: 57s\tremaining: 34m 47s\n",
      "266:\tlearn: 0.0529561\ttest: 0.0526459\tbest: 0.0526459 (266)\ttotal: 57.2s\tremaining: 34m 46s\n",
      "267:\tlearn: 0.0529577\ttest: 0.0526434\tbest: 0.0526434 (267)\ttotal: 57.4s\tremaining: 34m 45s\n",
      "268:\tlearn: 0.0529571\ttest: 0.0526416\tbest: 0.0526416 (268)\ttotal: 57.6s\tremaining: 34m 44s\n",
      "269:\tlearn: 0.0529560\ttest: 0.0526400\tbest: 0.0526400 (269)\ttotal: 57.8s\tremaining: 34m 44s\n",
      "270:\tlearn: 0.0529539\ttest: 0.0526365\tbest: 0.0526365 (270)\ttotal: 58s\tremaining: 34m 43s\n",
      "271:\tlearn: 0.0529532\ttest: 0.0526356\tbest: 0.0526356 (271)\ttotal: 58.2s\tremaining: 34m 42s\n",
      "272:\tlearn: 0.0529521\ttest: 0.0526345\tbest: 0.0526345 (272)\ttotal: 58.4s\tremaining: 34m 41s\n",
      "273:\tlearn: 0.0529528\ttest: 0.0526338\tbest: 0.0526338 (273)\ttotal: 58.6s\tremaining: 34m 40s\n",
      "274:\tlearn: 0.0529500\ttest: 0.0526270\tbest: 0.0526270 (274)\ttotal: 58.8s\tremaining: 34m 39s\n",
      "275:\tlearn: 0.0529462\ttest: 0.0526235\tbest: 0.0526235 (275)\ttotal: 59s\tremaining: 34m 39s\n",
      "276:\tlearn: 0.0529480\ttest: 0.0526204\tbest: 0.0526204 (276)\ttotal: 59.2s\tremaining: 34m 38s\n",
      "277:\tlearn: 0.0529470\ttest: 0.0526186\tbest: 0.0526186 (277)\ttotal: 59.4s\tremaining: 34m 38s\n",
      "278:\tlearn: 0.0529430\ttest: 0.0526135\tbest: 0.0526135 (278)\ttotal: 59.6s\tremaining: 34m 37s\n",
      "279:\tlearn: 0.0529442\ttest: 0.0526121\tbest: 0.0526121 (279)\ttotal: 59.8s\tremaining: 34m 37s\n",
      "280:\tlearn: 0.0529441\ttest: 0.0526112\tbest: 0.0526112 (280)\ttotal: 1m\tremaining: 34m 35s\n",
      "281:\tlearn: 0.0529340\ttest: 0.0526059\tbest: 0.0526059 (281)\ttotal: 1m\tremaining: 34m 35s\n",
      "282:\tlearn: 0.0529236\ttest: 0.0526051\tbest: 0.0526051 (282)\ttotal: 1m\tremaining: 34m 34s\n",
      "283:\tlearn: 0.0529223\ttest: 0.0526025\tbest: 0.0526025 (283)\ttotal: 1m\tremaining: 34m 33s\n",
      "284:\tlearn: 0.0529206\ttest: 0.0526012\tbest: 0.0526012 (284)\ttotal: 1m\tremaining: 34m 32s\n",
      "285:\tlearn: 0.0529191\ttest: 0.0526002\tbest: 0.0526002 (285)\ttotal: 1m\tremaining: 34m 31s\n",
      "286:\tlearn: 0.0529169\ttest: 0.0525980\tbest: 0.0525980 (286)\ttotal: 1m 1s\tremaining: 34m 31s\n",
      "287:\tlearn: 0.0529168\ttest: 0.0525964\tbest: 0.0525964 (287)\ttotal: 1m 1s\tremaining: 34m 30s\n",
      "288:\tlearn: 0.0529169\ttest: 0.0525954\tbest: 0.0525954 (288)\ttotal: 1m 1s\tremaining: 34m 30s\n",
      "289:\tlearn: 0.0529158\ttest: 0.0525943\tbest: 0.0525943 (289)\ttotal: 1m 1s\tremaining: 34m 29s\n",
      "290:\tlearn: 0.0529142\ttest: 0.0525924\tbest: 0.0525924 (290)\ttotal: 1m 1s\tremaining: 34m 28s\n",
      "291:\tlearn: 0.0529095\ttest: 0.0525886\tbest: 0.0525886 (291)\ttotal: 1m 2s\tremaining: 34m 27s\n",
      "292:\tlearn: 0.0528866\ttest: 0.0525744\tbest: 0.0525744 (292)\ttotal: 1m 2s\tremaining: 34m 26s\n",
      "293:\tlearn: 0.0528862\ttest: 0.0525742\tbest: 0.0525742 (293)\ttotal: 1m 2s\tremaining: 34m 24s\n",
      "294:\tlearn: 0.0528743\ttest: 0.0525583\tbest: 0.0525583 (294)\ttotal: 1m 2s\tremaining: 34m 23s\n",
      "295:\tlearn: 0.0528748\ttest: 0.0525553\tbest: 0.0525553 (295)\ttotal: 1m 2s\tremaining: 34m 23s\n",
      "296:\tlearn: 0.0528744\ttest: 0.0525543\tbest: 0.0525543 (296)\ttotal: 1m 3s\tremaining: 34m 23s\n",
      "297:\tlearn: 0.0528736\ttest: 0.0525535\tbest: 0.0525535 (297)\ttotal: 1m 3s\tremaining: 34m 22s\n",
      "298:\tlearn: 0.0528735\ttest: 0.0525513\tbest: 0.0525513 (298)\ttotal: 1m 3s\tremaining: 34m 22s\n",
      "299:\tlearn: 0.0528738\ttest: 0.0525485\tbest: 0.0525485 (299)\ttotal: 1m 3s\tremaining: 34m 23s\n",
      "300:\tlearn: 0.0528740\ttest: 0.0525402\tbest: 0.0525402 (300)\ttotal: 1m 4s\tremaining: 34m 23s\n",
      "301:\tlearn: 0.0527915\ttest: 0.0525227\tbest: 0.0525227 (301)\ttotal: 1m 4s\tremaining: 34m 23s\n",
      "302:\tlearn: 0.0527907\ttest: 0.0525217\tbest: 0.0525217 (302)\ttotal: 1m 4s\tremaining: 34m 22s\n",
      "303:\tlearn: 0.0527901\ttest: 0.0525209\tbest: 0.0525209 (303)\ttotal: 1m 4s\tremaining: 34m 22s\n",
      "304:\tlearn: 0.0527890\ttest: 0.0525195\tbest: 0.0525195 (304)\ttotal: 1m 4s\tremaining: 34m 21s\n",
      "305:\tlearn: 0.0527838\ttest: 0.0525142\tbest: 0.0525142 (305)\ttotal: 1m 5s\tremaining: 34m 20s\n",
      "306:\tlearn: 0.0527814\ttest: 0.0525115\tbest: 0.0525115 (306)\ttotal: 1m 5s\tremaining: 34m 20s\n",
      "307:\tlearn: 0.0527799\ttest: 0.0525101\tbest: 0.0525101 (307)\ttotal: 1m 5s\tremaining: 34m 20s\n",
      "308:\tlearn: 0.0527807\ttest: 0.0525090\tbest: 0.0525090 (308)\ttotal: 1m 5s\tremaining: 34m 20s\n",
      "309:\tlearn: 0.0527701\ttest: 0.0524943\tbest: 0.0524943 (309)\ttotal: 1m 5s\tremaining: 34m 19s\n",
      "310:\tlearn: 0.0527695\ttest: 0.0524939\tbest: 0.0524939 (310)\ttotal: 1m 6s\tremaining: 34m 19s\n",
      "311:\tlearn: 0.0527670\ttest: 0.0524930\tbest: 0.0524930 (311)\ttotal: 1m 6s\tremaining: 34m 18s\n",
      "312:\tlearn: 0.0527631\ttest: 0.0524800\tbest: 0.0524800 (312)\ttotal: 1m 6s\tremaining: 34m 18s\n",
      "313:\tlearn: 0.0527618\ttest: 0.0524789\tbest: 0.0524789 (313)\ttotal: 1m 6s\tremaining: 34m 17s\n",
      "314:\tlearn: 0.0527599\ttest: 0.0524762\tbest: 0.0524762 (314)\ttotal: 1m 6s\tremaining: 34m 17s\n",
      "315:\tlearn: 0.0527511\ttest: 0.0524660\tbest: 0.0524660 (315)\ttotal: 1m 7s\tremaining: 34m 17s\n",
      "316:\tlearn: 0.0527501\ttest: 0.0524653\tbest: 0.0524653 (316)\ttotal: 1m 7s\tremaining: 34m 16s\n",
      "317:\tlearn: 0.0527490\ttest: 0.0524636\tbest: 0.0524636 (317)\ttotal: 1m 7s\tremaining: 34m 15s\n",
      "318:\tlearn: 0.0527455\ttest: 0.0524599\tbest: 0.0524599 (318)\ttotal: 1m 7s\tremaining: 34m 15s\n",
      "319:\tlearn: 0.0527449\ttest: 0.0524592\tbest: 0.0524592 (319)\ttotal: 1m 7s\tremaining: 34m 13s\n",
      "320:\tlearn: 0.0527460\ttest: 0.0524588\tbest: 0.0524588 (320)\ttotal: 1m 8s\tremaining: 34m 12s\n",
      "321:\tlearn: 0.0527456\ttest: 0.0524584\tbest: 0.0524584 (321)\ttotal: 1m 8s\tremaining: 34m 12s\n",
      "322:\tlearn: 0.0527426\ttest: 0.0524538\tbest: 0.0524538 (322)\ttotal: 1m 8s\tremaining: 34m 11s\n",
      "323:\tlearn: 0.0526942\ttest: 0.0524508\tbest: 0.0524508 (323)\ttotal: 1m 8s\tremaining: 34m 11s\n",
      "324:\tlearn: 0.0526934\ttest: 0.0524499\tbest: 0.0524499 (324)\ttotal: 1m 8s\tremaining: 34m 10s\n",
      "325:\tlearn: 0.0526934\ttest: 0.0524491\tbest: 0.0524491 (325)\ttotal: 1m 9s\tremaining: 34m 10s\n",
      "326:\tlearn: 0.0526919\ttest: 0.0524478\tbest: 0.0524478 (326)\ttotal: 1m 9s\tremaining: 34m 9s\n",
      "327:\tlearn: 0.0526910\ttest: 0.0524472\tbest: 0.0524472 (327)\ttotal: 1m 9s\tremaining: 34m 9s\n",
      "328:\tlearn: 0.0526897\ttest: 0.0524456\tbest: 0.0524456 (328)\ttotal: 1m 9s\tremaining: 34m 8s\n",
      "329:\tlearn: 0.0526919\ttest: 0.0524453\tbest: 0.0524453 (329)\ttotal: 1m 9s\tremaining: 34m 6s\n",
      "330:\tlearn: 0.0526818\ttest: 0.0524355\tbest: 0.0524355 (330)\ttotal: 1m 10s\tremaining: 34m 5s\n",
      "331:\tlearn: 0.0526809\ttest: 0.0524325\tbest: 0.0524325 (331)\ttotal: 1m 10s\tremaining: 34m 5s\n",
      "332:\tlearn: 0.0526805\ttest: 0.0524320\tbest: 0.0524320 (332)\ttotal: 1m 10s\tremaining: 34m 4s\n",
      "333:\tlearn: 0.0526776\ttest: 0.0524248\tbest: 0.0524248 (333)\ttotal: 1m 10s\tremaining: 34m 3s\n",
      "334:\tlearn: 0.0526766\ttest: 0.0524241\tbest: 0.0524241 (334)\ttotal: 1m 10s\tremaining: 34m 2s\n",
      "335:\tlearn: 0.0526771\ttest: 0.0524233\tbest: 0.0524233 (335)\ttotal: 1m 11s\tremaining: 34m 2s\n",
      "336:\tlearn: 0.0526758\ttest: 0.0524228\tbest: 0.0524228 (336)\ttotal: 1m 11s\tremaining: 34m 3s\n",
      "337:\tlearn: 0.0526753\ttest: 0.0524223\tbest: 0.0524223 (337)\ttotal: 1m 11s\tremaining: 34m 2s\n",
      "338:\tlearn: 0.0526752\ttest: 0.0524187\tbest: 0.0524187 (338)\ttotal: 1m 11s\tremaining: 34m 1s\n",
      "339:\tlearn: 0.0526737\ttest: 0.0524172\tbest: 0.0524172 (339)\ttotal: 1m 11s\tremaining: 34m 1s\n",
      "340:\tlearn: 0.0526583\ttest: 0.0524106\tbest: 0.0524106 (340)\ttotal: 1m 12s\tremaining: 34m 1s\n",
      "341:\tlearn: 0.0526598\ttest: 0.0524103\tbest: 0.0524103 (341)\ttotal: 1m 12s\tremaining: 34m\n",
      "342:\tlearn: 0.0526589\ttest: 0.0524095\tbest: 0.0524095 (342)\ttotal: 1m 12s\tremaining: 33m 59s\n",
      "343:\tlearn: 0.0526585\ttest: 0.0524091\tbest: 0.0524091 (343)\ttotal: 1m 12s\tremaining: 33m 58s\n",
      "344:\tlearn: 0.0526572\ttest: 0.0524082\tbest: 0.0524082 (344)\ttotal: 1m 12s\tremaining: 33m 58s\n",
      "345:\tlearn: 0.0526563\ttest: 0.0524074\tbest: 0.0524074 (345)\ttotal: 1m 13s\tremaining: 33m 57s\n",
      "346:\tlearn: 0.0526557\ttest: 0.0524069\tbest: 0.0524069 (346)\ttotal: 1m 13s\tremaining: 33m 56s\n",
      "347:\tlearn: 0.0526550\ttest: 0.0524062\tbest: 0.0524062 (347)\ttotal: 1m 13s\tremaining: 33m 56s\n",
      "348:\tlearn: 0.0526523\ttest: 0.0524034\tbest: 0.0524034 (348)\ttotal: 1m 13s\tremaining: 33m 56s\n",
      "349:\tlearn: 0.0526511\ttest: 0.0524020\tbest: 0.0524020 (349)\ttotal: 1m 13s\tremaining: 33m 55s\n",
      "350:\tlearn: 0.0526491\ttest: 0.0524000\tbest: 0.0524000 (350)\ttotal: 1m 14s\tremaining: 33m 54s\n",
      "351:\tlearn: 0.0526485\ttest: 0.0523991\tbest: 0.0523991 (351)\ttotal: 1m 14s\tremaining: 33m 54s\n",
      "352:\tlearn: 0.0526493\ttest: 0.0523957\tbest: 0.0523957 (352)\ttotal: 1m 14s\tremaining: 33m 54s\n",
      "353:\tlearn: 0.0526504\ttest: 0.0523945\tbest: 0.0523945 (353)\ttotal: 1m 14s\tremaining: 33m 53s\n",
      "354:\tlearn: 0.0526453\ttest: 0.0523893\tbest: 0.0523893 (354)\ttotal: 1m 14s\tremaining: 33m 53s\n",
      "355:\tlearn: 0.0526443\ttest: 0.0523879\tbest: 0.0523879 (355)\ttotal: 1m 15s\tremaining: 33m 52s\n",
      "356:\tlearn: 0.0526434\ttest: 0.0523873\tbest: 0.0523873 (356)\ttotal: 1m 15s\tremaining: 33m 51s\n",
      "357:\tlearn: 0.0526421\ttest: 0.0523863\tbest: 0.0523863 (357)\ttotal: 1m 15s\tremaining: 33m 51s\n",
      "358:\tlearn: 0.0526348\ttest: 0.0523836\tbest: 0.0523836 (358)\ttotal: 1m 15s\tremaining: 33m 50s\n",
      "359:\tlearn: 0.0526318\ttest: 0.0523769\tbest: 0.0523769 (359)\ttotal: 1m 15s\tremaining: 33m 50s\n",
      "360:\tlearn: 0.0526313\ttest: 0.0523766\tbest: 0.0523766 (360)\ttotal: 1m 16s\tremaining: 33m 49s\n",
      "361:\tlearn: 0.0526314\ttest: 0.0523766\tbest: 0.0523766 (361)\ttotal: 1m 16s\tremaining: 33m 48s\n",
      "362:\tlearn: 0.0526335\ttest: 0.0523761\tbest: 0.0523761 (362)\ttotal: 1m 16s\tremaining: 33m 48s\n",
      "363:\tlearn: 0.0526323\ttest: 0.0523749\tbest: 0.0523749 (363)\ttotal: 1m 16s\tremaining: 33m 48s\n",
      "364:\tlearn: 0.0526313\ttest: 0.0523745\tbest: 0.0523745 (364)\ttotal: 1m 16s\tremaining: 33m 47s\n",
      "365:\tlearn: 0.0526305\ttest: 0.0523734\tbest: 0.0523734 (365)\ttotal: 1m 17s\tremaining: 33m 46s\n",
      "366:\tlearn: 0.0526269\ttest: 0.0523721\tbest: 0.0523721 (366)\ttotal: 1m 17s\tremaining: 33m 46s\n",
      "367:\tlearn: 0.0526257\ttest: 0.0523709\tbest: 0.0523709 (367)\ttotal: 1m 17s\tremaining: 33m 46s\n",
      "368:\tlearn: 0.0526274\ttest: 0.0523701\tbest: 0.0523701 (368)\ttotal: 1m 17s\tremaining: 33m 45s\n",
      "369:\tlearn: 0.0526264\ttest: 0.0523696\tbest: 0.0523696 (369)\ttotal: 1m 17s\tremaining: 33m 45s\n",
      "370:\tlearn: 0.0526277\ttest: 0.0523670\tbest: 0.0523670 (370)\ttotal: 1m 18s\tremaining: 33m 45s\n",
      "371:\tlearn: 0.0526271\ttest: 0.0523663\tbest: 0.0523663 (371)\ttotal: 1m 18s\tremaining: 33m 45s\n",
      "372:\tlearn: 0.0526097\ttest: 0.0523653\tbest: 0.0523653 (372)\ttotal: 1m 18s\tremaining: 33m 44s\n",
      "373:\tlearn: 0.0526110\ttest: 0.0523648\tbest: 0.0523648 (373)\ttotal: 1m 18s\tremaining: 33m 45s\n",
      "374:\tlearn: 0.0526080\ttest: 0.0523622\tbest: 0.0523622 (374)\ttotal: 1m 18s\tremaining: 33m 44s\n",
      "375:\tlearn: 0.0526092\ttest: 0.0523617\tbest: 0.0523617 (375)\ttotal: 1m 19s\tremaining: 33m 44s\n",
      "376:\tlearn: 0.0526072\ttest: 0.0523610\tbest: 0.0523610 (376)\ttotal: 1m 19s\tremaining: 33m 43s\n",
      "377:\tlearn: 0.0526064\ttest: 0.0523603\tbest: 0.0523603 (377)\ttotal: 1m 19s\tremaining: 33m 43s\n",
      "378:\tlearn: 0.0526052\ttest: 0.0523579\tbest: 0.0523579 (378)\ttotal: 1m 19s\tremaining: 33m 43s\n",
      "379:\tlearn: 0.0526047\ttest: 0.0523553\tbest: 0.0523553 (379)\ttotal: 1m 19s\tremaining: 33m 43s\n",
      "380:\tlearn: 0.0526044\ttest: 0.0523547\tbest: 0.0523547 (380)\ttotal: 1m 20s\tremaining: 33m 43s\n",
      "381:\tlearn: 0.0526027\ttest: 0.0523530\tbest: 0.0523530 (381)\ttotal: 1m 20s\tremaining: 33m 43s\n",
      "382:\tlearn: 0.0526015\ttest: 0.0523522\tbest: 0.0523522 (382)\ttotal: 1m 20s\tremaining: 33m 43s\n",
      "383:\tlearn: 0.0525992\ttest: 0.0523497\tbest: 0.0523497 (383)\ttotal: 1m 20s\tremaining: 33m 42s\n",
      "384:\tlearn: 0.0525986\ttest: 0.0523493\tbest: 0.0523493 (384)\ttotal: 1m 20s\tremaining: 33m 42s\n",
      "385:\tlearn: 0.0525903\ttest: 0.0523389\tbest: 0.0523389 (385)\ttotal: 1m 21s\tremaining: 33m 41s\n",
      "386:\tlearn: 0.0525907\ttest: 0.0523387\tbest: 0.0523387 (386)\ttotal: 1m 21s\tremaining: 33m 40s\n",
      "387:\tlearn: 0.0525898\ttest: 0.0523379\tbest: 0.0523379 (387)\ttotal: 1m 21s\tremaining: 33m 39s\n",
      "388:\tlearn: 0.0525914\ttest: 0.0523377\tbest: 0.0523377 (388)\ttotal: 1m 21s\tremaining: 33m 39s\n",
      "389:\tlearn: 0.0525905\ttest: 0.0523368\tbest: 0.0523368 (389)\ttotal: 1m 21s\tremaining: 33m 38s\n",
      "390:\tlearn: 0.0525900\ttest: 0.0523364\tbest: 0.0523364 (390)\ttotal: 1m 22s\tremaining: 33m 38s\n",
      "391:\tlearn: 0.0525895\ttest: 0.0523349\tbest: 0.0523349 (391)\ttotal: 1m 22s\tremaining: 33m 39s\n",
      "392:\tlearn: 0.0525874\ttest: 0.0523332\tbest: 0.0523332 (392)\ttotal: 1m 22s\tremaining: 33m 38s\n",
      "393:\tlearn: 0.0525867\ttest: 0.0523322\tbest: 0.0523322 (393)\ttotal: 1m 22s\tremaining: 33m 38s\n",
      "394:\tlearn: 0.0525854\ttest: 0.0523309\tbest: 0.0523309 (394)\ttotal: 1m 22s\tremaining: 33m 37s\n",
      "395:\tlearn: 0.0525859\ttest: 0.0523260\tbest: 0.0523260 (395)\ttotal: 1m 23s\tremaining: 33m 38s\n",
      "396:\tlearn: 0.0525848\ttest: 0.0523238\tbest: 0.0523238 (396)\ttotal: 1m 23s\tremaining: 33m 39s\n",
      "397:\tlearn: 0.0525890\ttest: 0.0523213\tbest: 0.0523213 (397)\ttotal: 1m 23s\tremaining: 33m 39s\n",
      "398:\tlearn: 0.0525794\ttest: 0.0523115\tbest: 0.0523115 (398)\ttotal: 1m 23s\tremaining: 33m 39s\n",
      "399:\tlearn: 0.0525786\ttest: 0.0523102\tbest: 0.0523102 (399)\ttotal: 1m 24s\tremaining: 33m 38s\n",
      "400:\tlearn: 0.0525792\ttest: 0.0523098\tbest: 0.0523098 (400)\ttotal: 1m 24s\tremaining: 33m 38s\n",
      "401:\tlearn: 0.0525787\ttest: 0.0523024\tbest: 0.0523024 (401)\ttotal: 1m 24s\tremaining: 33m 38s\n",
      "402:\tlearn: 0.0525769\ttest: 0.0523009\tbest: 0.0523009 (402)\ttotal: 1m 24s\tremaining: 33m 37s\n",
      "403:\tlearn: 0.0525769\ttest: 0.0523006\tbest: 0.0523006 (403)\ttotal: 1m 24s\tremaining: 33m 37s\n",
      "404:\tlearn: 0.0525787\ttest: 0.0522999\tbest: 0.0522999 (404)\ttotal: 1m 25s\tremaining: 33m 36s\n",
      "405:\tlearn: 0.0525777\ttest: 0.0522990\tbest: 0.0522990 (405)\ttotal: 1m 25s\tremaining: 33m 35s\n",
      "406:\tlearn: 0.0525773\ttest: 0.0522983\tbest: 0.0522983 (406)\ttotal: 1m 25s\tremaining: 33m 35s\n",
      "407:\tlearn: 0.0525767\ttest: 0.0522976\tbest: 0.0522976 (407)\ttotal: 1m 25s\tremaining: 33m 34s\n",
      "408:\tlearn: 0.0525773\ttest: 0.0522976\tbest: 0.0522976 (408)\ttotal: 1m 25s\tremaining: 33m 33s\n",
      "409:\tlearn: 0.0525749\ttest: 0.0522962\tbest: 0.0522962 (409)\ttotal: 1m 26s\tremaining: 33m 33s\n",
      "410:\tlearn: 0.0525736\ttest: 0.0522949\tbest: 0.0522949 (410)\ttotal: 1m 26s\tremaining: 33m 33s\n",
      "411:\tlearn: 0.0525705\ttest: 0.0522918\tbest: 0.0522918 (411)\ttotal: 1m 26s\tremaining: 33m 33s\n",
      "412:\tlearn: 0.0525466\ttest: 0.0522863\tbest: 0.0522863 (412)\ttotal: 1m 26s\tremaining: 33m 33s\n",
      "413:\tlearn: 0.0525489\ttest: 0.0522857\tbest: 0.0522857 (413)\ttotal: 1m 26s\tremaining: 33m 32s\n",
      "414:\tlearn: 0.0525485\ttest: 0.0522852\tbest: 0.0522852 (414)\ttotal: 1m 27s\tremaining: 33m 33s\n",
      "415:\tlearn: 0.0525468\ttest: 0.0522834\tbest: 0.0522834 (415)\ttotal: 1m 27s\tremaining: 33m 32s\n",
      "416:\tlearn: 0.0525459\ttest: 0.0522825\tbest: 0.0522825 (416)\ttotal: 1m 27s\tremaining: 33m 32s\n",
      "417:\tlearn: 0.0525457\ttest: 0.0522822\tbest: 0.0522822 (417)\ttotal: 1m 27s\tremaining: 33m 31s\n",
      "418:\tlearn: 0.0525454\ttest: 0.0522818\tbest: 0.0522818 (418)\ttotal: 1m 27s\tremaining: 33m 31s\n",
      "419:\tlearn: 0.0525031\ttest: 0.0522749\tbest: 0.0522749 (419)\ttotal: 1m 28s\tremaining: 33m 31s\n",
      "420:\tlearn: 0.0525003\ttest: 0.0522740\tbest: 0.0522740 (420)\ttotal: 1m 28s\tremaining: 33m 31s\n",
      "421:\tlearn: 0.0524974\ttest: 0.0522719\tbest: 0.0522719 (421)\ttotal: 1m 28s\tremaining: 33m 30s\n",
      "422:\tlearn: 0.0524974\ttest: 0.0522710\tbest: 0.0522710 (422)\ttotal: 1m 28s\tremaining: 33m 30s\n",
      "423:\tlearn: 0.0524898\ttest: 0.0522629\tbest: 0.0522629 (423)\ttotal: 1m 28s\tremaining: 33m 29s\n",
      "424:\tlearn: 0.0524894\ttest: 0.0522623\tbest: 0.0522623 (424)\ttotal: 1m 29s\tremaining: 33m 28s\n",
      "425:\tlearn: 0.0524917\ttest: 0.0522566\tbest: 0.0522566 (425)\ttotal: 1m 29s\tremaining: 33m 27s\n",
      "426:\tlearn: 0.0524916\ttest: 0.0522562\tbest: 0.0522562 (426)\ttotal: 1m 29s\tremaining: 33m 27s\n",
      "427:\tlearn: 0.0524914\ttest: 0.0522560\tbest: 0.0522560 (427)\ttotal: 1m 29s\tremaining: 33m 26s\n",
      "428:\tlearn: 0.0524816\ttest: 0.0522509\tbest: 0.0522509 (428)\ttotal: 1m 29s\tremaining: 33m 25s\n",
      "429:\tlearn: 0.0524829\ttest: 0.0522504\tbest: 0.0522504 (429)\ttotal: 1m 30s\tremaining: 33m 24s\n",
      "430:\tlearn: 0.0524794\ttest: 0.0522488\tbest: 0.0522488 (430)\ttotal: 1m 30s\tremaining: 33m 24s\n",
      "431:\tlearn: 0.0524785\ttest: 0.0522478\tbest: 0.0522478 (431)\ttotal: 1m 30s\tremaining: 33m 23s\n",
      "432:\tlearn: 0.0524769\ttest: 0.0522419\tbest: 0.0522419 (432)\ttotal: 1m 30s\tremaining: 33m 23s\n",
      "433:\tlearn: 0.0524802\ttest: 0.0522405\tbest: 0.0522405 (433)\ttotal: 1m 30s\tremaining: 33m 22s\n",
      "434:\tlearn: 0.0524757\ttest: 0.0522359\tbest: 0.0522359 (434)\ttotal: 1m 31s\tremaining: 33m 21s\n",
      "435:\tlearn: 0.0524763\ttest: 0.0522344\tbest: 0.0522344 (435)\ttotal: 1m 31s\tremaining: 33m 20s\n",
      "436:\tlearn: 0.0524763\ttest: 0.0522344\tbest: 0.0522344 (436)\ttotal: 1m 31s\tremaining: 33m 19s\n",
      "437:\tlearn: 0.0524638\ttest: 0.0522317\tbest: 0.0522317 (437)\ttotal: 1m 31s\tremaining: 33m 18s\n",
      "438:\tlearn: 0.0524635\ttest: 0.0522299\tbest: 0.0522299 (438)\ttotal: 1m 31s\tremaining: 33m 18s\n",
      "439:\tlearn: 0.0524663\ttest: 0.0522288\tbest: 0.0522288 (439)\ttotal: 1m 31s\tremaining: 33m 17s\n",
      "440:\tlearn: 0.0524662\ttest: 0.0522288\tbest: 0.0522288 (440)\ttotal: 1m 32s\tremaining: 33m 15s\n",
      "441:\tlearn: 0.0524647\ttest: 0.0522272\tbest: 0.0522272 (441)\ttotal: 1m 32s\tremaining: 33m 15s\n",
      "442:\tlearn: 0.0524618\ttest: 0.0522199\tbest: 0.0522199 (442)\ttotal: 1m 32s\tremaining: 33m 15s\n",
      "443:\tlearn: 0.0524601\ttest: 0.0522154\tbest: 0.0522154 (443)\ttotal: 1m 32s\tremaining: 33m 15s\n",
      "444:\tlearn: 0.0524595\ttest: 0.0522148\tbest: 0.0522148 (444)\ttotal: 1m 32s\tremaining: 33m 14s\n",
      "445:\tlearn: 0.0524558\ttest: 0.0522104\tbest: 0.0522104 (445)\ttotal: 1m 33s\tremaining: 33m 15s\n",
      "446:\tlearn: 0.0524556\ttest: 0.0522048\tbest: 0.0522048 (446)\ttotal: 1m 33s\tremaining: 33m 15s\n",
      "447:\tlearn: 0.0524550\ttest: 0.0522046\tbest: 0.0522046 (447)\ttotal: 1m 33s\tremaining: 33m 14s\n",
      "448:\tlearn: 0.0524543\ttest: 0.0522043\tbest: 0.0522043 (448)\ttotal: 1m 33s\tremaining: 33m 14s\n",
      "449:\tlearn: 0.0524537\ttest: 0.0522036\tbest: 0.0522036 (449)\ttotal: 1m 33s\tremaining: 33m 13s\n",
      "450:\tlearn: 0.0524535\ttest: 0.0522031\tbest: 0.0522031 (450)\ttotal: 1m 34s\tremaining: 33m 12s\n",
      "451:\tlearn: 0.0524485\ttest: 0.0521966\tbest: 0.0521966 (451)\ttotal: 1m 34s\tremaining: 33m 12s\n",
      "452:\tlearn: 0.0524477\ttest: 0.0521959\tbest: 0.0521959 (452)\ttotal: 1m 34s\tremaining: 33m 11s\n",
      "453:\tlearn: 0.0524491\ttest: 0.0521941\tbest: 0.0521941 (453)\ttotal: 1m 34s\tremaining: 33m 11s\n",
      "454:\tlearn: 0.0524500\ttest: 0.0521932\tbest: 0.0521932 (454)\ttotal: 1m 34s\tremaining: 33m 12s\n",
      "455:\tlearn: 0.0524537\ttest: 0.0521920\tbest: 0.0521920 (455)\ttotal: 1m 35s\tremaining: 33m 11s\n",
      "456:\tlearn: 0.0524529\ttest: 0.0521915\tbest: 0.0521915 (456)\ttotal: 1m 35s\tremaining: 33m 11s\n",
      "457:\tlearn: 0.0524507\ttest: 0.0521909\tbest: 0.0521909 (457)\ttotal: 1m 35s\tremaining: 33m 11s\n",
      "458:\tlearn: 0.0524495\ttest: 0.0521886\tbest: 0.0521886 (458)\ttotal: 1m 35s\tremaining: 33m 10s\n",
      "459:\tlearn: 0.0524485\ttest: 0.0521878\tbest: 0.0521878 (459)\ttotal: 1m 35s\tremaining: 33m 10s\n",
      "460:\tlearn: 0.0524482\ttest: 0.0521875\tbest: 0.0521875 (460)\ttotal: 1m 36s\tremaining: 33m 10s\n",
      "461:\tlearn: 0.0524482\ttest: 0.0521875\tbest: 0.0521875 (460)\ttotal: 1m 36s\tremaining: 33m 9s\n",
      "462:\tlearn: 0.0524520\ttest: 0.0521865\tbest: 0.0521865 (462)\ttotal: 1m 36s\tremaining: 33m 9s\n",
      "463:\tlearn: 0.0524516\ttest: 0.0521862\tbest: 0.0521862 (463)\ttotal: 1m 36s\tremaining: 33m 9s\n",
      "464:\tlearn: 0.0524488\ttest: 0.0521824\tbest: 0.0521824 (464)\ttotal: 1m 36s\tremaining: 33m 8s\n",
      "465:\tlearn: 0.0524488\ttest: 0.0521824\tbest: 0.0521824 (465)\ttotal: 1m 37s\tremaining: 33m 8s\n",
      "466:\tlearn: 0.0524480\ttest: 0.0521779\tbest: 0.0521779 (466)\ttotal: 1m 37s\tremaining: 33m 8s\n",
      "467:\tlearn: 0.0524472\ttest: 0.0521772\tbest: 0.0521772 (467)\ttotal: 1m 37s\tremaining: 33m 7s\n",
      "468:\tlearn: 0.0524474\ttest: 0.0521731\tbest: 0.0521731 (468)\ttotal: 1m 37s\tremaining: 33m 7s\n",
      "469:\tlearn: 0.0524471\ttest: 0.0521726\tbest: 0.0521726 (469)\ttotal: 1m 38s\tremaining: 33m 7s\n",
      "470:\tlearn: 0.0524464\ttest: 0.0521721\tbest: 0.0521721 (470)\ttotal: 1m 38s\tremaining: 33m 6s\n",
      "471:\tlearn: 0.0524444\ttest: 0.0521695\tbest: 0.0521695 (471)\ttotal: 1m 38s\tremaining: 33m 6s\n",
      "472:\tlearn: 0.0524432\ttest: 0.0521656\tbest: 0.0521656 (472)\ttotal: 1m 38s\tremaining: 33m 6s\n",
      "473:\tlearn: 0.0524427\ttest: 0.0521651\tbest: 0.0521651 (473)\ttotal: 1m 38s\tremaining: 33m 5s\n",
      "474:\tlearn: 0.0524448\ttest: 0.0521639\tbest: 0.0521639 (474)\ttotal: 1m 38s\tremaining: 33m 5s\n",
      "475:\tlearn: 0.0524448\ttest: 0.0521639\tbest: 0.0521639 (475)\ttotal: 1m 39s\tremaining: 33m 3s\n",
      "476:\tlearn: 0.0524438\ttest: 0.0521615\tbest: 0.0521615 (476)\ttotal: 1m 39s\tremaining: 33m 3s\n",
      "477:\tlearn: 0.0524390\ttest: 0.0521582\tbest: 0.0521582 (477)\ttotal: 1m 39s\tremaining: 33m 2s\n",
      "478:\tlearn: 0.0524381\ttest: 0.0521573\tbest: 0.0521573 (478)\ttotal: 1m 39s\tremaining: 33m 1s\n",
      "479:\tlearn: 0.0524372\ttest: 0.0521561\tbest: 0.0521561 (479)\ttotal: 1m 39s\tremaining: 33m 1s\n",
      "480:\tlearn: 0.0524335\ttest: 0.0521544\tbest: 0.0521544 (480)\ttotal: 1m 40s\tremaining: 33m\n",
      "481:\tlearn: 0.0524328\ttest: 0.0521538\tbest: 0.0521538 (481)\ttotal: 1m 40s\tremaining: 33m\n",
      "482:\tlearn: 0.0524318\ttest: 0.0521526\tbest: 0.0521526 (482)\ttotal: 1m 40s\tremaining: 33m\n",
      "483:\tlearn: 0.0524286\ttest: 0.0521524\tbest: 0.0521524 (483)\ttotal: 1m 40s\tremaining: 33m\n",
      "484:\tlearn: 0.0524311\ttest: 0.0521499\tbest: 0.0521499 (484)\ttotal: 1m 40s\tremaining: 32m 59s\n",
      "485:\tlearn: 0.0524298\ttest: 0.0521487\tbest: 0.0521487 (485)\ttotal: 1m 41s\tremaining: 32m 59s\n",
      "486:\tlearn: 0.0524286\ttest: 0.0521478\tbest: 0.0521478 (486)\ttotal: 1m 41s\tremaining: 32m 59s\n",
      "487:\tlearn: 0.0524254\ttest: 0.0521464\tbest: 0.0521464 (487)\ttotal: 1m 41s\tremaining: 32m 59s\n",
      "488:\tlearn: 0.0524248\ttest: 0.0521459\tbest: 0.0521459 (488)\ttotal: 1m 41s\tremaining: 32m 58s\n",
      "489:\tlearn: 0.0524245\ttest: 0.0521458\tbest: 0.0521458 (489)\ttotal: 1m 41s\tremaining: 32m 57s\n",
      "490:\tlearn: 0.0524270\ttest: 0.0521453\tbest: 0.0521453 (490)\ttotal: 1m 42s\tremaining: 32m 57s\n",
      "491:\tlearn: 0.0524265\ttest: 0.0521451\tbest: 0.0521451 (491)\ttotal: 1m 42s\tremaining: 32m 57s\n",
      "492:\tlearn: 0.0524235\ttest: 0.0521447\tbest: 0.0521447 (492)\ttotal: 1m 42s\tremaining: 32m 56s\n",
      "493:\tlearn: 0.0524237\ttest: 0.0521446\tbest: 0.0521446 (493)\ttotal: 1m 42s\tremaining: 32m 56s\n",
      "494:\tlearn: 0.0524174\ttest: 0.0521432\tbest: 0.0521432 (494)\ttotal: 1m 42s\tremaining: 32m 55s\n",
      "495:\tlearn: 0.0524175\ttest: 0.0521431\tbest: 0.0521431 (495)\ttotal: 1m 43s\tremaining: 32m 54s\n",
      "496:\tlearn: 0.0524183\ttest: 0.0521408\tbest: 0.0521408 (496)\ttotal: 1m 43s\tremaining: 32m 54s\n",
      "497:\tlearn: 0.0524149\ttest: 0.0521385\tbest: 0.0521385 (497)\ttotal: 1m 43s\tremaining: 32m 54s\n",
      "498:\tlearn: 0.0524110\ttest: 0.0521373\tbest: 0.0521373 (498)\ttotal: 1m 43s\tremaining: 32m 54s\n",
      "499:\tlearn: 0.0524135\ttest: 0.0521368\tbest: 0.0521368 (499)\ttotal: 1m 43s\tremaining: 32m 53s\n",
      "500:\tlearn: 0.0524126\ttest: 0.0521339\tbest: 0.0521339 (500)\ttotal: 1m 44s\tremaining: 32m 53s\n",
      "501:\tlearn: 0.0524112\ttest: 0.0521306\tbest: 0.0521306 (501)\ttotal: 1m 44s\tremaining: 32m 53s\n",
      "502:\tlearn: 0.0524104\ttest: 0.0521297\tbest: 0.0521297 (502)\ttotal: 1m 44s\tremaining: 32m 53s\n",
      "503:\tlearn: 0.0524098\ttest: 0.0521292\tbest: 0.0521292 (503)\ttotal: 1m 44s\tremaining: 32m 53s\n",
      "504:\tlearn: 0.0524093\ttest: 0.0521269\tbest: 0.0521269 (504)\ttotal: 1m 44s\tremaining: 32m 52s\n",
      "505:\tlearn: 0.0524071\ttest: 0.0521249\tbest: 0.0521249 (505)\ttotal: 1m 45s\tremaining: 32m 52s\n",
      "506:\tlearn: 0.0524064\ttest: 0.0521241\tbest: 0.0521241 (506)\ttotal: 1m 45s\tremaining: 32m 51s\n",
      "507:\tlearn: 0.0524064\ttest: 0.0521240\tbest: 0.0521240 (507)\ttotal: 1m 45s\tremaining: 32m 50s\n",
      "508:\tlearn: 0.0524059\ttest: 0.0521222\tbest: 0.0521222 (508)\ttotal: 1m 45s\tremaining: 32m 50s\n",
      "509:\tlearn: 0.0524047\ttest: 0.0521214\tbest: 0.0521214 (509)\ttotal: 1m 45s\tremaining: 32m 49s\n",
      "510:\tlearn: 0.0524045\ttest: 0.0521213\tbest: 0.0521213 (510)\ttotal: 1m 46s\tremaining: 32m 49s\n",
      "511:\tlearn: 0.0524045\ttest: 0.0521208\tbest: 0.0521208 (511)\ttotal: 1m 46s\tremaining: 32m 49s\n",
      "512:\tlearn: 0.0524038\ttest: 0.0521204\tbest: 0.0521204 (512)\ttotal: 1m 46s\tremaining: 32m 49s\n",
      "513:\tlearn: 0.0524024\ttest: 0.0521182\tbest: 0.0521182 (513)\ttotal: 1m 46s\tremaining: 32m 49s\n",
      "514:\tlearn: 0.0524026\ttest: 0.0521177\tbest: 0.0521177 (514)\ttotal: 1m 46s\tremaining: 32m 48s\n",
      "515:\tlearn: 0.0524026\ttest: 0.0521177\tbest: 0.0521177 (515)\ttotal: 1m 47s\tremaining: 32m 47s\n",
      "516:\tlearn: 0.0524024\ttest: 0.0521174\tbest: 0.0521174 (516)\ttotal: 1m 47s\tremaining: 32m 47s\n",
      "517:\tlearn: 0.0524022\ttest: 0.0521171\tbest: 0.0521171 (517)\ttotal: 1m 47s\tremaining: 32m 47s\n",
      "518:\tlearn: 0.0524001\ttest: 0.0521153\tbest: 0.0521153 (518)\ttotal: 1m 47s\tremaining: 32m 47s\n",
      "519:\tlearn: 0.0524003\ttest: 0.0521150\tbest: 0.0521150 (519)\ttotal: 1m 47s\tremaining: 32m 47s\n",
      "520:\tlearn: 0.0524002\ttest: 0.0521148\tbest: 0.0521148 (520)\ttotal: 1m 48s\tremaining: 32m 47s\n",
      "521:\tlearn: 0.0523995\ttest: 0.0521140\tbest: 0.0521140 (521)\ttotal: 1m 48s\tremaining: 32m 46s\n",
      "522:\tlearn: 0.0523968\ttest: 0.0521118\tbest: 0.0521118 (522)\ttotal: 1m 48s\tremaining: 32m 46s\n",
      "523:\tlearn: 0.0523963\ttest: 0.0521115\tbest: 0.0521115 (523)\ttotal: 1m 48s\tremaining: 32m 46s\n",
      "524:\tlearn: 0.0523955\ttest: 0.0521113\tbest: 0.0521113 (524)\ttotal: 1m 48s\tremaining: 32m 46s\n",
      "525:\tlearn: 0.0523959\ttest: 0.0521106\tbest: 0.0521106 (525)\ttotal: 1m 49s\tremaining: 32m 45s\n",
      "526:\tlearn: 0.0523954\ttest: 0.0521103\tbest: 0.0521103 (526)\ttotal: 1m 49s\tremaining: 32m 45s\n",
      "527:\tlearn: 0.0523954\ttest: 0.0521101\tbest: 0.0521101 (527)\ttotal: 1m 49s\tremaining: 32m 44s\n",
      "528:\tlearn: 0.0523949\ttest: 0.0521087\tbest: 0.0521087 (528)\ttotal: 1m 49s\tremaining: 32m 43s\n",
      "529:\tlearn: 0.0523948\ttest: 0.0521084\tbest: 0.0521084 (529)\ttotal: 1m 49s\tremaining: 32m 42s\n",
      "530:\tlearn: 0.0523944\ttest: 0.0521080\tbest: 0.0521080 (530)\ttotal: 1m 50s\tremaining: 32m 43s\n",
      "531:\tlearn: 0.0523943\ttest: 0.0521066\tbest: 0.0521066 (531)\ttotal: 1m 50s\tremaining: 32m 43s\n",
      "532:\tlearn: 0.0523923\ttest: 0.0521039\tbest: 0.0521039 (532)\ttotal: 1m 50s\tremaining: 32m 42s\n",
      "533:\tlearn: 0.0523922\ttest: 0.0521034\tbest: 0.0521034 (533)\ttotal: 1m 50s\tremaining: 32m 41s\n",
      "534:\tlearn: 0.0523920\ttest: 0.0521032\tbest: 0.0521032 (534)\ttotal: 1m 50s\tremaining: 32m 41s\n",
      "535:\tlearn: 0.0523916\ttest: 0.0521030\tbest: 0.0521030 (535)\ttotal: 1m 51s\tremaining: 32m 41s\n",
      "536:\tlearn: 0.0523903\ttest: 0.0521016\tbest: 0.0521016 (536)\ttotal: 1m 51s\tremaining: 32m 40s\n",
      "537:\tlearn: 0.0523898\ttest: 0.0521014\tbest: 0.0521014 (537)\ttotal: 1m 51s\tremaining: 32m 40s\n",
      "538:\tlearn: 0.0523905\ttest: 0.0521011\tbest: 0.0521011 (538)\ttotal: 1m 51s\tremaining: 32m 39s\n",
      "539:\tlearn: 0.0523905\ttest: 0.0521010\tbest: 0.0521010 (539)\ttotal: 1m 51s\tremaining: 32m 39s\n",
      "540:\tlearn: 0.0523903\ttest: 0.0521008\tbest: 0.0521008 (540)\ttotal: 1m 52s\tremaining: 32m 39s\n",
      "541:\tlearn: 0.0523915\ttest: 0.0520992\tbest: 0.0520992 (541)\ttotal: 1m 52s\tremaining: 32m 39s\n",
      "542:\tlearn: 0.0523912\ttest: 0.0520992\tbest: 0.0520992 (542)\ttotal: 1m 52s\tremaining: 32m 38s\n",
      "543:\tlearn: 0.0523911\ttest: 0.0520991\tbest: 0.0520991 (543)\ttotal: 1m 52s\tremaining: 32m 37s\n",
      "544:\tlearn: 0.0523911\ttest: 0.0520990\tbest: 0.0520990 (544)\ttotal: 1m 52s\tremaining: 32m 36s\n",
      "545:\tlearn: 0.0523906\ttest: 0.0520983\tbest: 0.0520983 (545)\ttotal: 1m 52s\tremaining: 32m 36s\n",
      "546:\tlearn: 0.0523906\ttest: 0.0520975\tbest: 0.0520975 (546)\ttotal: 1m 53s\tremaining: 32m 36s\n",
      "547:\tlearn: 0.0523887\ttest: 0.0520958\tbest: 0.0520958 (547)\ttotal: 1m 53s\tremaining: 32m 36s\n",
      "548:\tlearn: 0.0523840\ttest: 0.0520908\tbest: 0.0520908 (548)\ttotal: 1m 53s\tremaining: 32m 35s\n",
      "549:\tlearn: 0.0523840\ttest: 0.0520908\tbest: 0.0520908 (549)\ttotal: 1m 53s\tremaining: 32m 35s\n",
      "550:\tlearn: 0.0523853\ttest: 0.0520895\tbest: 0.0520895 (550)\ttotal: 1m 54s\tremaining: 32m 34s\n",
      "551:\tlearn: 0.0523847\ttest: 0.0520890\tbest: 0.0520890 (551)\ttotal: 1m 54s\tremaining: 32m 34s\n",
      "552:\tlearn: 0.0523830\ttest: 0.0520878\tbest: 0.0520878 (552)\ttotal: 1m 54s\tremaining: 32m 34s\n",
      "553:\tlearn: 0.0523826\ttest: 0.0520874\tbest: 0.0520874 (553)\ttotal: 1m 54s\tremaining: 32m 34s\n",
      "554:\tlearn: 0.0523822\ttest: 0.0520872\tbest: 0.0520872 (554)\ttotal: 1m 54s\tremaining: 32m 34s\n",
      "555:\tlearn: 0.0523822\ttest: 0.0520872\tbest: 0.0520872 (554)\ttotal: 1m 55s\tremaining: 32m 33s\n",
      "556:\tlearn: 0.0523838\ttest: 0.0520870\tbest: 0.0520870 (556)\ttotal: 1m 55s\tremaining: 32m 33s\n",
      "557:\tlearn: 0.0523807\ttest: 0.0520827\tbest: 0.0520827 (557)\ttotal: 1m 55s\tremaining: 32m 33s\n",
      "558:\tlearn: 0.0523836\ttest: 0.0520815\tbest: 0.0520815 (558)\ttotal: 1m 55s\tremaining: 32m 32s\n",
      "559:\tlearn: 0.0523830\ttest: 0.0520812\tbest: 0.0520812 (559)\ttotal: 1m 55s\tremaining: 32m 31s\n",
      "560:\tlearn: 0.0523826\ttest: 0.0520802\tbest: 0.0520802 (560)\ttotal: 1m 56s\tremaining: 32m 31s\n",
      "561:\tlearn: 0.0523657\ttest: 0.0520798\tbest: 0.0520798 (561)\ttotal: 1m 56s\tremaining: 32m 31s\n",
      "562:\tlearn: 0.0523655\ttest: 0.0520798\tbest: 0.0520798 (562)\ttotal: 1m 56s\tremaining: 32m 30s\n",
      "563:\tlearn: 0.0523672\ttest: 0.0520782\tbest: 0.0520782 (563)\ttotal: 1m 56s\tremaining: 32m 30s\n",
      "564:\tlearn: 0.0523665\ttest: 0.0520777\tbest: 0.0520777 (564)\ttotal: 1m 56s\tremaining: 32m 29s\n",
      "565:\tlearn: 0.0523682\ttest: 0.0520766\tbest: 0.0520766 (565)\ttotal: 1m 56s\tremaining: 32m 29s\n",
      "566:\tlearn: 0.0523672\ttest: 0.0520758\tbest: 0.0520758 (566)\ttotal: 1m 57s\tremaining: 32m 29s\n",
      "567:\tlearn: 0.0523670\ttest: 0.0520754\tbest: 0.0520754 (567)\ttotal: 1m 57s\tremaining: 32m 29s\n",
      "568:\tlearn: 0.0523665\ttest: 0.0520752\tbest: 0.0520752 (568)\ttotal: 1m 57s\tremaining: 32m 29s\n",
      "569:\tlearn: 0.0523653\ttest: 0.0520739\tbest: 0.0520739 (569)\ttotal: 1m 57s\tremaining: 32m 29s\n",
      "570:\tlearn: 0.0523647\ttest: 0.0520724\tbest: 0.0520724 (570)\ttotal: 1m 58s\tremaining: 32m 28s\n",
      "571:\tlearn: 0.0523634\ttest: 0.0520719\tbest: 0.0520719 (571)\ttotal: 1m 58s\tremaining: 32m 28s\n",
      "572:\tlearn: 0.0523636\ttest: 0.0520719\tbest: 0.0520719 (572)\ttotal: 1m 58s\tremaining: 32m 27s\n",
      "573:\tlearn: 0.0523635\ttest: 0.0520710\tbest: 0.0520710 (573)\ttotal: 1m 58s\tremaining: 32m 26s\n",
      "574:\tlearn: 0.0523634\ttest: 0.0520709\tbest: 0.0520709 (574)\ttotal: 1m 58s\tremaining: 32m 26s\n",
      "575:\tlearn: 0.0523628\ttest: 0.0520703\tbest: 0.0520703 (575)\ttotal: 1m 58s\tremaining: 32m 25s\n",
      "576:\tlearn: 0.0523626\ttest: 0.0520690\tbest: 0.0520690 (576)\ttotal: 1m 59s\tremaining: 32m 25s\n",
      "577:\tlearn: 0.0523626\ttest: 0.0520681\tbest: 0.0520681 (577)\ttotal: 1m 59s\tremaining: 32m 25s\n",
      "578:\tlearn: 0.0523626\ttest: 0.0520673\tbest: 0.0520673 (578)\ttotal: 1m 59s\tremaining: 32m 24s\n",
      "579:\tlearn: 0.0523604\ttest: 0.0520668\tbest: 0.0520668 (579)\ttotal: 1m 59s\tremaining: 32m 24s\n",
      "580:\tlearn: 0.0523617\ttest: 0.0520664\tbest: 0.0520664 (580)\ttotal: 1m 59s\tremaining: 32m 24s\n",
      "581:\tlearn: 0.0523586\ttest: 0.0520647\tbest: 0.0520647 (581)\ttotal: 2m\tremaining: 32m 23s\n",
      "582:\tlearn: 0.0523584\ttest: 0.0520645\tbest: 0.0520645 (582)\ttotal: 2m\tremaining: 32m 23s\n",
      "583:\tlearn: 0.0523555\ttest: 0.0520635\tbest: 0.0520635 (583)\ttotal: 2m\tremaining: 32m 23s\n",
      "584:\tlearn: 0.0523555\ttest: 0.0520623\tbest: 0.0520623 (584)\ttotal: 2m\tremaining: 32m 22s\n",
      "585:\tlearn: 0.0523469\ttest: 0.0520613\tbest: 0.0520613 (585)\ttotal: 2m\tremaining: 32m 21s\n",
      "586:\tlearn: 0.0523546\ttest: 0.0520612\tbest: 0.0520612 (586)\ttotal: 2m 1s\tremaining: 32m 21s\n",
      "587:\tlearn: 0.0523538\ttest: 0.0520610\tbest: 0.0520610 (587)\ttotal: 2m 1s\tremaining: 32m 21s\n",
      "588:\tlearn: 0.0523460\ttest: 0.0520599\tbest: 0.0520599 (588)\ttotal: 2m 1s\tremaining: 32m 20s\n",
      "589:\tlearn: 0.0523534\ttest: 0.0520597\tbest: 0.0520597 (589)\ttotal: 2m 1s\tremaining: 32m 20s\n",
      "590:\tlearn: 0.0523451\ttest: 0.0520591\tbest: 0.0520591 (590)\ttotal: 2m 1s\tremaining: 32m 19s\n",
      "591:\tlearn: 0.0523528\ttest: 0.0520587\tbest: 0.0520587 (591)\ttotal: 2m 2s\tremaining: 32m 19s\n",
      "592:\tlearn: 0.0523517\ttest: 0.0520582\tbest: 0.0520582 (592)\ttotal: 2m 2s\tremaining: 32m 18s\n",
      "593:\tlearn: 0.0523376\ttest: 0.0520576\tbest: 0.0520576 (593)\ttotal: 2m 2s\tremaining: 32m 18s\n",
      "594:\tlearn: 0.0523371\ttest: 0.0520571\tbest: 0.0520571 (594)\ttotal: 2m 2s\tremaining: 32m 17s\n",
      "595:\tlearn: 0.0523446\ttest: 0.0520567\tbest: 0.0520567 (595)\ttotal: 2m 2s\tremaining: 32m 17s\n",
      "596:\tlearn: 0.0523363\ttest: 0.0520560\tbest: 0.0520560 (596)\ttotal: 2m 3s\tremaining: 32m 17s\n",
      "597:\tlearn: 0.0523441\ttest: 0.0520559\tbest: 0.0520559 (597)\ttotal: 2m 3s\tremaining: 32m 16s\n",
      "598:\tlearn: 0.0523437\ttest: 0.0520547\tbest: 0.0520547 (598)\ttotal: 2m 3s\tremaining: 32m 16s\n",
      "599:\tlearn: 0.0523431\ttest: 0.0520541\tbest: 0.0520541 (599)\ttotal: 2m 3s\tremaining: 32m 16s\n",
      "600:\tlearn: 0.0523422\ttest: 0.0520535\tbest: 0.0520535 (600)\ttotal: 2m 3s\tremaining: 32m 16s\n",
      "601:\tlearn: 0.0523344\ttest: 0.0520533\tbest: 0.0520533 (601)\ttotal: 2m 3s\tremaining: 32m 15s\n",
      "602:\tlearn: 0.0523419\ttest: 0.0520532\tbest: 0.0520532 (602)\ttotal: 2m 4s\tremaining: 32m 15s\n",
      "603:\tlearn: 0.0523421\ttest: 0.0520523\tbest: 0.0520523 (603)\ttotal: 2m 4s\tremaining: 32m 14s\n",
      "604:\tlearn: 0.0523341\ttest: 0.0520523\tbest: 0.0520523 (604)\ttotal: 2m 4s\tremaining: 32m 13s\n",
      "605:\tlearn: 0.0523334\ttest: 0.0520517\tbest: 0.0520517 (605)\ttotal: 2m 4s\tremaining: 32m 13s\n",
      "606:\tlearn: 0.0523392\ttest: 0.0520509\tbest: 0.0520509 (606)\ttotal: 2m 4s\tremaining: 32m 13s\n",
      "607:\tlearn: 0.0523309\ttest: 0.0520469\tbest: 0.0520469 (607)\ttotal: 2m 5s\tremaining: 32m 12s\n",
      "608:\tlearn: 0.0523286\ttest: 0.0520446\tbest: 0.0520446 (608)\ttotal: 2m 5s\tremaining: 32m 12s\n",
      "609:\tlearn: 0.0523274\ttest: 0.0520432\tbest: 0.0520432 (609)\ttotal: 2m 5s\tremaining: 32m 12s\n",
      "610:\tlearn: 0.0523244\ttest: 0.0520430\tbest: 0.0520430 (610)\ttotal: 2m 5s\tremaining: 32m 11s\n",
      "611:\tlearn: 0.0523253\ttest: 0.0520429\tbest: 0.0520429 (611)\ttotal: 2m 5s\tremaining: 32m 10s\n",
      "612:\tlearn: 0.0523244\ttest: 0.0520429\tbest: 0.0520429 (612)\ttotal: 2m 6s\tremaining: 32m 10s\n",
      "613:\tlearn: 0.0523243\ttest: 0.0520425\tbest: 0.0520425 (613)\ttotal: 2m 6s\tremaining: 32m 9s\n",
      "614:\tlearn: 0.0523245\ttest: 0.0520400\tbest: 0.0520400 (614)\ttotal: 2m 6s\tremaining: 32m 9s\n",
      "615:\tlearn: 0.0523244\ttest: 0.0520398\tbest: 0.0520398 (615)\ttotal: 2m 6s\tremaining: 32m 9s\n",
      "616:\tlearn: 0.0523256\ttest: 0.0520396\tbest: 0.0520396 (616)\ttotal: 2m 6s\tremaining: 32m 9s\n",
      "617:\tlearn: 0.0523249\ttest: 0.0520391\tbest: 0.0520391 (617)\ttotal: 2m 7s\tremaining: 32m 8s\n",
      "618:\tlearn: 0.0523231\ttest: 0.0520384\tbest: 0.0520384 (618)\ttotal: 2m 7s\tremaining: 32m 7s\n",
      "619:\tlearn: 0.0523227\ttest: 0.0520379\tbest: 0.0520379 (619)\ttotal: 2m 7s\tremaining: 32m 7s\n",
      "620:\tlearn: 0.0523223\ttest: 0.0520375\tbest: 0.0520375 (620)\ttotal: 2m 7s\tremaining: 32m 7s\n",
      "621:\tlearn: 0.0523219\ttest: 0.0520369\tbest: 0.0520369 (621)\ttotal: 2m 7s\tremaining: 32m 7s\n",
      "622:\tlearn: 0.0523217\ttest: 0.0520360\tbest: 0.0520360 (622)\ttotal: 2m 8s\tremaining: 32m 7s\n",
      "623:\tlearn: 0.0523240\ttest: 0.0520360\tbest: 0.0520360 (623)\ttotal: 2m 8s\tremaining: 32m 6s\n",
      "624:\tlearn: 0.0523239\ttest: 0.0520359\tbest: 0.0520359 (624)\ttotal: 2m 8s\tremaining: 32m 6s\n",
      "625:\tlearn: 0.0523238\ttest: 0.0520355\tbest: 0.0520355 (625)\ttotal: 2m 8s\tremaining: 32m 5s\n",
      "626:\tlearn: 0.0523230\ttest: 0.0520352\tbest: 0.0520352 (626)\ttotal: 2m 8s\tremaining: 32m 5s\n",
      "627:\tlearn: 0.0523228\ttest: 0.0520351\tbest: 0.0520351 (627)\ttotal: 2m 9s\tremaining: 32m 5s\n",
      "628:\tlearn: 0.0523250\ttest: 0.0520344\tbest: 0.0520344 (628)\ttotal: 2m 9s\tremaining: 32m 4s\n",
      "629:\tlearn: 0.0523232\ttest: 0.0520336\tbest: 0.0520336 (629)\ttotal: 2m 9s\tremaining: 32m 4s\n",
      "630:\tlearn: 0.0523262\ttest: 0.0520326\tbest: 0.0520326 (630)\ttotal: 2m 9s\tremaining: 32m 4s\n",
      "631:\tlearn: 0.0523261\ttest: 0.0520326\tbest: 0.0520326 (631)\ttotal: 2m 9s\tremaining: 32m 3s\n",
      "632:\tlearn: 0.0523230\ttest: 0.0520317\tbest: 0.0520317 (632)\ttotal: 2m 10s\tremaining: 32m 3s\n",
      "633:\tlearn: 0.0523269\ttest: 0.0520314\tbest: 0.0520314 (633)\ttotal: 2m 10s\tremaining: 32m 3s\n",
      "634:\tlearn: 0.0523269\ttest: 0.0520314\tbest: 0.0520314 (633)\ttotal: 2m 10s\tremaining: 32m 3s\n",
      "635:\tlearn: 0.0523267\ttest: 0.0520311\tbest: 0.0520311 (635)\ttotal: 2m 10s\tremaining: 32m 2s\n",
      "636:\tlearn: 0.0523264\ttest: 0.0520304\tbest: 0.0520304 (636)\ttotal: 2m 10s\tremaining: 32m 2s\n",
      "637:\tlearn: 0.0523195\ttest: 0.0520294\tbest: 0.0520294 (637)\ttotal: 2m 10s\tremaining: 32m 2s\n",
      "638:\tlearn: 0.0523194\ttest: 0.0520286\tbest: 0.0520286 (638)\ttotal: 2m 11s\tremaining: 32m 1s\n",
      "639:\tlearn: 0.0523212\ttest: 0.0520281\tbest: 0.0520281 (639)\ttotal: 2m 11s\tremaining: 32m 1s\n",
      "640:\tlearn: 0.0523210\ttest: 0.0520278\tbest: 0.0520278 (640)\ttotal: 2m 11s\tremaining: 32m 1s\n",
      "641:\tlearn: 0.0523226\ttest: 0.0520275\tbest: 0.0520275 (641)\ttotal: 2m 11s\tremaining: 32m\n",
      "642:\tlearn: 0.0523216\ttest: 0.0520271\tbest: 0.0520271 (642)\ttotal: 2m 11s\tremaining: 32m\n",
      "643:\tlearn: 0.0523207\ttest: 0.0520269\tbest: 0.0520269 (643)\ttotal: 2m 12s\tremaining: 32m\n",
      "644:\tlearn: 0.0523185\ttest: 0.0520265\tbest: 0.0520265 (644)\ttotal: 2m 12s\tremaining: 32m\n",
      "645:\tlearn: 0.0523174\ttest: 0.0520261\tbest: 0.0520261 (645)\ttotal: 2m 12s\tremaining: 31m 59s\n",
      "646:\tlearn: 0.0523187\ttest: 0.0520257\tbest: 0.0520257 (646)\ttotal: 2m 12s\tremaining: 31m 59s\n",
      "647:\tlearn: 0.0523180\ttest: 0.0520251\tbest: 0.0520251 (647)\ttotal: 2m 13s\tremaining: 31m 59s\n",
      "648:\tlearn: 0.0523180\ttest: 0.0520248\tbest: 0.0520248 (648)\ttotal: 2m 13s\tremaining: 31m 59s\n",
      "649:\tlearn: 0.0523174\ttest: 0.0520243\tbest: 0.0520243 (649)\ttotal: 2m 13s\tremaining: 31m 58s\n",
      "650:\tlearn: 0.0523168\ttest: 0.0520241\tbest: 0.0520241 (650)\ttotal: 2m 13s\tremaining: 31m 58s\n",
      "651:\tlearn: 0.0523165\ttest: 0.0520239\tbest: 0.0520239 (651)\ttotal: 2m 13s\tremaining: 31m 57s\n",
      "652:\tlearn: 0.0523137\ttest: 0.0520236\tbest: 0.0520236 (652)\ttotal: 2m 13s\tremaining: 31m 57s\n",
      "653:\tlearn: 0.0523138\ttest: 0.0520227\tbest: 0.0520227 (653)\ttotal: 2m 14s\tremaining: 31m 57s\n",
      "654:\tlearn: 0.0523132\ttest: 0.0520220\tbest: 0.0520220 (654)\ttotal: 2m 14s\tremaining: 31m 57s\n",
      "655:\tlearn: 0.0523132\ttest: 0.0520220\tbest: 0.0520220 (655)\ttotal: 2m 14s\tremaining: 31m 56s\n",
      "656:\tlearn: 0.0523132\ttest: 0.0520216\tbest: 0.0520216 (656)\ttotal: 2m 14s\tremaining: 31m 55s\n",
      "657:\tlearn: 0.0523142\ttest: 0.0520214\tbest: 0.0520214 (657)\ttotal: 2m 14s\tremaining: 31m 55s\n",
      "658:\tlearn: 0.0523140\ttest: 0.0520212\tbest: 0.0520212 (658)\ttotal: 2m 15s\tremaining: 31m 55s\n",
      "659:\tlearn: 0.0523122\ttest: 0.0520206\tbest: 0.0520206 (659)\ttotal: 2m 15s\tremaining: 31m 54s\n",
      "660:\tlearn: 0.0523122\ttest: 0.0520206\tbest: 0.0520206 (660)\ttotal: 2m 15s\tremaining: 31m 54s\n",
      "661:\tlearn: 0.0523131\ttest: 0.0520203\tbest: 0.0520203 (661)\ttotal: 2m 15s\tremaining: 31m 53s\n",
      "662:\tlearn: 0.0523130\ttest: 0.0520201\tbest: 0.0520201 (662)\ttotal: 2m 15s\tremaining: 31m 53s\n",
      "663:\tlearn: 0.0523126\ttest: 0.0520198\tbest: 0.0520198 (663)\ttotal: 2m 16s\tremaining: 31m 52s\n",
      "664:\tlearn: 0.0523124\ttest: 0.0520195\tbest: 0.0520195 (664)\ttotal: 2m 16s\tremaining: 31m 52s\n",
      "665:\tlearn: 0.0523124\ttest: 0.0520195\tbest: 0.0520195 (665)\ttotal: 2m 16s\tremaining: 31m 51s\n",
      "666:\tlearn: 0.0523121\ttest: 0.0520192\tbest: 0.0520192 (666)\ttotal: 2m 16s\tremaining: 31m 50s\n",
      "667:\tlearn: 0.0523149\ttest: 0.0520188\tbest: 0.0520188 (667)\ttotal: 2m 16s\tremaining: 31m 50s\n",
      "668:\tlearn: 0.0523149\ttest: 0.0520188\tbest: 0.0520188 (667)\ttotal: 2m 16s\tremaining: 31m 49s\n",
      "669:\tlearn: 0.0523150\ttest: 0.0520188\tbest: 0.0520188 (669)\ttotal: 2m 17s\tremaining: 31m 49s\n",
      "670:\tlearn: 0.0523145\ttest: 0.0520184\tbest: 0.0520184 (670)\ttotal: 2m 17s\tremaining: 31m 48s\n",
      "671:\tlearn: 0.0523145\ttest: 0.0520183\tbest: 0.0520183 (671)\ttotal: 2m 17s\tremaining: 31m 48s\n",
      "672:\tlearn: 0.0523145\ttest: 0.0520183\tbest: 0.0520183 (672)\ttotal: 2m 17s\tremaining: 31m 47s\n",
      "673:\tlearn: 0.0523147\ttest: 0.0520180\tbest: 0.0520180 (673)\ttotal: 2m 17s\tremaining: 31m 47s\n",
      "674:\tlearn: 0.0523158\ttest: 0.0520179\tbest: 0.0520179 (674)\ttotal: 2m 18s\tremaining: 31m 46s\n",
      "675:\tlearn: 0.0523151\ttest: 0.0520174\tbest: 0.0520174 (675)\ttotal: 2m 18s\tremaining: 31m 46s\n",
      "676:\tlearn: 0.0523147\ttest: 0.0520166\tbest: 0.0520166 (676)\ttotal: 2m 18s\tremaining: 31m 46s\n",
      "677:\tlearn: 0.0523133\ttest: 0.0520163\tbest: 0.0520163 (677)\ttotal: 2m 18s\tremaining: 31m 46s\n",
      "678:\tlearn: 0.0523131\ttest: 0.0520161\tbest: 0.0520161 (678)\ttotal: 2m 18s\tremaining: 31m 46s\n",
      "679:\tlearn: 0.0523127\ttest: 0.0520159\tbest: 0.0520159 (679)\ttotal: 2m 19s\tremaining: 31m 46s\n",
      "680:\tlearn: 0.0523135\ttest: 0.0520156\tbest: 0.0520156 (680)\ttotal: 2m 19s\tremaining: 31m 45s\n",
      "681:\tlearn: 0.0523131\ttest: 0.0520153\tbest: 0.0520153 (681)\ttotal: 2m 19s\tremaining: 31m 45s\n",
      "682:\tlearn: 0.0523131\ttest: 0.0520153\tbest: 0.0520153 (682)\ttotal: 2m 19s\tremaining: 31m 44s\n",
      "683:\tlearn: 0.0523131\ttest: 0.0520153\tbest: 0.0520153 (683)\ttotal: 2m 19s\tremaining: 31m 44s\n",
      "684:\tlearn: 0.0523126\ttest: 0.0520146\tbest: 0.0520146 (684)\ttotal: 2m 20s\tremaining: 31m 44s\n",
      "685:\tlearn: 0.0523123\ttest: 0.0520145\tbest: 0.0520145 (685)\ttotal: 2m 20s\tremaining: 31m 43s\n",
      "686:\tlearn: 0.0523125\ttest: 0.0520142\tbest: 0.0520142 (686)\ttotal: 2m 20s\tremaining: 31m 43s\n",
      "687:\tlearn: 0.0523122\ttest: 0.0520138\tbest: 0.0520138 (687)\ttotal: 2m 20s\tremaining: 31m 42s\n",
      "688:\tlearn: 0.0523128\ttest: 0.0520138\tbest: 0.0520138 (688)\ttotal: 2m 20s\tremaining: 31m 41s\n",
      "689:\tlearn: 0.0523127\ttest: 0.0520138\tbest: 0.0520138 (689)\ttotal: 2m 20s\tremaining: 31m 41s\n",
      "690:\tlearn: 0.0523122\ttest: 0.0520134\tbest: 0.0520134 (690)\ttotal: 2m 21s\tremaining: 31m 41s\n",
      "691:\tlearn: 0.0523122\ttest: 0.0520134\tbest: 0.0520134 (691)\ttotal: 2m 21s\tremaining: 31m 40s\n",
      "692:\tlearn: 0.0523119\ttest: 0.0520131\tbest: 0.0520131 (692)\ttotal: 2m 21s\tremaining: 31m 40s\n",
      "693:\tlearn: 0.0523092\ttest: 0.0520128\tbest: 0.0520128 (693)\ttotal: 2m 21s\tremaining: 31m 39s\n",
      "694:\tlearn: 0.0523091\ttest: 0.0520127\tbest: 0.0520127 (694)\ttotal: 2m 21s\tremaining: 31m 38s\n",
      "695:\tlearn: 0.0523082\ttest: 0.0520094\tbest: 0.0520094 (695)\ttotal: 2m 22s\tremaining: 31m 38s\n",
      "696:\tlearn: 0.0523080\ttest: 0.0520085\tbest: 0.0520085 (696)\ttotal: 2m 22s\tremaining: 31m 38s\n",
      "697:\tlearn: 0.0523088\ttest: 0.0520082\tbest: 0.0520082 (697)\ttotal: 2m 22s\tremaining: 31m 37s\n",
      "698:\tlearn: 0.0523102\ttest: 0.0520068\tbest: 0.0520068 (698)\ttotal: 2m 22s\tremaining: 31m 37s\n",
      "699:\tlearn: 0.0523102\ttest: 0.0520068\tbest: 0.0520068 (698)\ttotal: 2m 22s\tremaining: 31m 37s\n",
      "700:\tlearn: 0.0523102\ttest: 0.0520067\tbest: 0.0520067 (700)\ttotal: 2m 22s\tremaining: 31m 36s\n",
      "701:\tlearn: 0.0523102\ttest: 0.0520067\tbest: 0.0520067 (701)\ttotal: 2m 23s\tremaining: 31m 35s\n",
      "702:\tlearn: 0.0523099\ttest: 0.0520066\tbest: 0.0520066 (702)\ttotal: 2m 23s\tremaining: 31m 35s\n",
      "703:\tlearn: 0.0523099\ttest: 0.0520066\tbest: 0.0520066 (702)\ttotal: 2m 23s\tremaining: 31m 35s\n",
      "704:\tlearn: 0.0523099\ttest: 0.0520066\tbest: 0.0520066 (702)\ttotal: 2m 23s\tremaining: 31m 34s\n",
      "705:\tlearn: 0.0523101\ttest: 0.0520066\tbest: 0.0520066 (705)\ttotal: 2m 23s\tremaining: 31m 34s\n",
      "706:\tlearn: 0.0523101\ttest: 0.0520065\tbest: 0.0520065 (706)\ttotal: 2m 24s\tremaining: 31m 33s\n",
      "707:\tlearn: 0.0523101\ttest: 0.0520064\tbest: 0.0520064 (707)\ttotal: 2m 24s\tremaining: 31m 32s\n",
      "708:\tlearn: 0.0523100\ttest: 0.0520052\tbest: 0.0520052 (708)\ttotal: 2m 24s\tremaining: 31m 32s\n",
      "709:\tlearn: 0.0523102\ttest: 0.0520051\tbest: 0.0520051 (709)\ttotal: 2m 24s\tremaining: 31m 32s\n",
      "710:\tlearn: 0.0523102\ttest: 0.0520051\tbest: 0.0520051 (709)\ttotal: 2m 24s\tremaining: 31m 31s\n",
      "711:\tlearn: 0.0523098\ttest: 0.0520050\tbest: 0.0520050 (711)\ttotal: 2m 24s\tremaining: 31m 31s\n",
      "712:\tlearn: 0.0523097\ttest: 0.0520049\tbest: 0.0520049 (712)\ttotal: 2m 25s\tremaining: 31m 30s\n",
      "713:\tlearn: 0.0523097\ttest: 0.0520049\tbest: 0.0520049 (713)\ttotal: 2m 25s\tremaining: 31m 30s\n",
      "714:\tlearn: 0.0523095\ttest: 0.0520047\tbest: 0.0520047 (714)\ttotal: 2m 25s\tremaining: 31m 30s\n",
      "715:\tlearn: 0.0523086\ttest: 0.0520040\tbest: 0.0520040 (715)\ttotal: 2m 25s\tremaining: 31m 29s\n",
      "716:\tlearn: 0.0523082\ttest: 0.0520039\tbest: 0.0520039 (716)\ttotal: 2m 25s\tremaining: 31m 29s\n",
      "717:\tlearn: 0.0523082\ttest: 0.0520039\tbest: 0.0520039 (717)\ttotal: 2m 26s\tremaining: 31m 28s\n",
      "718:\tlearn: 0.0523082\ttest: 0.0520039\tbest: 0.0520039 (718)\ttotal: 2m 26s\tremaining: 31m 27s\n",
      "719:\tlearn: 0.0523082\ttest: 0.0520039\tbest: 0.0520039 (718)\ttotal: 2m 26s\tremaining: 31m 26s\n",
      "720:\tlearn: 0.0523077\ttest: 0.0520036\tbest: 0.0520036 (720)\ttotal: 2m 26s\tremaining: 31m 26s\n",
      "721:\tlearn: 0.0523076\ttest: 0.0520035\tbest: 0.0520035 (721)\ttotal: 2m 26s\tremaining: 31m 25s\n",
      "722:\tlearn: 0.0523077\ttest: 0.0520035\tbest: 0.0520035 (722)\ttotal: 2m 26s\tremaining: 31m 24s\n",
      "723:\tlearn: 0.0523077\ttest: 0.0520035\tbest: 0.0520035 (723)\ttotal: 2m 27s\tremaining: 31m 24s\n",
      "724:\tlearn: 0.0523077\ttest: 0.0520035\tbest: 0.0520035 (724)\ttotal: 2m 27s\tremaining: 31m 24s\n",
      "725:\tlearn: 0.0523071\ttest: 0.0520032\tbest: 0.0520032 (725)\ttotal: 2m 27s\tremaining: 31m 23s\n",
      "726:\tlearn: 0.0523069\ttest: 0.0520030\tbest: 0.0520030 (726)\ttotal: 2m 27s\tremaining: 31m 23s\n",
      "727:\tlearn: 0.0523069\ttest: 0.0520030\tbest: 0.0520030 (727)\ttotal: 2m 27s\tremaining: 31m 23s\n",
      "728:\tlearn: 0.0523064\ttest: 0.0520027\tbest: 0.0520027 (728)\ttotal: 2m 28s\tremaining: 31m 23s\n",
      "729:\tlearn: 0.0523064\ttest: 0.0520027\tbest: 0.0520027 (729)\ttotal: 2m 28s\tremaining: 31m 22s\n",
      "730:\tlearn: 0.0523064\ttest: 0.0520027\tbest: 0.0520027 (730)\ttotal: 2m 28s\tremaining: 31m 21s\n",
      "731:\tlearn: 0.0523064\ttest: 0.0520027\tbest: 0.0520027 (730)\ttotal: 2m 28s\tremaining: 31m 21s\n",
      "732:\tlearn: 0.0523064\ttest: 0.0520027\tbest: 0.0520027 (730)\ttotal: 2m 28s\tremaining: 31m 20s\n",
      "733:\tlearn: 0.0523064\ttest: 0.0520027\tbest: 0.0520027 (733)\ttotal: 2m 28s\tremaining: 31m 19s\n",
      "734:\tlearn: 0.0523063\ttest: 0.0520026\tbest: 0.0520026 (734)\ttotal: 2m 29s\tremaining: 31m 19s\n",
      "735:\tlearn: 0.0523060\ttest: 0.0520021\tbest: 0.0520021 (735)\ttotal: 2m 29s\tremaining: 31m 19s\n",
      "736:\tlearn: 0.0523059\ttest: 0.0520020\tbest: 0.0520020 (736)\ttotal: 2m 29s\tremaining: 31m 18s\n",
      "737:\tlearn: 0.0523059\ttest: 0.0520020\tbest: 0.0520020 (736)\ttotal: 2m 29s\tremaining: 31m 18s\n",
      "738:\tlearn: 0.0523052\ttest: 0.0520016\tbest: 0.0520016 (738)\ttotal: 2m 29s\tremaining: 31m 17s\n",
      "739:\tlearn: 0.0523051\ttest: 0.0520016\tbest: 0.0520016 (739)\ttotal: 2m 30s\tremaining: 31m 17s\n",
      "740:\tlearn: 0.0523039\ttest: 0.0520001\tbest: 0.0520001 (740)\ttotal: 2m 30s\tremaining: 31m 17s\n",
      "741:\tlearn: 0.0523033\ttest: 0.0519996\tbest: 0.0519996 (741)\ttotal: 2m 30s\tremaining: 31m 16s\n",
      "742:\tlearn: 0.0523031\ttest: 0.0519994\tbest: 0.0519994 (742)\ttotal: 2m 30s\tremaining: 31m 15s\n",
      "743:\tlearn: 0.0523031\ttest: 0.0519994\tbest: 0.0519994 (743)\ttotal: 2m 30s\tremaining: 31m 15s\n",
      "744:\tlearn: 0.0523030\ttest: 0.0519994\tbest: 0.0519994 (744)\ttotal: 2m 30s\tremaining: 31m 14s\n",
      "745:\tlearn: 0.0523030\ttest: 0.0519994\tbest: 0.0519994 (744)\ttotal: 2m 31s\tremaining: 31m 14s\n",
      "746:\tlearn: 0.0523031\ttest: 0.0519994\tbest: 0.0519994 (746)\ttotal: 2m 31s\tremaining: 31m 13s\n",
      "747:\tlearn: 0.0523026\ttest: 0.0519991\tbest: 0.0519991 (747)\ttotal: 2m 31s\tremaining: 31m 13s\n",
      "748:\tlearn: 0.0523026\ttest: 0.0519991\tbest: 0.0519991 (747)\ttotal: 2m 31s\tremaining: 31m 12s\n",
      "749:\tlearn: 0.0523026\ttest: 0.0519991\tbest: 0.0519991 (747)\ttotal: 2m 31s\tremaining: 31m 12s\n",
      "750:\tlearn: 0.0523020\ttest: 0.0519987\tbest: 0.0519987 (750)\ttotal: 2m 32s\tremaining: 31m 12s\n",
      "751:\tlearn: 0.0523026\ttest: 0.0519987\tbest: 0.0519987 (751)\ttotal: 2m 32s\tremaining: 31m 11s\n",
      "752:\tlearn: 0.0523026\ttest: 0.0519986\tbest: 0.0519986 (752)\ttotal: 2m 32s\tremaining: 31m 11s\n",
      "753:\tlearn: 0.0523023\ttest: 0.0519986\tbest: 0.0519986 (753)\ttotal: 2m 32s\tremaining: 31m 10s\n",
      "754:\tlearn: 0.0523020\ttest: 0.0519981\tbest: 0.0519981 (754)\ttotal: 2m 32s\tremaining: 31m 10s\n",
      "755:\tlearn: 0.0523013\ttest: 0.0519976\tbest: 0.0519976 (755)\ttotal: 2m 32s\tremaining: 31m 9s\n",
      "756:\tlearn: 0.0523007\ttest: 0.0519976\tbest: 0.0519976 (756)\ttotal: 2m 33s\tremaining: 31m 9s\n",
      "757:\tlearn: 0.0523007\ttest: 0.0519976\tbest: 0.0519976 (756)\ttotal: 2m 33s\tremaining: 31m 8s\n",
      "758:\tlearn: 0.0523010\ttest: 0.0519976\tbest: 0.0519976 (758)\ttotal: 2m 33s\tremaining: 31m 8s\n",
      "759:\tlearn: 0.0523019\ttest: 0.0519976\tbest: 0.0519976 (759)\ttotal: 2m 33s\tremaining: 31m 7s\n",
      "760:\tlearn: 0.0523011\ttest: 0.0519973\tbest: 0.0519973 (760)\ttotal: 2m 33s\tremaining: 31m 7s\n",
      "761:\tlearn: 0.0523011\ttest: 0.0519973\tbest: 0.0519973 (760)\ttotal: 2m 34s\tremaining: 31m 7s\n",
      "762:\tlearn: 0.0523011\ttest: 0.0519973\tbest: 0.0519973 (760)\ttotal: 2m 34s\tremaining: 31m 6s\n",
      "763:\tlearn: 0.0523011\ttest: 0.0519964\tbest: 0.0519964 (763)\ttotal: 2m 34s\tremaining: 31m 6s\n",
      "764:\tlearn: 0.0523007\ttest: 0.0519961\tbest: 0.0519961 (764)\ttotal: 2m 34s\tremaining: 31m 6s\n",
      "765:\tlearn: 0.0523008\ttest: 0.0519961\tbest: 0.0519961 (765)\ttotal: 2m 34s\tremaining: 31m 5s\n",
      "766:\tlearn: 0.0523005\ttest: 0.0519961\tbest: 0.0519961 (766)\ttotal: 2m 34s\tremaining: 31m 5s\n",
      "767:\tlearn: 0.0523008\ttest: 0.0519961\tbest: 0.0519961 (767)\ttotal: 2m 35s\tremaining: 31m 5s\n",
      "768:\tlearn: 0.0523008\ttest: 0.0519961\tbest: 0.0519961 (768)\ttotal: 2m 35s\tremaining: 31m 4s\n",
      "769:\tlearn: 0.0523008\ttest: 0.0519961\tbest: 0.0519961 (769)\ttotal: 2m 35s\tremaining: 31m 4s\n",
      "770:\tlearn: 0.0523011\ttest: 0.0519961\tbest: 0.0519961 (770)\ttotal: 2m 35s\tremaining: 31m 3s\n",
      "771:\tlearn: 0.0523011\ttest: 0.0519961\tbest: 0.0519961 (770)\ttotal: 2m 35s\tremaining: 31m 3s\n",
      "772:\tlearn: 0.0523011\ttest: 0.0519961\tbest: 0.0519961 (770)\ttotal: 2m 36s\tremaining: 31m 2s\n",
      "773:\tlearn: 0.0523011\ttest: 0.0519961\tbest: 0.0519961 (770)\ttotal: 2m 36s\tremaining: 31m 2s\n",
      "774:\tlearn: 0.0523009\ttest: 0.0519959\tbest: 0.0519959 (774)\ttotal: 2m 36s\tremaining: 31m 1s\n",
      "775:\tlearn: 0.0523010\ttest: 0.0519959\tbest: 0.0519959 (775)\ttotal: 2m 36s\tremaining: 31m 1s\n",
      "776:\tlearn: 0.0523010\ttest: 0.0519959\tbest: 0.0519959 (775)\ttotal: 2m 36s\tremaining: 31m 1s\n",
      "777:\tlearn: 0.0523010\ttest: 0.0519959\tbest: 0.0519959 (777)\ttotal: 2m 36s\tremaining: 31m\n",
      "778:\tlearn: 0.0523020\ttest: 0.0519954\tbest: 0.0519954 (778)\ttotal: 2m 37s\tremaining: 31m\n",
      "779:\tlearn: 0.0523016\ttest: 0.0519954\tbest: 0.0519954 (779)\ttotal: 2m 37s\tremaining: 31m\n",
      "780:\tlearn: 0.0523021\ttest: 0.0519954\tbest: 0.0519954 (780)\ttotal: 2m 37s\tremaining: 30m 59s\n",
      "781:\tlearn: 0.0523021\ttest: 0.0519954\tbest: 0.0519954 (781)\ttotal: 2m 37s\tremaining: 30m 59s\n",
      "782:\tlearn: 0.0522521\ttest: 0.0519947\tbest: 0.0519947 (782)\ttotal: 2m 37s\tremaining: 30m 59s\n",
      "783:\tlearn: 0.0522517\ttest: 0.0519947\tbest: 0.0519947 (783)\ttotal: 2m 38s\tremaining: 30m 58s\n",
      "784:\tlearn: 0.0522519\ttest: 0.0519946\tbest: 0.0519946 (784)\ttotal: 2m 38s\tremaining: 30m 58s\n",
      "785:\tlearn: 0.0522519\ttest: 0.0519945\tbest: 0.0519945 (785)\ttotal: 2m 38s\tremaining: 30m 58s\n",
      "786:\tlearn: 0.0522519\ttest: 0.0519945\tbest: 0.0519945 (786)\ttotal: 2m 38s\tremaining: 30m 57s\n",
      "787:\tlearn: 0.0522519\ttest: 0.0519945\tbest: 0.0519945 (786)\ttotal: 2m 38s\tremaining: 30m 56s\n",
      "788:\tlearn: 0.0522519\ttest: 0.0519945\tbest: 0.0519945 (786)\ttotal: 2m 39s\tremaining: 30m 56s\n",
      "789:\tlearn: 0.0522519\ttest: 0.0519945\tbest: 0.0519945 (786)\ttotal: 2m 39s\tremaining: 30m 55s\n",
      "790:\tlearn: 0.0522519\ttest: 0.0519945\tbest: 0.0519945 (786)\ttotal: 2m 39s\tremaining: 30m 55s\n",
      "791:\tlearn: 0.0522514\ttest: 0.0519938\tbest: 0.0519938 (791)\ttotal: 2m 39s\tremaining: 30m 55s\n",
      "792:\tlearn: 0.0522518\ttest: 0.0519936\tbest: 0.0519936 (792)\ttotal: 2m 39s\tremaining: 30m 54s\n",
      "793:\tlearn: 0.0522518\ttest: 0.0519936\tbest: 0.0519936 (792)\ttotal: 2m 39s\tremaining: 30m 54s\n",
      "794:\tlearn: 0.0522518\ttest: 0.0519936\tbest: 0.0519936 (792)\ttotal: 2m 40s\tremaining: 30m 54s\n",
      "795:\tlearn: 0.0522517\ttest: 0.0519934\tbest: 0.0519934 (795)\ttotal: 2m 40s\tremaining: 30m 53s\n",
      "796:\tlearn: 0.0522513\ttest: 0.0519929\tbest: 0.0519929 (796)\ttotal: 2m 40s\tremaining: 30m 53s\n",
      "797:\tlearn: 0.0522513\ttest: 0.0519929\tbest: 0.0519929 (797)\ttotal: 2m 40s\tremaining: 30m 52s\n",
      "798:\tlearn: 0.0522510\ttest: 0.0519929\tbest: 0.0519929 (798)\ttotal: 2m 40s\tremaining: 30m 52s\n",
      "799:\tlearn: 0.0522511\ttest: 0.0519929\tbest: 0.0519929 (799)\ttotal: 2m 41s\tremaining: 30m 52s\n",
      "800:\tlearn: 0.0522517\ttest: 0.0519922\tbest: 0.0519922 (800)\ttotal: 2m 41s\tremaining: 30m 52s\n",
      "801:\tlearn: 0.0522516\ttest: 0.0519922\tbest: 0.0519922 (801)\ttotal: 2m 41s\tremaining: 30m 51s\n",
      "802:\tlearn: 0.0522522\ttest: 0.0519922\tbest: 0.0519922 (802)\ttotal: 2m 41s\tremaining: 30m 51s\n",
      "803:\tlearn: 0.0522493\ttest: 0.0519922\tbest: 0.0519922 (803)\ttotal: 2m 41s\tremaining: 30m 50s\n",
      "804:\tlearn: 0.0522488\ttest: 0.0519922\tbest: 0.0519922 (804)\ttotal: 2m 41s\tremaining: 30m 50s\n",
      "805:\tlearn: 0.0522491\ttest: 0.0519921\tbest: 0.0519921 (805)\ttotal: 2m 42s\tremaining: 30m 49s\n",
      "806:\tlearn: 0.0522491\ttest: 0.0519921\tbest: 0.0519921 (805)\ttotal: 2m 42s\tremaining: 30m 49s\n",
      "807:\tlearn: 0.0522489\ttest: 0.0519921\tbest: 0.0519921 (807)\ttotal: 2m 42s\tremaining: 30m 48s\n",
      "808:\tlearn: 0.0522489\ttest: 0.0519921\tbest: 0.0519921 (807)\ttotal: 2m 42s\tremaining: 30m 47s\n",
      "809:\tlearn: 0.0522489\ttest: 0.0519921\tbest: 0.0519921 (807)\ttotal: 2m 42s\tremaining: 30m 47s\n",
      "810:\tlearn: 0.0522512\ttest: 0.0519921\tbest: 0.0519921 (810)\ttotal: 2m 43s\tremaining: 30m 46s\n",
      "811:\tlearn: 0.0522512\ttest: 0.0519921\tbest: 0.0519921 (810)\ttotal: 2m 43s\tremaining: 30m 46s\n",
      "812:\tlearn: 0.0522497\ttest: 0.0519921\tbest: 0.0519921 (812)\ttotal: 2m 43s\tremaining: 30m 45s\n",
      "813:\tlearn: 0.0522496\ttest: 0.0519921\tbest: 0.0519921 (813)\ttotal: 2m 43s\tremaining: 30m 45s\n",
      "814:\tlearn: 0.0522496\ttest: 0.0519921\tbest: 0.0519921 (813)\ttotal: 2m 43s\tremaining: 30m 45s\n",
      "815:\tlearn: 0.0522514\ttest: 0.0519921\tbest: 0.0519921 (815)\ttotal: 2m 43s\tremaining: 30m 44s\n",
      "816:\tlearn: 0.0522514\ttest: 0.0519921\tbest: 0.0519921 (816)\ttotal: 2m 44s\tremaining: 30m 44s\n",
      "817:\tlearn: 0.0522511\ttest: 0.0519920\tbest: 0.0519920 (817)\ttotal: 2m 44s\tremaining: 30m 43s\n",
      "818:\tlearn: 0.0522511\ttest: 0.0519920\tbest: 0.0519920 (818)\ttotal: 2m 44s\tremaining: 30m 43s\n",
      "819:\tlearn: 0.0522511\ttest: 0.0519920\tbest: 0.0519920 (819)\ttotal: 2m 44s\tremaining: 30m 42s\n",
      "820:\tlearn: 0.0522518\ttest: 0.0519920\tbest: 0.0519920 (820)\ttotal: 2m 44s\tremaining: 30m 42s\n",
      "821:\tlearn: 0.0522526\ttest: 0.0519916\tbest: 0.0519916 (821)\ttotal: 2m 44s\tremaining: 30m 41s\n",
      "822:\tlearn: 0.0522511\ttest: 0.0519916\tbest: 0.0519916 (822)\ttotal: 2m 45s\tremaining: 30m 41s\n",
      "823:\tlearn: 0.0522511\ttest: 0.0519916\tbest: 0.0519916 (823)\ttotal: 2m 45s\tremaining: 30m 41s\n",
      "824:\tlearn: 0.0522516\ttest: 0.0519916\tbest: 0.0519916 (824)\ttotal: 2m 45s\tremaining: 30m 40s\n",
      "825:\tlearn: 0.0522511\ttest: 0.0519913\tbest: 0.0519913 (825)\ttotal: 2m 45s\tremaining: 30m 40s\n",
      "826:\tlearn: 0.0522510\ttest: 0.0519913\tbest: 0.0519913 (826)\ttotal: 2m 45s\tremaining: 30m 40s\n",
      "827:\tlearn: 0.0522513\ttest: 0.0519913\tbest: 0.0519913 (827)\ttotal: 2m 46s\tremaining: 30m 39s\n",
      "828:\tlearn: 0.0522513\ttest: 0.0519913\tbest: 0.0519913 (827)\ttotal: 2m 46s\tremaining: 30m 38s\n",
      "829:\tlearn: 0.0522513\ttest: 0.0519913\tbest: 0.0519913 (829)\ttotal: 2m 46s\tremaining: 30m 38s\n",
      "830:\tlearn: 0.0522518\ttest: 0.0519913\tbest: 0.0519913 (830)\ttotal: 2m 46s\tremaining: 30m 37s\n",
      "831:\tlearn: 0.0522518\ttest: 0.0519913\tbest: 0.0519913 (830)\ttotal: 2m 46s\tremaining: 30m 37s\n",
      "832:\tlearn: 0.0522518\ttest: 0.0519913\tbest: 0.0519913 (830)\ttotal: 2m 46s\tremaining: 30m 36s\n",
      "833:\tlearn: 0.0522518\ttest: 0.0519913\tbest: 0.0519913 (830)\ttotal: 2m 47s\tremaining: 30m 36s\n",
      "834:\tlearn: 0.0522510\ttest: 0.0519910\tbest: 0.0519910 (834)\ttotal: 2m 47s\tremaining: 30m 35s\n",
      "835:\tlearn: 0.0522516\ttest: 0.0519909\tbest: 0.0519909 (835)\ttotal: 2m 47s\tremaining: 30m 35s\n",
      "836:\tlearn: 0.0522515\ttest: 0.0519909\tbest: 0.0519909 (836)\ttotal: 2m 47s\tremaining: 30m 34s\n",
      "837:\tlearn: 0.0522515\ttest: 0.0519909\tbest: 0.0519909 (836)\ttotal: 2m 47s\tremaining: 30m 34s\n",
      "838:\tlearn: 0.0522515\ttest: 0.0519909\tbest: 0.0519909 (836)\ttotal: 2m 47s\tremaining: 30m 33s\n",
      "839:\tlearn: 0.0522515\ttest: 0.0519909\tbest: 0.0519909 (836)\ttotal: 2m 48s\tremaining: 30m 33s\n",
      "840:\tlearn: 0.0522515\ttest: 0.0519909\tbest: 0.0519909 (836)\ttotal: 2m 48s\tremaining: 30m 32s\n",
      "841:\tlearn: 0.0522515\ttest: 0.0519909\tbest: 0.0519909 (841)\ttotal: 2m 48s\tremaining: 30m 32s\n",
      "842:\tlearn: 0.0522516\ttest: 0.0519909\tbest: 0.0519909 (842)\ttotal: 2m 48s\tremaining: 30m 31s\n",
      "843:\tlearn: 0.0522517\ttest: 0.0519909\tbest: 0.0519909 (843)\ttotal: 2m 48s\tremaining: 30m 31s\n",
      "844:\tlearn: 0.0522519\ttest: 0.0519908\tbest: 0.0519908 (844)\ttotal: 2m 49s\tremaining: 30m 31s\n",
      "845:\tlearn: 0.0522524\ttest: 0.0519908\tbest: 0.0519908 (845)\ttotal: 2m 49s\tremaining: 30m 30s\n",
      "846:\tlearn: 0.0522519\ttest: 0.0519908\tbest: 0.0519908 (846)\ttotal: 2m 49s\tremaining: 30m 30s\n",
      "847:\tlearn: 0.0522519\ttest: 0.0519908\tbest: 0.0519908 (847)\ttotal: 2m 49s\tremaining: 30m 29s\n",
      "848:\tlearn: 0.0522526\ttest: 0.0519907\tbest: 0.0519907 (848)\ttotal: 2m 49s\tremaining: 30m 29s\n",
      "849:\tlearn: 0.0522529\ttest: 0.0519906\tbest: 0.0519906 (849)\ttotal: 2m 49s\tremaining: 30m 28s\n",
      "850:\tlearn: 0.0522547\ttest: 0.0519906\tbest: 0.0519906 (850)\ttotal: 2m 50s\tremaining: 30m 28s\n",
      "851:\tlearn: 0.0522547\ttest: 0.0519905\tbest: 0.0519905 (851)\ttotal: 2m 50s\tremaining: 30m 27s\n",
      "852:\tlearn: 0.0522538\ttest: 0.0519905\tbest: 0.0519905 (852)\ttotal: 2m 50s\tremaining: 30m 27s\n",
      "853:\tlearn: 0.0522556\ttest: 0.0519905\tbest: 0.0519905 (853)\ttotal: 2m 50s\tremaining: 30m 26s\n",
      "854:\tlearn: 0.0522552\ttest: 0.0519905\tbest: 0.0519905 (854)\ttotal: 2m 50s\tremaining: 30m 26s\n",
      "855:\tlearn: 0.0522543\ttest: 0.0519904\tbest: 0.0519904 (855)\ttotal: 2m 50s\tremaining: 30m 25s\n",
      "856:\tlearn: 0.0522548\ttest: 0.0519904\tbest: 0.0519904 (856)\ttotal: 2m 51s\tremaining: 30m 25s\n",
      "857:\tlearn: 0.0522543\ttest: 0.0519903\tbest: 0.0519903 (857)\ttotal: 2m 51s\tremaining: 30m 24s\n",
      "858:\tlearn: 0.0522543\ttest: 0.0519903\tbest: 0.0519903 (858)\ttotal: 2m 51s\tremaining: 30m 24s\n",
      "859:\tlearn: 0.0522545\ttest: 0.0519903\tbest: 0.0519903 (859)\ttotal: 2m 51s\tremaining: 30m 23s\n",
      "860:\tlearn: 0.0522543\ttest: 0.0519903\tbest: 0.0519903 (860)\ttotal: 2m 51s\tremaining: 30m 23s\n",
      "861:\tlearn: 0.0522545\ttest: 0.0519903\tbest: 0.0519903 (861)\ttotal: 2m 51s\tremaining: 30m 23s\n",
      "862:\tlearn: 0.0522545\ttest: 0.0519903\tbest: 0.0519903 (861)\ttotal: 2m 52s\tremaining: 30m 22s\n",
      "863:\tlearn: 0.0522545\ttest: 0.0519903\tbest: 0.0519903 (861)\ttotal: 2m 52s\tremaining: 30m 22s\n",
      "864:\tlearn: 0.0522545\ttest: 0.0519903\tbest: 0.0519903 (864)\ttotal: 2m 52s\tremaining: 30m 21s\n",
      "865:\tlearn: 0.0522547\ttest: 0.0519902\tbest: 0.0519902 (865)\ttotal: 2m 52s\tremaining: 30m 21s\n",
      "866:\tlearn: 0.0522547\ttest: 0.0519902\tbest: 0.0519902 (866)\ttotal: 2m 52s\tremaining: 30m 20s\n",
      "867:\tlearn: 0.0522547\ttest: 0.0519902\tbest: 0.0519902 (867)\ttotal: 2m 53s\tremaining: 30m 20s\n",
      "868:\tlearn: 0.0522554\ttest: 0.0519902\tbest: 0.0519902 (868)\ttotal: 2m 53s\tremaining: 30m 19s\n",
      "869:\tlearn: 0.0522554\ttest: 0.0519902\tbest: 0.0519902 (869)\ttotal: 2m 53s\tremaining: 30m 19s\n",
      "870:\tlearn: 0.0522555\ttest: 0.0519901\tbest: 0.0519901 (870)\ttotal: 2m 53s\tremaining: 30m 18s\n",
      "871:\tlearn: 0.0522553\ttest: 0.0519901\tbest: 0.0519901 (871)\ttotal: 2m 53s\tremaining: 30m 18s\n",
      "872:\tlearn: 0.0522553\ttest: 0.0519901\tbest: 0.0519901 (872)\ttotal: 2m 53s\tremaining: 30m 17s\n",
      "873:\tlearn: 0.0522552\ttest: 0.0519901\tbest: 0.0519901 (873)\ttotal: 2m 54s\tremaining: 30m 17s\n",
      "874:\tlearn: 0.0522553\ttest: 0.0519901\tbest: 0.0519901 (874)\ttotal: 2m 54s\tremaining: 30m 16s\n",
      "875:\tlearn: 0.0522552\ttest: 0.0519901\tbest: 0.0519901 (875)\ttotal: 2m 54s\tremaining: 30m 16s\n",
      "876:\tlearn: 0.0522553\ttest: 0.0519901\tbest: 0.0519901 (876)\ttotal: 2m 54s\tremaining: 30m 16s\n",
      "877:\tlearn: 0.0522557\ttest: 0.0519901\tbest: 0.0519901 (877)\ttotal: 2m 54s\tremaining: 30m 15s\n",
      "878:\tlearn: 0.0522556\ttest: 0.0519900\tbest: 0.0519900 (878)\ttotal: 2m 54s\tremaining: 30m 15s\n",
      "879:\tlearn: 0.0522539\ttest: 0.0519898\tbest: 0.0519898 (879)\ttotal: 2m 55s\tremaining: 30m 14s\n",
      "880:\tlearn: 0.0522537\ttest: 0.0519898\tbest: 0.0519898 (880)\ttotal: 2m 55s\tremaining: 30m 14s\n",
      "881:\tlearn: 0.0522546\ttest: 0.0519898\tbest: 0.0519898 (881)\ttotal: 2m 55s\tremaining: 30m 13s\n",
      "882:\tlearn: 0.0522543\ttest: 0.0519898\tbest: 0.0519898 (882)\ttotal: 2m 55s\tremaining: 30m 13s\n",
      "883:\tlearn: 0.0522544\ttest: 0.0519897\tbest: 0.0519897 (883)\ttotal: 2m 55s\tremaining: 30m 12s\n",
      "884:\tlearn: 0.0522544\ttest: 0.0519897\tbest: 0.0519897 (884)\ttotal: 2m 55s\tremaining: 30m 12s\n",
      "885:\tlearn: 0.0522544\ttest: 0.0519897\tbest: 0.0519897 (885)\ttotal: 2m 56s\tremaining: 30m 11s\n",
      "886:\tlearn: 0.0522544\ttest: 0.0519897\tbest: 0.0519897 (885)\ttotal: 2m 56s\tremaining: 30m 11s\n",
      "887:\tlearn: 0.0522545\ttest: 0.0519897\tbest: 0.0519897 (887)\ttotal: 2m 56s\tremaining: 30m 10s\n",
      "888:\tlearn: 0.0522545\ttest: 0.0519897\tbest: 0.0519897 (887)\ttotal: 2m 56s\tremaining: 30m 10s\n",
      "889:\tlearn: 0.0522545\ttest: 0.0519897\tbest: 0.0519897 (887)\ttotal: 2m 56s\tremaining: 30m 10s\n",
      "890:\tlearn: 0.0522544\ttest: 0.0519897\tbest: 0.0519897 (890)\ttotal: 2m 57s\tremaining: 30m 9s\n",
      "891:\tlearn: 0.0522545\ttest: 0.0519897\tbest: 0.0519897 (891)\ttotal: 2m 57s\tremaining: 30m 9s\n",
      "892:\tlearn: 0.0522563\ttest: 0.0519895\tbest: 0.0519895 (892)\ttotal: 2m 57s\tremaining: 30m 8s\n",
      "893:\tlearn: 0.0522553\ttest: 0.0519895\tbest: 0.0519895 (893)\ttotal: 2m 57s\tremaining: 30m 8s\n",
      "894:\tlearn: 0.0522562\ttest: 0.0519894\tbest: 0.0519894 (894)\ttotal: 2m 57s\tremaining: 30m 7s\n",
      "895:\tlearn: 0.0522562\ttest: 0.0519894\tbest: 0.0519894 (895)\ttotal: 2m 57s\tremaining: 30m 7s\n",
      "896:\tlearn: 0.0522562\ttest: 0.0519894\tbest: 0.0519894 (896)\ttotal: 2m 58s\tremaining: 30m 7s\n",
      "897:\tlearn: 0.0522562\ttest: 0.0519894\tbest: 0.0519894 (897)\ttotal: 2m 58s\tremaining: 30m 6s\n",
      "898:\tlearn: 0.0522562\ttest: 0.0519894\tbest: 0.0519894 (898)\ttotal: 2m 58s\tremaining: 30m 6s\n",
      "899:\tlearn: 0.0522562\ttest: 0.0519894\tbest: 0.0519894 (899)\ttotal: 2m 58s\tremaining: 30m 5s\n",
      "900:\tlearn: 0.0522563\ttest: 0.0519894\tbest: 0.0519894 (900)\ttotal: 2m 58s\tremaining: 30m 5s\n",
      "901:\tlearn: 0.0522563\ttest: 0.0519894\tbest: 0.0519894 (901)\ttotal: 2m 58s\tremaining: 30m 5s\n",
      "902:\tlearn: 0.0522571\ttest: 0.0519893\tbest: 0.0519893 (902)\ttotal: 2m 59s\tremaining: 30m 4s\n",
      "903:\tlearn: 0.0522571\ttest: 0.0519893\tbest: 0.0519893 (903)\ttotal: 2m 59s\tremaining: 30m 4s\n",
      "904:\tlearn: 0.0522572\ttest: 0.0519893\tbest: 0.0519893 (904)\ttotal: 2m 59s\tremaining: 30m 3s\n",
      "905:\tlearn: 0.0522572\ttest: 0.0519892\tbest: 0.0519892 (905)\ttotal: 2m 59s\tremaining: 30m 3s\n",
      "906:\tlearn: 0.0522571\ttest: 0.0519892\tbest: 0.0519892 (906)\ttotal: 2m 59s\tremaining: 30m 2s\n",
      "907:\tlearn: 0.0522572\ttest: 0.0519887\tbest: 0.0519887 (907)\ttotal: 3m\tremaining: 30m 2s\n",
      "908:\tlearn: 0.0522569\ttest: 0.0519881\tbest: 0.0519881 (908)\ttotal: 3m\tremaining: 30m 2s\n",
      "909:\tlearn: 0.0522569\ttest: 0.0519881\tbest: 0.0519881 (908)\ttotal: 3m\tremaining: 30m 2s\n",
      "910:\tlearn: 0.0522569\ttest: 0.0519881\tbest: 0.0519881 (908)\ttotal: 3m\tremaining: 30m 1s\n",
      "911:\tlearn: 0.0522569\ttest: 0.0519881\tbest: 0.0519881 (911)\ttotal: 3m\tremaining: 30m 1s\n",
      "912:\tlearn: 0.0522569\ttest: 0.0519881\tbest: 0.0519881 (912)\ttotal: 3m\tremaining: 30m\n",
      "913:\tlearn: 0.0522570\ttest: 0.0519880\tbest: 0.0519880 (913)\ttotal: 3m 1s\tremaining: 30m\n",
      "914:\tlearn: 0.0522578\ttest: 0.0519880\tbest: 0.0519880 (914)\ttotal: 3m 1s\tremaining: 29m 59s\n",
      "915:\tlearn: 0.0522585\ttest: 0.0519879\tbest: 0.0519879 (915)\ttotal: 3m 1s\tremaining: 29m 59s\n",
      "916:\tlearn: 0.0522585\ttest: 0.0519879\tbest: 0.0519879 (916)\ttotal: 3m 1s\tremaining: 29m 58s\n",
      "917:\tlearn: 0.0522546\ttest: 0.0519878\tbest: 0.0519878 (917)\ttotal: 3m 1s\tremaining: 29m 58s\n",
      "918:\tlearn: 0.0522563\ttest: 0.0519878\tbest: 0.0519878 (918)\ttotal: 3m 1s\tremaining: 29m 58s\n",
      "919:\tlearn: 0.0522562\ttest: 0.0519878\tbest: 0.0519878 (919)\ttotal: 3m 2s\tremaining: 29m 57s\n",
      "920:\tlearn: 0.0522562\ttest: 0.0519878\tbest: 0.0519878 (920)\ttotal: 3m 2s\tremaining: 29m 57s\n",
      "921:\tlearn: 0.0522562\ttest: 0.0519877\tbest: 0.0519877 (921)\ttotal: 3m 2s\tremaining: 29m 56s\n",
      "922:\tlearn: 0.0522562\ttest: 0.0519877\tbest: 0.0519877 (922)\ttotal: 3m 2s\tremaining: 29m 56s\n",
      "923:\tlearn: 0.0522554\ttest: 0.0519875\tbest: 0.0519875 (923)\ttotal: 3m 2s\tremaining: 29m 56s\n",
      "924:\tlearn: 0.0522562\ttest: 0.0519875\tbest: 0.0519875 (924)\ttotal: 3m 3s\tremaining: 29m 55s\n",
      "925:\tlearn: 0.0522562\ttest: 0.0519875\tbest: 0.0519875 (925)\ttotal: 3m 3s\tremaining: 29m 55s\n",
      "926:\tlearn: 0.0522569\ttest: 0.0519874\tbest: 0.0519874 (926)\ttotal: 3m 3s\tremaining: 29m 54s\n",
      "927:\tlearn: 0.0522571\ttest: 0.0519873\tbest: 0.0519873 (927)\ttotal: 3m 3s\tremaining: 29m 54s\n",
      "928:\tlearn: 0.0522571\ttest: 0.0519871\tbest: 0.0519871 (928)\ttotal: 3m 3s\tremaining: 29m 54s\n",
      "929:\tlearn: 0.0522569\ttest: 0.0519864\tbest: 0.0519864 (929)\ttotal: 3m 3s\tremaining: 29m 54s\n",
      "930:\tlearn: 0.0522569\ttest: 0.0519856\tbest: 0.0519856 (930)\ttotal: 3m 4s\tremaining: 29m 54s\n",
      "931:\tlearn: 0.0522567\ttest: 0.0519850\tbest: 0.0519850 (931)\ttotal: 3m 4s\tremaining: 29m 53s\n",
      "932:\tlearn: 0.0522543\ttest: 0.0519849\tbest: 0.0519849 (932)\ttotal: 3m 4s\tremaining: 29m 53s\n",
      "933:\tlearn: 0.0522549\ttest: 0.0519849\tbest: 0.0519849 (933)\ttotal: 3m 4s\tremaining: 29m 53s\n",
      "934:\tlearn: 0.0522546\ttest: 0.0519845\tbest: 0.0519845 (934)\ttotal: 3m 4s\tremaining: 29m 52s\n",
      "935:\tlearn: 0.0522545\ttest: 0.0519845\tbest: 0.0519845 (935)\ttotal: 3m 5s\tremaining: 29m 52s\n",
      "936:\tlearn: 0.0522543\ttest: 0.0519840\tbest: 0.0519840 (936)\ttotal: 3m 5s\tremaining: 29m 52s\n",
      "937:\tlearn: 0.0522543\ttest: 0.0519839\tbest: 0.0519839 (937)\ttotal: 3m 5s\tremaining: 29m 51s\n",
      "938:\tlearn: 0.0522543\ttest: 0.0519839\tbest: 0.0519839 (937)\ttotal: 3m 5s\tremaining: 29m 51s\n",
      "939:\tlearn: 0.0522543\ttest: 0.0519839\tbest: 0.0519839 (939)\ttotal: 3m 5s\tremaining: 29m 51s\n",
      "940:\tlearn: 0.0522544\ttest: 0.0519839\tbest: 0.0519839 (940)\ttotal: 3m 5s\tremaining: 29m 50s\n",
      "941:\tlearn: 0.0522548\ttest: 0.0519838\tbest: 0.0519838 (941)\ttotal: 3m 6s\tremaining: 29m 50s\n",
      "942:\tlearn: 0.0522546\ttest: 0.0519833\tbest: 0.0519833 (942)\ttotal: 3m 6s\tremaining: 29m 50s\n",
      "943:\tlearn: 0.0522542\ttest: 0.0519827\tbest: 0.0519827 (943)\ttotal: 3m 6s\tremaining: 29m 50s\n",
      "944:\tlearn: 0.0522559\ttest: 0.0519826\tbest: 0.0519826 (944)\ttotal: 3m 6s\tremaining: 29m 49s\n",
      "945:\tlearn: 0.0522557\ttest: 0.0519822\tbest: 0.0519822 (945)\ttotal: 3m 6s\tremaining: 29m 49s\n",
      "946:\tlearn: 0.0522555\ttest: 0.0519818\tbest: 0.0519818 (946)\ttotal: 3m 7s\tremaining: 29m 49s\n",
      "947:\tlearn: 0.0522554\ttest: 0.0519817\tbest: 0.0519817 (947)\ttotal: 3m 7s\tremaining: 29m 49s\n",
      "948:\tlearn: 0.0522548\ttest: 0.0519813\tbest: 0.0519813 (948)\ttotal: 3m 7s\tremaining: 29m 48s\n",
      "949:\tlearn: 0.0522550\ttest: 0.0519812\tbest: 0.0519812 (949)\ttotal: 3m 7s\tremaining: 29m 48s\n",
      "950:\tlearn: 0.0522555\ttest: 0.0519810\tbest: 0.0519810 (950)\ttotal: 3m 7s\tremaining: 29m 48s\n",
      "951:\tlearn: 0.0522555\ttest: 0.0519810\tbest: 0.0519810 (951)\ttotal: 3m 8s\tremaining: 29m 47s\n",
      "952:\tlearn: 0.0522541\ttest: 0.0519805\tbest: 0.0519805 (952)\ttotal: 3m 8s\tremaining: 29m 47s\n",
      "953:\tlearn: 0.0522540\ttest: 0.0519801\tbest: 0.0519801 (953)\ttotal: 3m 8s\tremaining: 29m 47s\n",
      "954:\tlearn: 0.0522539\ttest: 0.0519801\tbest: 0.0519801 (954)\ttotal: 3m 8s\tremaining: 29m 47s\n",
      "955:\tlearn: 0.0522532\ttest: 0.0519795\tbest: 0.0519795 (955)\ttotal: 3m 8s\tremaining: 29m 47s\n",
      "956:\tlearn: 0.0522529\ttest: 0.0519791\tbest: 0.0519791 (956)\ttotal: 3m 9s\tremaining: 29m 47s\n",
      "957:\tlearn: 0.0522524\ttest: 0.0519787\tbest: 0.0519787 (957)\ttotal: 3m 9s\tremaining: 29m 46s\n",
      "958:\tlearn: 0.0522532\ttest: 0.0519787\tbest: 0.0519787 (958)\ttotal: 3m 9s\tremaining: 29m 46s\n",
      "959:\tlearn: 0.0522532\ttest: 0.0519787\tbest: 0.0519787 (959)\ttotal: 3m 9s\tremaining: 29m 45s\n",
      "960:\tlearn: 0.0522531\ttest: 0.0519783\tbest: 0.0519783 (960)\ttotal: 3m 9s\tremaining: 29m 45s\n",
      "961:\tlearn: 0.0522531\ttest: 0.0519783\tbest: 0.0519783 (961)\ttotal: 3m 10s\tremaining: 29m 45s\n",
      "962:\tlearn: 0.0522539\ttest: 0.0519782\tbest: 0.0519782 (962)\ttotal: 3m 10s\tremaining: 29m 45s\n",
      "963:\tlearn: 0.0522535\ttest: 0.0519777\tbest: 0.0519777 (963)\ttotal: 3m 10s\tremaining: 29m 44s\n",
      "964:\tlearn: 0.0522535\ttest: 0.0519772\tbest: 0.0519772 (964)\ttotal: 3m 10s\tremaining: 29m 44s\n",
      "965:\tlearn: 0.0522537\ttest: 0.0519766\tbest: 0.0519766 (965)\ttotal: 3m 10s\tremaining: 29m 44s\n",
      "966:\tlearn: 0.0522535\ttest: 0.0519762\tbest: 0.0519762 (966)\ttotal: 3m 11s\tremaining: 29m 44s\n",
      "967:\tlearn: 0.0522532\ttest: 0.0519759\tbest: 0.0519759 (967)\ttotal: 3m 11s\tremaining: 29m 43s\n",
      "968:\tlearn: 0.0522525\ttest: 0.0519753\tbest: 0.0519753 (968)\ttotal: 3m 11s\tremaining: 29m 43s\n",
      "969:\tlearn: 0.0522519\ttest: 0.0519750\tbest: 0.0519750 (969)\ttotal: 3m 11s\tremaining: 29m 43s\n",
      "970:\tlearn: 0.0522518\ttest: 0.0519747\tbest: 0.0519747 (970)\ttotal: 3m 11s\tremaining: 29m 43s\n",
      "971:\tlearn: 0.0522518\ttest: 0.0519744\tbest: 0.0519744 (971)\ttotal: 3m 11s\tremaining: 29m 42s\n",
      "972:\tlearn: 0.0522517\ttest: 0.0519741\tbest: 0.0519741 (972)\ttotal: 3m 12s\tremaining: 29m 42s\n",
      "973:\tlearn: 0.0522508\ttest: 0.0519738\tbest: 0.0519738 (973)\ttotal: 3m 12s\tremaining: 29m 42s\n",
      "974:\tlearn: 0.0522503\ttest: 0.0519733\tbest: 0.0519733 (974)\ttotal: 3m 12s\tremaining: 29m 42s\n",
      "975:\tlearn: 0.0522499\ttest: 0.0519729\tbest: 0.0519729 (975)\ttotal: 3m 12s\tremaining: 29m 41s\n",
      "976:\tlearn: 0.0522499\ttest: 0.0519729\tbest: 0.0519729 (976)\ttotal: 3m 12s\tremaining: 29m 41s\n",
      "977:\tlearn: 0.0522498\ttest: 0.0519726\tbest: 0.0519726 (977)\ttotal: 3m 13s\tremaining: 29m 41s\n",
      "978:\tlearn: 0.0522495\ttest: 0.0519723\tbest: 0.0519723 (978)\ttotal: 3m 13s\tremaining: 29m 40s\n",
      "979:\tlearn: 0.0522495\ttest: 0.0519718\tbest: 0.0519718 (979)\ttotal: 3m 13s\tremaining: 29m 40s\n",
      "980:\tlearn: 0.0522501\ttest: 0.0519718\tbest: 0.0519718 (980)\ttotal: 3m 13s\tremaining: 29m 40s\n",
      "981:\tlearn: 0.0522499\ttest: 0.0519717\tbest: 0.0519717 (981)\ttotal: 3m 13s\tremaining: 29m 39s\n",
      "982:\tlearn: 0.0522499\ttest: 0.0519717\tbest: 0.0519717 (982)\ttotal: 3m 13s\tremaining: 29m 39s\n",
      "983:\tlearn: 0.0522499\ttest: 0.0519715\tbest: 0.0519715 (983)\ttotal: 3m 14s\tremaining: 29m 39s\n",
      "984:\tlearn: 0.0522496\ttest: 0.0519713\tbest: 0.0519713 (984)\ttotal: 3m 14s\tremaining: 29m 39s\n",
      "985:\tlearn: 0.0522497\ttest: 0.0519712\tbest: 0.0519712 (985)\ttotal: 3m 14s\tremaining: 29m 39s\n",
      "986:\tlearn: 0.0522490\ttest: 0.0519709\tbest: 0.0519709 (986)\ttotal: 3m 14s\tremaining: 29m 39s\n",
      "987:\tlearn: 0.0522495\ttest: 0.0519709\tbest: 0.0519709 (987)\ttotal: 3m 15s\tremaining: 29m 38s\n",
      "988:\tlearn: 0.0522488\ttest: 0.0519706\tbest: 0.0519706 (988)\ttotal: 3m 15s\tremaining: 29m 38s\n",
      "989:\tlearn: 0.0522482\ttest: 0.0519700\tbest: 0.0519700 (989)\ttotal: 3m 15s\tremaining: 29m 38s\n",
      "990:\tlearn: 0.0522476\ttest: 0.0519696\tbest: 0.0519696 (990)\ttotal: 3m 15s\tremaining: 29m 38s\n",
      "991:\tlearn: 0.0522472\ttest: 0.0519693\tbest: 0.0519693 (991)\ttotal: 3m 15s\tremaining: 29m 37s\n",
      "992:\tlearn: 0.0522473\ttest: 0.0519693\tbest: 0.0519693 (992)\ttotal: 3m 15s\tremaining: 29m 37s\n",
      "993:\tlearn: 0.0522473\ttest: 0.0519693\tbest: 0.0519693 (992)\ttotal: 3m 16s\tremaining: 29m 36s\n",
      "994:\tlearn: 0.0522470\ttest: 0.0519689\tbest: 0.0519689 (994)\ttotal: 3m 16s\tremaining: 29m 36s\n",
      "995:\tlearn: 0.0522466\ttest: 0.0519686\tbest: 0.0519686 (995)\ttotal: 3m 16s\tremaining: 29m 36s\n",
      "996:\tlearn: 0.0522460\ttest: 0.0519680\tbest: 0.0519680 (996)\ttotal: 3m 16s\tremaining: 29m 36s\n",
      "997:\tlearn: 0.0522459\ttest: 0.0519680\tbest: 0.0519680 (997)\ttotal: 3m 16s\tremaining: 29m 36s\n",
      "998:\tlearn: 0.0522459\ttest: 0.0519680\tbest: 0.0519680 (998)\ttotal: 3m 17s\tremaining: 29m 35s\n",
      "999:\tlearn: 0.0522458\ttest: 0.0519677\tbest: 0.0519677 (999)\ttotal: 3m 17s\tremaining: 29m 35s\n",
      "1000:\tlearn: 0.0522452\ttest: 0.0519670\tbest: 0.0519670 (1000)\ttotal: 3m 17s\tremaining: 29m 34s\n",
      "1001:\tlearn: 0.0522454\ttest: 0.0519670\tbest: 0.0519670 (1001)\ttotal: 3m 17s\tremaining: 29m 34s\n",
      "1002:\tlearn: 0.0522452\ttest: 0.0519668\tbest: 0.0519668 (1002)\ttotal: 3m 17s\tremaining: 29m 34s\n",
      "1003:\tlearn: 0.0522453\ttest: 0.0519668\tbest: 0.0519668 (1003)\ttotal: 3m 18s\tremaining: 29m 34s\n",
      "1004:\tlearn: 0.0522453\ttest: 0.0519667\tbest: 0.0519667 (1004)\ttotal: 3m 18s\tremaining: 29m 33s\n",
      "1005:\tlearn: 0.0522454\ttest: 0.0519665\tbest: 0.0519665 (1005)\ttotal: 3m 18s\tremaining: 29m 33s\n",
      "1006:\tlearn: 0.0522459\ttest: 0.0519663\tbest: 0.0519663 (1006)\ttotal: 3m 18s\tremaining: 29m 33s\n",
      "1007:\tlearn: 0.0522451\ttest: 0.0519663\tbest: 0.0519663 (1007)\ttotal: 3m 18s\tremaining: 29m 33s\n",
      "1008:\tlearn: 0.0522448\ttest: 0.0519660\tbest: 0.0519660 (1008)\ttotal: 3m 18s\tremaining: 29m 32s\n",
      "1009:\tlearn: 0.0522445\ttest: 0.0519657\tbest: 0.0519657 (1009)\ttotal: 3m 19s\tremaining: 29m 32s\n",
      "1010:\tlearn: 0.0522445\ttest: 0.0519656\tbest: 0.0519656 (1010)\ttotal: 3m 19s\tremaining: 29m 31s\n",
      "1011:\tlearn: 0.0522441\ttest: 0.0519652\tbest: 0.0519652 (1011)\ttotal: 3m 19s\tremaining: 29m 31s\n",
      "1012:\tlearn: 0.0522441\ttest: 0.0519651\tbest: 0.0519651 (1012)\ttotal: 3m 19s\tremaining: 29m 31s\n",
      "1013:\tlearn: 0.0522437\ttest: 0.0519648\tbest: 0.0519648 (1013)\ttotal: 3m 19s\tremaining: 29m 31s\n",
      "1014:\tlearn: 0.0522436\ttest: 0.0519648\tbest: 0.0519648 (1014)\ttotal: 3m 20s\tremaining: 29m 30s\n",
      "1015:\tlearn: 0.0522435\ttest: 0.0519648\tbest: 0.0519648 (1015)\ttotal: 3m 20s\tremaining: 29m 30s\n",
      "1016:\tlearn: 0.0522436\ttest: 0.0519648\tbest: 0.0519648 (1016)\ttotal: 3m 20s\tremaining: 29m 29s\n",
      "1017:\tlearn: 0.0522437\ttest: 0.0519648\tbest: 0.0519648 (1017)\ttotal: 3m 20s\tremaining: 29m 29s\n",
      "1018:\tlearn: 0.0522449\ttest: 0.0519648\tbest: 0.0519648 (1018)\ttotal: 3m 20s\tremaining: 29m 29s\n",
      "1019:\tlearn: 0.0522446\ttest: 0.0519645\tbest: 0.0519645 (1019)\ttotal: 3m 20s\tremaining: 29m 28s\n",
      "1020:\tlearn: 0.0522446\ttest: 0.0519644\tbest: 0.0519644 (1020)\ttotal: 3m 21s\tremaining: 29m 28s\n",
      "1021:\tlearn: 0.0522443\ttest: 0.0519640\tbest: 0.0519640 (1021)\ttotal: 3m 21s\tremaining: 29m 28s\n",
      "1022:\tlearn: 0.0522429\ttest: 0.0519636\tbest: 0.0519636 (1022)\ttotal: 3m 21s\tremaining: 29m 28s\n",
      "1023:\tlearn: 0.0522440\ttest: 0.0519636\tbest: 0.0519636 (1023)\ttotal: 3m 21s\tremaining: 29m 27s\n",
      "1024:\tlearn: 0.0522430\ttest: 0.0519636\tbest: 0.0519636 (1024)\ttotal: 3m 21s\tremaining: 29m 27s\n",
      "1025:\tlearn: 0.0522439\ttest: 0.0519636\tbest: 0.0519636 (1025)\ttotal: 3m 21s\tremaining: 29m 26s\n",
      "1026:\tlearn: 0.0522430\ttest: 0.0519636\tbest: 0.0519636 (1026)\ttotal: 3m 22s\tremaining: 29m 26s\n",
      "1027:\tlearn: 0.0522427\ttest: 0.0519633\tbest: 0.0519633 (1027)\ttotal: 3m 22s\tremaining: 29m 26s\n",
      "1028:\tlearn: 0.0522429\ttest: 0.0519633\tbest: 0.0519633 (1028)\ttotal: 3m 22s\tremaining: 29m 25s\n",
      "1029:\tlearn: 0.0522424\ttest: 0.0519630\tbest: 0.0519630 (1029)\ttotal: 3m 22s\tremaining: 29m 25s\n",
      "1030:\tlearn: 0.0522423\ttest: 0.0519630\tbest: 0.0519630 (1030)\ttotal: 3m 22s\tremaining: 29m 24s\n",
      "1031:\tlearn: 0.0522423\ttest: 0.0519630\tbest: 0.0519630 (1031)\ttotal: 3m 23s\tremaining: 29m 24s\n",
      "1032:\tlearn: 0.0522441\ttest: 0.0519628\tbest: 0.0519628 (1032)\ttotal: 3m 23s\tremaining: 29m 24s\n",
      "1033:\tlearn: 0.0522437\ttest: 0.0519623\tbest: 0.0519623 (1033)\ttotal: 3m 23s\tremaining: 29m 24s\n",
      "1034:\tlearn: 0.0522432\ttest: 0.0519620\tbest: 0.0519620 (1034)\ttotal: 3m 23s\tremaining: 29m 23s\n",
      "1035:\tlearn: 0.0522431\ttest: 0.0519618\tbest: 0.0519618 (1035)\ttotal: 3m 23s\tremaining: 29m 23s\n",
      "1036:\tlearn: 0.0522432\ttest: 0.0519618\tbest: 0.0519618 (1036)\ttotal: 3m 24s\tremaining: 29m 23s\n",
      "1037:\tlearn: 0.0522423\ttest: 0.0519612\tbest: 0.0519612 (1037)\ttotal: 3m 24s\tremaining: 29m 23s\n",
      "1038:\tlearn: 0.0522424\ttest: 0.0519611\tbest: 0.0519611 (1038)\ttotal: 3m 24s\tremaining: 29m 22s\n",
      "1039:\tlearn: 0.0522423\ttest: 0.0519608\tbest: 0.0519608 (1039)\ttotal: 3m 24s\tremaining: 29m 22s\n",
      "1040:\tlearn: 0.0522421\ttest: 0.0519605\tbest: 0.0519605 (1040)\ttotal: 3m 24s\tremaining: 29m 21s\n",
      "1041:\tlearn: 0.0522420\ttest: 0.0519605\tbest: 0.0519605 (1041)\ttotal: 3m 24s\tremaining: 29m 21s\n",
      "1042:\tlearn: 0.0522421\ttest: 0.0519605\tbest: 0.0519605 (1042)\ttotal: 3m 25s\tremaining: 29m 21s\n",
      "1043:\tlearn: 0.0522420\ttest: 0.0519605\tbest: 0.0519605 (1043)\ttotal: 3m 25s\tremaining: 29m 20s\n",
      "1044:\tlearn: 0.0522420\ttest: 0.0519604\tbest: 0.0519604 (1044)\ttotal: 3m 25s\tremaining: 29m 20s\n",
      "1045:\tlearn: 0.0522419\ttest: 0.0519604\tbest: 0.0519604 (1045)\ttotal: 3m 25s\tremaining: 29m 19s\n",
      "1046:\tlearn: 0.0522422\ttest: 0.0519601\tbest: 0.0519601 (1046)\ttotal: 3m 25s\tremaining: 29m 19s\n",
      "1047:\tlearn: 0.0522422\ttest: 0.0519601\tbest: 0.0519601 (1047)\ttotal: 3m 25s\tremaining: 29m 19s\n",
      "1048:\tlearn: 0.0522422\ttest: 0.0519601\tbest: 0.0519601 (1048)\ttotal: 3m 26s\tremaining: 29m 18s\n",
      "1049:\tlearn: 0.0522420\ttest: 0.0519598\tbest: 0.0519598 (1049)\ttotal: 3m 26s\tremaining: 29m 18s\n",
      "1050:\tlearn: 0.0522416\ttest: 0.0519595\tbest: 0.0519595 (1050)\ttotal: 3m 26s\tremaining: 29m 18s\n",
      "1051:\tlearn: 0.0522416\ttest: 0.0519595\tbest: 0.0519595 (1051)\ttotal: 3m 26s\tremaining: 29m 17s\n",
      "1052:\tlearn: 0.0522416\ttest: 0.0519593\tbest: 0.0519593 (1052)\ttotal: 3m 26s\tremaining: 29m 17s\n",
      "1053:\tlearn: 0.0522413\ttest: 0.0519591\tbest: 0.0519591 (1053)\ttotal: 3m 27s\tremaining: 29m 17s\n",
      "1054:\tlearn: 0.0522413\ttest: 0.0519588\tbest: 0.0519588 (1054)\ttotal: 3m 27s\tremaining: 29m 17s\n",
      "1055:\tlearn: 0.0522413\ttest: 0.0519588\tbest: 0.0519588 (1055)\ttotal: 3m 27s\tremaining: 29m 16s\n",
      "1056:\tlearn: 0.0522412\ttest: 0.0519588\tbest: 0.0519588 (1056)\ttotal: 3m 27s\tremaining: 29m 16s\n",
      "1057:\tlearn: 0.0522413\ttest: 0.0519587\tbest: 0.0519587 (1057)\ttotal: 3m 27s\tremaining: 29m 16s\n",
      "1058:\tlearn: 0.0522405\ttest: 0.0519587\tbest: 0.0519587 (1058)\ttotal: 3m 27s\tremaining: 29m 15s\n",
      "1059:\tlearn: 0.0522405\ttest: 0.0519586\tbest: 0.0519586 (1059)\ttotal: 3m 28s\tremaining: 29m 15s\n",
      "1060:\tlearn: 0.0522412\ttest: 0.0519582\tbest: 0.0519582 (1060)\ttotal: 3m 28s\tremaining: 29m 14s\n",
      "1061:\tlearn: 0.0522404\ttest: 0.0519581\tbest: 0.0519581 (1061)\ttotal: 3m 28s\tremaining: 29m 14s\n",
      "1062:\tlearn: 0.0522401\ttest: 0.0519579\tbest: 0.0519579 (1062)\ttotal: 3m 28s\tremaining: 29m 14s\n",
      "1063:\tlearn: 0.0522397\ttest: 0.0519577\tbest: 0.0519577 (1063)\ttotal: 3m 28s\tremaining: 29m 13s\n",
      "1064:\tlearn: 0.0522045\ttest: 0.0519543\tbest: 0.0519543 (1064)\ttotal: 3m 28s\tremaining: 29m 13s\n",
      "1065:\tlearn: 0.0522045\ttest: 0.0519542\tbest: 0.0519542 (1065)\ttotal: 3m 29s\tremaining: 29m 12s\n",
      "1066:\tlearn: 0.0522019\ttest: 0.0519542\tbest: 0.0519542 (1066)\ttotal: 3m 29s\tremaining: 29m 12s\n",
      "1067:\tlearn: 0.0522016\ttest: 0.0519536\tbest: 0.0519536 (1067)\ttotal: 3m 29s\tremaining: 29m 12s\n",
      "1068:\tlearn: 0.0522043\ttest: 0.0519535\tbest: 0.0519535 (1068)\ttotal: 3m 29s\tremaining: 29m 12s\n",
      "1069:\tlearn: 0.0522041\ttest: 0.0519532\tbest: 0.0519532 (1069)\ttotal: 3m 29s\tremaining: 29m 11s\n",
      "1070:\tlearn: 0.0522041\ttest: 0.0519532\tbest: 0.0519532 (1070)\ttotal: 3m 30s\tremaining: 29m 11s\n",
      "1071:\tlearn: 0.0522041\ttest: 0.0519532\tbest: 0.0519532 (1071)\ttotal: 3m 30s\tremaining: 29m 10s\n",
      "1072:\tlearn: 0.0522041\ttest: 0.0519532\tbest: 0.0519532 (1072)\ttotal: 3m 30s\tremaining: 29m 10s\n",
      "1073:\tlearn: 0.0522012\ttest: 0.0519532\tbest: 0.0519532 (1073)\ttotal: 3m 30s\tremaining: 29m 10s\n",
      "1074:\tlearn: 0.0522009\ttest: 0.0519530\tbest: 0.0519530 (1074)\ttotal: 3m 30s\tremaining: 29m 9s\n",
      "1075:\tlearn: 0.0522009\ttest: 0.0519530\tbest: 0.0519530 (1075)\ttotal: 3m 30s\tremaining: 29m 9s\n",
      "1076:\tlearn: 0.0522009\ttest: 0.0519530\tbest: 0.0519530 (1076)\ttotal: 3m 31s\tremaining: 29m 9s\n",
      "1077:\tlearn: 0.0522009\ttest: 0.0519530\tbest: 0.0519530 (1076)\ttotal: 3m 31s\tremaining: 29m 8s\n",
      "1078:\tlearn: 0.0522009\ttest: 0.0519530\tbest: 0.0519530 (1078)\ttotal: 3m 31s\tremaining: 29m 8s\n",
      "1079:\tlearn: 0.0522010\ttest: 0.0519530\tbest: 0.0519530 (1079)\ttotal: 3m 31s\tremaining: 29m 8s\n",
      "1080:\tlearn: 0.0522010\ttest: 0.0519530\tbest: 0.0519530 (1080)\ttotal: 3m 31s\tremaining: 29m 7s\n",
      "1081:\tlearn: 0.0522010\ttest: 0.0519530\tbest: 0.0519530 (1081)\ttotal: 3m 32s\tremaining: 29m 7s\n",
      "1082:\tlearn: 0.0522010\ttest: 0.0519528\tbest: 0.0519528 (1082)\ttotal: 3m 32s\tremaining: 29m 7s\n",
      "1083:\tlearn: 0.0522006\ttest: 0.0519523\tbest: 0.0519523 (1083)\ttotal: 3m 32s\tremaining: 29m 7s\n",
      "1084:\tlearn: 0.0522012\ttest: 0.0519522\tbest: 0.0519522 (1084)\ttotal: 3m 32s\tremaining: 29m 7s\n",
      "1085:\tlearn: 0.0521990\ttest: 0.0519519\tbest: 0.0519519 (1085)\ttotal: 3m 32s\tremaining: 29m 7s\n",
      "1086:\tlearn: 0.0521989\ttest: 0.0519517\tbest: 0.0519517 (1086)\ttotal: 3m 33s\tremaining: 29m 6s\n",
      "1087:\tlearn: 0.0521984\ttest: 0.0519515\tbest: 0.0519515 (1087)\ttotal: 3m 33s\tremaining: 29m 6s\n",
      "1088:\tlearn: 0.0521981\ttest: 0.0519513\tbest: 0.0519513 (1088)\ttotal: 3m 33s\tremaining: 29m 6s\n",
      "1089:\tlearn: 0.0521981\ttest: 0.0519513\tbest: 0.0519513 (1088)\ttotal: 3m 33s\tremaining: 29m 5s\n",
      "1090:\tlearn: 0.0521981\ttest: 0.0519513\tbest: 0.0519513 (1088)\ttotal: 3m 33s\tremaining: 29m 5s\n",
      "1091:\tlearn: 0.0521981\ttest: 0.0519513\tbest: 0.0519513 (1088)\ttotal: 3m 33s\tremaining: 29m 4s\n",
      "1092:\tlearn: 0.0521981\ttest: 0.0519513\tbest: 0.0519513 (1088)\ttotal: 3m 34s\tremaining: 29m 4s\n",
      "1093:\tlearn: 0.0521981\ttest: 0.0519513\tbest: 0.0519513 (1088)\ttotal: 3m 34s\tremaining: 29m 4s\n",
      "1094:\tlearn: 0.0521981\ttest: 0.0519513\tbest: 0.0519513 (1088)\ttotal: 3m 34s\tremaining: 29m 3s\n",
      "1095:\tlearn: 0.0521981\ttest: 0.0519513\tbest: 0.0519513 (1088)\ttotal: 3m 34s\tremaining: 29m 2s\n",
      "1096:\tlearn: 0.0521981\ttest: 0.0519513\tbest: 0.0519513 (1088)\ttotal: 3m 34s\tremaining: 29m 2s\n",
      "1097:\tlearn: 0.0521981\ttest: 0.0519513\tbest: 0.0519513 (1088)\ttotal: 3m 34s\tremaining: 29m 1s\n",
      "1098:\tlearn: 0.0521981\ttest: 0.0519513\tbest: 0.0519513 (1088)\ttotal: 3m 35s\tremaining: 29m 1s\n",
      "1099:\tlearn: 0.0521981\ttest: 0.0519513\tbest: 0.0519513 (1088)\ttotal: 3m 35s\tremaining: 29m 1s\n",
      "1100:\tlearn: 0.0521981\ttest: 0.0519513\tbest: 0.0519513 (1088)\ttotal: 3m 35s\tremaining: 29m\n",
      "1101:\tlearn: 0.0521981\ttest: 0.0519513\tbest: 0.0519513 (1088)\ttotal: 3m 35s\tremaining: 29m\n",
      "1102:\tlearn: 0.0521981\ttest: 0.0519513\tbest: 0.0519513 (1088)\ttotal: 3m 35s\tremaining: 28m 59s\n",
      "1103:\tlearn: 0.0521981\ttest: 0.0519513\tbest: 0.0519513 (1088)\ttotal: 3m 35s\tremaining: 28m 59s\n",
      "1104:\tlearn: 0.0521981\ttest: 0.0519513\tbest: 0.0519513 (1088)\ttotal: 3m 36s\tremaining: 28m 58s\n",
      "1105:\tlearn: 0.0521981\ttest: 0.0519513\tbest: 0.0519513 (1088)\ttotal: 3m 36s\tremaining: 28m 58s\n",
      "1106:\tlearn: 0.0521981\ttest: 0.0519513\tbest: 0.0519513 (1088)\ttotal: 3m 36s\tremaining: 28m 57s\n",
      "1107:\tlearn: 0.0521981\ttest: 0.0519513\tbest: 0.0519513 (1088)\ttotal: 3m 36s\tremaining: 28m 57s\n",
      "1108:\tlearn: 0.0521981\ttest: 0.0519513\tbest: 0.0519513 (1088)\ttotal: 3m 36s\tremaining: 28m 56s\n",
      "1109:\tlearn: 0.0521981\ttest: 0.0519513\tbest: 0.0519513 (1088)\ttotal: 3m 36s\tremaining: 28m 56s\n",
      "1110:\tlearn: 0.0521981\ttest: 0.0519513\tbest: 0.0519513 (1088)\ttotal: 3m 36s\tremaining: 28m 55s\n",
      "1111:\tlearn: 0.0521981\ttest: 0.0519513\tbest: 0.0519513 (1088)\ttotal: 3m 37s\tremaining: 28m 55s\n",
      "1112:\tlearn: 0.0521981\ttest: 0.0519513\tbest: 0.0519513 (1088)\ttotal: 3m 37s\tremaining: 28m 55s\n",
      "1113:\tlearn: 0.0521981\ttest: 0.0519513\tbest: 0.0519513 (1088)\ttotal: 3m 37s\tremaining: 28m 54s\n",
      "1114:\tlearn: 0.0521981\ttest: 0.0519513\tbest: 0.0519513 (1088)\ttotal: 3m 37s\tremaining: 28m 54s\n",
      "1115:\tlearn: 0.0521981\ttest: 0.0519513\tbest: 0.0519513 (1088)\ttotal: 3m 37s\tremaining: 28m 53s\n",
      "1116:\tlearn: 0.0521981\ttest: 0.0519513\tbest: 0.0519513 (1088)\ttotal: 3m 37s\tremaining: 28m 53s\n",
      "1117:\tlearn: 0.0521981\ttest: 0.0519513\tbest: 0.0519513 (1088)\ttotal: 3m 38s\tremaining: 28m 53s\n",
      "1118:\tlearn: 0.0521981\ttest: 0.0519513\tbest: 0.0519513 (1088)\ttotal: 3m 38s\tremaining: 28m 52s\n",
      "1119:\tlearn: 0.0521981\ttest: 0.0519513\tbest: 0.0519513 (1088)\ttotal: 3m 38s\tremaining: 28m 52s\n",
      "1120:\tlearn: 0.0521981\ttest: 0.0519513\tbest: 0.0519513 (1088)\ttotal: 3m 38s\tremaining: 28m 51s\n",
      "1121:\tlearn: 0.0521981\ttest: 0.0519513\tbest: 0.0519513 (1088)\ttotal: 3m 38s\tremaining: 28m 51s\n",
      "1122:\tlearn: 0.0521981\ttest: 0.0519513\tbest: 0.0519513 (1088)\ttotal: 3m 38s\tremaining: 28m 51s\n",
      "1123:\tlearn: 0.0521981\ttest: 0.0519513\tbest: 0.0519513 (1088)\ttotal: 3m 39s\tremaining: 28m 50s\n",
      "1124:\tlearn: 0.0521981\ttest: 0.0519513\tbest: 0.0519513 (1088)\ttotal: 3m 39s\tremaining: 28m 50s\n",
      "1125:\tlearn: 0.0521981\ttest: 0.0519513\tbest: 0.0519513 (1088)\ttotal: 3m 39s\tremaining: 28m 49s\n",
      "1126:\tlearn: 0.0521981\ttest: 0.0519513\tbest: 0.0519513 (1088)\ttotal: 3m 39s\tremaining: 28m 49s\n",
      "1127:\tlearn: 0.0521981\ttest: 0.0519513\tbest: 0.0519513 (1088)\ttotal: 3m 39s\tremaining: 28m 49s\n",
      "1128:\tlearn: 0.0521981\ttest: 0.0519513\tbest: 0.0519513 (1088)\ttotal: 3m 40s\tremaining: 28m 48s\n",
      "1129:\tlearn: 0.0521981\ttest: 0.0519513\tbest: 0.0519513 (1088)\ttotal: 3m 40s\tremaining: 28m 48s\n",
      "1130:\tlearn: 0.0521981\ttest: 0.0519513\tbest: 0.0519513 (1088)\ttotal: 3m 40s\tremaining: 28m 47s\n",
      "1131:\tlearn: 0.0521981\ttest: 0.0519513\tbest: 0.0519513 (1088)\ttotal: 3m 40s\tremaining: 28m 47s\n",
      "1132:\tlearn: 0.0521981\ttest: 0.0519513\tbest: 0.0519513 (1088)\ttotal: 3m 40s\tremaining: 28m 47s\n",
      "1133:\tlearn: 0.0521981\ttest: 0.0519513\tbest: 0.0519513 (1088)\ttotal: 3m 40s\tremaining: 28m 46s\n",
      "1134:\tlearn: 0.0521981\ttest: 0.0519513\tbest: 0.0519513 (1088)\ttotal: 3m 41s\tremaining: 28m 46s\n",
      "1135:\tlearn: 0.0521981\ttest: 0.0519513\tbest: 0.0519513 (1088)\ttotal: 3m 41s\tremaining: 28m 45s\n",
      "1136:\tlearn: 0.0521981\ttest: 0.0519513\tbest: 0.0519513 (1088)\ttotal: 3m 41s\tremaining: 28m 45s\n",
      "1137:\tlearn: 0.0521981\ttest: 0.0519513\tbest: 0.0519513 (1088)\ttotal: 3m 41s\tremaining: 28m 44s\n",
      "1138:\tlearn: 0.0521981\ttest: 0.0519513\tbest: 0.0519513 (1088)\ttotal: 3m 41s\tremaining: 28m 44s\n",
      "1139:\tlearn: 0.0521981\ttest: 0.0519513\tbest: 0.0519513 (1088)\ttotal: 3m 41s\tremaining: 28m 44s\n",
      "1140:\tlearn: 0.0521981\ttest: 0.0519513\tbest: 0.0519513 (1088)\ttotal: 3m 42s\tremaining: 28m 43s\n",
      "1141:\tlearn: 0.0521981\ttest: 0.0519513\tbest: 0.0519513 (1088)\ttotal: 3m 42s\tremaining: 28m 43s\n",
      "1142:\tlearn: 0.0521981\ttest: 0.0519513\tbest: 0.0519513 (1088)\ttotal: 3m 42s\tremaining: 28m 43s\n",
      "1143:\tlearn: 0.0521981\ttest: 0.0519513\tbest: 0.0519513 (1088)\ttotal: 3m 42s\tremaining: 28m 42s\n",
      "1144:\tlearn: 0.0521981\ttest: 0.0519513\tbest: 0.0519513 (1088)\ttotal: 3m 42s\tremaining: 28m 42s\n",
      "1145:\tlearn: 0.0521981\ttest: 0.0519513\tbest: 0.0519513 (1088)\ttotal: 3m 42s\tremaining: 28m 41s\n",
      "1146:\tlearn: 0.0521981\ttest: 0.0519513\tbest: 0.0519513 (1088)\ttotal: 3m 43s\tremaining: 28m 41s\n",
      "1147:\tlearn: 0.0521981\ttest: 0.0519513\tbest: 0.0519513 (1088)\ttotal: 3m 43s\tremaining: 28m 41s\n",
      "1148:\tlearn: 0.0521981\ttest: 0.0519513\tbest: 0.0519513 (1088)\ttotal: 3m 43s\tremaining: 28m 40s\n",
      "1149:\tlearn: 0.0521981\ttest: 0.0519513\tbest: 0.0519513 (1088)\ttotal: 3m 43s\tremaining: 28m 40s\n",
      "1150:\tlearn: 0.0521981\ttest: 0.0519513\tbest: 0.0519513 (1088)\ttotal: 3m 43s\tremaining: 28m 39s\n",
      "1151:\tlearn: 0.0521981\ttest: 0.0519513\tbest: 0.0519513 (1088)\ttotal: 3m 43s\tremaining: 28m 39s\n",
      "1152:\tlearn: 0.0521981\ttest: 0.0519513\tbest: 0.0519513 (1088)\ttotal: 3m 44s\tremaining: 28m 38s\n",
      "1153:\tlearn: 0.0521981\ttest: 0.0519513\tbest: 0.0519513 (1088)\ttotal: 3m 44s\tremaining: 28m 38s\n",
      "1154:\tlearn: 0.0521981\ttest: 0.0519513\tbest: 0.0519513 (1088)\ttotal: 3m 44s\tremaining: 28m 38s\n",
      "1155:\tlearn: 0.0521981\ttest: 0.0519513\tbest: 0.0519513 (1088)\ttotal: 3m 44s\tremaining: 28m 37s\n",
      "1156:\tlearn: 0.0521981\ttest: 0.0519513\tbest: 0.0519513 (1088)\ttotal: 3m 44s\tremaining: 28m 37s\n",
      "1157:\tlearn: 0.0521981\ttest: 0.0519513\tbest: 0.0519513 (1088)\ttotal: 3m 44s\tremaining: 28m 36s\n",
      "1158:\tlearn: 0.0521981\ttest: 0.0519513\tbest: 0.0519513 (1088)\ttotal: 3m 45s\tremaining: 28m 36s\n",
      "1159:\tlearn: 0.0521981\ttest: 0.0519513\tbest: 0.0519513 (1088)\ttotal: 3m 45s\tremaining: 28m 36s\n",
      "1160:\tlearn: 0.0521981\ttest: 0.0519513\tbest: 0.0519513 (1088)\ttotal: 3m 45s\tremaining: 28m 35s\n",
      "1161:\tlearn: 0.0521981\ttest: 0.0519513\tbest: 0.0519513 (1088)\ttotal: 3m 45s\tremaining: 28m 35s\n",
      "1162:\tlearn: 0.0521981\ttest: 0.0519513\tbest: 0.0519513 (1088)\ttotal: 3m 45s\tremaining: 28m 34s\n",
      "1163:\tlearn: 0.0521981\ttest: 0.0519513\tbest: 0.0519513 (1088)\ttotal: 3m 45s\tremaining: 28m 34s\n",
      "1164:\tlearn: 0.0521981\ttest: 0.0519513\tbest: 0.0519513 (1088)\ttotal: 3m 46s\tremaining: 28m 34s\n",
      "1165:\tlearn: 0.0521981\ttest: 0.0519513\tbest: 0.0519513 (1088)\ttotal: 3m 46s\tremaining: 28m 33s\n",
      "1166:\tlearn: 0.0521981\ttest: 0.0519513\tbest: 0.0519513 (1088)\ttotal: 3m 46s\tremaining: 28m 33s\n",
      "1167:\tlearn: 0.0521981\ttest: 0.0519513\tbest: 0.0519513 (1088)\ttotal: 3m 46s\tremaining: 28m 33s\n",
      "1168:\tlearn: 0.0521981\ttest: 0.0519513\tbest: 0.0519513 (1088)\ttotal: 3m 46s\tremaining: 28m 32s\n",
      "1169:\tlearn: 0.0521981\ttest: 0.0519513\tbest: 0.0519513 (1088)\ttotal: 3m 46s\tremaining: 28m 32s\n",
      "1170:\tlearn: 0.0521981\ttest: 0.0519513\tbest: 0.0519513 (1088)\ttotal: 3m 47s\tremaining: 28m 31s\n",
      "1171:\tlearn: 0.0521981\ttest: 0.0519513\tbest: 0.0519513 (1088)\ttotal: 3m 47s\tremaining: 28m 31s\n",
      "1172:\tlearn: 0.0521981\ttest: 0.0519513\tbest: 0.0519513 (1088)\ttotal: 3m 47s\tremaining: 28m 31s\n",
      "1173:\tlearn: 0.0521981\ttest: 0.0519513\tbest: 0.0519513 (1088)\ttotal: 3m 47s\tremaining: 28m 30s\n",
      "1174:\tlearn: 0.0521981\ttest: 0.0519513\tbest: 0.0519513 (1088)\ttotal: 3m 47s\tremaining: 28m 30s\n",
      "1175:\tlearn: 0.0521981\ttest: 0.0519513\tbest: 0.0519513 (1088)\ttotal: 3m 47s\tremaining: 28m 29s\n",
      "1176:\tlearn: 0.0521981\ttest: 0.0519513\tbest: 0.0519513 (1088)\ttotal: 3m 48s\tremaining: 28m 29s\n",
      "1177:\tlearn: 0.0521981\ttest: 0.0519513\tbest: 0.0519513 (1088)\ttotal: 3m 48s\tremaining: 28m 29s\n",
      "1178:\tlearn: 0.0521981\ttest: 0.0519513\tbest: 0.0519513 (1088)\ttotal: 3m 48s\tremaining: 28m 28s\n",
      "1179:\tlearn: 0.0521981\ttest: 0.0519513\tbest: 0.0519513 (1088)\ttotal: 3m 48s\tremaining: 28m 28s\n",
      "1180:\tlearn: 0.0521981\ttest: 0.0519513\tbest: 0.0519513 (1088)\ttotal: 3m 48s\tremaining: 28m 28s\n",
      "1181:\tlearn: 0.0521981\ttest: 0.0519513\tbest: 0.0519513 (1088)\ttotal: 3m 48s\tremaining: 28m 27s\n",
      "1182:\tlearn: 0.0521981\ttest: 0.0519513\tbest: 0.0519513 (1088)\ttotal: 3m 49s\tremaining: 28m 27s\n",
      "1183:\tlearn: 0.0521981\ttest: 0.0519513\tbest: 0.0519513 (1088)\ttotal: 3m 49s\tremaining: 28m 26s\n",
      "1184:\tlearn: 0.0521981\ttest: 0.0519513\tbest: 0.0519513 (1088)\ttotal: 3m 49s\tremaining: 28m 26s\n",
      "1185:\tlearn: 0.0521981\ttest: 0.0519513\tbest: 0.0519513 (1088)\ttotal: 3m 49s\tremaining: 28m 26s\n",
      "1186:\tlearn: 0.0521981\ttest: 0.0519513\tbest: 0.0519513 (1088)\ttotal: 3m 49s\tremaining: 28m 25s\n",
      "1187:\tlearn: 0.0521981\ttest: 0.0519513\tbest: 0.0519513 (1088)\ttotal: 3m 49s\tremaining: 28m 25s\n",
      "1188:\tlearn: 0.0521981\ttest: 0.0519513\tbest: 0.0519513 (1088)\ttotal: 3m 50s\tremaining: 28m 24s\n",
      "1189:\tlearn: 0.0521981\ttest: 0.0519513\tbest: 0.0519513 (1088)\ttotal: 3m 50s\tremaining: 28m 24s\n",
      "1190:\tlearn: 0.0521981\ttest: 0.0519513\tbest: 0.0519513 (1088)\ttotal: 3m 50s\tremaining: 28m 24s\n",
      "1191:\tlearn: 0.0521981\ttest: 0.0519513\tbest: 0.0519513 (1088)\ttotal: 3m 50s\tremaining: 28m 23s\n",
      "1192:\tlearn: 0.0521981\ttest: 0.0519513\tbest: 0.0519513 (1088)\ttotal: 3m 50s\tremaining: 28m 23s\n",
      "1193:\tlearn: 0.0521981\ttest: 0.0519513\tbest: 0.0519513 (1088)\ttotal: 3m 50s\tremaining: 28m 23s\n",
      "1194:\tlearn: 0.0521981\ttest: 0.0519513\tbest: 0.0519513 (1088)\ttotal: 3m 51s\tremaining: 28m 22s\n",
      "1195:\tlearn: 0.0521981\ttest: 0.0519513\tbest: 0.0519513 (1088)\ttotal: 3m 51s\tremaining: 28m 22s\n",
      "1196:\tlearn: 0.0521981\ttest: 0.0519513\tbest: 0.0519513 (1088)\ttotal: 3m 51s\tremaining: 28m 21s\n",
      "1197:\tlearn: 0.0521981\ttest: 0.0519513\tbest: 0.0519513 (1088)\ttotal: 3m 51s\tremaining: 28m 21s\n",
      "1198:\tlearn: 0.0521981\ttest: 0.0519513\tbest: 0.0519513 (1088)\ttotal: 3m 51s\tremaining: 28m 21s\n",
      "1199:\tlearn: 0.0521981\ttest: 0.0519513\tbest: 0.0519513 (1088)\ttotal: 3m 51s\tremaining: 28m 20s\n",
      "1200:\tlearn: 0.0521981\ttest: 0.0519513\tbest: 0.0519513 (1088)\ttotal: 3m 52s\tremaining: 28m 20s\n",
      "1201:\tlearn: 0.0521981\ttest: 0.0519513\tbest: 0.0519513 (1088)\ttotal: 3m 52s\tremaining: 28m 19s\n",
      "1202:\tlearn: 0.0521981\ttest: 0.0519513\tbest: 0.0519513 (1088)\ttotal: 3m 52s\tremaining: 28m 19s\n",
      "1203:\tlearn: 0.0521981\ttest: 0.0519513\tbest: 0.0519513 (1088)\ttotal: 3m 52s\tremaining: 28m 19s\n",
      "1204:\tlearn: 0.0521981\ttest: 0.0519513\tbest: 0.0519513 (1088)\ttotal: 3m 52s\tremaining: 28m 18s\n",
      "1205:\tlearn: 0.0521981\ttest: 0.0519513\tbest: 0.0519513 (1088)\ttotal: 3m 52s\tremaining: 28m 18s\n",
      "1206:\tlearn: 0.0521981\ttest: 0.0519513\tbest: 0.0519513 (1088)\ttotal: 3m 53s\tremaining: 28m 18s\n",
      "1207:\tlearn: 0.0521981\ttest: 0.0519513\tbest: 0.0519513 (1088)\ttotal: 3m 53s\tremaining: 28m 17s\n",
      "1208:\tlearn: 0.0521981\ttest: 0.0519513\tbest: 0.0519513 (1088)\ttotal: 3m 53s\tremaining: 28m 17s\n",
      "1209:\tlearn: 0.0521981\ttest: 0.0519513\tbest: 0.0519513 (1088)\ttotal: 3m 53s\tremaining: 28m 16s\n",
      "1210:\tlearn: 0.0521981\ttest: 0.0519513\tbest: 0.0519513 (1088)\ttotal: 3m 53s\tremaining: 28m 16s\n",
      "1211:\tlearn: 0.0521981\ttest: 0.0519513\tbest: 0.0519513 (1088)\ttotal: 3m 53s\tremaining: 28m 16s\n",
      "1212:\tlearn: 0.0521981\ttest: 0.0519513\tbest: 0.0519513 (1088)\ttotal: 3m 54s\tremaining: 28m 15s\n",
      "1213:\tlearn: 0.0521981\ttest: 0.0519513\tbest: 0.0519513 (1088)\ttotal: 3m 54s\tremaining: 28m 15s\n",
      "1214:\tlearn: 0.0521981\ttest: 0.0519513\tbest: 0.0519513 (1088)\ttotal: 3m 54s\tremaining: 28m 14s\n",
      "1215:\tlearn: 0.0521981\ttest: 0.0519513\tbest: 0.0519513 (1088)\ttotal: 3m 54s\tremaining: 28m 14s\n",
      "1216:\tlearn: 0.0521981\ttest: 0.0519513\tbest: 0.0519513 (1088)\ttotal: 3m 54s\tremaining: 28m 13s\n",
      "1217:\tlearn: 0.0521981\ttest: 0.0519513\tbest: 0.0519513 (1088)\ttotal: 3m 54s\tremaining: 28m 13s\n",
      "1218:\tlearn: 0.0521981\ttest: 0.0519513\tbest: 0.0519513 (1088)\ttotal: 3m 55s\tremaining: 28m 13s\n",
      "1219:\tlearn: 0.0521981\ttest: 0.0519513\tbest: 0.0519513 (1088)\ttotal: 3m 55s\tremaining: 28m 12s\n",
      "1220:\tlearn: 0.0521981\ttest: 0.0519513\tbest: 0.0519513 (1088)\ttotal: 3m 55s\tremaining: 28m 12s\n",
      "1221:\tlearn: 0.0521981\ttest: 0.0519513\tbest: 0.0519513 (1088)\ttotal: 3m 55s\tremaining: 28m 12s\n",
      "1222:\tlearn: 0.0521981\ttest: 0.0519513\tbest: 0.0519513 (1088)\ttotal: 3m 55s\tremaining: 28m 11s\n",
      "1223:\tlearn: 0.0521981\ttest: 0.0519513\tbest: 0.0519513 (1088)\ttotal: 3m 55s\tremaining: 28m 11s\n",
      "1224:\tlearn: 0.0521981\ttest: 0.0519513\tbest: 0.0519513 (1088)\ttotal: 3m 56s\tremaining: 28m 11s\n",
      "1225:\tlearn: 0.0521981\ttest: 0.0519513\tbest: 0.0519513 (1088)\ttotal: 3m 56s\tremaining: 28m 10s\n",
      "1226:\tlearn: 0.0521981\ttest: 0.0519513\tbest: 0.0519513 (1088)\ttotal: 3m 56s\tremaining: 28m 10s\n",
      "1227:\tlearn: 0.0521981\ttest: 0.0519513\tbest: 0.0519513 (1088)\ttotal: 3m 56s\tremaining: 28m 10s\n",
      "1228:\tlearn: 0.0521981\ttest: 0.0519513\tbest: 0.0519513 (1088)\ttotal: 3m 56s\tremaining: 28m 9s\n",
      "1229:\tlearn: 0.0521981\ttest: 0.0519513\tbest: 0.0519513 (1088)\ttotal: 3m 56s\tremaining: 28m 9s\n",
      "1230:\tlearn: 0.0521981\ttest: 0.0519513\tbest: 0.0519513 (1088)\ttotal: 3m 57s\tremaining: 28m 8s\n",
      "1231:\tlearn: 0.0521981\ttest: 0.0519513\tbest: 0.0519513 (1088)\ttotal: 3m 57s\tremaining: 28m 8s\n",
      "1232:\tlearn: 0.0521981\ttest: 0.0519513\tbest: 0.0519513 (1088)\ttotal: 3m 57s\tremaining: 28m 8s\n",
      "1233:\tlearn: 0.0521981\ttest: 0.0519513\tbest: 0.0519513 (1088)\ttotal: 3m 57s\tremaining: 28m 7s\n",
      "1234:\tlearn: 0.0521981\ttest: 0.0519513\tbest: 0.0519513 (1088)\ttotal: 3m 57s\tremaining: 28m 7s\n",
      "1235:\tlearn: 0.0521981\ttest: 0.0519513\tbest: 0.0519513 (1088)\ttotal: 3m 57s\tremaining: 28m 7s\n",
      "1236:\tlearn: 0.0521981\ttest: 0.0519513\tbest: 0.0519513 (1088)\ttotal: 3m 58s\tremaining: 28m 6s\n",
      "1237:\tlearn: 0.0521981\ttest: 0.0519513\tbest: 0.0519513 (1088)\ttotal: 3m 58s\tremaining: 28m 6s\n",
      "1238:\tlearn: 0.0521981\ttest: 0.0519513\tbest: 0.0519513 (1088)\ttotal: 3m 58s\tremaining: 28m 6s\n",
      "1239:\tlearn: 0.0521981\ttest: 0.0519513\tbest: 0.0519513 (1088)\ttotal: 3m 58s\tremaining: 28m 5s\n",
      "1240:\tlearn: 0.0521981\ttest: 0.0519513\tbest: 0.0519513 (1088)\ttotal: 3m 58s\tremaining: 28m 5s\n",
      "1241:\tlearn: 0.0521981\ttest: 0.0519513\tbest: 0.0519513 (1088)\ttotal: 3m 58s\tremaining: 28m 4s\n",
      "1242:\tlearn: 0.0521981\ttest: 0.0519513\tbest: 0.0519513 (1088)\ttotal: 3m 59s\tremaining: 28m 4s\n",
      "1243:\tlearn: 0.0521981\ttest: 0.0519513\tbest: 0.0519513 (1088)\ttotal: 3m 59s\tremaining: 28m 4s\n",
      "1244:\tlearn: 0.0521981\ttest: 0.0519513\tbest: 0.0519513 (1088)\ttotal: 3m 59s\tremaining: 28m 3s\n",
      "1245:\tlearn: 0.0521981\ttest: 0.0519513\tbest: 0.0519513 (1088)\ttotal: 3m 59s\tremaining: 28m 3s\n",
      "1246:\tlearn: 0.0521981\ttest: 0.0519513\tbest: 0.0519513 (1088)\ttotal: 3m 59s\tremaining: 28m 3s\n",
      "1247:\tlearn: 0.0521981\ttest: 0.0519513\tbest: 0.0519513 (1088)\ttotal: 3m 59s\tremaining: 28m 2s\n",
      "1248:\tlearn: 0.0521981\ttest: 0.0519513\tbest: 0.0519513 (1088)\ttotal: 4m\tremaining: 28m 2s\n",
      "1249:\tlearn: 0.0521981\ttest: 0.0519513\tbest: 0.0519513 (1088)\ttotal: 4m\tremaining: 28m 2s\n",
      "1250:\tlearn: 0.0521981\ttest: 0.0519513\tbest: 0.0519513 (1088)\ttotal: 4m\tremaining: 28m 1s\n",
      "1251:\tlearn: 0.0521981\ttest: 0.0519513\tbest: 0.0519513 (1088)\ttotal: 4m\tremaining: 28m 1s\n",
      "1252:\tlearn: 0.0521981\ttest: 0.0519513\tbest: 0.0519513 (1088)\ttotal: 4m\tremaining: 28m\n",
      "1253:\tlearn: 0.0521981\ttest: 0.0519513\tbest: 0.0519513 (1088)\ttotal: 4m\tremaining: 28m\n",
      "1254:\tlearn: 0.0521981\ttest: 0.0519513\tbest: 0.0519513 (1088)\ttotal: 4m 1s\tremaining: 28m\n",
      "1255:\tlearn: 0.0521981\ttest: 0.0519513\tbest: 0.0519513 (1088)\ttotal: 4m 1s\tremaining: 28m\n",
      "1256:\tlearn: 0.0521981\ttest: 0.0519513\tbest: 0.0519513 (1088)\ttotal: 4m 1s\tremaining: 27m 59s\n",
      "1257:\tlearn: 0.0521981\ttest: 0.0519513\tbest: 0.0519513 (1088)\ttotal: 4m 1s\tremaining: 27m 59s\n",
      "1258:\tlearn: 0.0521981\ttest: 0.0519513\tbest: 0.0519513 (1088)\ttotal: 4m 1s\tremaining: 27m 59s\n",
      "1259:\tlearn: 0.0521981\ttest: 0.0519513\tbest: 0.0519513 (1088)\ttotal: 4m 2s\tremaining: 27m 58s\n",
      "1260:\tlearn: 0.0521981\ttest: 0.0519513\tbest: 0.0519513 (1088)\ttotal: 4m 2s\tremaining: 27m 58s\n",
      "1261:\tlearn: 0.0521981\ttest: 0.0519513\tbest: 0.0519513 (1088)\ttotal: 4m 2s\tremaining: 27m 57s\n",
      "1262:\tlearn: 0.0521981\ttest: 0.0519513\tbest: 0.0519513 (1088)\ttotal: 4m 2s\tremaining: 27m 57s\n",
      "1263:\tlearn: 0.0521981\ttest: 0.0519513\tbest: 0.0519513 (1088)\ttotal: 4m 2s\tremaining: 27m 57s\n",
      "1264:\tlearn: 0.0521981\ttest: 0.0519513\tbest: 0.0519513 (1088)\ttotal: 4m 2s\tremaining: 27m 56s\n",
      "1265:\tlearn: 0.0521981\ttest: 0.0519513\tbest: 0.0519513 (1088)\ttotal: 4m 3s\tremaining: 27m 56s\n",
      "1266:\tlearn: 0.0521981\ttest: 0.0519513\tbest: 0.0519513 (1088)\ttotal: 4m 3s\tremaining: 27m 56s\n",
      "1267:\tlearn: 0.0521981\ttest: 0.0519513\tbest: 0.0519513 (1088)\ttotal: 4m 3s\tremaining: 27m 55s\n",
      "1268:\tlearn: 0.0521981\ttest: 0.0519513\tbest: 0.0519513 (1088)\ttotal: 4m 3s\tremaining: 27m 55s\n",
      "1269:\tlearn: 0.0521981\ttest: 0.0519513\tbest: 0.0519513 (1088)\ttotal: 4m 3s\tremaining: 27m 55s\n",
      "1270:\tlearn: 0.0521981\ttest: 0.0519513\tbest: 0.0519513 (1088)\ttotal: 4m 3s\tremaining: 27m 54s\n",
      "1271:\tlearn: 0.0521981\ttest: 0.0519513\tbest: 0.0519513 (1088)\ttotal: 4m 4s\tremaining: 27m 54s\n",
      "1272:\tlearn: 0.0521981\ttest: 0.0519513\tbest: 0.0519513 (1088)\ttotal: 4m 4s\tremaining: 27m 54s\n",
      "1273:\tlearn: 0.0521981\ttest: 0.0519513\tbest: 0.0519513 (1088)\ttotal: 4m 4s\tremaining: 27m 53s\n",
      "1274:\tlearn: 0.0521981\ttest: 0.0519513\tbest: 0.0519513 (1088)\ttotal: 4m 4s\tremaining: 27m 53s\n",
      "1275:\tlearn: 0.0521981\ttest: 0.0519513\tbest: 0.0519513 (1088)\ttotal: 4m 4s\tremaining: 27m 53s\n",
      "1276:\tlearn: 0.0521981\ttest: 0.0519513\tbest: 0.0519513 (1088)\ttotal: 4m 4s\tremaining: 27m 52s\n",
      "1277:\tlearn: 0.0521981\ttest: 0.0519513\tbest: 0.0519513 (1088)\ttotal: 4m 5s\tremaining: 27m 52s\n",
      "1278:\tlearn: 0.0521981\ttest: 0.0519513\tbest: 0.0519513 (1088)\ttotal: 4m 5s\tremaining: 27m 52s\n",
      "1279:\tlearn: 0.0521981\ttest: 0.0519513\tbest: 0.0519513 (1088)\ttotal: 4m 5s\tremaining: 27m 51s\n",
      "1280:\tlearn: 0.0521981\ttest: 0.0519513\tbest: 0.0519513 (1088)\ttotal: 4m 5s\tremaining: 27m 51s\n",
      "1281:\tlearn: 0.0521981\ttest: 0.0519513\tbest: 0.0519513 (1088)\ttotal: 4m 5s\tremaining: 27m 51s\n",
      "1282:\tlearn: 0.0521981\ttest: 0.0519513\tbest: 0.0519513 (1088)\ttotal: 4m 5s\tremaining: 27m 50s\n",
      "1283:\tlearn: 0.0521981\ttest: 0.0519513\tbest: 0.0519513 (1088)\ttotal: 4m 6s\tremaining: 27m 50s\n",
      "1284:\tlearn: 0.0521981\ttest: 0.0519513\tbest: 0.0519513 (1088)\ttotal: 4m 6s\tremaining: 27m 50s\n",
      "1285:\tlearn: 0.0521981\ttest: 0.0519513\tbest: 0.0519513 (1088)\ttotal: 4m 6s\tremaining: 27m 49s\n",
      "1286:\tlearn: 0.0521981\ttest: 0.0519513\tbest: 0.0519513 (1088)\ttotal: 4m 6s\tremaining: 27m 49s\n",
      "1287:\tlearn: 0.0521981\ttest: 0.0519513\tbest: 0.0519513 (1088)\ttotal: 4m 6s\tremaining: 27m 49s\n",
      "1288:\tlearn: 0.0521981\ttest: 0.0519513\tbest: 0.0519513 (1088)\ttotal: 4m 6s\tremaining: 27m 48s\n",
      "1289:\tlearn: 0.0521981\ttest: 0.0519513\tbest: 0.0519513 (1088)\ttotal: 4m 7s\tremaining: 27m 48s\n",
      "1290:\tlearn: 0.0521981\ttest: 0.0519513\tbest: 0.0519513 (1088)\ttotal: 4m 7s\tremaining: 27m 47s\n",
      "1291:\tlearn: 0.0521981\ttest: 0.0519513\tbest: 0.0519513 (1088)\ttotal: 4m 7s\tremaining: 27m 47s\n",
      "1292:\tlearn: 0.0521981\ttest: 0.0519513\tbest: 0.0519513 (1088)\ttotal: 4m 7s\tremaining: 27m 47s\n",
      "1293:\tlearn: 0.0521981\ttest: 0.0519513\tbest: 0.0519513 (1088)\ttotal: 4m 7s\tremaining: 27m 46s\n",
      "1294:\tlearn: 0.0521981\ttest: 0.0519513\tbest: 0.0519513 (1088)\ttotal: 4m 7s\tremaining: 27m 46s\n",
      "1295:\tlearn: 0.0521981\ttest: 0.0519513\tbest: 0.0519513 (1088)\ttotal: 4m 8s\tremaining: 27m 46s\n",
      "1296:\tlearn: 0.0521981\ttest: 0.0519513\tbest: 0.0519513 (1088)\ttotal: 4m 8s\tremaining: 27m 45s\n",
      "1297:\tlearn: 0.0521981\ttest: 0.0519513\tbest: 0.0519513 (1088)\ttotal: 4m 8s\tremaining: 27m 45s\n",
      "1298:\tlearn: 0.0521981\ttest: 0.0519513\tbest: 0.0519513 (1088)\ttotal: 4m 8s\tremaining: 27m 45s\n",
      "1299:\tlearn: 0.0521981\ttest: 0.0519513\tbest: 0.0519513 (1088)\ttotal: 4m 8s\tremaining: 27m 44s\n",
      "1300:\tlearn: 0.0521981\ttest: 0.0519513\tbest: 0.0519513 (1088)\ttotal: 4m 8s\tremaining: 27m 44s\n",
      "1301:\tlearn: 0.0521981\ttest: 0.0519513\tbest: 0.0519513 (1088)\ttotal: 4m 9s\tremaining: 27m 44s\n",
      "1302:\tlearn: 0.0521981\ttest: 0.0519513\tbest: 0.0519513 (1088)\ttotal: 4m 9s\tremaining: 27m 43s\n",
      "1303:\tlearn: 0.0521981\ttest: 0.0519513\tbest: 0.0519513 (1088)\ttotal: 4m 9s\tremaining: 27m 43s\n",
      "1304:\tlearn: 0.0521981\ttest: 0.0519513\tbest: 0.0519513 (1088)\ttotal: 4m 9s\tremaining: 27m 43s\n",
      "1305:\tlearn: 0.0521981\ttest: 0.0519513\tbest: 0.0519513 (1088)\ttotal: 4m 9s\tremaining: 27m 42s\n",
      "1306:\tlearn: 0.0521981\ttest: 0.0519513\tbest: 0.0519513 (1088)\ttotal: 4m 9s\tremaining: 27m 42s\n",
      "1307:\tlearn: 0.0521981\ttest: 0.0519513\tbest: 0.0519513 (1088)\ttotal: 4m 10s\tremaining: 27m 41s\n",
      "1308:\tlearn: 0.0521981\ttest: 0.0519513\tbest: 0.0519513 (1088)\ttotal: 4m 10s\tremaining: 27m 41s\n",
      "1309:\tlearn: 0.0521981\ttest: 0.0519513\tbest: 0.0519513 (1088)\ttotal: 4m 10s\tremaining: 27m 41s\n",
      "1310:\tlearn: 0.0521981\ttest: 0.0519513\tbest: 0.0519513 (1088)\ttotal: 4m 10s\tremaining: 27m 41s\n",
      "1311:\tlearn: 0.0521981\ttest: 0.0519513\tbest: 0.0519513 (1088)\ttotal: 4m 10s\tremaining: 27m 40s\n",
      "1312:\tlearn: 0.0521981\ttest: 0.0519513\tbest: 0.0519513 (1088)\ttotal: 4m 10s\tremaining: 27m 40s\n",
      "1313:\tlearn: 0.0521981\ttest: 0.0519513\tbest: 0.0519513 (1088)\ttotal: 4m 11s\tremaining: 27m 40s\n",
      "1314:\tlearn: 0.0521981\ttest: 0.0519513\tbest: 0.0519513 (1088)\ttotal: 4m 11s\tremaining: 27m 39s\n",
      "1315:\tlearn: 0.0521981\ttest: 0.0519513\tbest: 0.0519513 (1088)\ttotal: 4m 11s\tremaining: 27m 39s\n",
      "1316:\tlearn: 0.0521981\ttest: 0.0519513\tbest: 0.0519513 (1088)\ttotal: 4m 11s\tremaining: 27m 38s\n",
      "1317:\tlearn: 0.0521981\ttest: 0.0519513\tbest: 0.0519513 (1088)\ttotal: 4m 11s\tremaining: 27m 38s\n",
      "1318:\tlearn: 0.0521981\ttest: 0.0519513\tbest: 0.0519513 (1088)\ttotal: 4m 11s\tremaining: 27m 38s\n",
      "1319:\tlearn: 0.0521981\ttest: 0.0519513\tbest: 0.0519513 (1088)\ttotal: 4m 12s\tremaining: 27m 37s\n",
      "1320:\tlearn: 0.0521981\ttest: 0.0519513\tbest: 0.0519513 (1088)\ttotal: 4m 12s\tremaining: 27m 37s\n",
      "1321:\tlearn: 0.0521981\ttest: 0.0519513\tbest: 0.0519513 (1088)\ttotal: 4m 12s\tremaining: 27m 37s\n",
      "1322:\tlearn: 0.0521981\ttest: 0.0519513\tbest: 0.0519513 (1088)\ttotal: 4m 12s\tremaining: 27m 37s\n",
      "1323:\tlearn: 0.0521981\ttest: 0.0519513\tbest: 0.0519513 (1088)\ttotal: 4m 12s\tremaining: 27m 36s\n",
      "1324:\tlearn: 0.0521981\ttest: 0.0519513\tbest: 0.0519513 (1088)\ttotal: 4m 12s\tremaining: 27m 36s\n",
      "1325:\tlearn: 0.0521981\ttest: 0.0519513\tbest: 0.0519513 (1088)\ttotal: 4m 13s\tremaining: 27m 36s\n",
      "1326:\tlearn: 0.0521981\ttest: 0.0519513\tbest: 0.0519513 (1088)\ttotal: 4m 13s\tremaining: 27m 35s\n",
      "1327:\tlearn: 0.0521981\ttest: 0.0519513\tbest: 0.0519513 (1088)\ttotal: 4m 13s\tremaining: 27m 35s\n",
      "1328:\tlearn: 0.0521981\ttest: 0.0519513\tbest: 0.0519513 (1088)\ttotal: 4m 13s\tremaining: 27m 34s\n",
      "1329:\tlearn: 0.0521981\ttest: 0.0519513\tbest: 0.0519513 (1088)\ttotal: 4m 13s\tremaining: 27m 34s\n",
      "1330:\tlearn: 0.0521981\ttest: 0.0519513\tbest: 0.0519513 (1088)\ttotal: 4m 13s\tremaining: 27m 34s\n",
      "1331:\tlearn: 0.0521981\ttest: 0.0519513\tbest: 0.0519513 (1088)\ttotal: 4m 14s\tremaining: 27m 33s\n",
      "1332:\tlearn: 0.0521981\ttest: 0.0519513\tbest: 0.0519513 (1088)\ttotal: 4m 14s\tremaining: 27m 33s\n",
      "1333:\tlearn: 0.0521981\ttest: 0.0519513\tbest: 0.0519513 (1088)\ttotal: 4m 14s\tremaining: 27m 33s\n",
      "1334:\tlearn: 0.0521981\ttest: 0.0519513\tbest: 0.0519513 (1088)\ttotal: 4m 14s\tremaining: 27m 32s\n",
      "1335:\tlearn: 0.0521981\ttest: 0.0519513\tbest: 0.0519513 (1088)\ttotal: 4m 14s\tremaining: 27m 32s\n",
      "1336:\tlearn: 0.0521981\ttest: 0.0519513\tbest: 0.0519513 (1088)\ttotal: 4m 15s\tremaining: 27m 32s\n",
      "1337:\tlearn: 0.0521981\ttest: 0.0519513\tbest: 0.0519513 (1088)\ttotal: 4m 15s\tremaining: 27m 31s\n",
      "1338:\tlearn: 0.0521981\ttest: 0.0519513\tbest: 0.0519513 (1088)\ttotal: 4m 15s\tremaining: 27m 31s\n",
      "1339:\tlearn: 0.0521981\ttest: 0.0519513\tbest: 0.0519513 (1088)\ttotal: 4m 15s\tremaining: 27m 31s\n",
      "1340:\tlearn: 0.0521981\ttest: 0.0519513\tbest: 0.0519513 (1088)\ttotal: 4m 15s\tremaining: 27m 31s\n",
      "1341:\tlearn: 0.0521981\ttest: 0.0519513\tbest: 0.0519513 (1088)\ttotal: 4m 15s\tremaining: 27m 30s\n",
      "1342:\tlearn: 0.0521981\ttest: 0.0519513\tbest: 0.0519513 (1088)\ttotal: 4m 16s\tremaining: 27m 30s\n",
      "1343:\tlearn: 0.0521981\ttest: 0.0519513\tbest: 0.0519513 (1088)\ttotal: 4m 16s\tremaining: 27m 29s\n",
      "1344:\tlearn: 0.0521981\ttest: 0.0519513\tbest: 0.0519513 (1088)\ttotal: 4m 16s\tremaining: 27m 29s\n",
      "1345:\tlearn: 0.0521981\ttest: 0.0519513\tbest: 0.0519513 (1088)\ttotal: 4m 16s\tremaining: 27m 29s\n",
      "1346:\tlearn: 0.0521981\ttest: 0.0519513\tbest: 0.0519513 (1088)\ttotal: 4m 16s\tremaining: 27m 29s\n",
      "1347:\tlearn: 0.0521981\ttest: 0.0519513\tbest: 0.0519513 (1088)\ttotal: 4m 16s\tremaining: 27m 28s\n",
      "1348:\tlearn: 0.0521981\ttest: 0.0519513\tbest: 0.0519513 (1088)\ttotal: 4m 17s\tremaining: 27m 28s\n",
      "1349:\tlearn: 0.0521981\ttest: 0.0519513\tbest: 0.0519513 (1088)\ttotal: 4m 17s\tremaining: 27m 28s\n",
      "1350:\tlearn: 0.0521981\ttest: 0.0519513\tbest: 0.0519513 (1088)\ttotal: 4m 17s\tremaining: 27m 27s\n",
      "1351:\tlearn: 0.0521981\ttest: 0.0519513\tbest: 0.0519513 (1088)\ttotal: 4m 17s\tremaining: 27m 27s\n",
      "1352:\tlearn: 0.0521981\ttest: 0.0519513\tbest: 0.0519513 (1088)\ttotal: 4m 17s\tremaining: 27m 26s\n",
      "1353:\tlearn: 0.0521981\ttest: 0.0519513\tbest: 0.0519513 (1088)\ttotal: 4m 17s\tremaining: 27m 26s\n",
      "1354:\tlearn: 0.0521981\ttest: 0.0519513\tbest: 0.0519513 (1088)\ttotal: 4m 18s\tremaining: 27m 26s\n",
      "1355:\tlearn: 0.0521981\ttest: 0.0519513\tbest: 0.0519513 (1088)\ttotal: 4m 18s\tremaining: 27m 25s\n",
      "1356:\tlearn: 0.0521981\ttest: 0.0519513\tbest: 0.0519513 (1088)\ttotal: 4m 18s\tremaining: 27m 25s\n",
      "1357:\tlearn: 0.0521981\ttest: 0.0519513\tbest: 0.0519513 (1088)\ttotal: 4m 18s\tremaining: 27m 25s\n",
      "1358:\tlearn: 0.0521981\ttest: 0.0519513\tbest: 0.0519513 (1088)\ttotal: 4m 18s\tremaining: 27m 24s\n",
      "1359:\tlearn: 0.0521981\ttest: 0.0519513\tbest: 0.0519513 (1088)\ttotal: 4m 18s\tremaining: 27m 24s\n",
      "1360:\tlearn: 0.0521981\ttest: 0.0519513\tbest: 0.0519513 (1088)\ttotal: 4m 19s\tremaining: 27m 24s\n",
      "1361:\tlearn: 0.0521981\ttest: 0.0519513\tbest: 0.0519513 (1088)\ttotal: 4m 19s\tremaining: 27m 23s\n",
      "1362:\tlearn: 0.0521981\ttest: 0.0519513\tbest: 0.0519513 (1088)\ttotal: 4m 19s\tremaining: 27m 23s\n",
      "1363:\tlearn: 0.0521981\ttest: 0.0519513\tbest: 0.0519513 (1088)\ttotal: 4m 19s\tremaining: 27m 23s\n",
      "1364:\tlearn: 0.0521981\ttest: 0.0519513\tbest: 0.0519513 (1088)\ttotal: 4m 19s\tremaining: 27m 23s\n",
      "1365:\tlearn: 0.0521981\ttest: 0.0519513\tbest: 0.0519513 (1088)\ttotal: 4m 19s\tremaining: 27m 22s\n",
      "1366:\tlearn: 0.0521981\ttest: 0.0519513\tbest: 0.0519513 (1088)\ttotal: 4m 20s\tremaining: 27m 22s\n",
      "1367:\tlearn: 0.0521981\ttest: 0.0519513\tbest: 0.0519513 (1088)\ttotal: 4m 20s\tremaining: 27m 22s\n",
      "1368:\tlearn: 0.0521981\ttest: 0.0519513\tbest: 0.0519513 (1088)\ttotal: 4m 20s\tremaining: 27m 21s\n",
      "1369:\tlearn: 0.0521981\ttest: 0.0519513\tbest: 0.0519513 (1088)\ttotal: 4m 20s\tremaining: 27m 21s\n",
      "1370:\tlearn: 0.0521981\ttest: 0.0519513\tbest: 0.0519513 (1088)\ttotal: 4m 20s\tremaining: 27m 21s\n",
      "1371:\tlearn: 0.0521981\ttest: 0.0519513\tbest: 0.0519513 (1088)\ttotal: 4m 20s\tremaining: 27m 20s\n",
      "1372:\tlearn: 0.0521981\ttest: 0.0519513\tbest: 0.0519513 (1088)\ttotal: 4m 21s\tremaining: 27m 20s\n",
      "1373:\tlearn: 0.0521981\ttest: 0.0519513\tbest: 0.0519513 (1088)\ttotal: 4m 21s\tremaining: 27m 20s\n",
      "1374:\tlearn: 0.0521981\ttest: 0.0519513\tbest: 0.0519513 (1088)\ttotal: 4m 21s\tremaining: 27m 19s\n",
      "1375:\tlearn: 0.0521981\ttest: 0.0519513\tbest: 0.0519513 (1088)\ttotal: 4m 21s\tremaining: 27m 19s\n",
      "1376:\tlearn: 0.0521981\ttest: 0.0519513\tbest: 0.0519513 (1088)\ttotal: 4m 21s\tremaining: 27m 19s\n",
      "1377:\tlearn: 0.0521981\ttest: 0.0519513\tbest: 0.0519513 (1088)\ttotal: 4m 21s\tremaining: 27m 18s\n",
      "1378:\tlearn: 0.0521981\ttest: 0.0519513\tbest: 0.0519513 (1088)\ttotal: 4m 22s\tremaining: 27m 18s\n",
      "1379:\tlearn: 0.0521981\ttest: 0.0519513\tbest: 0.0519513 (1088)\ttotal: 4m 22s\tremaining: 27m 18s\n",
      "1380:\tlearn: 0.0521981\ttest: 0.0519513\tbest: 0.0519513 (1088)\ttotal: 4m 22s\tremaining: 27m 17s\n",
      "1381:\tlearn: 0.0521981\ttest: 0.0519513\tbest: 0.0519513 (1088)\ttotal: 4m 22s\tremaining: 27m 17s\n",
      "1382:\tlearn: 0.0521981\ttest: 0.0519513\tbest: 0.0519513 (1088)\ttotal: 4m 22s\tremaining: 27m 17s\n",
      "1383:\tlearn: 0.0521981\ttest: 0.0519513\tbest: 0.0519513 (1088)\ttotal: 4m 22s\tremaining: 27m 16s\n",
      "1384:\tlearn: 0.0521981\ttest: 0.0519513\tbest: 0.0519513 (1088)\ttotal: 4m 23s\tremaining: 27m 16s\n",
      "1385:\tlearn: 0.0521981\ttest: 0.0519513\tbest: 0.0519513 (1088)\ttotal: 4m 23s\tremaining: 27m 16s\n",
      "1386:\tlearn: 0.0521981\ttest: 0.0519513\tbest: 0.0519513 (1088)\ttotal: 4m 23s\tremaining: 27m 16s\n",
      "1387:\tlearn: 0.0521981\ttest: 0.0519513\tbest: 0.0519513 (1088)\ttotal: 4m 23s\tremaining: 27m 15s\n",
      "1388:\tlearn: 0.0521981\ttest: 0.0519513\tbest: 0.0519513 (1088)\ttotal: 4m 23s\tremaining: 27m 15s\n",
      "1389:\tlearn: 0.0521981\ttest: 0.0519513\tbest: 0.0519513 (1088)\ttotal: 4m 23s\tremaining: 27m 15s\n",
      "1390:\tlearn: 0.0521981\ttest: 0.0519513\tbest: 0.0519513 (1088)\ttotal: 4m 24s\tremaining: 27m 14s\n",
      "1391:\tlearn: 0.0521981\ttest: 0.0519513\tbest: 0.0519513 (1088)\ttotal: 4m 24s\tremaining: 27m 14s\n",
      "1392:\tlearn: 0.0521981\ttest: 0.0519513\tbest: 0.0519513 (1088)\ttotal: 4m 24s\tremaining: 27m 14s\n",
      "1393:\tlearn: 0.0521981\ttest: 0.0519513\tbest: 0.0519513 (1088)\ttotal: 4m 24s\tremaining: 27m 13s\n",
      "1394:\tlearn: 0.0521981\ttest: 0.0519513\tbest: 0.0519513 (1088)\ttotal: 4m 24s\tremaining: 27m 13s\n",
      "1395:\tlearn: 0.0521981\ttest: 0.0519513\tbest: 0.0519513 (1088)\ttotal: 4m 24s\tremaining: 27m 13s\n",
      "1396:\tlearn: 0.0521981\ttest: 0.0519513\tbest: 0.0519513 (1088)\ttotal: 4m 25s\tremaining: 27m 12s\n",
      "1397:\tlearn: 0.0521981\ttest: 0.0519513\tbest: 0.0519513 (1088)\ttotal: 4m 25s\tremaining: 27m 12s\n",
      "1398:\tlearn: 0.0521981\ttest: 0.0519513\tbest: 0.0519513 (1088)\ttotal: 4m 25s\tremaining: 27m 12s\n",
      "1399:\tlearn: 0.0521981\ttest: 0.0519513\tbest: 0.0519513 (1088)\ttotal: 4m 25s\tremaining: 27m 11s\n",
      "1400:\tlearn: 0.0521981\ttest: 0.0519513\tbest: 0.0519513 (1088)\ttotal: 4m 25s\tremaining: 27m 11s\n",
      "1401:\tlearn: 0.0521981\ttest: 0.0519513\tbest: 0.0519513 (1088)\ttotal: 4m 25s\tremaining: 27m 11s\n",
      "1402:\tlearn: 0.0521981\ttest: 0.0519513\tbest: 0.0519513 (1088)\ttotal: 4m 26s\tremaining: 27m 10s\n",
      "1403:\tlearn: 0.0521981\ttest: 0.0519513\tbest: 0.0519513 (1088)\ttotal: 4m 26s\tremaining: 27m 10s\n",
      "1404:\tlearn: 0.0521981\ttest: 0.0519513\tbest: 0.0519513 (1088)\ttotal: 4m 26s\tremaining: 27m 10s\n",
      "1405:\tlearn: 0.0521981\ttest: 0.0519513\tbest: 0.0519513 (1088)\ttotal: 4m 26s\tremaining: 27m 9s\n",
      "1406:\tlearn: 0.0521981\ttest: 0.0519513\tbest: 0.0519513 (1088)\ttotal: 4m 26s\tremaining: 27m 9s\n",
      "1407:\tlearn: 0.0521981\ttest: 0.0519513\tbest: 0.0519513 (1088)\ttotal: 4m 26s\tremaining: 27m 9s\n",
      "1408:\tlearn: 0.0521981\ttest: 0.0519513\tbest: 0.0519513 (1088)\ttotal: 4m 27s\tremaining: 27m 8s\n",
      "1409:\tlearn: 0.0521981\ttest: 0.0519513\tbest: 0.0519513 (1088)\ttotal: 4m 27s\tremaining: 27m 8s\n",
      "1410:\tlearn: 0.0521981\ttest: 0.0519513\tbest: 0.0519513 (1088)\ttotal: 4m 27s\tremaining: 27m 8s\n",
      "1411:\tlearn: 0.0521981\ttest: 0.0519513\tbest: 0.0519513 (1088)\ttotal: 4m 27s\tremaining: 27m 7s\n",
      "1412:\tlearn: 0.0521981\ttest: 0.0519513\tbest: 0.0519513 (1088)\ttotal: 4m 27s\tremaining: 27m 7s\n",
      "1413:\tlearn: 0.0521981\ttest: 0.0519513\tbest: 0.0519513 (1088)\ttotal: 4m 27s\tremaining: 27m 7s\n",
      "1414:\tlearn: 0.0521981\ttest: 0.0519513\tbest: 0.0519513 (1088)\ttotal: 4m 28s\tremaining: 27m 6s\n",
      "1415:\tlearn: 0.0521981\ttest: 0.0519513\tbest: 0.0519513 (1088)\ttotal: 4m 28s\tremaining: 27m 6s\n",
      "1416:\tlearn: 0.0521981\ttest: 0.0519513\tbest: 0.0519513 (1088)\ttotal: 4m 28s\tremaining: 27m 5s\n",
      "1417:\tlearn: 0.0521981\ttest: 0.0519513\tbest: 0.0519513 (1088)\ttotal: 4m 28s\tremaining: 27m 5s\n",
      "1418:\tlearn: 0.0521981\ttest: 0.0519513\tbest: 0.0519513 (1088)\ttotal: 4m 28s\tremaining: 27m 5s\n",
      "1419:\tlearn: 0.0521981\ttest: 0.0519513\tbest: 0.0519513 (1088)\ttotal: 4m 28s\tremaining: 27m 4s\n",
      "1420:\tlearn: 0.0521981\ttest: 0.0519513\tbest: 0.0519513 (1088)\ttotal: 4m 29s\tremaining: 27m 4s\n",
      "1421:\tlearn: 0.0521981\ttest: 0.0519513\tbest: 0.0519513 (1088)\ttotal: 4m 29s\tremaining: 27m 4s\n",
      "1422:\tlearn: 0.0521981\ttest: 0.0519513\tbest: 0.0519513 (1088)\ttotal: 4m 29s\tremaining: 27m 3s\n",
      "1423:\tlearn: 0.0521981\ttest: 0.0519513\tbest: 0.0519513 (1088)\ttotal: 4m 29s\tremaining: 27m 3s\n",
      "1424:\tlearn: 0.0521981\ttest: 0.0519513\tbest: 0.0519513 (1088)\ttotal: 4m 29s\tremaining: 27m 3s\n",
      "1425:\tlearn: 0.0521981\ttest: 0.0519513\tbest: 0.0519513 (1088)\ttotal: 4m 29s\tremaining: 27m 2s\n",
      "1426:\tlearn: 0.0521981\ttest: 0.0519513\tbest: 0.0519513 (1088)\ttotal: 4m 30s\tremaining: 27m 2s\n",
      "1427:\tlearn: 0.0521981\ttest: 0.0519513\tbest: 0.0519513 (1088)\ttotal: 4m 30s\tremaining: 27m 2s\n",
      "1428:\tlearn: 0.0521981\ttest: 0.0519513\tbest: 0.0519513 (1088)\ttotal: 4m 30s\tremaining: 27m 1s\n",
      "1429:\tlearn: 0.0521981\ttest: 0.0519513\tbest: 0.0519513 (1088)\ttotal: 4m 30s\tremaining: 27m 1s\n",
      "1430:\tlearn: 0.0521981\ttest: 0.0519513\tbest: 0.0519513 (1088)\ttotal: 4m 30s\tremaining: 27m 1s\n",
      "1431:\tlearn: 0.0521981\ttest: 0.0519513\tbest: 0.0519513 (1088)\ttotal: 4m 30s\tremaining: 27m\n",
      "1432:\tlearn: 0.0521981\ttest: 0.0519513\tbest: 0.0519513 (1088)\ttotal: 4m 31s\tremaining: 27m\n",
      "1433:\tlearn: 0.0521981\ttest: 0.0519513\tbest: 0.0519513 (1088)\ttotal: 4m 31s\tremaining: 27m\n",
      "1434:\tlearn: 0.0521981\ttest: 0.0519513\tbest: 0.0519513 (1088)\ttotal: 4m 31s\tremaining: 26m 59s\n",
      "1435:\tlearn: 0.0521981\ttest: 0.0519513\tbest: 0.0519513 (1088)\ttotal: 4m 31s\tremaining: 26m 59s\n",
      "\n",
      "bestTest = 0.05195128927\n",
      "bestIteration = 1088\n",
      "\n",
      "Shrink model to first 1089 iterations.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving ./auto_gl/exp-iot23-oversample/deploy-exp/STTACKING2_layer1_search/models/CatBoost_BAG_L1/T1/utils/oof.pkl\n",
      "Saving ./auto_gl/exp-iot23-oversample/deploy-exp/STTACKING2_layer1_search/models/CatBoost_BAG_L1/T1/model.pkl\n",
      "\t0.9953\t = Validation score   (roc_auc)\n",
      "\t2592.54s\t = Training   runtime\n",
      "\t2.16s\t = Validation runtime\n",
      "Saving ./auto_gl/exp-iot23-oversample/deploy-exp/STTACKING2_layer1_search/models/trainer.pkl\n",
      "Loading: ./auto_gl/exp-iot23-oversample/deploy-exp/STTACKING2_layer1_search/models/LightGBM_BAG_L1/T1/utils/oof.pkl\n",
      "Loading: ./auto_gl/exp-iot23-oversample/deploy-exp/STTACKING2_layer1_search/models/CatBoost_BAG_L1/T1/utils/oof.pkl\n",
      "Model configs that will be trained (in order):\n",
      "\tWeightedEnsemble_L2: \t{'ag_args': {'valid_base': False, 'name_bag_suffix': '', 'model_type': <class 'autogluon.core.models.greedy_ensemble.greedy_weighted_ensemble_model.GreedyWeightedEnsembleModel'>, 'priority': 0}, 'ag_args_ensemble': {'save_bag_folds': True}}\n",
      "Fitting model: WeightedEnsemble_L2 ... Training model for up to 3597.4s of the 33286.82s of remaining time.\n",
      "\tDropped 0 of 2 features.\n",
      "\tDropped 0 of 2 features.\n",
      "Saving ./auto_gl/exp-iot23-oversample/deploy-exp/STTACKING2_layer1_search/models/WeightedEnsemble_L2/utils/model_template.pkl\n",
      "Loading: ./auto_gl/exp-iot23-oversample/deploy-exp/STTACKING2_layer1_search/models/WeightedEnsemble_L2/utils/model_template.pkl\n",
      "\tDropped 0 of 2 features.\n",
      "\tFitting S1F1 with 'num_gpus': 0, 'num_cpus': 16\n",
      "Ensemble size: 4\n",
      "Ensemble indices: [0, 0, 0, 1]\n",
      "Ensemble weights: \n",
      "[0.75 0.25]\n",
      "\t8.27s\t= Estimated out-of-fold prediction time...\n",
      "Saving ./auto_gl/exp-iot23-oversample/deploy-exp/STTACKING2_layer1_search/models/WeightedEnsemble_L2/utils/oof.pkl\n",
      "Saving ./auto_gl/exp-iot23-oversample/deploy-exp/STTACKING2_layer1_search/models/WeightedEnsemble_L2/model.pkl\n",
      "\t0.9953\t = Validation score   (roc_auc)\n",
      "\t247.11s\t = Training   runtime\n",
      "\t1.02s\t = Validation runtime\n",
      "Saving ./auto_gl/exp-iot23-oversample/deploy-exp/STTACKING2_layer1_search/models/trainer.pkl\n",
      "Saving ./auto_gl/exp-iot23-oversample/deploy-exp/STTACKING2_layer1_search/models/trainer.pkl\n",
      "Saving ./auto_gl/exp-iot23-oversample/deploy-exp/STTACKING2_layer1_search/models/trainer.pkl\n",
      "AutoGluon training complete, total runtime = 2964.28s ... Best model: \"WeightedEnsemble_L2\"\n",
      "Loading: ./auto_gl/exp-iot23-oversample/deploy-exp/STTACKING2_layer1_search/models/trainer.pkl\n",
      "Saving ./auto_gl/exp-iot23-oversample/deploy-exp/STTACKING2_layer1_search/models/trainer.pkl\n",
      "Loading: ./auto_gl/exp-iot23-oversample/deploy-exp/STTACKING2_layer1_search/models/LightGBM_BAG_L1/T1/model.pkl\n",
      "Saving ./auto_gl/exp-iot23-oversample/deploy-exp/STTACKING2_layer1_search/models/LightGBM_BAG_L1/T1/model.pkl\n",
      "Loading: ./auto_gl/exp-iot23-oversample/deploy-exp/STTACKING2_layer1_search/models/CatBoost_BAG_L1/T1/model.pkl\n",
      "Saving ./auto_gl/exp-iot23-oversample/deploy-exp/STTACKING2_layer1_search/models/CatBoost_BAG_L1/T1/model.pkl\n",
      "Loading: ./auto_gl/exp-iot23-oversample/deploy-exp/STTACKING2_layer1_search/models/WeightedEnsemble_L2/model.pkl\n",
      "Saving ./auto_gl/exp-iot23-oversample/deploy-exp/STTACKING2_layer1_search/models/WeightedEnsemble_L2/model.pkl\n",
      "Saving ./auto_gl/exp-iot23-oversample/deploy-exp/STTACKING2_layer1_search/models/trainer.pkl\n",
      "Saving ./auto_gl/exp-iot23-oversample/deploy-exp/STTACKING2_layer1_search/models/trainer.pkl\n",
      "Saving ./auto_gl/exp-iot23-oversample/deploy-exp/STTACKING2_layer1_search/learner.pkl\n",
      "Saving ./auto_gl/exp-iot23-oversample/deploy-exp/STTACKING2_layer1_search/predictor.pkl\n",
      "Saving ./auto_gl/exp-iot23-oversample/deploy-exp/STTACKING2_layer1_search/__version__ with contents \"0.4.0\"\n",
      "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"./auto_gl/exp-iot23-oversample/deploy-exp/STTACKING2_layer1_search/\")\n"
     ]
    }
   ],
   "source": [
    "from autogluon.tabular import TabularPredictor,TabularDataset\n",
    "# test_data = TabularDataset(\"./Data/split/test_data_big.csv\")\n",
    "train_data = TabularDataset(\"./Data/split/train_data_big_balance.csv\")\n",
    "save_path = './auto_gl/exp-iot23-oversample/deploy-exp/STTACKING2_layer1_search'\n",
    "label = 'label'\n",
    "predictor_tune = TabularPredictor(label=label, eval_metric='roc_auc',path=save_path).fit(\n",
    "    train_data,\n",
    "    time_limit=time_limit, presets='optimize_for_deployment',hyperparameters=hyperparameters, hyperparameter_tune_kwargs=hyperparameter_tune_kwargs,verbosity = 4,num_bag_folds=5, num_bag_sets=1, num_stack_levels=0,\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "File delimiter for ./Data/split/test_data_big_balance.csv inferred as ',' (comma). If this is incorrect, please manually load the data as a pandas DataFrame.\n",
      "Loaded data from: ./Data/split/test_data_big_balance.csv | Columns = 31 / 31 | Rows = 2344146 -> 2344146\n",
      "Loading: ./auto_gl/exp-iot23-oversample/deploy-exp/STTACKING2_layer1_search/models/LightGBM_BAG_L1/T1/model.pkl\n",
      "Loading: ./auto_gl/exp-iot23-oversample/deploy-exp/STTACKING2_layer1_search/models/CatBoost_BAG_L1/T1/model.pkl\n",
      "Loading: ./auto_gl/exp-iot23-oversample/deploy-exp/STTACKING2_layer1_search/models/WeightedEnsemble_L2/model.pkl\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** Summary of fit() ***\n",
      "Estimated performance of each model:\n",
      "                 model  score_val  pred_time_val     fit_time  pred_time_val_marginal  fit_time_marginal  stack_level  can_infer  fit_order\n",
      "0  WeightedEnsemble_L2   0.995345       6.820710  2906.922355                1.015193         247.109045            2       True          3\n",
      "1   LightGBM_BAG_L1/T1   0.995344       3.650043    67.277333                3.650043          67.277333            1       True          1\n",
      "2   CatBoost_BAG_L1/T1   0.995332       2.155474  2592.535978                2.155474        2592.535978            1       True          2\n",
      "Number of models trained: 3\n",
      "Types of models trained:\n",
      "{'StackerEnsembleModel_CatBoost', 'StackerEnsembleModel_LGB', 'WeightedEnsembleModel'}\n",
      "Bagging used: True  (with 5 folds)\n",
      "Multi-layer stack-ensembling used: False \n",
      "Feature Metadata (Processed):\n",
      "(raw dtype, special dtypes):\n",
      "('float', [])     : 14 | ['duration', 'orig_bytes', 'resp_bytes', 'missed_bytes', 'orig_pkts', ...]\n",
      "('int', ['bool']) : 16 | ['proto_tcp', 'service_dhcp', 'service_http', 'service_ssh', 'service_ssl', ...]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/media/wuguo-buaa/LENOVO_USB_HDD/PycharmProjects/Machine_learning_venv/lib/python3.8/site-packages/autogluon/core/utils/plots.py:138: UserWarning: AutoGluon summary plots cannot be created because bokeh is not installed. To see plots, please do: \"pip install bokeh==2.0.1\"\n",
      "  warnings.warn('AutoGluon summary plots cannot be created because bokeh is not installed. To see plots, please do: \"pip install bokeh==2.0.1\"')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** End of fit() summary ***\n",
      "{'model_types': {'LightGBM_BAG_L1/T1': 'StackerEnsembleModel_LGB', 'CatBoost_BAG_L1/T1': 'StackerEnsembleModel_CatBoost', 'WeightedEnsemble_L2': 'WeightedEnsembleModel'}, 'model_performance': {'LightGBM_BAG_L1/T1': 0.9953436278383646, 'CatBoost_BAG_L1/T1': 0.9953322011641894, 'WeightedEnsemble_L2': 0.9953447220274515}, 'model_best': 'WeightedEnsemble_L2', 'model_paths': {'LightGBM_BAG_L1/T1': './auto_gl/exp-iot23-oversample/deploy-exp/STTACKING2_layer1_search/models/LightGBM_BAG_L1/T1/', 'CatBoost_BAG_L1/T1': './auto_gl/exp-iot23-oversample/deploy-exp/STTACKING2_layer1_search/models/CatBoost_BAG_L1/T1/', 'WeightedEnsemble_L2': './auto_gl/exp-iot23-oversample/deploy-exp/STTACKING2_layer1_search/models/WeightedEnsemble_L2/'}, 'model_fit_times': {'LightGBM_BAG_L1/T1': 67.27733254432678, 'CatBoost_BAG_L1/T1': 2592.5359778404236, 'WeightedEnsemble_L2': 247.10904502868652}, 'model_pred_times': {'LightGBM_BAG_L1/T1': 3.650043249130249, 'CatBoost_BAG_L1/T1': 2.1554739475250244, 'WeightedEnsemble_L2': 1.015193223953247}, 'num_bag_folds': 5, 'max_stack_level': 2, 'num_classes': 2, 'model_hyperparams': {'LightGBM_BAG_L1/T1': {'use_orig_features': True, 'max_base_models': 25, 'max_base_models_per_type': 5, 'save_bag_folds': True}, 'CatBoost_BAG_L1/T1': {'use_orig_features': True, 'max_base_models': 25, 'max_base_models_per_type': 5, 'save_bag_folds': True}, 'WeightedEnsemble_L2': {'use_orig_features': False, 'max_base_models': 25, 'max_base_models_per_type': 5, 'save_bag_folds': True}}, 'leaderboard':                  model  score_val  pred_time_val     fit_time  \\\n",
      "0  WeightedEnsemble_L2   0.995345       6.820710  2906.922355   \n",
      "1   LightGBM_BAG_L1/T1   0.995344       3.650043    67.277333   \n",
      "2   CatBoost_BAG_L1/T1   0.995332       2.155474  2592.535978   \n",
      "\n",
      "   pred_time_val_marginal  fit_time_marginal  stack_level  can_infer  \\\n",
      "0                1.015193         247.109045            2       True   \n",
      "1                3.650043          67.277333            1       True   \n",
      "2                2.155474        2592.535978            1       True   \n",
      "\n",
      "   fit_order  \n",
      "0          3  \n",
      "1          1  \n",
      "2          2  }\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading: ./auto_gl/exp-iot23-oversample/deploy-exp/STTACKING2_layer1_search/models/WeightedEnsemble_L2/model.pkl\n",
      "Loading: ./auto_gl/exp-iot23-oversample/deploy-exp/STTACKING2_layer1_search/models/CatBoost_BAG_L1/T1/model.pkl\n",
      "Loading: ./auto_gl/exp-iot23-oversample/deploy-exp/STTACKING2_layer1_search/models/LightGBM_BAG_L1/T1/model.pkl\n",
      "Evaluation: roc_auc on test data: 0.995306233529061\n",
      "Evaluations on test data:\n",
      "{\n",
      "    \"roc_auc\": 0.995306233529061,\n",
      "    \"accuracy\": 0.9857483279625074,\n",
      "    \"balanced_accuracy\": 0.9857483279625074,\n",
      "    \"mcc\": 0.9715123024163506,\n",
      "    \"f1\": 0.9857886555969505,\n",
      "    \"precision\": 0.9830070627160703,\n",
      "    \"recall\": 0.9885860351701643\n",
      "}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'roc_auc': 0.995306233529061, 'accuracy': 0.9857483279625074, 'balanced_accuracy': 0.9857483279625074, 'mcc': 0.9715123024163506, 'f1': 0.9857886555969505, 'precision': 0.9830070627160703, 'recall': 0.9885860351701643}\n"
     ]
    }
   ],
   "source": [
    "from autogluon.tabular import TabularPredictor,TabularDataset\n",
    "test_data = TabularDataset(\"./Data/split/test_data_big_balance.csv\")\n",
    "# save_path = './auto_gl/exp-iot23/deploy-exp/XGB'\n",
    "# save_path = './auto_gl/exp-iot23/medium-exp/medium-RF'\n",
    "# predictor_tune = TabularPredictor.load(save_path)\n",
    "print(predictor_tune.fit_summary())\n",
    "perf = predictor_tune.evaluate(test_data, auxiliary_metrics=True)\n",
    "print(perf)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading: ./auto_gl/exp-iot23-oversample/deploy-exp/STTACKING2_layer1_search/models/WeightedEnsemble_L2/model.pkl\n",
      "Loading: ./auto_gl/exp-iot23-oversample/deploy-exp/STTACKING2_layer1_search/models/CatBoost_BAG_L1/T1/model.pkl\n",
      "Loading: ./auto_gl/exp-iot23-oversample/deploy-exp/STTACKING2_layer1_search/models/LightGBM_BAG_L1/T1/model.pkl\n"
     ]
    },
    {
     "data": {
      "text/plain": "7.775620028440516e-06"
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "t0 = time.time()\n",
    "predictor_tune.predict(test_data)\n",
    "t1 = time.time()\n",
    "# print(t0,t1)\n",
    "# perf = predictor_tune.evaluate(test_data, auxiliary_metrics=True)\n",
    "# print(perf)\n",
    "(t1-t0)/2344146"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading: ./auto_gl/exp-iot23-oversample/deploy-exp/RF_search/models/RandomForest/model.pkl\n",
      "Loading: ./auto_gl/exp-iot23-oversample/deploy-exp/RF_search/models/RandomForest/info.pkl\n",
      "Loading: ./auto_gl/exp-iot23-oversample/deploy-exp/RF_search/models/RandomForest/model.pkl\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'name': 'RandomForest', 'model_type': 'RFModel', 'problem_type': 'binary', 'eval_metric': 'roc_auc', 'stopping_metric': 'log_loss', 'fit_time': 229.2842116355896, 'num_classes': 2, 'quantile_levels': None, 'predict_time': 107.53102731704712, 'val_score': 0.9947523345006606, 'hyperparameters': {'n_estimators': 300, 'n_jobs': -1, 'random_state': 0, 'bootstrap': True}, 'hyperparameters_fit': {'n_estimators': 300}, 'hyperparameters_nondefault': [], 'ag_args_fit': {'max_memory_usage_ratio': 1.0, 'max_time_limit_ratio': 1.0, 'max_time_limit': None, 'min_time_limit': 0, 'valid_raw_types': ['bool', 'int', 'float', 'category'], 'valid_special_types': None, 'ignored_type_group_special': None, 'ignored_type_group_raw': None, 'get_features_kwargs': None, 'get_features_kwargs_extra': None, 'predict_1_batch_size': None, 'num_gpus': 1}, 'num_features': 30, 'features': ['duration', 'orig_bytes', 'resp_bytes', 'missed_bytes', 'orig_pkts', 'orig_ip_bytes', 'resp_pkts', 'resp_ip_bytes', 'proto_icmp', 'proto_tcp', 'proto_udp', 'service_-', 'service_dhcp', 'service_dns', 'service_http', 'service_ssh', 'service_ssl', 'service_irc', 'conn_state_OTH', 'conn_state_REJ', 'conn_state_RSTO', 'conn_state_RSTOS0', 'conn_state_RSTR', 'conn_state_S0', 'conn_state_S1', 'conn_state_S2', 'conn_state_S3', 'conn_state_SF', 'conn_state_SH', 'conn_state_SHR'], 'feature_metadata': <autogluon.common.features.feature_metadata.FeatureMetadata object at 0x7f2c282551f0>, 'memory_size': 372128886}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading: ./auto_gl/exp-iot23-oversample/deploy-exp/RF_search/models/WeightedEnsemble_L2/info.pkl\n",
      "Loading: ./auto_gl/exp-iot23-oversample/deploy-exp/RF_search/models/WeightedEnsemble_L2/model.pkl\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'path': './auto_gl/exp-iot23-oversample/deploy-exp/RF_search/', 'label': 'label', 'random_state': 0, 'version': '0.4.0', 'features': ['duration', 'orig_bytes', 'resp_bytes', 'missed_bytes', 'orig_pkts', 'orig_ip_bytes', 'resp_pkts', 'resp_ip_bytes', 'proto_icmp', 'proto_tcp', 'proto_udp', 'service_-', 'service_dhcp', 'service_dns', 'service_http', 'service_ssh', 'service_ssl', 'service_irc', 'conn_state_OTH', 'conn_state_REJ', 'conn_state_RSTO', 'conn_state_RSTOS0', 'conn_state_RSTR', 'conn_state_S0', 'conn_state_S1', 'conn_state_S2', 'conn_state_S3', 'conn_state_SF', 'conn_state_SH', 'conn_state_SHR'], 'feature_metadata_in': <autogluon.common.features.feature_metadata.FeatureMetadata object at 0x7f2c4c0b4af0>, 'time_fit_preprocessing': 26.565864324569702, 'time_fit_training': 348.50979232788086, 'time_fit_total': 375.07565665245056, 'time_limit': 36000, 'time_train_start': 1653103227.608024, 'num_rows_train': 5469674, 'num_cols_train': 30, 'num_classes': 2, 'problem_type': 'binary', 'eval_metric': 'roc_auc', 'best_model': 'WeightedEnsemble_L2', 'best_model_score_val': 0.9945616479389987, 'best_model_stack_level': 2, 'num_models_trained': 2, 'num_bag_folds': 0, 'max_stack_level': 2, 'max_core_stack_level': 1, 'model_info': {'RandomForest': {'name': 'RandomForest', 'model_type': 'RFModel', 'problem_type': 'binary', 'eval_metric': 'roc_auc', 'stopping_metric': 'log_loss', 'fit_time': 229.2842116355896, 'num_classes': 2, 'quantile_levels': None, 'predict_time': 107.53102731704712, 'val_score': 0.9947523345006606, 'hyperparameters': {'n_estimators': 300, 'n_jobs': -1, 'random_state': 0, 'bootstrap': True}, 'hyperparameters_fit': {'n_estimators': 300}, 'hyperparameters_nondefault': [], 'ag_args_fit': {'max_memory_usage_ratio': 1.0, 'max_time_limit_ratio': 1.0, 'max_time_limit': None, 'min_time_limit': 0, 'valid_raw_types': ['bool', 'int', 'float', 'category'], 'valid_special_types': None, 'ignored_type_group_special': None, 'ignored_type_group_raw': None, 'get_features_kwargs': None, 'get_features_kwargs_extra': None, 'predict_1_batch_size': None, 'num_gpus': 1}, 'num_features': 30, 'features': ['duration', 'orig_bytes', 'resp_bytes', 'missed_bytes', 'orig_pkts', 'orig_ip_bytes', 'resp_pkts', 'resp_ip_bytes', 'proto_icmp', 'proto_tcp', 'proto_udp', 'service_-', 'service_dhcp', 'service_dns', 'service_http', 'service_ssh', 'service_ssl', 'service_irc', 'conn_state_OTH', 'conn_state_REJ', 'conn_state_RSTO', 'conn_state_RSTOS0', 'conn_state_RSTR', 'conn_state_S0', 'conn_state_S1', 'conn_state_S2', 'conn_state_S3', 'conn_state_SF', 'conn_state_SH', 'conn_state_SHR'], 'feature_metadata': <autogluon.common.features.feature_metadata.FeatureMetadata object at 0x7f2c2830ac10>, 'memory_size': 372128886}, 'WeightedEnsemble_L2': {'name': 'WeightedEnsemble_L2', 'model_type': 'WeightedEnsembleModel', 'problem_type': 'binary', 'eval_metric': 'roc_auc', 'stopping_metric': 'roc_auc', 'fit_time': 0.018808364868164062, 'num_classes': 2, 'quantile_levels': None, 'predict_time': 0.014421939849853516, 'val_score': 0.9945616479389987, 'hyperparameters': {'use_orig_features': False, 'max_base_models': 25, 'max_base_models_per_type': 5, 'save_bag_folds': True}, 'hyperparameters_fit': {}, 'hyperparameters_nondefault': ['save_bag_folds'], 'ag_args_fit': {'max_memory_usage_ratio': 1.0, 'max_time_limit_ratio': 1.0, 'max_time_limit': None, 'min_time_limit': 0, 'valid_raw_types': None, 'valid_special_types': None, 'ignored_type_group_special': None, 'ignored_type_group_raw': None, 'get_features_kwargs': None, 'get_features_kwargs_extra': None, 'predict_1_batch_size': None, 'drop_unique': False}, 'num_features': 1, 'features': ['RandomForest'], 'feature_metadata': <autogluon.common.features.feature_metadata.FeatureMetadata object at 0x7f2c29980460>, 'memory_size': 2670, 'bagged_info': {'child_model_type': 'GreedyWeightedEnsembleModel', 'num_child_models': 1, 'child_model_names': ['S1F1'], '_n_repeats': 1, '_k_per_n_repeat': [1], '_random_state': 2, 'low_memory': False, 'bagged_mode': False, 'max_memory_size': 2670, 'min_memory_size': 2670, 'child_hyperparameters': {'ensemble_size': 100}, 'child_hyperparameters_fit': {'ensemble_size': 1}, 'child_ag_args_fit': {'max_memory_usage_ratio': 1.0, 'max_time_limit_ratio': 1.0, 'max_time_limit': None, 'min_time_limit': 0, 'valid_raw_types': None, 'valid_special_types': None, 'ignored_type_group_special': None, 'ignored_type_group_raw': None, 'get_features_kwargs': None, 'get_features_kwargs_extra': None, 'predict_1_batch_size': None, 'drop_unique': False}}, 'stacker_info': {'num_base_models': 1, 'base_model_names': ['RandomForest']}, 'children_info': {'S1F1': {'name': 'S1F1', 'model_type': 'GreedyWeightedEnsembleModel', 'problem_type': 'binary', 'eval_metric': 'roc_auc', 'stopping_metric': 'roc_auc', 'fit_time': 0.018808364868164062, 'num_classes': 2, 'quantile_levels': None, 'predict_time': None, 'val_score': None, 'hyperparameters': {'ensemble_size': 100}, 'hyperparameters_fit': {'ensemble_size': 1}, 'hyperparameters_nondefault': [], 'ag_args_fit': {'max_memory_usage_ratio': 1.0, 'max_time_limit_ratio': 1.0, 'max_time_limit': None, 'min_time_limit': 0, 'valid_raw_types': None, 'valid_special_types': None, 'ignored_type_group_special': None, 'ignored_type_group_raw': None, 'get_features_kwargs': None, 'get_features_kwargs_extra': None, 'predict_1_batch_size': None, 'drop_unique': False}, 'num_features': 1, 'features': ['RandomForest'], 'feature_metadata': <autogluon.common.features.feature_metadata.FeatureMetadata object at 0x7f2c299808b0>, 'memory_size': 4891, 'model_weights': {'RandomForest': 1.0}}}}}}\n"
     ]
    }
   ],
   "source": [
    "all_models = predictor_tune.get_model_names()\n",
    "model_to_use = all_models[0]\n",
    "specific_model = predictor_tune._trainer.load_model(model_to_use)\n",
    "\n",
    "# Objects defined below are dicts of various information (not printed here as they are quite large):\n",
    "model_info = specific_model.get_info()\n",
    "print(model_info)\n",
    "predictor_information = predictor_tune.info()\n",
    "print(predictor_information)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading: ./auto_gl/exp-iot23/medium-RF/models/WeightedEnsemble_L2/model.pkl\n",
      "Loading: ./auto_gl/exp-iot23/medium-RF/models/RandomForest/model.pkl\n",
      "Evaluation: roc_auc on test data: 0.9078832396305138\n",
      "Evaluations on test data:\n",
      "{\n",
      "    \"roc_auc\": 0.9078832396305138,\n",
      "    \"accuracy\": 0.8570673886485951,\n",
      "    \"balanced_accuracy\": 0.8565192713238672,\n",
      "    \"mcc\": 0.7246394502001015,\n",
      "    \"f1\": 0.8425302826379543,\n",
      "    \"precision\": 0.9307241019046854,\n",
      "    \"recall\": 0.7696039340776183\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "perf = predictor_tune.evaluate(test_data, auxiliary_metrics=True)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [
    {
     "data": {
      "text/plain": "['duration',\n 'orig_bytes',\n 'resp_bytes',\n 'missed_bytes',\n 'orig_pkts',\n 'orig_ip_bytes',\n 'resp_pkts',\n 'resp_ip_bytes',\n 'proto_icmp',\n 'proto_tcp',\n 'proto_udp',\n 'service_-',\n 'service_dhcp',\n 'service_dns',\n 'service_http',\n 'service_ssh',\n 'service_ssl',\n 'service_irc',\n 'conn_state_OTH',\n 'conn_state_REJ',\n 'conn_state_RSTO',\n 'conn_state_RSTOS0',\n 'conn_state_RSTR',\n 'conn_state_S0',\n 'conn_state_S1',\n 'conn_state_S2',\n 'conn_state_S3',\n 'conn_state_SF',\n 'conn_state_SH',\n 'conn_state_SHR']"
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictor_tune.features()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [
    {
     "data": {
      "text/plain": "'WeightedEnsemble_L2'"
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictor_tune.get_model_best()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading: AutogluonModels/ag-20220513_042729/models/LightGBM/T1/info.pkl\n",
      "Loading: AutogluonModels/ag-20220513_042729/models/LightGBM/T1/model.pkl\n",
      "Loading: AutogluonModels/ag-20220513_042729/models/WeightedEnsemble_L2/info.pkl\n",
      "Loading: AutogluonModels/ag-20220513_042729/models/WeightedEnsemble_L2/model.pkl\n"
     ]
    },
    {
     "data": {
      "text/plain": "                 model  score_val  pred_time_val  fit_time  \\\n0          LightGBM/T1        1.0       0.028088  0.593865   \n1  WeightedEnsemble_L2        1.0       0.033417  4.233542   \n\n   pred_time_val_marginal  fit_time_marginal  stack_level  can_infer  \\\n0                0.028088           0.593865            1       True   \n1                0.005329           3.639677            2       True   \n\n   fit_order  num_features  ...             child_model_type  \\\n0          1            30  ...                         None   \n1          2             1  ...  GreedyWeightedEnsembleModel   \n\n                                                                                                      hyperparameters  \\\n0  {'learning_rate': 0.05, 'num_boost_round': 100, 'num_leaves': 36, 'feature_fraction': 1.0, 'min_data_in_leaf': 20}   \n1          {'use_orig_features': False, 'max_base_models': 25, 'max_base_models_per_type': 5, 'save_bag_folds': True}   \n\n        hyperparameters_fit  \\\n0  {'num_boost_round': 100}   \n1                        {}   \n\n                                                                                                                                                                                                                                                                                                                                                                        ag_args_fit  \\\n0  {'max_memory_usage_ratio': 1.0, 'max_time_limit_ratio': 1.0, 'max_time_limit': None, 'min_time_limit': 0, 'valid_raw_types': ['bool', 'int', 'float', 'category'], 'valid_special_types': None, 'ignored_type_group_special': None, 'ignored_type_group_raw': None, 'get_features_kwargs': None, 'get_features_kwargs_extra': None, 'predict_1_batch_size': None, 'num_gpus': 1}   \n1                           {'max_memory_usage_ratio': 1.0, 'max_time_limit_ratio': 1.0, 'max_time_limit': None, 'min_time_limit': 0, 'valid_raw_types': None, 'valid_special_types': None, 'ignored_type_group_special': None, 'ignored_type_group_raw': None, 'get_features_kwargs': None, 'get_features_kwargs_extra': None, 'predict_1_batch_size': None, 'drop_unique': False}   \n\n                                                                                                                                                                                                                                                                                                                                                                                                                           features  \\\n0  [duration, orig_bytes, resp_bytes, missed_bytes, orig_pkts, orig_ip_bytes, resp_pkts, resp_ip_bytes, proto_icmp, proto_tcp, proto_udp, service_-, service_dhcp, service_dns, service_http, service_ssh, service_ssl, service_irc, conn_state_OTH, conn_state_REJ, conn_state_RSTO, conn_state_RSTOS0, conn_state_RSTR, conn_state_S0, conn_state_S1, conn_state_S2, conn_state_S3, conn_state_SF, conn_state_SH, conn_state_SHR]   \n1                                                                                                                                                                                                                                                                                                                                                                                                                     [LightGBM/T1]   \n\n    child_hyperparameters  child_hyperparameters_fit  \\\n0                    None                       None   \n1  {'ensemble_size': 100}       {'ensemble_size': 1}   \n\n                                                                                                                                                                                                                                                                                                                                         child_ag_args_fit  \\\n0                                                                                                                                                                                                                                                                                                                                                     None   \n1  {'max_memory_usage_ratio': 1.0, 'max_time_limit_ratio': 1.0, 'max_time_limit': None, 'min_time_limit': 0, 'valid_raw_types': None, 'valid_special_types': None, 'ignored_type_group_special': None, 'ignored_type_group_raw': None, 'get_features_kwargs': None, 'get_features_kwargs_extra': None, 'predict_1_batch_size': None, 'drop_unique': False}   \n\n       ancestors            descendants  \n0             []  [WeightedEnsemble_L2]  \n1  [LightGBM/T1]                     []  \n\n[2 rows x 29 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>model</th>\n      <th>score_val</th>\n      <th>pred_time_val</th>\n      <th>fit_time</th>\n      <th>pred_time_val_marginal</th>\n      <th>fit_time_marginal</th>\n      <th>stack_level</th>\n      <th>can_infer</th>\n      <th>fit_order</th>\n      <th>num_features</th>\n      <th>...</th>\n      <th>child_model_type</th>\n      <th>hyperparameters</th>\n      <th>hyperparameters_fit</th>\n      <th>ag_args_fit</th>\n      <th>features</th>\n      <th>child_hyperparameters</th>\n      <th>child_hyperparameters_fit</th>\n      <th>child_ag_args_fit</th>\n      <th>ancestors</th>\n      <th>descendants</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>LightGBM/T1</td>\n      <td>1.0</td>\n      <td>0.028088</td>\n      <td>0.593865</td>\n      <td>0.028088</td>\n      <td>0.593865</td>\n      <td>1</td>\n      <td>True</td>\n      <td>1</td>\n      <td>30</td>\n      <td>...</td>\n      <td>None</td>\n      <td>{'learning_rate': 0.05, 'num_boost_round': 100, 'num_leaves': 36, 'feature_fraction': 1.0, 'min_data_in_leaf': 20}</td>\n      <td>{'num_boost_round': 100}</td>\n      <td>{'max_memory_usage_ratio': 1.0, 'max_time_limit_ratio': 1.0, 'max_time_limit': None, 'min_time_limit': 0, 'valid_raw_types': ['bool', 'int', 'float', 'category'], 'valid_special_types': None, 'ignored_type_group_special': None, 'ignored_type_group_raw': None, 'get_features_kwargs': None, 'get_features_kwargs_extra': None, 'predict_1_batch_size': None, 'num_gpus': 1}</td>\n      <td>[duration, orig_bytes, resp_bytes, missed_bytes, orig_pkts, orig_ip_bytes, resp_pkts, resp_ip_bytes, proto_icmp, proto_tcp, proto_udp, service_-, service_dhcp, service_dns, service_http, service_ssh, service_ssl, service_irc, conn_state_OTH, conn_state_REJ, conn_state_RSTO, conn_state_RSTOS0, conn_state_RSTR, conn_state_S0, conn_state_S1, conn_state_S2, conn_state_S3, conn_state_SF, conn_state_SH, conn_state_SHR]</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>[]</td>\n      <td>[WeightedEnsemble_L2]</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>WeightedEnsemble_L2</td>\n      <td>1.0</td>\n      <td>0.033417</td>\n      <td>4.233542</td>\n      <td>0.005329</td>\n      <td>3.639677</td>\n      <td>2</td>\n      <td>True</td>\n      <td>2</td>\n      <td>1</td>\n      <td>...</td>\n      <td>GreedyWeightedEnsembleModel</td>\n      <td>{'use_orig_features': False, 'max_base_models': 25, 'max_base_models_per_type': 5, 'save_bag_folds': True}</td>\n      <td>{}</td>\n      <td>{'max_memory_usage_ratio': 1.0, 'max_time_limit_ratio': 1.0, 'max_time_limit': None, 'min_time_limit': 0, 'valid_raw_types': None, 'valid_special_types': None, 'ignored_type_group_special': None, 'ignored_type_group_raw': None, 'get_features_kwargs': None, 'get_features_kwargs_extra': None, 'predict_1_batch_size': None, 'drop_unique': False}</td>\n      <td>[LightGBM/T1]</td>\n      <td>{'ensemble_size': 100}</td>\n      <td>{'ensemble_size': 1}</td>\n      <td>{'max_memory_usage_ratio': 1.0, 'max_time_limit_ratio': 1.0, 'max_time_limit': None, 'min_time_limit': 0, 'valid_raw_types': None, 'valid_special_types': None, 'ignored_type_group_special': None, 'ignored_type_group_raw': None, 'get_features_kwargs': None, 'get_features_kwargs_extra': None, 'predict_1_batch_size': None, 'drop_unique': False}</td>\n      <td>[LightGBM/T1]</td>\n      <td>[]</td>\n    </tr>\n  </tbody>\n</table>\n<p>2 rows  29 columns</p>\n</div>"
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictor_tune.leaderboard(extra_info=True, silent=True)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# only for test"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://mirrors.aliyun.com/pypi/simple/\r\n",
      "Requirement already satisfied: bokeh==2.0.1 in /media/wuguo-buaa/LENOVO_USB_HDD/PycharmProjects/Machine_learning_venv/lib/python3.8/site-packages (2.0.1)\r\n",
      "Requirement already satisfied: python-dateutil>=2.1 in /media/wuguo-buaa/LENOVO_USB_HDD/PycharmProjects/Machine_learning_venv/lib/python3.8/site-packages (from bokeh==2.0.1) (2.8.2)\r\n",
      "Requirement already satisfied: pillow>=4.0 in /media/wuguo-buaa/LENOVO_USB_HDD/PycharmProjects/Machine_learning_venv/lib/python3.8/site-packages (from bokeh==2.0.1) (9.0.1)\r\n",
      "Requirement already satisfied: numpy>=1.11.3 in /media/wuguo-buaa/LENOVO_USB_HDD/PycharmProjects/Machine_learning_venv/lib/python3.8/site-packages (from bokeh==2.0.1) (1.22.3)\r\n",
      "Requirement already satisfied: tornado>=5 in /media/wuguo-buaa/LENOVO_USB_HDD/PycharmProjects/Machine_learning_venv/lib/python3.8/site-packages (from bokeh==2.0.1) (6.1)\r\n",
      "Requirement already satisfied: typing-extensions>=3.7.4 in /media/wuguo-buaa/LENOVO_USB_HDD/PycharmProjects/Machine_learning_venv/lib/python3.8/site-packages (from bokeh==2.0.1) (4.2.0)\r\n",
      "Requirement already satisfied: Jinja2>=2.7 in /media/wuguo-buaa/LENOVO_USB_HDD/PycharmProjects/Machine_learning_venv/lib/python3.8/site-packages (from bokeh==2.0.1) (3.1.2)\r\n",
      "Requirement already satisfied: PyYAML>=3.10 in /media/wuguo-buaa/LENOVO_USB_HDD/PycharmProjects/Machine_learning_venv/lib/python3.8/site-packages (from bokeh==2.0.1) (6.0)\r\n",
      "Requirement already satisfied: packaging>=16.8 in /media/wuguo-buaa/LENOVO_USB_HDD/PycharmProjects/Machine_learning_venv/lib/python3.8/site-packages (from bokeh==2.0.1) (21.3)\r\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /media/wuguo-buaa/LENOVO_USB_HDD/PycharmProjects/Machine_learning_venv/lib/python3.8/site-packages (from Jinja2>=2.7->bokeh==2.0.1) (2.1.1)\r\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /media/wuguo-buaa/LENOVO_USB_HDD/PycharmProjects/Machine_learning_venv/lib/python3.8/site-packages (from packaging>=16.8->bokeh==2.0.1) (3.0.8)\r\n",
      "Requirement already satisfied: six>=1.5 in /media/wuguo-buaa/LENOVO_USB_HDD/PycharmProjects/Machine_learning_venv/lib/python3.8/site-packages (from python-dateutil>=2.1->bokeh==2.0.1) (1.16.0)\r\n"
     ]
    }
   ],
   "source": [
    "!pip install bokeh==2.0.1"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loaded data from: ./Data/test/iot23_Benign_combined_all.csv | Columns = 31 / 31 | Rows = 2800645 -> 2800645\n"
     ]
    }
   ],
   "source": [
    "from autogluon.tabular import TabularPredictor,TabularDataset\n",
    "test_data = TabularDataset(\"./Data/test/iot23_Benign_combined_all.csv\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading: ./auto_gl/exp-iot23-oversample/deploy-exp/FastAI/predictor.pkl\n",
      "Loading: ./auto_gl/exp-iot23-oversample/deploy-exp/FastAI/learner.pkl\n",
      "Loading: ./auto_gl/exp-iot23-oversample/deploy-exp/FastAI/models/trainer.pkl\n",
      "Loading: ./auto_gl/exp-iot23-oversample/deploy-exp/FastAI/models/WeightedEnsemble_L2/model.pkl\n",
      "Loading: ./auto_gl/exp-iot23-oversample/deploy-exp/FastAI/models/NeuralNetFastAI/T1/model.pkl\n",
      "Loading: ./auto_gl/exp-iot23-oversample/deploy-exp/FastAI/models/NeuralNetFastAI/T1/model-internals.pkl\n"
     ]
    },
    {
     "data": {
      "text/plain": "1.0252934649032988e-05"
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import time\n",
    "# save_path = './auto_gl/exp-iot23-oversample/deploy-exp/XGB'\n",
    "predictor_tune = TabularPredictor.load(save_path)\n",
    "label = 'label'\n",
    "# print(predictor_tune.fit_summary())\n",
    "t0 = time.time()\n",
    "predictor_tune.predict(test_data)\n",
    "t1 = time.time()\n",
    "# print(t0,t1)\n",
    "# perf = predictor_tune.evaluate(test_data, auxiliary_metrics=True)\n",
    "# print(perf)\n",
    "(t1-t0)/2800645"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [
    {
     "data": {
      "text/plain": "4.648589836587212e-06"
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(t1-t0)/2800645"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# ToN iot"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [],
   "source": [
    "import autogluon.core as ag\n",
    "\n",
    "nn_options = {  # specifies non-default hyperparameter values for neural network models\n",
    "    'num_epochs': 50,\n",
    "        'learning_rate': ag.space.Real(1e-4, 3e-2, default=3e-4, log=True),\n",
    "        'weight_decay': ag.space.Real(1e-12, 0.1, default=1e-6, log=True),\n",
    "        'dropout_prob': ag.space.Categorical(0.1, 0.0, 0.5, 0.2, 0.3, 0.4),\n",
    "        'embedding_size_factor': ag.space.Categorical(1.0, 0.5, 1.5, 0.7, 0.6, 0.8, 0.9, 1.1, 1.2, 1.3, 1.4),\n",
    "        'proc.embed_min_categories': ag.space.Categorical(4, 3, 10, 100, 1000),\n",
    "        'proc.impute_strategy': ag.space.Categorical('median', 'mean', 'most_frequent'),\n",
    "        'proc.max_category_levels': ag.space.Categorical(100, 10, 20, 200, 300, 400, 500, 1000, 10000),\n",
    "        'proc.skew_threshold': ag.space.Categorical(0.99, 0.2, 0.3, 0.5, 0.8, 0.9, 0.999, 1.0, 10.0, 100.0),\n",
    "        'num_layers': ag.space.Categorical(2, 3, 4),\n",
    "        'hidden_size': ag.space.Categorical(128, 256, 512),\n",
    "        'activation': ag.space.Categorical('relu', 'elu'),\n",
    "    'use_batchnorm':True\n",
    "}\n",
    "nn_option_best = {'num_epochs': 50, 'epochs_wo_improve': 20, 'activation': 'elu', 'embedding_size_factor': 1.5, 'embed_exponent': 0.56, 'max_embedding_dim': 100, 'y_range': None, 'y_range_extend': 0.05, 'dropout_prob': 0.0, 'optimizer': 'adam', 'learning_rate': 0.0009692634970399649, 'weight_decay': 9.401548382548757e-08, 'proc.embed_min_categories': 10, 'proc.impute_strategy': 'mean', 'proc.max_category_levels': 400, 'proc.skew_threshold': 0.9, 'use_ngram_features': False, 'num_layers': 3, 'hidden_size': 256, 'max_batch_size': 512, 'use_batchnorm': True, 'loss_function': 'auto'}\n",
    "CAT_options = {\n",
    "    'learning_rate': ag.space.Real(lower=5e-3, upper=0.2, default=0.05, log=True),\n",
    "        'depth': ag.space.Int(lower=5, upper=8, default=6),\n",
    "        'l2_leaf_reg': ag.space.Real(lower=1, upper=5, default=3),\n",
    "}\n",
    "CAT_option_best ={'iterations': 10000, 'learning_rate': 0.04042960750241689, 'random_seed': 0, 'allow_writing_files': False, 'eval_metric': 'Logloss', 'depth': 8, 'l2_leaf_reg': 3.7698884774800794}\n",
    "\n",
    "gbm_options = {  # specifies non-default hyperparameter values for lightGBM gradient boosted trees\n",
    "    'num_boost_round': 100,  # number of boosting rounds (controls training time of GBM models)\n",
    "    'num_leaves': ag.space.Int(lower=26, upper=66, default=36),  # number of leaves in trees (integer hyperparameter)\n",
    "            'learning_rate': ag.space.Real(lower=5e-3, upper=0.2, default=0.05, log=True),\n",
    "        'feature_fraction': ag.space.Real(lower=0.75, upper=1.0, default=1.0),\n",
    "        'min_data_in_leaf': ag.space.Int(lower=2, upper=60, default=20),  # TODO: Use size of dataset to set upper, if row count is small upper should be small\n",
    "}\n",
    "gbm_option_best ={\n",
    "    'learning_rate': 0.103335706015396,\n",
    "    'num_boost_round': 100,\n",
    "    'num_leaves': 62,\n",
    "    'feature_fraction': 0.842181292665241,\n",
    "    'min_data_in_leaf': 2}\n",
    "XGB_option_best = {'n_estimators': 10000, 'learning_rate': 0.1, 'n_jobs': -1, 'proc.max_category_levels': 100, 'objective': 'binary:logistic', 'booster': 'gbtree', 'use_label_encoder': False, 'max_depth': 6, 'min_child_weight': 1, 'gamma': 0.01, 'subsample': 1.0, 'colsample_bytree': 1.0, 'reg_alpha': 0.0, 'reg_lambda': 1.0}\n",
    "\n",
    "XGB_option ={\n",
    "            'learning_rate': ag.space.Real(lower=5e-3, upper=0.2, default=0.1, log=True),\n",
    "        'max_depth': ag.space.Int(lower=3, upper=10, default=6),\n",
    "        'min_child_weight': ag.space.Int(lower=1, upper=5, default=1),\n",
    "        'gamma': ag.space.Real(lower=0, upper=5, default=0.01),\n",
    "        'subsample': ag.space.Real(lower=0.5, upper=1.0, default=1.0),\n",
    "        'colsample_bytree': ag.space.Real(lower=0.5, upper=1.0, default=1.0),\n",
    "        'reg_alpha': ag.space.Real(lower=0.0, upper=10.0, default=0.0),\n",
    "        'reg_lambda': ag.space.Real(lower=0.0, upper=10.0, default=1.0),\n",
    "}\n",
    "\n",
    "XT_options = {}\n",
    "RF_option = {}\n",
    "FASTAI_options = {\n",
    "            # 'layers': ag.space.Categorical(None, [200, 100], [200], [500],  [500, 200], [50, 25], [200, 100, 50], [500, 200, 100]),\n",
    "        'emb_drop': ag.space.Real(0.0, 0.5, default=0.2),\n",
    "        'ps': ag.space.Real(0.0, 0.5, default=0.1),\n",
    "        'bs': ag.space.Categorical(256, 64, 128, 512, 1024, 2048, 4096),\n",
    "        'lr': ag.space.Real(5e-5, 1e-1, default=1e-3, log=True),\n",
    "}\n",
    "hyperparameters = {  # hyperparameters of each model type\n",
    "    # 'XGB': XGB_option_best\n",
    "    'RF':RF_option,\n",
    "    'XT' : XT_options,\n",
    "    # 'GBM': gbm_options,\n",
    "    #  'CAT' : CAT_option_best,\n",
    "    # 'NN_TORCH': nn_options,  # NOTE: comment this line out if you get errors on Mac OSX\n",
    "\n",
    "}  # When these keys are missing from hyperparameters dict, no models of that type are trained\n",
    "\n",
    "time_limit = 600 * 60  # train various models for ~2 min\n",
    "num_trials = 50  # try at most 5 different hyperparameter configurations for each type of model\n",
    "search_strategy = 'auto'  # to tune hyperparameters using random search routine with a local scheduler\n",
    "\n",
    "hyperparameter_tune_kwargs = {  # HPO is not performed unless hyperparameter_tune_kwargs is specified\n",
    "    'num_trials': num_trials,\n",
    "    'scheduler': 'local',\n",
    "    'searcher': search_strategy,\n",
    "}"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "File delimiter for ./Data/split/train_data_ToN_big_balance.csv inferred as ',' (comma). If this is incorrect, please manually load the data as a pandas DataFrame.\n",
      "Loaded data from: ./Data/split/train_data_ToN_big_balance.csv | Columns = 41 / 41 | Rows = 475881 -> 475881\n",
      "Warning: path already exists! This predictor may overwrite an existing predictor! path=\"./auto_gl/ToN-iot-oversample/deploy-exp/STACCKING2_1layer_search\"\n",
      "Presets specified: ['optimize_for_deployment']\n",
      "============ fit kwarg info ============\n",
      "User Specified kwargs:\n",
      "{'ag_args_fit': {'num_gpus': 1},\n",
      " 'hyperparameter_tune_kwargs': {'num_trials': 50,\n",
      "                                'scheduler': 'local',\n",
      "                                'searcher': 'auto'},\n",
      " 'keep_only_best': True,\n",
      " 'num_bag_folds': 5,\n",
      " 'num_bag_sets': 1,\n",
      " 'num_stack_levels': 0,\n",
      " 'save_space': True,\n",
      " 'verbosity': 4}\n",
      "Full kwargs:\n",
      "{'_feature_generator_kwargs': None,\n",
      " '_save_bag_folds': None,\n",
      " 'ag_args': None,\n",
      " 'ag_args_ensemble': None,\n",
      " 'ag_args_fit': {'num_gpus': 1},\n",
      " 'auto_stack': False,\n",
      " 'calibrate': 'auto',\n",
      " 'excluded_model_types': None,\n",
      " 'feature_generator': 'auto',\n",
      " 'feature_prune_kwargs': None,\n",
      " 'holdout_frac': None,\n",
      " 'hyperparameter_tune_kwargs': {'num_trials': 50,\n",
      "                                'scheduler': 'local',\n",
      "                                'searcher': 'auto'},\n",
      " 'keep_only_best': True,\n",
      " 'name_suffix': None,\n",
      " 'num_bag_folds': 5,\n",
      " 'num_bag_sets': 1,\n",
      " 'num_stack_levels': 0,\n",
      " 'pseudo_data': None,\n",
      " 'quantile_levels': None,\n",
      " 'refit_full': False,\n",
      " 'save_space': True,\n",
      " 'set_best_to_refit_full': False,\n",
      " 'unlabeled_data': None,\n",
      " 'use_bag_holdout': False,\n",
      " 'verbosity': 4}\n",
      "========================================\n",
      "Warning: hyperparameter tuning is currently experimental and may cause the process to hang.\n",
      "Saving ./auto_gl/ToN-iot-oversample/deploy-exp/STACCKING2_1layer_search/learner.pkl\n",
      "Saving ./auto_gl/ToN-iot-oversample/deploy-exp/STACCKING2_1layer_search/predictor.pkl\n",
      "Beginning AutoGluon training ... Time limit = 36000s\n",
      "AutoGluon will save models to \"./auto_gl/ToN-iot-oversample/deploy-exp/STACCKING2_1layer_search/\"\n",
      "AutoGluon Version:  0.4.0\n",
      "Python Version:     3.8.13\n",
      "Operating System:   Linux\n",
      "Train Data Rows:    475881\n",
      "Train Data Columns: 40\n",
      "Label Column: label\n",
      "Preprocessing data ...\n",
      "AutoGluon infers your prediction problem is: 'binary' (because only two unique label-values observed).\n",
      "\t2 unique label values:  ['Benign', 'Malicious']\n",
      "\tIf 'binary' is not the correct problem_type, please manually specify the problem_type parameter during predictor init (You may specify problem_type as one of: ['binary', 'multiclass', 'regression'])\n",
      "Selected class <--> label mapping:  class 1 = Malicious, class 0 = Benign\n",
      "\tNote: For your binary classification, AutoGluon arbitrarily selected which label-value represents positive (Malicious) vs negative (Benign) class.\n",
      "\tTo explicitly set the positive_class, either rename classes to 1 and 0, or specify positive_class in Predictor init.\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    9474.65 MB\n",
      "\tTrain Data (Original)  Memory Usage: 152.28 MB (1.6% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\t\t\tNote: Converting 4 features to boolean dtype as they only contain 2 unique values.\n",
      "\t\t\tOriginal Features (exact raw dtype, raw dtype):\n",
      "\t\t\t\t('float64', 'float') : 40 | ['src_ip_bytes', 'proto_tcp', 'src_bytes', 'dst_ip_bytes', 'src_pkts', ...]\n",
      "\t\t\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t\t\t('float', []) : 40 | ['src_ip_bytes', 'proto_tcp', 'src_bytes', 'dst_ip_bytes', 'src_pkts', ...]\n",
      "\t\t\tTypes of features in processed data (exact raw dtype, raw dtype):\n",
      "\t\t\t\t('float64', 'float') : 36 | ['src_ip_bytes', 'proto_tcp', 'src_bytes', 'dst_ip_bytes', 'src_pkts', ...]\n",
      "\t\t\t\t('int8', 'int')      :  4 | ['dns_qtype_12', 'dns_rcode_2', 'service_gssapi', 'service_dce_rpc']\n",
      "\t\t\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t\t\t('float', [])     : 36 | ['src_ip_bytes', 'proto_tcp', 'src_bytes', 'dst_ip_bytes', 'src_pkts', ...]\n",
      "\t\t\t\t('int', ['bool']) :  4 | ['dns_qtype_12', 'dns_rcode_2', 'service_gssapi', 'service_dce_rpc']\n",
      "\t\t\t0.7s = Fit runtime\n",
      "\t\t\t40 features in original data used to generate 40 features in processed data.\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\t\t\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t\t\t('float', [])     : 36 | ['src_ip_bytes', 'proto_tcp', 'src_bytes', 'dst_ip_bytes', 'src_pkts', ...]\n",
      "\t\t\t\t('int', ['bool']) :  4 | ['dns_qtype_12', 'dns_rcode_2', 'service_gssapi', 'service_dce_rpc']\n",
      "\t\t\tTypes of features in processed data (exact raw dtype, raw dtype):\n",
      "\t\t\t\t('float64', 'float') : 36 | ['src_ip_bytes', 'proto_tcp', 'src_bytes', 'dst_ip_bytes', 'src_pkts', ...]\n",
      "\t\t\t\t('int8', 'int')      :  4 | ['dns_qtype_12', 'dns_rcode_2', 'service_gssapi', 'service_dce_rpc']\n",
      "\t\t\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t\t\t('float', [])     : 36 | ['src_ip_bytes', 'proto_tcp', 'src_bytes', 'dst_ip_bytes', 'src_pkts', ...]\n",
      "\t\t\t\t('int', ['bool']) :  4 | ['dns_qtype_12', 'dns_rcode_2', 'service_gssapi', 'service_dce_rpc']\n",
      "\t\t\t0.1s = Fit runtime\n",
      "\t\t\t40 features in original data used to generate 40 features in processed data.\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\t\t\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t\t\t('float', [])     : 36 | ['src_ip_bytes', 'proto_tcp', 'src_bytes', 'dst_ip_bytes', 'src_pkts', ...]\n",
      "\t\t\t\t('int', ['bool']) :  4 | ['dns_qtype_12', 'dns_rcode_2', 'service_gssapi', 'service_dce_rpc']\n",
      "\t\t\tTypes of features in processed data (exact raw dtype, raw dtype):\n",
      "\t\t\t\t('float64', 'float') : 36 | ['src_ip_bytes', 'proto_tcp', 'src_bytes', 'dst_ip_bytes', 'src_pkts', ...]\n",
      "\t\t\t\t('int8', 'int')      :  4 | ['dns_qtype_12', 'dns_rcode_2', 'service_gssapi', 'service_dce_rpc']\n",
      "\t\t\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t\t\t('float', [])     : 36 | ['src_ip_bytes', 'proto_tcp', 'src_bytes', 'dst_ip_bytes', 'src_pkts', ...]\n",
      "\t\t\t\t('int', ['bool']) :  4 | ['dns_qtype_12', 'dns_rcode_2', 'service_gssapi', 'service_dce_rpc']\n",
      "\t\t\t0.1s = Fit runtime\n",
      "\t\t\t40 features in original data used to generate 40 features in processed data.\n",
      "\t\tSkipping CategoryFeatureGenerator: No input feature with required dtypes.\n",
      "\t\tSkipping DatetimeFeatureGenerator: No input feature with required dtypes.\n",
      "\t\tSkipping TextSpecialFeatureGenerator: No input feature with required dtypes.\n",
      "\t\tSkipping TextNgramFeatureGenerator: No input feature with required dtypes.\n",
      "\t\tSkipping IdentityFeatureGenerator: No input feature with required dtypes.\n",
      "\t\tSkipping IsNanFeatureGenerator: No input feature with required dtypes.\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\t\t\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t\t\t('float', [])     : 36 | ['src_ip_bytes', 'proto_tcp', 'src_bytes', 'dst_ip_bytes', 'src_pkts', ...]\n",
      "\t\t\t\t('int', ['bool']) :  4 | ['dns_qtype_12', 'dns_rcode_2', 'service_gssapi', 'service_dce_rpc']\n",
      "\t\t\tTypes of features in processed data (exact raw dtype, raw dtype):\n",
      "\t\t\t\t('float64', 'float') : 36 | ['src_ip_bytes', 'proto_tcp', 'src_bytes', 'dst_ip_bytes', 'src_pkts', ...]\n",
      "\t\t\t\t('int8', 'int')      :  4 | ['dns_qtype_12', 'dns_rcode_2', 'service_gssapi', 'service_dce_rpc']\n",
      "\t\t\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t\t\t('float', [])     : 36 | ['src_ip_bytes', 'proto_tcp', 'src_bytes', 'dst_ip_bytes', 'src_pkts', ...]\n",
      "\t\t\t\t('int', ['bool']) :  4 | ['dns_qtype_12', 'dns_rcode_2', 'service_gssapi', 'service_dce_rpc']\n",
      "\t\t\t0.3s = Fit runtime\n",
      "\t\t\t40 features in original data used to generate 40 features in processed data.\n",
      "\tTypes of features in original data (exact raw dtype, raw dtype):\n",
      "\t\t('float64', 'float') : 40 | ['src_ip_bytes', 'proto_tcp', 'src_bytes', 'dst_ip_bytes', 'src_pkts', ...]\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('float', []) : 40 | ['src_ip_bytes', 'proto_tcp', 'src_bytes', 'dst_ip_bytes', 'src_pkts', ...]\n",
      "\tTypes of features in processed data (exact raw dtype, raw dtype):\n",
      "\t\t('float64', 'float') : 36 | ['src_ip_bytes', 'proto_tcp', 'src_bytes', 'dst_ip_bytes', 'src_pkts', ...]\n",
      "\t\t('int8', 'int')      :  4 | ['dns_qtype_12', 'dns_rcode_2', 'service_gssapi', 'service_dce_rpc']\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('float', [])     : 36 | ['src_ip_bytes', 'proto_tcp', 'src_bytes', 'dst_ip_bytes', 'src_pkts', ...]\n",
      "\t\t('int', ['bool']) :  4 | ['dns_qtype_12', 'dns_rcode_2', 'service_gssapi', 'service_dce_rpc']\n",
      "\t1.6s = Fit runtime\n",
      "\t40 features in original data used to generate 40 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 138.96 MB (1.5% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 1.88s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'roc_auc'\n",
      "\tThis metric expects predicted probabilities rather than predicted class labels, so you'll need to use predict_proba() instead of predict()\n",
      "\tTo change this, specify the eval_metric parameter of Predictor()\n",
      "Saving ./auto_gl/ToN-iot-oversample/deploy-exp/STACCKING2_1layer_search/learner.pkl\n",
      "Saving ./auto_gl/ToN-iot-oversample/deploy-exp/STACCKING2_1layer_search/utils/data/X.pkl\n",
      "Saving ./auto_gl/ToN-iot-oversample/deploy-exp/STACCKING2_1layer_search/utils/data/y.pkl\n",
      "Model configs that will be trained (in order):\n",
      "\tRandomForest_BAG_L1: \t{'ag_args': {'hyperparameter_tune_kwargs': {'num_trials': 50, 'scheduler': 'local', 'searcher': 'auto'}, 'model_type': <class 'autogluon.tabular.models.rf.rf_model.RFModel'>, 'priority': 80}, 'ag_args_fit': {'num_gpus': 1}, 'ag_args_ensemble': {'use_child_oof': True}}\n",
      "\tExtraTrees_BAG_L1: \t{'ag_args': {'hyperparameter_tune_kwargs': {'num_trials': 50, 'scheduler': 'local', 'searcher': 'auto'}, 'model_type': <class 'autogluon.tabular.models.xt.xt_model.XTModel'>, 'priority': 60}, 'ag_args_fit': {'num_gpus': 1}, 'ag_args_ensemble': {'use_child_oof': True}}\n",
      "Fitting 2 L1 models ...\n",
      "Hyperparameter tuning model: RandomForest_BAG_L1 ... Tuning model for up to 3239.83s of the 35998.12s of remaining time.\n",
      "\tDropped 0 of 40 features.\n",
      "\tDropped 0 of 40 features.\n",
      "\tDropped 0 of 40 features.\n",
      "Starting generic AbstractModel hyperparameter tuning for RandomForest model...\n",
      "\tNo hyperparameter search space specified for RandomForest. Skipping HPO. Will train one model based on the provided hyperparameters.\n",
      "\tFitting RandomForest with 'num_gpus': 1, 'num_cpus': 16\n",
      "Saving ./auto_gl/ToN-iot-oversample/deploy-exp/STACCKING2_1layer_search/models/RandomForest_BAG_L1/hpo/model.pkl\n",
      "Loading: ./auto_gl/ToN-iot-oversample/deploy-exp/STACCKING2_1layer_search/models/RandomForest_BAG_L1/hpo/model.pkl\n",
      "Saving ./auto_gl/ToN-iot-oversample/deploy-exp/STACCKING2_1layer_search/models/RandomForest_BAG_L1/T1/utils/model_template.pkl\n",
      "Saving ./auto_gl/ToN-iot-oversample/deploy-exp/STACCKING2_1layer_search/models/RandomForest_BAG_L1/T1/utils/oof.pkl\n",
      "Saving ./auto_gl/ToN-iot-oversample/deploy-exp/STACCKING2_1layer_search/models/RandomForest_BAG_L1/T1/model.pkl\n",
      "Loading: ./auto_gl/ToN-iot-oversample/deploy-exp/STACCKING2_1layer_search/models/RandomForest_BAG_L1/T1/model.pkl\n",
      "Fitted model: RandomForest_BAG_L1/T1 ...\n",
      "\t1.0\t = Validation score   (roc_auc)\n",
      "\t28.83s\t = Training   runtime\n",
      "\t8.6s\t = Validation runtime\n",
      "Saving ./auto_gl/ToN-iot-oversample/deploy-exp/STACCKING2_1layer_search/models/trainer.pkl\n",
      "Hyperparameter tuning model: ExtraTrees_BAG_L1 ... Tuning model for up to 3239.83s of the 35951.09s of remaining time.\n",
      "\tDropped 0 of 40 features.\n",
      "\tDropped 0 of 40 features.\n",
      "\tDropped 0 of 40 features.\n",
      "Starting generic AbstractModel hyperparameter tuning for ExtraTrees model...\n",
      "\tNo hyperparameter search space specified for ExtraTrees. Skipping HPO. Will train one model based on the provided hyperparameters.\n",
      "\tFitting ExtraTrees with 'num_gpus': 1, 'num_cpus': 16\n",
      "Saving ./auto_gl/ToN-iot-oversample/deploy-exp/STACCKING2_1layer_search/models/ExtraTrees_BAG_L1/hpo/model.pkl\n",
      "Loading: ./auto_gl/ToN-iot-oversample/deploy-exp/STACCKING2_1layer_search/models/ExtraTrees_BAG_L1/hpo/model.pkl\n",
      "Saving ./auto_gl/ToN-iot-oversample/deploy-exp/STACCKING2_1layer_search/models/ExtraTrees_BAG_L1/T1/utils/model_template.pkl\n",
      "Saving ./auto_gl/ToN-iot-oversample/deploy-exp/STACCKING2_1layer_search/models/ExtraTrees_BAG_L1/T1/utils/oof.pkl\n",
      "Saving ./auto_gl/ToN-iot-oversample/deploy-exp/STACCKING2_1layer_search/models/ExtraTrees_BAG_L1/T1/model.pkl\n",
      "Loading: ./auto_gl/ToN-iot-oversample/deploy-exp/STACCKING2_1layer_search/models/ExtraTrees_BAG_L1/T1/model.pkl\n",
      "Fitted model: ExtraTrees_BAG_L1/T1 ...\n",
      "\t1.0\t = Validation score   (roc_auc)\n",
      "\t37.93s\t = Training   runtime\n",
      "\t10.34s\t = Validation runtime\n",
      "Saving ./auto_gl/ToN-iot-oversample/deploy-exp/STACCKING2_1layer_search/models/trainer.pkl\n",
      "Loading: ./auto_gl/ToN-iot-oversample/deploy-exp/STACCKING2_1layer_search/models/RandomForest_BAG_L1/T1/model.pkl\n",
      "Fitting model: RandomForest_BAG_L1/T1 ... Training model for up to 35891.3s of the 35891.3s of remaining time.\n",
      "Loading: ./auto_gl/ToN-iot-oversample/deploy-exp/STACCKING2_1layer_search/models/RandomForest_BAG_L1/T1/utils/oof.pkl\n",
      "Saving ./auto_gl/ToN-iot-oversample/deploy-exp/STACCKING2_1layer_search/models/RandomForest_BAG_L1/T1/utils/oof.pkl\n",
      "Saving ./auto_gl/ToN-iot-oversample/deploy-exp/STACCKING2_1layer_search/models/RandomForest_BAG_L1/T1/model.pkl\n",
      "\t1.0\t = Validation score   (roc_auc)\n",
      "\t28.83s\t = Training   runtime\n",
      "\t8.6s\t = Validation runtime\n",
      "Saving ./auto_gl/ToN-iot-oversample/deploy-exp/STACCKING2_1layer_search/models/trainer.pkl\n",
      "Loading: ./auto_gl/ToN-iot-oversample/deploy-exp/STACCKING2_1layer_search/models/ExtraTrees_BAG_L1/T1/model.pkl\n",
      "Fitting model: ExtraTrees_BAG_L1/T1 ... Training model for up to 35891.23s of the 35891.23s of remaining time.\n",
      "Loading: ./auto_gl/ToN-iot-oversample/deploy-exp/STACCKING2_1layer_search/models/ExtraTrees_BAG_L1/T1/utils/oof.pkl\n",
      "Saving ./auto_gl/ToN-iot-oversample/deploy-exp/STACCKING2_1layer_search/models/ExtraTrees_BAG_L1/T1/utils/oof.pkl\n",
      "Saving ./auto_gl/ToN-iot-oversample/deploy-exp/STACCKING2_1layer_search/models/ExtraTrees_BAG_L1/T1/model.pkl\n",
      "\t1.0\t = Validation score   (roc_auc)\n",
      "\t37.93s\t = Training   runtime\n",
      "\t10.34s\t = Validation runtime\n",
      "Saving ./auto_gl/ToN-iot-oversample/deploy-exp/STACCKING2_1layer_search/models/trainer.pkl\n",
      "Loading: ./auto_gl/ToN-iot-oversample/deploy-exp/STACCKING2_1layer_search/models/RandomForest_BAG_L1/T1/utils/oof.pkl\n",
      "Loading: ./auto_gl/ToN-iot-oversample/deploy-exp/STACCKING2_1layer_search/models/ExtraTrees_BAG_L1/T1/utils/oof.pkl\n",
      "Model configs that will be trained (in order):\n",
      "\tWeightedEnsemble_L2: \t{'ag_args': {'valid_base': False, 'name_bag_suffix': '', 'model_type': <class 'autogluon.core.models.greedy_ensemble.greedy_weighted_ensemble_model.GreedyWeightedEnsembleModel'>, 'priority': 0}, 'ag_args_ensemble': {'save_bag_folds': True}}\n",
      "Fitting model: WeightedEnsemble_L2 ... Training model for up to 3599.81s of the 35890.99s of remaining time.\n",
      "\tDropped 0 of 2 features.\n",
      "\tDropped 0 of 2 features.\n",
      "Saving ./auto_gl/ToN-iot-oversample/deploy-exp/STACCKING2_1layer_search/models/WeightedEnsemble_L2/utils/model_template.pkl\n",
      "Loading: ./auto_gl/ToN-iot-oversample/deploy-exp/STACCKING2_1layer_search/models/WeightedEnsemble_L2/utils/model_template.pkl\n",
      "\tDropped 0 of 2 features.\n",
      "\tFitting S1F1 with 'num_gpus': 0, 'num_cpus': 16\n",
      "Ensemble size: 47\n",
      "Ensemble indices: [1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0]\n",
      "Ensemble weights: \n",
      "[0.72340426 0.27659574]\n",
      "\t0.64s\t= Estimated out-of-fold prediction time...\n",
      "Saving ./auto_gl/ToN-iot-oversample/deploy-exp/STACCKING2_1layer_search/models/WeightedEnsemble_L2/utils/oof.pkl\n",
      "Saving ./auto_gl/ToN-iot-oversample/deploy-exp/STACCKING2_1layer_search/models/WeightedEnsemble_L2/model.pkl\n",
      "\t1.0\t = Validation score   (roc_auc)\n",
      "\t13.72s\t = Training   runtime\n",
      "\t0.06s\t = Validation runtime\n",
      "Saving ./auto_gl/ToN-iot-oversample/deploy-exp/STACCKING2_1layer_search/models/trainer.pkl\n",
      "Saving ./auto_gl/ToN-iot-oversample/deploy-exp/STACCKING2_1layer_search/models/trainer.pkl\n",
      "Saving ./auto_gl/ToN-iot-oversample/deploy-exp/STACCKING2_1layer_search/models/trainer.pkl\n",
      "AutoGluon training complete, total runtime = 123.34s ... Best model: \"WeightedEnsemble_L2\"\n",
      "Loading: ./auto_gl/ToN-iot-oversample/deploy-exp/STACCKING2_1layer_search/models/trainer.pkl\n",
      "Saving ./auto_gl/ToN-iot-oversample/deploy-exp/STACCKING2_1layer_search/models/trainer.pkl\n",
      "Loading: ./auto_gl/ToN-iot-oversample/deploy-exp/STACCKING2_1layer_search/models/RandomForest_BAG_L1/T1/model.pkl\n",
      "Saving ./auto_gl/ToN-iot-oversample/deploy-exp/STACCKING2_1layer_search/models/RandomForest_BAG_L1/T1/model.pkl\n",
      "Loading: ./auto_gl/ToN-iot-oversample/deploy-exp/STACCKING2_1layer_search/models/ExtraTrees_BAG_L1/T1/model.pkl\n",
      "Saving ./auto_gl/ToN-iot-oversample/deploy-exp/STACCKING2_1layer_search/models/ExtraTrees_BAG_L1/T1/model.pkl\n",
      "Loading: ./auto_gl/ToN-iot-oversample/deploy-exp/STACCKING2_1layer_search/models/WeightedEnsemble_L2/model.pkl\n",
      "Saving ./auto_gl/ToN-iot-oversample/deploy-exp/STACCKING2_1layer_search/models/WeightedEnsemble_L2/model.pkl\n",
      "Saving ./auto_gl/ToN-iot-oversample/deploy-exp/STACCKING2_1layer_search/models/trainer.pkl\n",
      "Saving ./auto_gl/ToN-iot-oversample/deploy-exp/STACCKING2_1layer_search/models/trainer.pkl\n",
      "Saving ./auto_gl/ToN-iot-oversample/deploy-exp/STACCKING2_1layer_search/learner.pkl\n",
      "Saving ./auto_gl/ToN-iot-oversample/deploy-exp/STACCKING2_1layer_search/predictor.pkl\n",
      "Saving ./auto_gl/ToN-iot-oversample/deploy-exp/STACCKING2_1layer_search/__version__ with contents \"0.4.0\"\n",
      "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"./auto_gl/ToN-iot-oversample/deploy-exp/STACCKING2_1layer_search/\")\n"
     ]
    }
   ],
   "source": [
    "from loguru import logger\n",
    "from autogluon.tabular import TabularPredictor,TabularDataset\n",
    "# test_data = TabularDataset(\"./Data/split/test_data_big.csv\")\n",
    "train_data = TabularDataset(\"./Data/split/train_data_ToN_big_balance.csv\")\n",
    "save_path = './auto_gl/ToN-iot-oversample/deploy-exp/STACCKING2_1layer_search'\n",
    "log_path = save_path+'/log.log'\n",
    "label = 'label'\n",
    "logger.add(log_path)\n",
    "logger.log(1,TabularPredictor(label=label, eval_metric='roc_auc',path=save_path).fit(\n",
    "    train_data, num_bag_folds=5, num_bag_sets=1, num_stack_levels=0,\n",
    "    time_limit=time_limit, presets='optimize_for_deployment', hyperparameters=hyperparameters,\n",
    "    hyperparameter_tune_kwargs=hyperparameter_tune_kwargs, verbosity=4,\n",
    "    ag_args_fit={'num_gpus': 1},\n",
    "))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "File delimiter for ./Data/split/test_data_ToN_big_balance.csv inferred as ',' (comma). If this is incorrect, please manually load the data as a pandas DataFrame.\n",
      "Loaded data from: ./Data/split/test_data_ToN_big_balance.csv | Columns = 41 / 41 | Rows = 118971 -> 118971\n",
      "Loading: ./auto_gl/ToN-iot-oversample/deploy-exp/STACCKING2_1layer_search/predictor.pkl\n",
      "Loading: ./auto_gl/ToN-iot-oversample/deploy-exp/STACCKING2_1layer_search/learner.pkl\n",
      "Loading: ./auto_gl/ToN-iot-oversample/deploy-exp/STACCKING2_1layer_search/models/trainer.pkl\n",
      "Loading: ./auto_gl/ToN-iot-oversample/deploy-exp/STACCKING2_1layer_search/models/RandomForest_BAG_L1/T1/model.pkl\n",
      "Loading: ./auto_gl/ToN-iot-oversample/deploy-exp/STACCKING2_1layer_search/models/ExtraTrees_BAG_L1/T1/model.pkl\n",
      "Loading: ./auto_gl/ToN-iot-oversample/deploy-exp/STACCKING2_1layer_search/models/WeightedEnsemble_L2/model.pkl\n",
      "/media/wuguo-buaa/LENOVO_USB_HDD/PycharmProjects/Machine_learning_venv/lib/python3.8/site-packages/autogluon/core/utils/plots.py:138: UserWarning: AutoGluon summary plots cannot be created because bokeh is not installed. To see plots, please do: \"pip install bokeh==2.0.1\"\n",
      "  warnings.warn('AutoGluon summary plots cannot be created because bokeh is not installed. To see plots, please do: \"pip install bokeh==2.0.1\"')\n",
      "Loading: ./auto_gl/ToN-iot-oversample/deploy-exp/STACCKING2_1layer_search/models/WeightedEnsemble_L2/model.pkl\n",
      "Loading: ./auto_gl/ToN-iot-oversample/deploy-exp/STACCKING2_1layer_search/models/ExtraTrees_BAG_L1/T1/model.pkl\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** Summary of fit() ***\n",
      "Estimated performance of each model:\n",
      "                    model  score_val  pred_time_val   fit_time  pred_time_val_marginal  fit_time_marginal  stack_level  can_infer  fit_order\n",
      "0     WeightedEnsemble_L2   0.999963      18.998158  80.479070                0.063670          13.721038            2       True          3\n",
      "1    ExtraTrees_BAG_L1/T1   0.999961      10.336292  37.930839               10.336292          37.930839            1       True          2\n",
      "2  RandomForest_BAG_L1/T1   0.999955       8.598196  28.827193                8.598196          28.827193            1       True          1\n",
      "Number of models trained: 3\n",
      "Types of models trained:\n",
      "{'StackerEnsembleModel_RF', 'WeightedEnsembleModel', 'StackerEnsembleModel_XT'}\n",
      "Bagging used: True  (with 5 folds)\n",
      "Multi-layer stack-ensembling used: False \n",
      "Feature Metadata (Processed):\n",
      "(raw dtype, special dtypes):\n",
      "('float', [])     : 36 | ['src_ip_bytes', 'proto_tcp', 'src_bytes', 'dst_ip_bytes', 'src_pkts', ...]\n",
      "('int', ['bool']) :  4 | ['dns_qtype_12', 'dns_rcode_2', 'service_gssapi', 'service_dce_rpc']\n",
      "*** End of fit() summary ***\n",
      "{'model_types': {'RandomForest_BAG_L1/T1': 'StackerEnsembleModel_RF', 'ExtraTrees_BAG_L1/T1': 'StackerEnsembleModel_XT', 'WeightedEnsemble_L2': 'WeightedEnsembleModel'}, 'model_performance': {'RandomForest_BAG_L1/T1': 0.9999548488109352, 'ExtraTrees_BAG_L1/T1': 0.9999607937735604, 'WeightedEnsemble_L2': 0.9999631897712937}, 'model_best': 'WeightedEnsemble_L2', 'model_paths': {'RandomForest_BAG_L1/T1': './auto_gl/ToN-iot-oversample/deploy-exp/STACCKING2_1layer_search/models/RandomForest_BAG_L1/T1/', 'ExtraTrees_BAG_L1/T1': './auto_gl/ToN-iot-oversample/deploy-exp/STACCKING2_1layer_search/models/ExtraTrees_BAG_L1/T1/', 'WeightedEnsemble_L2': './auto_gl/ToN-iot-oversample/deploy-exp/STACCKING2_1layer_search/models/WeightedEnsemble_L2/'}, 'model_fit_times': {'RandomForest_BAG_L1/T1': 28.827192783355713, 'ExtraTrees_BAG_L1/T1': 37.93083930015564, 'WeightedEnsemble_L2': 13.72103762626648}, 'model_pred_times': {'RandomForest_BAG_L1/T1': 8.598195791244507, 'ExtraTrees_BAG_L1/T1': 10.336292028427124, 'WeightedEnsemble_L2': 0.06367039680480957}, 'num_bag_folds': 5, 'max_stack_level': 2, 'num_classes': 2, 'model_hyperparams': {'RandomForest_BAG_L1/T1': {'use_orig_features': True, 'max_base_models': 25, 'max_base_models_per_type': 5, 'save_bag_folds': True, 'use_child_oof': True}, 'ExtraTrees_BAG_L1/T1': {'use_orig_features': True, 'max_base_models': 25, 'max_base_models_per_type': 5, 'save_bag_folds': True, 'use_child_oof': True}, 'WeightedEnsemble_L2': {'use_orig_features': False, 'max_base_models': 25, 'max_base_models_per_type': 5, 'save_bag_folds': True}}, 'leaderboard':                     model  score_val  pred_time_val   fit_time  \\\n",
      "0     WeightedEnsemble_L2   0.999963      18.998158  80.479070   \n",
      "1    ExtraTrees_BAG_L1/T1   0.999961      10.336292  37.930839   \n",
      "2  RandomForest_BAG_L1/T1   0.999955       8.598196  28.827193   \n",
      "\n",
      "   pred_time_val_marginal  fit_time_marginal  stack_level  can_infer  \\\n",
      "0                0.063670          13.721038            2       True   \n",
      "1               10.336292          37.930839            1       True   \n",
      "2                8.598196          28.827193            1       True   \n",
      "\n",
      "   fit_order  \n",
      "0          3  \n",
      "1          2  \n",
      "2          1  }\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading: ./auto_gl/ToN-iot-oversample/deploy-exp/STACCKING2_1layer_search/models/RandomForest_BAG_L1/T1/model.pkl\n",
      "Evaluation: roc_auc on test data: 0.9999993816630051\n",
      "Evaluations on test data:\n",
      "{\n",
      "    \"roc_auc\": 0.9999993816630051,\n",
      "    \"accuracy\": 0.9996721890208539,\n",
      "    \"balanced_accuracy\": 0.9996721742858445,\n",
      "    \"mcc\": 0.9993443790728835,\n",
      "    \"f1\": 0.9996723872886267,\n",
      "    \"precision\": 0.9996471952018547,\n",
      "    \"recall\": 0.9996975806451613\n",
      "}\n",
      "Loading: ./auto_gl/ToN-iot-oversample/deploy-exp/STACCKING2_1layer_search/models/WeightedEnsemble_L2/model.pkl\n",
      "Loading: ./auto_gl/ToN-iot-oversample/deploy-exp/STACCKING2_1layer_search/models/ExtraTrees_BAG_L1/T1/model.pkl\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'roc_auc': 0.9999993816630051, 'accuracy': 0.9996721890208539, 'balanced_accuracy': 0.9996721742858445, 'mcc': 0.9993443790728835, 'f1': 0.9996723872886267, 'precision': 0.9996471952018547, 'recall': 0.9996975806451613}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading: ./auto_gl/ToN-iot-oversample/deploy-exp/STACCKING2_1layer_search/models/RandomForest_BAG_L1/T1/model.pkl\n"
     ]
    },
    {
     "data": {
      "text/plain": "9.409520857150029e-06"
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from autogluon.tabular import TabularPredictor, TabularDataset\n",
    "\n",
    "test_data = TabularDataset(\"./Data/split/test_data_ToN_big_balance.csv\")\n",
    "# save_path = './auto_gl//ToN-iot-oversample/deploy-exp/lgb_search'\n",
    "# save_path = './auto_gl/exp-iot23/medium-exp/medium-RF'\n",
    "predictor_tune = TabularPredictor.load(save_path)\n",
    "print(predictor_tune.fit_summary())\n",
    "perf = predictor_tune.evaluate(test_data, auxiliary_metrics=True)\n",
    "print(perf)\n",
    "import time\n",
    "\n",
    "t0 = time.time()\n",
    "predictor_tune.predict(test_data)\n",
    "t1 = time.time()\n",
    "# print(t0,t1)\n",
    "# perf = predictor_tune.evaluate(test_data, auxiliary_metrics=True)\n",
    "# print(perf)\n",
    "(t1-t0)/118971"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "These features in provided data are not utilized by the predictor and will be ignored: ['http_trans_depth_10', 'http_trans_depth_5', 'http_user_agent_Debian APT-HTTP/1.3 (1.6.6)', 'http_user_agent_Mozilla/4.08 [en] (WinNT; I ;Nav)', 'http_user_agent_Mozilla/5.0 (SMART-TV; Linux; Tizen 2.3) AppleWebkit/538.1 (KHTML; like Gecko) SamsungBrowser/1.0 Safari/538.1', 'http_user_agent_Mozilla/5.0 (Windows NT 6.1; rv:21.0) Gecko/20130401 Firefox/21.0', 'http_user_agent_Mozilla/5.0 (Windows NT 6.3; WOW64) AppleWebKit/537.36 (KHTML; like Gecko) Chrome/53.0.2785.143 Safari/537.36']\n"
     ]
    },
    {
     "data": {
      "text/plain": "               importance    stddev   p_value  n  p99_high   p99_low\nsrc_ip_bytes     0.031709  0.001510  0.000378  3  0.040362  0.023057\nproto_tcp        0.010496  0.000922  0.001281  3  0.015780  0.005212\nsrc_bytes        0.004465  0.000641  0.003398  3  0.008137  0.000793\ndst_ip_bytes     0.004044  0.000718  0.005172  3  0.008158 -0.000070\nsrc_pkts         0.001439  0.000256  0.005194  3  0.002905 -0.000028\n...                   ...       ...       ... ..       ...       ...\nconn_state_S3   -0.000026  0.000088  0.671171  3  0.000478 -0.000531\ndns_RD_T        -0.000041  0.000112  0.705264  3  0.000601 -0.000683\ndns_AA_F        -0.000042  0.000064  0.815161  3  0.000322 -0.000407\ndns_RA_T        -0.000066  0.000150  0.736224  3  0.000794 -0.000925\ndns_qtype_1     -0.000085  0.000161  0.772082  3  0.000839 -0.001010\n\n[180 rows x 6 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>importance</th>\n      <th>stddev</th>\n      <th>p_value</th>\n      <th>n</th>\n      <th>p99_high</th>\n      <th>p99_low</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>src_ip_bytes</th>\n      <td>0.031709</td>\n      <td>0.001510</td>\n      <td>0.000378</td>\n      <td>3</td>\n      <td>0.040362</td>\n      <td>0.023057</td>\n    </tr>\n    <tr>\n      <th>proto_tcp</th>\n      <td>0.010496</td>\n      <td>0.000922</td>\n      <td>0.001281</td>\n      <td>3</td>\n      <td>0.015780</td>\n      <td>0.005212</td>\n    </tr>\n    <tr>\n      <th>src_bytes</th>\n      <td>0.004465</td>\n      <td>0.000641</td>\n      <td>0.003398</td>\n      <td>3</td>\n      <td>0.008137</td>\n      <td>0.000793</td>\n    </tr>\n    <tr>\n      <th>dst_ip_bytes</th>\n      <td>0.004044</td>\n      <td>0.000718</td>\n      <td>0.005172</td>\n      <td>3</td>\n      <td>0.008158</td>\n      <td>-0.000070</td>\n    </tr>\n    <tr>\n      <th>src_pkts</th>\n      <td>0.001439</td>\n      <td>0.000256</td>\n      <td>0.005194</td>\n      <td>3</td>\n      <td>0.002905</td>\n      <td>-0.000028</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>conn_state_S3</th>\n      <td>-0.000026</td>\n      <td>0.000088</td>\n      <td>0.671171</td>\n      <td>3</td>\n      <td>0.000478</td>\n      <td>-0.000531</td>\n    </tr>\n    <tr>\n      <th>dns_RD_T</th>\n      <td>-0.000041</td>\n      <td>0.000112</td>\n      <td>0.705264</td>\n      <td>3</td>\n      <td>0.000601</td>\n      <td>-0.000683</td>\n    </tr>\n    <tr>\n      <th>dns_AA_F</th>\n      <td>-0.000042</td>\n      <td>0.000064</td>\n      <td>0.815161</td>\n      <td>3</td>\n      <td>0.000322</td>\n      <td>-0.000407</td>\n    </tr>\n    <tr>\n      <th>dns_RA_T</th>\n      <td>-0.000066</td>\n      <td>0.000150</td>\n      <td>0.736224</td>\n      <td>3</td>\n      <td>0.000794</td>\n      <td>-0.000925</td>\n    </tr>\n    <tr>\n      <th>dns_qtype_1</th>\n      <td>-0.000085</td>\n      <td>0.000161</td>\n      <td>0.772082</td>\n      <td>3</td>\n      <td>0.000839</td>\n      <td>-0.001010</td>\n    </tr>\n  </tbody>\n</table>\n<p>180 rows  6 columns</p>\n</div>"
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictor_tune.feature_importance(test_data)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "all_models = predictor_tune.get_model_names()\n",
    "model_to_use = all_models[0]\n",
    "specific_model = predictor_tune._trainer.load_model(model_to_use)\n",
    "\n",
    "# Objects defined below are dicts of various information (not printed here as they are quite large):\n",
    "model_info = specific_model.get_info()\n",
    "print(model_info)\n",
    "predictor_information = predictor_tune.info()\n",
    "print(predictor_information)\n",
    "perf = predictor_tune.evaluate(test_data, auxiliary_metrics=True)\n",
    "predictor_tune.features()\n",
    "predictor_tune.get_model_best()\n",
    "predictor_tune.leaderboard(extra_info=True, silent=True)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "predictor_tune.predict(test_data)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# only for test on Ton iot"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'roc_auc': 0.8922002299707488, 'accuracy': 0.9141217391304348, 'balanced_accuracy': 0.8725426853064666, 'mcc': 0.5213096976228496, 'f1': 0.9528758338343497, 'precision': 0.9889760503951982, 'recall': 0.9193183073693515}\n"
     ]
    }
   ],
   "source": [
    "from autogluon.tabular import TabularPredictor, TabularDataset\n",
    "\n",
    "test_data = TabularDataset(\"./Data/test/ToN-iot_test.csv\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'roc_auc': 0.8317768724566219, 'accuracy': 0.8151478260869566, 'balanced_accuracy': 0.6263240821319557, 'mcc': 0.152199572976604, 'f1': 0.8955144651862338, 'precision': 0.9605238185613969, 'recall': 0.8387470997679815}\n"
     ]
    }
   ],
   "source": [
    "save_path = './auto_gl/ToN-iot/deploy-exp/XT'\n",
    "predictor_tune = TabularPredictor.load(save_path)\n",
    "label = 'label'\n",
    "# print(predictor_tune.fit_summary())\n",
    "perf = predictor_tune.evaluate(test_data, auxiliary_metrics=True)\n",
    "print(perf)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}